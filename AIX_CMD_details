===================sysinfo=============================

Server Release info:-
	oslevel -r							<--
	oslevel -s

Server type:-
	prtconf								<--
	prtconf | grep -i 'System Model'

Hardware Info:-
	lscfg -v
	lscfg -l ent0
	lscfg -vl fcs0 (find the WWN of HBA adapter)

lsdev
	lsdev -Cc disk
	lsdev -Cc disk -p scsi0

	lsslot -c [pci|phb|port]
	lsslot -c pci -l ent0

	lspath -l hdisk0

	diag								<--Performs hardware problem determination.
	Menu driven program to run a wide choice of tasks and service aids (diagnostics, hardware error report, format, microcode and bootlist management,  ...).
	Diagnostics modes:
	Concurrent mode: diag is used during normal operation (only devices not in use can be tested).
	Single-user mode: run diag after shutdown -m.
	Stand-alone mode: boot from Diagnostics CD (press F5 when acoustic beep is heard)
	or boot and press F6 when acoustic beep is heard to load diag from hard disk.
	if diag returns "diag is not supported on this model" use:
	SMS mode: boot and press F1 when acoustic beep is heard, select "test the computer". Some older models use a SMS diskette.


Memory:-
	prtconf -m
	prtconf |grep -i memory
	lsattr -El sys0 -a realmem
	bootinfo -r

CPU (type, number, etc):-
	prtconf |grep -i processor

Disk Drives:-
	lsdev -Cc disk
	lsdev -Cc disk -p scsi0 (specific controller)
	lsdev -Cc disk -S [a|d|s] (available, defined, stopped)

	lscfg -v -l hdisk0

Kernel File and associated directories:-
	/unix

	/usr/lib/boot
	/usr/lib/drivers

	Note: /unix - symbolic link to kernel file i.e /usr/lib/boot/unix_64


Kernel 32 or 64:-
	prtconf -k
	bootinfo -K

Display Firmware:-
	prtconf |grep -i firmware
	lscfg -pv
	invscout

Display IRQ, IO ports and DMA:-
	prtconf
	
GUI admin tool:-
	smit
	smitty

===============Memory and Swap============================

Memory:-
	prtconf -m
	prtconf |grep -i memory
	lsattr -El sys0 -a realmem
	bootinfo -r

page size (memory):-
	pagesize
	pagesize -a (display all supported pagesizes)

display swap:-
	lsps -a (detailed)
	lsps -s

adding swap:-
	mkps -a -s 4 -n <volume group>

	# change the attributes
	chps -a n paging00 (don't use after restart)

	# change the logical volume attributes (name in this case)
	chlv -n <new name> <old old> (chang page space name)

	Note:

	-a reconfigure paging space after restart
	-s size of the page space (logical partitions)
	-n activiates the paging space (use swapoff to deactivate)

	also see /etc/swapspaces file

removing swap:-
	swapoff /dev/paging00
	rmps paging00

	Note: paging space must be deactiviated before removing.

=====================Disks, Filesystems and Devices==============

Disk Drives:-
lsdev -Cc disk
lsdev -Cc disk -p scsi0 (specific controller)
lsdev -Cc disk -S [a|d|s] (available, defined,stopped)

lscfg -v -l hdisk0

Disk serial Number, type, etc:-
lscfg -vl hdisk0
lscfg -vl hdisk*

Disk disk partitions:-
lsvg -l rootvg
lchangelv

cat /etc/filesystems

List Raw Partitions:-
Just create a new LVOL without a filesystem

# create a raw volume
mklv -y rawVolume vg01 10

Bad Blocks:-
chlv -b [y|n] <lv>

Note: enables bad block relocation

Filesystem commands:-
df -k
lsfs [<filesystem>]
lsfs -q <filesystem> (detailed)

Filesystem (create|remove):-
crfs -v jfs2 -d data02lv -m /data02 -A yes

-v filesystem type
-d device or logical volume
-m mountpoint
-A mount after restart [yes|no]

rmfs -ri /data02

-r remove the mountpoint
-i display warning before removing

chfs -a size=+1G /var (grow by additional 1GB)
chfs -a size=1G /var (grow to 1GB in size)

Tune Filesystems:-
chfs

Note: you can perform the following
resize
freeze
change mountpoint
permissions
lots more..............................

Force fsck:-


backup filesystem:-
backup|restore
tar
dd
cpio

Display the boot device:-
bootinfo -b (display last boot device)
bootlist -m [normal|service] -o (display bootable devices)

Setting the boot device:-
bootlist -m normal hdisk0 hdisk1

Creating boot device (MBR):-
bosboot -a (uses default device)
bosboot -ad hdisk1

Format floppy drive:-
format -d /dev/rfd0
format -d /dev/fd0.18 (high format)

mount/unmount floppy:-	
mount /dev/rfd0 /floppy
	
mount/unmount CDROM:-
mount -v cdrfs -r /dev/cd0 /cdrom
umount /cdrom
	
	
	
mount/umount ISO image:-	
	
	
	
	
remount a filesystem:-
	mount -o remount,rw <filesystem>
	
	Note:I did find a note that it should be possible to remount a jfs2 filesystem, but it did not work on my system
create boot disk or recovery tape:-
	mksysb
	
	
boot cdrom/diskette (single user):-	
	based on a 9114-275 workstation
	
	1. Restart the machine.
	2. Wait the the AIX splash screen to come up. Devices begin to initialize here.
	3. When you see the [keyboard] word on screen hit the F5 button or the 5 key depending on your console.
	4. Choose “default boot list ” when the maintenance screen comes up.
	
boot into maintenace mode:-	
	based on a 9114-275 workstation
	
	1. Restart the machine.
	2. Wait the the AIX splash screen to come up. Devices begin to initialize here.
	3. When you see the [keyboard] word on screen hit the F5 button or the 5 key depending on your console.
	4. Choose “select boot options ” when the maintenance screen comes up, then option 1, then option 1 for scsi, then option 3 service mode boot
	
Device paths:-
	floppy:
	/dev/fd0
	/dev/rfd0
	
	disk:
	/dev/hdisk0
	
	tape:
	
	cdrom:
	/dev/cd0
	
update /dev directory:-	
	cfgmgr
	cfgmgr -l scsi0
	
	mkdev
	
remove or change a device:-	
	rmdev
	rmdev -l cd0
	
	chdev
	chdev -l rmt0 -a ret=no
list device drivers:-
	lsdev
	lsdev -Cc disk
	lsdev -Cc disk -p scsi0
	
	lsslot -c pci -l ent0
	
	lscfg
	lscfg -l ent0
	lscfg -vl fcs0 (find the WWN of HBA adapter)
	
	lspath -l hdisk0
	
	getconf DISK_SIZE hdisk1 (detailed)
	
==============Networking==================================

Basic network information(hostname, ip address):-

	stores information in the ODM (Object Database Manager)
	
displaying network interfaces:-
	ifconfig -a

	entstat -d <interface>
	entstat -d ent0								<--Copious network statistics:
	
	lsdev -Cc if
	lsdev -Cc tcpip

	odmget -q "name=en0" CuAt

	lsattr -EHl en0

Configure network interface:-
	mktcpip (completely setup a network interface)
	rmtcpip (remove all network interfaces)

	# configure an interface
	mktcpip -h aix1 -a 192.168.1.200 -m 255.255.255.0 -i en1 -g 192.168.0.10

	-h - hostname assigned to interface
	-a - ip address
	-m - netmask
	-i - interface name
	-g - gateway ip address

	# remove an interface
	ifconfig en1 detach

	ifconfig (configures IP address)

	chdev (add aliases to network interface)

Starting and stopping a network interface:-
ifconfig en0 up
ifconfig en0 down
ifconfig en0 detach (remove)

Setting NIC speed:-
	chdev -l ent0 -a media_speed=1000_Full_Duplex -P
	chdev -l ent0 -a media_speed=Auto_Negotiation -P

	Note:
	entX - physical device
	enX - frame type run on entX

Change NIC parameters:-
	netstat -v
	entstat -d <interface>

	no -a
	no -o "ipforwarding=1"

Display NIC statistics:-
	netstat -i [-f inet]
	netstat -s
	entstat -d <interface>

display MAC address:-
	netstat -ia

Displaying network packets:-
	tcpdump -i <interface>
	iptrace -i <interface> <output file>
	ipreport (used with iptrace to view reports)

	Note: you must stop the iptrace by using "kill -15"

default router:-
	route add 0 <gateway IP address>

	Note: there is no file that holds the default router

display routing table:-
	netstat -rn
	netstat -r -f inet
	lsattr -EHl inet0 -a route

Test IPMP, Bonding:-
	smitty etherchannel (creates, deletes and tests)

	entstat -d ent0

change the hostname:-
	hostname <new hostname>
	chdev -l inet0 -a hostname=<hostname>

setup DNS:-
	/etc/resolv.conf

Name service switch file (DNS client):-
	/etc/netsvc.conf
	/etc/resolv.conf
	/etc/irs.conf (may not be there)

	chnamsv     (change name service)
	rmnamsv     (remove a name service)
	lsnamsv -C   (list name services)

Flush DNS cache:-
	netcdctrl -t dns -e hosts -f

Domain Name:-
	domainname <domainname>

Obtain IP Address routing:-
	route -n get <hostname>

Find Services on the network:-
	Boot (jumpstart) servers:
	rpcinfo -b bootparam 1

	NFS servers:
	rpcinfo -b mountd 1

	NIS servers/slaves:
	rpcinfo -b ypserv 1

=======================Crash Dump=======================

Crash Dump:-
	sysdumpdev -l (list dump destination)
	sysdumpdev -e (estimates dumpsize)
	sysdumpdev -L (info)

	sysdumpstart -p (start dump primary)
	sysdumpstart -s (start dump secondary)

	# set the dump device permanently
	sysdumpdev -p <dump device> -P

	# analyse dump file
	echo "stat\n status\n t -m" | crash /var/adm/ras/vmcore.0

===================Performance Monitoring and Diagnostics=========

CPU:-
	topas -P
	topas -L  (logical partitions)
	mpstat
	sar -c
	w          (load average)
	uptime   (load average)
	lparstat
	ps
	iostat -tT 1
	tprof
	curt

Memory:-
	topas
	vmstat
	sar -b
	svmon
	ps
	ipcs -a
	lockstat (version 4)
	rmss

Network:-

	[ent|tok|fddi|atm]stat
	netstat
	netpmon (trcstop to stop trace)

Disk:-
	topas -D   (disk)
	topas -F   (filesystem)
	iostat
	sar -D
	fcstat (fibre)
	lvmstat
	filemon (trcstop to stop)
	fileplace

	# disk stat history
	chdev -l sys0 -a iostat=true
	lsattr -HEl sys0 -a iostat

Application:-
	topas
	truss
	sar
	probevue
	tprof
	svmon -P <pid>

NFS:-
	nfsstat

Process:-


==================Kernel Modules and Parameters====================

display loaded modules:-
genkex

load modules:-

unload modules:-

set kernel parameters (tuning):-
	chdev -l sys0 -a <parameter>=<value>
	no -a          (network)
	vmo -a        (virtual memory)
	nfso -a        (NFS)
	ioo -a         (Input/Ouput) 
	raso -a        (reliability, availability, serviceability)
	schedo -a   (processor scheduler)

	vi /etc/security/limits
	cd /etc/tunables

	tunchange, tundefault, tunsave, tunrestore, tuncheck

	Note: most parameters are dynamically changed in AIX , for example memory segments are dynamically adjusted

display kernel parameters:-
	lsattr -EHl sys0

	Note: only a few kernel parameters can be changed

build kernel:-
	chdev -l sys0 -a <parameter>=<value>

	Note: most parameters are dynamically changed in AIX , for example memory segments are dynamically adjusted

interprocess communication:-
	ipcs -a

====================Services==============================

display services:-
	lssrc -a

start services:-
	startsrc -s <subsystem>
	startsrc -g <group>

stop services:-
	stopsrc -s <subsystem>
	stopsrc -g <group>

reload service:-
	refresh -s <subsystem>

restart service:-
	stopsrc -s <subsystem>
	startsrc -s <subsystem>

service status:-
	lssrc -a

service dependencies:-

service dependants:-

Service notifications:-

service logging, etc:-
	/var/adm/ras
	/etc/syslog.conf
	/etc/rc.tcpip

change service startup:-

Add a new service:-

========================Patching / Software===========================

display installed patches:-
instfix -ia

adding patch:-
instfix -k

removing patch:-
installp -r

instfix -i | grep ML
#instfix -ivk <APAR no.>						<--The specifix fixes can be checked using instfix command:
e.g #instfix -ivk IY56076

instfix -ciqk 4330-08_AIX_ML | grep ":-:"		<--Lists what filesets need to be installed for instfix to show "All filesets for 4330-08 were found". display installed packages:-
instfix -k "IX#####" -d /dev/rmt0.1				<--Installs the APAR and its prerequisites on the system.



lslpp -L all (all filesets)
lslpp -L <package> (single fileset)
lslpp -w <file> (file belongs)
lslpp -ha (history of filesets)

rpm -qa (all packages)
rpm -q (single package)
rpm -qf (file belongs)
rpm -qi <package> (very detailed)

oslevel -g (install packkages above os level)

whereis <filename>
which_fileset <filename>

adding package:-
installp -a
installp -c (cleanup after failed install)
installp -Xagqd /dev/rmt0.1 X11.base.rte		<--Installs Xwindows on the system.
installp -u										<--deletes an AIX lpp.


rpm -i

geninstall (generic installer: installp, RPM, etc)

removing packages:-
installp -u (commited packages)
installp -r (applied packages)

rpm -e <package>

geninstall -u <package>

verify package:-
lppchk -v

rpm -V <package>

List files in package:-
lslpp -f <fileset>

rpm -ql <package>

Other package commands:-

Package directory:-
/usr/lpp

/var/lib/rpm

List libraries required for binary program:-
ldd <file>


====================Accounts======================
display users:-
cat /etc/passwd
lsuser -f ALL   (detailed)

create a user:-
mkuser
useradd

remove a user:-
rmuser
userdel

modify a user:-
chuser -a
usermod
passwd -f
passwd -s
chfn <username>
chfn <username><shell>

change user password:-	
	passwd
	pwdadm
	pwdck -t ALL
	
create a group:-	
	mkgroup <group name>

remove a group:-	
	rmgroup <group name>

modify a goup:-	
	chgroup <attribute><group name>

password files:-	
	/etc/security/passwd
	
useful user commands:-	
	id
	whoami
	who
	w
	uptime (displays # of users logged in)
	finger
	
	# License information
	lslicense
	chlicense
	
	# Maximum number of processes for a user
	lsattr -D -l sys0 -a maxuproc
	chdev -l sys0 -a maxuproc=<number>
	
useful group commands:-	
	groups
	setgroups
	lsgroup ALL
	
Password Policy:-	
	
Password Aging:-	
	

====================NFS============================
NFS Daemons:-
	server: rpc.mountd, nfsd
	client: rpc.statd, rpc.lockd
NFS files:-
	/etc/exports
	/etc/xtab
	
List nfs clients that have a remote mount:-
	/etc/xtab
display nfs shares:-
	exportfs
	showmount -e localhost
create nfs share:-
	mknfsexp -d <directory>
	mknfsmnt
	shareall	
uncreate nfs share:-
	rmnfsexp  -d <directory> (unshares and removes from file)
	
	exportfs -u <filesystem>
	unshareall
	
start/change nfs daemons:-
	mknfs
	chnfs
	startsrc -s nfsd
	startsrc -s rpc.mountd
stop nfs daemons:-
	rmnfs
	stopsrc -s nfsd
	stopsrc -s rpc.mountd
nfs status:-
	lssrc -a |grep -i nfs
nfs reload:-
	exportfs -av
nfs performanace:-
	nfsstat
nfs Options:-
	nfso -a
	nfso -o <option>=<value>
	exportfs (display options)
solaris/redhat mount problems (nfs v3 to v4):-

====================NTP============================
Time daemons:-
xntpd

ntp setup:-
/etc/ntp.conf

startsrc -s xntpd
stopsrc -s xntpd

lslpp -L all|grep xntpd

ntp daemon options:-
startsrc -s xntpd -a "-x"

/etc/rc.tcpip

NTP Trace commands:-
ntpq -p
ntptrace
ntpdate

====================Log Files============================	
messages:-	
/var/adm/ras

syslog:-
	/var/adm/ras
	
mail:-
	/usr/spool/mqueue/syslog
	
cron:-
	/var/adm/cron/log
	
boot:-
	/var/adm/ras
	alog				<--Creates and maintains fixed-size log files.
	alog -o -t boot		<--view the boot log (the log that holds boot information).
	alog -o -t console
	alog -L				<--(list all the logs available)lists the logs defined in the alog database.
Error logging:-
	/usr/lib/errdemon -l			<--displays the path to the system error log file and error log size.(display attributes)
	/usr/lib/errdemon				<--starts the error logging daemon. (start error logging)
	/usr/lib/errstop 				<--(stop error logging)
	/usr/lib/errdemon -s 2000000    <--changes the maximum size of the error log file to 2 MB.
	errdemon
	
errpt:-					<--Generates a report of logged errors in the system error log.
	# use with above errorlog file
	errpt (summary errorlog report)
	errpt -a (detailed errorlog report)
	errpt -j <identifier> (single errorlog report)
	errpt -c > /dev/console					<--formats and displays each of the errors at logtime (concurrent error logging) on /dev/console.

errclear:-				<--Deletes entries from the system error log. Software and operator errors (older than 30 days) and hardware errors (older than 90 days) are removed using crontab.
	errclear (clears errorlog)
	errclear -d <class><days> (clears class errors)
	
errlogger:-
	Logs an operator message.
	errlogger new disk added on scsi1 adapter : logs "new disk added on scsi1 adapter" in the system error log.
	errlogger "message upto 230 chars"
	
errinstall:-
	Installs or replaces messages in the error logging message sets of the error log message catalog.

errupdate:-
	Updates the Error Record Template Repository (default file /var/adm/ras/errtmplt).
	
syslogd:-
	The syslogd daemon logs messages from kernel, daemons and system applications using /etc/syslog.conf.
	*.debug          errlog (add this line to to syslog.conf to redirect all syslog messages to the system error log).
	stopsrc -s syslogd : stops the syslogd daemon.
	startsrc -s syslogd : starts the syslogd daemon.
	refresh -s syslogd : refreshes the syslogd daemon.

====================Security============================
Checking the passwd file:-
	pwdck -t ALL
	usrck -t ALL
checking the group file:-
	grpck
console login (allow/deny):-
	# No reboot required
	/etc/security/user
	
	chsec -f /etc/security/user -s root
	
====================Misc============================
startup:-
	bootlist -m normal hdisk0 hdisk1
		
shutdown:-
	shutdown -F (fast shutdown)
	shutdown -Fr (fast shutdown and reboot)
		
Change run level:-
	init
	shutdown
	reboot
	telinit
	halt
	
	
init status:-
0	0 - reserved
1	1 - reserved
2	2 - multiuser mode with NFS
3	3 - user defined
4	4 - user defined
5	5 - user defined
6	6 - user defined
	7-9 - user defined
	
	# change default - change the initdefault line
	vi /etc/inittab
	
Startup options:-
	Based on 9114-275 workstation
	1. switch off the machine
	2. power on and enter the SMS menu
	Note: to enter the SMS menu press numeric 1 after the word keyboard but before the word speaker

startup scripts:-
	/etc/rc.d
	/etc/rc.d/init.d
	/etc/rc.d/rc2.d - rc9.d
	/etc/rc.* (config files for auto-starting)
	also uses the System Resource Controller
boot prompt commands:-
	Based on a 9114-275 workstation	
	1. switch off the machine	
	2. power on and enter the SMS menu	
	Note: to enter the SMS menu press numeric 1 after the word keyboard but before the word speaker
		
Boot process:-
	Phases:
	Read Only Storage (ROS): check the system board, perform POST, locate and load boot image, begin system initialization and execute phase 1 of the /etc/rc.boot script
	Base Device Configuration: start configuration manager to configue base devices
	System Boot: start init process phase 2, switch to hard-disk root filesystem, start other processes defined by /etc/inittab and execute phase 3 of the /etc/rc.boot script
	
Boot Environments (BE):-	
	
determine the run level:-
	who -r
	
obtain default run level:-
	/etc/inittab
list locale:-
	locale -a
start xwindows:-
	n/a
	
initialize system:-
	install_assist
	
Timezone:-
	/etc/environment
	/etc/profile
==========================================================	
alt_disk_install:-
	Installs an alternate disk with a mksysb install image or clones the currently running system to an alternate disk.
	Note: install bos.alt_disk_install fileset to use alt_disk_install.
	alt_disk_install -C hdisk2 : Clones the current rootvg to hdisk2.
	alt_disk_install -C -b update_all -l /dev/cd0 hdisk4 : Creates clone of the current rootvg on hdisk4, 
	installs a ML on the clone and changes the bootlist to hdisk4.
	alt_disk_install -X old_rootvg : Removes the original rootvg from the ODM, 
	after booting from the new alternate disk (you can still reboot from old_rootvg).

nimadm:-
	Performs Alternate Disk Migration (to a new version or release) of AIX using NIM resources.
	
	nimadm -c aix1 -s spot2 -l lpp2 -d "hdisk1 hdisk2" -Y : migrates totarget NIM client aix1, 
	using NIM SPOT resource spot2, the NIM lpp_source lpp2, and hdisk1 and hdisk2 target disks, 
	and agreeing to all required software license agreements for the software being installed (-Y).
	
	nim -o alt_disk_install -a source=rootvg -a disk='hdisk2' -a phase=12 holland : clones a rootvg on client holland to hdisk1, 
	but only run phase1 and phase2 (leaving the /alt_inst file systems mounted).

==========================================================




==========================================================


AIX UPDATE - COMMANDS
COMMANDS:

oslevel                             shows the actual BOS level
oslevel -r                          shows the TL level (or earlier ML)
oslevel -s                          shows what SP level installed
oslevel -sg 5300-09-01-0847         shows which fileset is greater than the given service pack (it is used with bos.rte.install)
oslevel -rl 5300-10                 shows which filesets are below the given TL level (TL level is from instfix -i | grep ML)
oslevel -sl 53-09-020849            shows which filesets are below the given servicepack (used after bos.rte.install has been updated)

------------------------------
bffcreate -ld <dir>                 shows info about the packages in a dir (I:install, U:updatte package)
bffcreate -c -d /bb1                it will change the bff name from U#### to normal fileset name in bb1 !!!overwrites original bff!!!
------------------------------

export INST_DEBUG=yes               setting up debug mode prior install/geninstall/nimadm operation, provides useful info of the failure

------------------------------

installp                            installs and maintainins LPP packages
        -a (apply)
        -c (commit)
        -p (preview)
        -g (apply prerequisites)
        -X (expand file systems, if needed)
        -Y (accept license agreements)
        -d (device or directory location of software)
        -q (quiet mode)

installp -apgXYd . bos.rte.install  preview install of given fileset from current (.) location
installp -agXYd /home/bb all        installs all fileset from given location
installp -aF -d /home/bb all        force install all filesets from given location

installp -s                         list of applied updates that can be committed or rejected
installp -c all                     commit all applied filesets

installp -C                         remove all files which were installed in failed state
installp -ld /dev/cd0               list what installable software is available on a device (cd rom)
installp -ld <file.bff>             lists what filesets are in the given bff file
installp -u <fileset>               removes a fileset (installp -ug <fileset> <--it will remove dependencies as well)
installp -upg X11*                  preview remove all X11 related software and prerequisistes

------------------------------

geninstall                          generic installer that installs software of various package formats: LPP, RPM etc.
           -I (use installp flags)
           -p (preview)
           -d (device or directory location of software)

geninstall -I "-acgXY" -p -d /home/bb all   preview install for all files in given location (using installp format)
geninstall -I "-acgXY" -d . bos.rte.install install a fileset from current (.) location (using installp format)

------------------------------

install_all_updates -pcYd .          preview of update
install_all_updates -cYd .           actually does the update
/var/adm/ras/install_all_updates.log here is the logfile of install_all_updates

------------------------------

instfix -i|grep ML (instfix -i|grep TL)    shows whether all filesets are installed
instfix -i | grep SP
instfix -icqk 5300-05_AIX_ML| grep ":-:"   shows missing software levels
instfix -ik IY24043                        shows if a fix (APAR) is installed on the system (instfix -ivk ... <--verbose mode)
instfix -k IY73748 -d /dev/cd0             install APAR iY733748 from /dev/cd0

------------------------------

lslpp -L                            displays info about all installed filesets or fileset updates
lslpp -L <fileset>                  displays info about that fileset
lslpp -h <fileset>                  shows the history of the fileset
lslpp -l | grep <fileset>           shows if it is installed or not
lslpp -lc| grep <fileset>           shows the state (Aplp., Comm., Broken..) in /etc/objrepos and in /usr/lib/objrepos of a fileset

lslpp -f <fileset>                  shows all files that are installed with  a particular fileset
lslpp -w /usr/local/bin/lsof        shows the fileset which contains the given file (binary) (which command shows full path: which lsof)

lslpp -p <fileset>                  shows requisite information for a specified fileset (-p means possibly prerequisite)
lslpp -d <fileset>                  shows filesets that are dependents on the specified fileset

------------------------------

lppchk -v                           verify the installed software is in consistent state
lppchk -v -m3                       if lppchk -v gives an error, with this we can get more info about it
lppchk -c -m3                       makes a checksum on the filesets as well
------------------------------

smitty install                      software installation and maintenance menu
smitty update_all                   update installed software to latest level
smitty remove                       removing installed software
smitty reject                       removes applied filesets
smitty commit                       commits softwares
smitty software_maintain            many functions like reject, commit...

------------------------------

restore -Tqvf EMCpower_install      show which files will be changed by the fileset
/usr/lpp/PackageName                here are the previous version of the updates which are in applied state (not commited yet)       
inutoc <path>                       creates a .toc file in the given path
ldd /root/gzip                      lists the path names of all dependencies (lists dynamic dependencies)
which_fileset <command>             searches the /usr/lpp/bos/AIX_file_list file for a specified file name or command
/usr/lib/instl/lppmgr -d /nim/5304 -rub    the directory will be checked and all duplicate filesets will be removed
                                    (-r: remove, -u:check update filesets, -b: check base level filesets)
multibos                             http://www.ibmsystemsmag.com/aix/aprilmay08/tipstechniques/20226p1.aspx
---------------------------------------------------------------------

INSTFIX CORRECTION:

1. instfix -i | grep ML
    All filesets for 5.3.0.0_AIX_ML were found.
    All filesets for 5300-01_AIX_ML were found.
    All filesets for 5300-04_AIX_ML were found.
    Not all filesets for 5300-05_AIX_ML were found.
    ...
2. instfix -vick 5300-05_AIX_ML | grep :-:
   (instfix -icqk 5300-05_AIX_ML | grep ":-:"                         <--this command was used in the NIM redbook)

5300-05_AIX_ML:X11.adt.motif:5.3.0.50:5.3.0.0:-:AIX 5300-05 Update    <-- shows what is missing

3.lslpp -L X11.adt.motif                                              <-- shows if it is installed and what is the current version
  Fileset                      Level  State  Type  Description (Uninstaller)
  ----------------------------------------------------------------------------
  X11.adt.motif              5.3.0.0    C     F    AIXwindows Application
                                                   Development Toolkit Motif


4. if we have found it in a dir: installp -l -d .
  Fileset Name                Level                     I/U Q Content
  ====================================================================
  X11.adt.motif               5.3.0.50                   S  N usr     <--shows if reboot needed after install (N= not affected, no reboot)
                                                                     (Y and B: it affects the currently running programs)
                                                                     (B and b: causes bosboot to occur + reboot is needed)

5. smitty update_all (or smitty install)


6. now it is OK: instfix -i | grep ML
    All filesets for 5.3.0.0_AIX_ML were found.
    All filesets for 5300-01_AIX_ML were found.
    All filesets for 5300-04_AIX_ML were found.
    All filesets for 5300-05_AIX_ML were found.
---------------------------------------------------------------------

FIXING FILESETS in ODM:

lppchk -v shows problems with a fileset and you don't want to remove it:

devices.common.IBM.iscsi.rte 5.2.0.0    (not installed; requisite fileset)

1. save ODM
   tar -cvf /tmp/odm.etc.tar /etc/objrepos
   tar -cvf /tmp/odm.usr.lib.tar /usr/lib/objrepos


2. check lpp_id
   odmget -q name=devices.common.IBM.iscsi.rte lpp
   output will show lpp_id:
    ...
    lpp_id = 355

3. delete from ODM
   odmdelete -q name=devices.common.IBM.iscsi.rte -o lpp
   odmdelete -q lpp_name=devices.common.IBM.iscsi.rte -o product
   odmdelete -q lpp_id="355" -o history
   odmdelete -q lpp_id="355" -o inventory

4. reinstall base fileset with force flag (then update)
   installp -aF -d /home/bb/bb1 all

----------------
UPDATE - IFIX

IFIX:

An interim fix, or ifix (previously called an emergency fix or efix) is a code update to resolve a specific known problem, or APAR, while an official PTF is undergoing the formal development process.

An APAR is an Authorized Problem Analysis Report. IBM acknowledges that there is some sort of defect in a software program. This report sums up the problem and instructs the software lab to fix it. (IXnnnnn or IYnnnnn number - and not long ago IZnnnnn)

A PTF is a Program Temporary Fix and provides a solution for a problem. (Unnnnnn number for AIX) I guess the U is for UNIX).

Most people use PTF and APAR interchangably. PTF's have the word temporary in them but really are not temporary, they are just a patch.
A temporary patch would be an efix (ifix) that you would get directly from IBM. Ifixes need to be uninstalled before a TL update (as these ifixes should be contained in the new TL level). The terminology is confusing but just think of both PTF's and APAR's as patches. There could be some sort of technical difference between the two but it doesn't really matter.

Starting in AIX 5.3 TL 10 and AIX 6.1 TL 3, the installp command will automatically remove an ifix from the system if you are installing the Technology Level, Service Pack, or PTF that provides the official fix for the problem.

more info: http://www-304.ibm.com/support/docview.wss?uid=isg3T1012104

install:
emgr -de /mnt/IZ12345.epkg.Z    displays some info about an ifix package (-e: e(i)fix package name; emgr -dv3 -e <ifix>: verbose output)
emgr -pe /mnt/IZ12345.epkg.Z    preview of the install of given ifix package
emgr -e /mnt/IZ12345.epkg.Z     installs the specified ifix (the ifix package should be in compressed state)

listing:
emgr -l                         lists interim fixes (emgr -lv3: verbose mode listing)
emgr -l -L IZ12345              you can list information about a specific installed ifix by running the command (v3 (verbose) can be used)
emgr -c -L ifix_label           an ifix can be verified by running the command (if -L <ifix> is omitted all installed ifixes are checked)

removal:
emgr -r -L iy77276              removes the given interim fix
emgr -r -n 1                    removes the specified interim fix with the given ID (ID can be obtained: emgr -lv3)
emgr -r -u VUID                 removes the specified interim fix with the given VUID (VUID can be obtained: emgr -lv3)

You can also specify different levels of verbosity by using the -v flag. Level 1 is the default and level 3 is the maximum.
(I usually use v3.)

------------------------------

Concurrent ifix

A concurrent ifix is initially installed to memory, then is optionally committed to disk, either at the time of installation, or at a later time. A concurrent ifix that is installed only in memory will not be loaded when the system reboots. Concurrent ifixes may also be installed in the traditional manner.

A concurrent ifix:
-a feature introduced in AIX 6.1, may be available for ifixes which fix a problem in the kernel, or certain kernel extensions.
-it can update the kernel or kernel extension in memory, without requiring a reboot.
-it is initially installed to memory, then is optionally committed to disk, either at the time of installation, or at a later time.
-if it is installed only in memory will not be loaded when the system reboots.

emgr -i IZ12345.epkg.Z          installs a concurrent ifix in memory only (the ifix will not be loaded when the system reboots)
emgr -C -L IZ12345              commits a fix that is only installed in memory to disk, allowing it to be loaded when the system reboots
emgr -Ci IZ12345.epkg.Z         installs an ifix in memory and commit it to disk in a single operation

------------------------------

ifix states

S = Stable                      ifix was successfully installed in the traditional way (using the -e flag)
Q = Reboot Required             ifix was installed successfully, but a reboot is required. After reboot it will be moved to the S state
P = Patched                     concurrent ifix has been installed only to memory. A reboot will clear the ifix from memory.
N = Not Patched                 concurrent ifix is not loaded in memory (conc. ifix is installed only in memory, then system was rebooted)
SP = Stable + Patched           concurrent ifix has been installed in memory and committed to disk
QP = Reboot Required + Patched  concurrent ifix was installed to memory and committed to disk, but the system has not been rebooted
B = Broken                      something has gone wrong with the installation or removal of the ifix and should be corrected

===========================================================================================================================================>

Rootvg backup (mksysb)

The mksysb command creates a backup of the rootvg, which can be used to reinstall the system or restore it to another system. 
It backs up only the rootvg and only those filesystems which are mounted (nfs mounted filesystems are not being backed up.) 
The created backup file can be restored from NIM server or the mksysb file can be converted to bootable DVD images using mkdvd command.

/image.data

The image. data file contains information describing the image installed during the BOS installation process. 
This information includes the sizes, names, maps, and mount points of logical volumes and file systems in the root volume group. 
The mkszfile command generates the image.

# cat /image.data
========================================================================================================================================
/etc/exclude.rootvg

It is also possible to exclude some files, directories from the backup.
In this case we need to create /etc/exclude.rootvg file with the list of excluded directories, files.
If mksysb command is started with -e flag then /etc/exclude.rootvg file will be applied during mksysb creation.
for example:
^./tmp/    it will backup /tmp, but not the content of it (at restore an empty /tmp will be created)

# cat /etc/exclude.rootvg
^./tmp/
^./opt/jenkins/

==========================================================================================================================================
mksysb -i /mnt/aixserv.mksysb                creating an mksysb to the given location (usually to an NFS mount)
mksysb -ie /mnt/aixserv.mksysb               creating mksysb using exclude file

lsmksysb -lf /mnt/my_mksysb                  list header of the mksysb (VG, size, oslevel, lv info)
lsmksysb -f /mnt/my_mksysb                   list all the files in the mksysb
lsmksysb -f /mnt/my_mksysb –r ./etc/filesystems     restores /etc/filesystem file

The restorevgfiles and listvgbackup -r commands perform identical operations and should be considered interchangeable
listvgbackup -f /mnt/aix11.mksysb -r /etc/resolv.conf    restores the file /etc/resolv.conf from the specified backup

==========================================================================================================================================
Full mksysb backup to 1 single large ISO image

If we want to have a bootable ISO image of an LPAR, and we need that in 1 large ISO file, unfortunately it is not so easy to accomplish. With mkdvd it is possible to create mksysb images in DVD format, but the maximum size of a volume is 4.7GB. There is no way to avoid this cutting of larger mksysb file into DVD sized volumes.

A workaround for this, if on VIO server we create and assign a virtual optical device to the LPAR, and on LPAR side we do mksysb directly to /dev/cd0!!!!
(This method by default uses UDF type, so there is no limitation on DVD size (4.7GB), it can be for example 20GB or more.)


1.  df -tk `lsvgfs rootvg` | awk '{total+=$3} END {printf "Estimated mksysb size: %d bytes, %.2f GB\n", total*1024, total/1024/1024}' 
                                                      on VIO client estimate size of mksysb

2.  mkvdev -fbo -vadapter vhostX                      on VIOS create vtopt device
3.  mkvopt -name aixserv_mksysb.udf -size 10G         create ISO file with the size estimated before
4.  loadopt -vtd vtoptX -disk aixserv_mksysb.udf      load ISO file to the vtopt device

5.  vi /etc/exclude.rootvg: ^./opt/jenkins/           on VIO client update /etc/exclude.rootvg with necessary entries
6.  cfgmgr                                            bring up cd device on VIO client (which was assigned previously from VIOS, lsdev will show)
7.  mksysb -ie /dev/cd0                               start backup directly to /dev/cd0
8.  rmdev -dl cd0                                     delete cd0

9.  unloadopt -vtd vtoptX                             on VIOS unload iso image
10. rmvdev -vtd vtopt                                 remove vtopt
11. mv /var/vio/VMLibrary/aixserv_mksysb.udf /mnt     save ISO to NFS mount

==========================================================================================================================================
mkdvd

The mkdvd command creates multi-volume DVDs from different backup formats: mksysb, savevg, savewpar. For example regarding mksysb, it can create an mksysb image from the rootvg and then convert it to bootable DVD images or it can use a previously created mksysb image which will be converted to DVD images. The same way it can also create multi-volume DVDs from a savevg, or savewpar backup image. By default the created DVD images can be used to boot up an LPAR and then restore its content (similar to an mksysb restore). Each created volume has a maximum size of 4.7GB, so if an mksysb is greater than this size, it will be cut into multiple volumes.

-m mksysbimage    Specifies the location of a previously created mksysb image which should be converted to DVD image
-M mksysbtarget   If you do not specify the -m flag, the mkdvd command calls mksysb, and the created backup is stored in this location
                  if no location is specified /mkcd/mksysbimage filesystem is created, where the mksysb is temporarily stored.
-S                Stops the mkdvd command before it burns the DVD images, without removing the image files.
                  (by default mkdvd removes the images, but in this case the images remain in the directory marked by the -I flag, or in the /mkcd/cd_images directory.)


mkdvd -S -M /mnt -I /mnt                                          create mksysb backup in bootable ISO image format
                                                                  (-R should be the same as -S, -e exclude file could be used)
mkdvd -R -S -m /mnt/aixserv2/aixserv2.mksysb -I /mnt/aixserv2     create ISO image from the specified mksysb file

==========================================================================================================================================
device /dev/cd0 does not appear to be ready

root@aix-mgmt:/mgmt # mkdvd -m /mgmt/mksysb_5439724 -U -d /dev/cd0
Initializing mkdvd log: /var/adm/ras/mkcd.log...
Verifying command parameters...
0512-332 mkdvd: Device /dev/cd0 does not appear to be ready.  For
information about possible causes, see /usr/lpp/bos.sysmgt/mkcd.README.txt
  Continuing...
The device is not ready for operation.
check_cd_ready[41]: /dev/cd0: 0403-016 Cannot find or open the file.
0512-399 mkdvd: Unable to create UDF media.
Cleaning up...


Solution:
loadopt was missing on VIO, so we tried to "burn cd" when the "cd tray" was empty.

==========================================================================================================================================
0512-399 mkdvd: Unable to create UDF media

mkdvd -m /home/labuser/mksysb_5439724 -U -d /dev/cd0
Initializing mkdvd log: /var/adm/ras/mkcd.log...
Verifying command parameters...
0512-399 mkdvd: Unable to create UDF media.
Cleaning up...

Solution was below udfcreate command, after it was successful:
# udfcreate -d /dev/cd0

==========================================================================================================================================
/usr/sbin/bosboot[6]: dirname:  not found

root@ls-aix-test: / # mkdvd -m /home/labuser/mksysb_5439724 -U -d /dev/cd0
Initializing mkdvd log: /var/adm/ras/mkcd.log...
Verifying command parameters...
Populating the CD or DVD file system...
Building chrp boot image...
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/usr/sbin/bosboot[6]: dirname:  not found
/tmp/bosboot_14024764_15499/usr/lib/drivers/cfs.ext: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/planar_pal_chrp: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/pci/sisraid_dd: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/udfs.ext: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/scdisk: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/vdev_busdd: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/vscsi_initdd: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/scsidiskpin: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/scsidisk: No such file or directory
/tmp/bosboot_14024764_15499/usr/lib/drivers/scdiskpin: No such file or directory
Filesystem Helper: Implementation-specific error, code =  (112)


Detailed Solution is at this link:
https://www.ibm.com/developerworks/community/forums/html/topic?id=d06862fa-1566-4c34-9575-d74147c4d904

In general the "coreutils" rpm package overwrites the AIX "dirname" command,

2 steps will be needed:
- install latest coreutils (in newer coreutils this bug has been fixed, but it does not help on the current overwritten system) 
- from another AIX (same oslevel) where no coreutils is installed copy over dirname binary from /usr/bin/dirname

----------------------------------------

devices.scsi.disk.diag.com

Cannot find file system or does not match filter: ramdisk0
Populating the CD or DVD file system...
0512-323 mkdvd: The following files are required for the
creation of the CD or DVD image and are not available on the source system:
/usr/lpp/diagnostics/bin/uformat        devices.scsi.disk.diag.com

The files can be installed from the listed filesets.
0512-321 mkdvd: Error populating the CD or DVD file system
using the /usr/lpp/bosinst/cdfs.required.list proto file.
Cleaning up...


Solution was to install devices.scsi.disk.diag from below fileset (the other is a requirement):

-rw-r--r--    1 root     system         2651 Oct 14 07:31 .toc
-rw-r--r--    1 root     system      3171328 Oct 14 07:30 devices.pci.14107802
-rw-r--r--    1 root     system      1426432 Oct 14 07:30 devices.scsi.disk


# installp -apgXYd . devices.scsi.disk

----------------------------------------

Earlier general idea was to convert mksysb to UDF (DVD) format, which has no 4.7 GB max. limit. <<<< unfortunately this does not work. mkdvd always cut an image to pieces
After we have this image we can load it on VIO server and boot+restore from there

Backup:

1. Take a normal mksysb on nfs-share
- mount nfs share
- mksysb -i /mnt/ls-aix-j11b720.mksysb

2. On VIOVirtual optical device has been assigned to aix-mgmt
- (if needed on VIO create virt opt. dev (vtopt) to aix-mgmt) mkvdev -fbo -vadapter vhost1
- (on VIO create image file where mksysb will be written) mkvopt -name jdk_iso -size 60G
- load virt opt file: loadopt -disk jdk_iso -vtd vtopt0

3. on aix mgmt convert/copy mksys to UDF file format for /dev/cd0
- mkdvd -U… will used UDF format: mkdvd -m /home/labuser/mksysb_5439724 -U -d /dev/cd0


----------------------------------------

Volume Group Backup (savevg, restvg)


savevg -f /bckfs/backup.0725 bckvg             backs up all files belonging to bckvg to the specified file
restvg -f /bckfs/backup.0725                   restores the vg and all the files what have been saved with savevg
                                               (it creates the vg, lv, fs...)

----------------------------------------

Filesystem backup (bckfs)

find /bckfs -print | backup -i -f /dev/rmt0    backup all the files and subdirs
                                               find: genereates a list of all the files
                                               -i: files will be read from standard input

restore                                        extracts files from archives created with the backup command.

JFS2 snapshot:
creates a point in time image, it is very quick and very small

----------------------------------------

1. To confirm which network adapter is plugged into the switch in IBM AIX
This will not only tell you where you have a connection but it will also tell you what speed the port on the switch is. 

# netstat -v |grep -E "ETHERMedia"
ETHERNET STATISTICS (ent0) :
Media Speed Selected: 100 Mbps Full Duplex
Media Speed Running: 100 Mbps Full Duplex
ETHERNET STATISTICS (ent1) :
Media Speed Selected: 1000 Mbps Full Duplex
Media Speed Running: 1000 Mbps Full Duplex

----------------------------------------------------------------------------------------------------------------

2. How to determine if IBM AIX 64 bit kernel (sotware) is installed on your IBM AIX server?

# lslpp -l bos.64bit 
bos.64bit 4.3.3.76 COMMITTED Base Operating System 64 bit

----------------------------------------------------------------------------------------------------------------

3. How you create a snapshot of your IBM AIX server to send to IBM for tech support ?

This is requried whenver you face issues with your server and you seek help from IBM to sort out the issue.

# snap -gc

This will create a file called snap.pax.Z in the directory /tmp/ibmsupt. Send this file to IBM so that they will get full configuration of your server.

----------------------------------------------------------------------------------------------------------------

4. How to enable entended history in AIX 5.3 ?

In AIX 5.3, you have the capability to have a time stamped history. To enable it, just set the following variable:
EXTENDED_HISTORY=ON

Example:
export EXTENDED_HISTORY=ON

If required add this line to your .profile.
----------------------------------------------------------------------------------------------------------------

5. How to find the microcode level of tape drives ? 

To find microcode level (firmware) of tape drives in IBM AIX:
# tapeutil -f /dev/rmt1 vpd

---------------------------------------------------------------------------------------------------------------- 
6. pgrep and pkill - how to terminate processes ?

You can use the pgrep and pkill commands to identify and stop command processes that you no longer want to run. These commands are useful when you mistakenly start a process that takes a long time to run.

To terminate a process:
a. pgrep - to find out the PID(s) for the process(es)
b. pkill - followed by the PID(s)

The following example illustrates how to find all the processes with a specific name (xterm) and terminate the xterm process that was started last.
# pgrep xterm 17818 17828 17758 18210
# pkill -n 18210

Note: If you need to forcibly terminate a process, use the -9 option to the pkill command. 

For Example
# kill -9 -n xterm

----------------------------------------------------------------------------------------------------------------
7. How to modify Asynchronous I/O variables in AIX ? 

To modify the minservers asynchronous I/O variable (MINIMUM number of servers) in IBM AIX:
# chdev -l aio0 -a minservers='1'

To modify the maxservers asynchronous I/O variable (MAXIMUM number of servers per cpu) in IBM AIX 5L:
# chdev -l aio0 -a maxservers='10'

To modify the maxservers asynchronous I/O variable (MAXIMUM number of servers) in IBM AIX v4.3:
# chdev -l aio0 -a maxservers='80'

To modify the requests asynchronous I/O variable (Maximum number of REQUESTS) in IBM AIX:
# chdev -l aio0 -a requests='4096'

Notes:
1) Valeus will only take effect after a reboot
2) You may use multiple -a options on the same command line3) 

The maxservers variable is PER CPU for AIX 5L and TOTAL for AIX v4.3

----------------------------------------------------------------------------------------------------------------
8. How to display microcode and firmware levels of the system and adapters in IBM AIX ? 

To displays microcode level information for all supported devices in IBM AIX :

# lsmcode -A
sys0!system:SF240_284 (t) SF240_261 (p) SF240_284 (t)
ent0!14108902.DV0210
ent1!14108902.DV0210
ent2!14108902.DV0210
ent3!14108902.DV0210
sisscsia0!44415254.05080064
sisscsia1!44415255.050A0064
hdisk0!ST37320.4A553042.43373038
hdisk1!ST37320.4A553042.43373038 

----------------------------------------------------------------------------------------------------------------
9. How to determine if simultaneous multi-threading (SMT) is enabled in AIX ?

Your system is capable of SMT if it's a POWER5-based system running AIX 5L Version 5.3.To determine if it is enabled:# smtctl

To enable SMT: # smtctl -m on [ -w boot now]
To disable SMT: # smtctl -m off [ -w boot now]

Note: If neither the -w boot or the -w now options are specified, then the mode change is made immediately. It persists across subsequent reboots if you run the bosboot command before the next system reboot.

----------------------------------------------------------------------------------------------------------------
10. How to find top users of memory space in IBM AIX ?

To list the top ten users of paging space in IBM AIX:
# svmon -Pgt 10

To list the top ten users of realmem in IBM AIX:
# svmon -Put 10

----------------------------------------------------------------------------------------------------------------
11. How to list the filesystems in a volume group in IBM AIX ?

# lsvgfs volume_group

----------------------------------------------------------------------------------------------------------------
12. How to query the volume group descriptor area on a drive in IBM AIX ?

To query the volume group descriptor area on the drive, so you can find out if there's a VG on the disk, even if there isn't anything imported on the drive in IBM AIX:

# lqueryvg -Atp hdisk#

----------------------------------------------------------------------------------------------------------------
13. How to set IBM AIX for full core dumps and files to unlimited

To set IBM AIX for full core dumps to unlimited:
# ulimit -c unlimited

To set IBM AIX for files to unlimited:
# ulimit -f unlimited

To view your ulimit settings:
# ulimit –a

----------------------------------------------------------------------------------------------------------------
14. How to determine what the speed and duplex is of an interface in AIX ?

# entstat -d en0 grep "Media Speed" 

------------------------------------------------------------------------------------------------
15. How to find the highest technology level and service pack installed in IBM AIX ?

Starting in 2006, in IBM AIX, a Maintenance Level will be referred to as a Technology Level and will only be released twice per year.

The Service Pack concept will allow service-only updates (as known as PTF’s) that are released between Technology Levels to be grouped together for easier identification.
Sample output for a V5.3 system, with Technology Level 4, and Service Pack 2 installed would be:

# oslevel –s
----------------------------------------------------------------------------------------------------------------
16. How to find number of active processors in IBM AIX ?

To find the number of active processors in IBM AIX:
# bindprocessor -q 
The available processors are: 0 1 2

To find the number of processors installed (but not necessarily available):

# lscfg -v grep proc
proc0 00-00 Processor
proc2 00-02 Processor
proc4 00-04 Processor
----------------------------------------------------------------------------------------------------------------
17. How to read the contents of /etc/security/failedlogin in IBM AIX ?
# who /etc/security/failedlogin# /usr/sbin/acct/fwtmp < /etc/security/failedlogin

---------------------------------------------------------------------------------------------------------------- 

18. How to reserve or lock a terminal under AIX 5L ? 

This command will lock your terminal and reserve it for later use in AIX 5L

# lock
# lock -30 (lock for 30 minutes) 

Note: default lock time is 15 mintes lock will ask you for a password twice then lock the terminal. you can unlock it by entering the password a third time. 

---------------------------------------------------------------------------------------------------------------- 

19. How to stop IBM AIX from forcing a user to change their password at first login ? 

# pwdadm -c username 

---------------------------------------------------------------------------------------------------------------- 

20. Redhat Package Manager for IBM AIX and Linux 

To query all packages installed: 
# rpm -q –a

To list file in a specific package:
# rpm -q -l package.rpm

To install a RPM package:
# rpm -i package.rpm

To delete (erase) a RPM package:
# rpm -e package.rpm

To query for RPM package owning file:
# rpm -q -f /path/to/file

To upgrade a RPM package
# rpm -U package.rpm

----------------------------------------------------------------------------------------------------------------

21. How to capture TCPIP packet information in IBM AIX ?

Here is a command to capture TCP/IP packet information between your server and another in IBM AIX: 

Become root user, Find a temporary directory to capture the data (/tmp in this example) Run the iptrace command:

# iptrace -a -d host_destination -b /tmp/ip.out

iptrace will run in the background and results will be in /tmp/ip.out

To see the results of the trace:
# ipreport /tmp/ip.out more

Don't foregt to kill iptrace when you're done:
# ps -ef grep iptrace grep -v grep awk '{system("kill " $2)}'

Some other cool options of iptrace:
-d : specify destination IP address -s : specify origin IP address
-b : show 2-way traffic (as in "-s xxx -b" or "-d xxx -b")
-a : no ARP requests (less pollution in the trace)

To see all packets going in and out of server, unixserv, without ARP requests:

# iptrace -a -d unixserv -b /tmp/ip.out

iptrace and ipreport are in IBM AIX LPP "bos.net.tcp.server"

----------------------------------------------------------------------------------------------------------------

22. How to check if a system dump completed successfully on IBM AIX ?

To verify if a system dump completed successfully on an IBM AIX server:

# sysdumpdev –L 
0453-039 
Device name: /dev/hd6 
Major device number: 10 
Minor device number: 1 
Size: 124371456 bytes 
Date/Time: Sun Sep 15 12:19:02 EDT 2002 
Dump status: 0 ( 0 = Ok) 
dump completed successfully 
0481-195 
Failed to copy the dump from /dev/hd6 to /var/adm/ras

----------------------------------------------------------------------------------------------------------------

23. How to check two file systems simultaneously on different drives in IBM AIX ?

To check two file systems simultaneously on different drives in IBM AIX.The dfsck command permits you to interact with two fsck commands at once. To aid in this, the dfsck command displays the file system name with each message. When responding to a question from the dfsck command, prefix your response with a 1 or a 2 to indicate whether the answer refers to the first or second file system group.

# dfsck [ FlagList1 ] FileSystem1 [ FlagList2 ] FileSystem2

Example to check two filesystems:
# dfsck -p /dev/hd1 - -p /dev/hd7

Note: you can also specify the file system names found in the /etc/filesystems. Attention: Do not use the dfsck command to check the root file system.

----------------------------------------------------------------------------------------------------------------

24. How to make a disk flash in IBM AIX ?

For disk replacement, it is often useful to make the disk flash so that you know which disk to replace in IBM AIX:

# diag to continue
Select "Task Selection (Diagnostics, Advanced Diagnostics, Service Aids, etc.)"
Select "Hot Plug Task"Select "SCSI and SCSI RAID Hot Plug Manager"
Select "Identify a Device Attached to a SCSI Hot Swap Enclosure Device"
Select the slot you wish the disk to flash Replace the appropriate disk by checking which disk is flashing
----------------------------------------------------------------------------------------------------------------

25. How to determine which application created the OS core file in AIX ?

# /usr/sbin/lquerypv -h /path/to/core 6b0 64
The output of this command is neat, clean and easy to read.

Here is an example:

# lquerypv -h core 6b0 64
000006B0 7FFFFFFF FFFFFFFF 7FFFFFFF FFFFFFFF ................
000006C0 00000000 000007D0 7FFFFFFF FFFFFFFF ................
000006D0 00120000 1312C9C0 00000000 00000017 ................
000006E0 6E657473 63617065 5F616978 34000000 netscape_aix4...
000006F0 00000000 00000000 00000000 00000000 ................
00000700 00000000 00000000 00000000 00000ADB ................
00000710 00000000 000008BF 00000000 00000A1E ................

The executable is located between the pipes on the right hand side of the output. In this case, the core was generated by Netscape.

----------------------------------------------------------------------------------------------------------------

26. How to find the system id number of an IBM AIX server ?

# lsattr -El sys0 -a systemid
# uname -u
# lscfg -vpgrep -p "System VPD:" grep -i Serial

Note: commands may not work on all IBM models

----------------------------------------------------------------------------------------------------------------

27. Tips on Memory Tuning :

Do not use the command vmtune in AIX 5L. From AIX 5L. vmo and ioo commands are introduced to tune memory and I/O.

Here is how we set various memory options now:

# vmo -p -o maxfree=128
# vmo -p -o minperm%=5
# vmo -p -o maxclient%=10
# vmo -p -o maxperm%=10
# vmo -p -o maxfree=632
# vmo -p -o minfree=600
# ioo -p -o maxpgahead=32

To see the results of the changes:
# vmo –L
# ioo –L

If you have a problem with slow telnet sessions:
# chdev -l sys0 -a maxpout='33' -a minpout='24'

To set AIO (asynchronous IO) options use smitty

----------------------------------------------------------------------------------------------------------------

28. If you reinstall an IBM AIX server and the mksysb used was for a server on another vlan, you can end up with 2 default routes. Lets see how to solve this issue
In order to see the default routes stored in the ODM:

# lsattr -El inet0 grep Route
route net,-hopcount,0,,0,172.26.247.92 Route True
route net,-hopcount,0,,0,172.26.14.1 Route True

To see the default routes you have in your routing table:
# netstat -rn grep default
default 172.26.14.1 UGc 0 0 en0 - - =>
default 172.26.247.92 UGc 0 0 en0 - -

To remove one of the default routes, use smitty and not a the route command otherwise you will end up with 2 default routes after a reboot.

----------------------------------------------------------------------------------------------------------------

29. EFix - How to manage ?

To list efix :
# emgr –l

To install an efix package:
# emgr -e efixPackage

----------------------------------------------------------------------------------------------------------------

30. Kernel Processes in AIX: An Overview

# ps -kl
# pstat -a (as root)

There are several kprocs, and they do a number of things. Often they have fixed priority and will run ahead of any user processes.

A couple are:
Kproc Kernel (wait) wait process
Kproc Kernel (lrud) Least Recently Used Daemon (mem mgmt)
Kproc Kernal (swapper) Memory/Process swapping ?
Kproc Kernel (kbiod) Kernel Block I/O daemon (disk I/O)?
kproc Kernel ( gil) 1032 Networking off-level stuff
Kproc Kernel (netm) Network memory allocator
Kproc Kernel (aump) Automounter

A kproc is a kernel process, started by the kernel on behalf of either another kernel process, or as a result of an application initiating a system call or call to a kernel service.
Wait - You will find that the "wait" kproc will have accumulated a lot of cpu time. This just means your system is idle a lot. When nothing else needs to run, the wait kproc is charged the time slice

GIL - "Global ISR List"
ISR->Interrupt Service Routines - multithreaded kproc runs at fixed pri of 37 Used to process various timers (tcp, streams, ....) and also used to pass packets from demux layer to IP layer for non-CDLI drivers.

ps -lk
The processes with nice value of -- are running with fixed priorities. Their nice values can not be changed. On my system that would processes such as swapper (pid=0, pri=16) and the wait kproc (pid=514, pri=127).

This will list out all the kprocs. Now do a pstat -a to find what they really are?
This will show you the real name of the kproc.

Aump kernel thread is left over after you stop the automounter daemon.
Yes. It goes away after reboot. However, there is an APAR for it: IY33240

----------------------------------------------------------------------------------------------------------------

31. How to manage network tuning parameters in AIX ?

The no command is used to configure network tuning parameters in IBM AIX. The no command sets or displays current or next boot values for network tuning parameters. This command can also make permanent changes or defer changes until the next reboot.

Syntax:
no [ -p -r ] { -o Tunable[=NewValue] }
no [ -p -r ] {-d Tunable }
no [ -p -r ] { -D }
no [ -p -r ] -a
no -h [ Tunable ]
no -L [ Tunable ]
no -x [ Tunable ]

where:
-a : displays current, reboot or permanent value for all tunable parameters
-d : resets Tunable its to default value
-D : resets all tunables to their default value
-h : displays help about Tunable parameter
-L : lists the characteristics of one or all Tunables
-o : displays the value or sets the Tunable to NewValue
-p : makes changes apply to both current and reboot values (I heard this option in many interviews)
-r : makes changes apply to reboot values (I heard this option in many interviews)
-x : lists characteristics of one or all tunables using spreadhset format

Example to set the value of tunable tcp_sendspace to 65536 permanently:
# no -p -o tcp_sendspace=65536

Example to set the value of tunable sb_max to 2097152 at next reboot:
# no -r -o sb_max=2097152

Example to display all values of tunables:
# no -a

Example to display all values of tunables at next reboot:
# no -r -a

Example to set the value of tunable tcp_sendspace to 65536:
# no -o tcp_sendspace=65536

----------------------------------------------------------------------------------------------------------------

32. How to verify your ntp setup is working properly ?

# ntpq -c peersremote refid st t when poll reach delay offset disp =========================================================================
*time.domain.co doghaus.cns.uto 3 u 12 64 177 1.46 -2.515 145.19

If you have a star (*) in the first column of the name of the time server, your time is being synchronised properly.

The third column, st, is the stratum. The lower the number, the closer you are to the time source.

Stratum 16 means you are not synchronised.

----------------------------------------------------------------------------------------------------------------

33. How to synchronize your server time to a time server ?

If you don't want to run NTP (network time protocol), you can update your system time with the command:

# ntpdate timeserver.domain.com

----------------------------------------------------------------------------------------------------------------

34.How to list open files ?

To list all open files:
# lsof

To list all open files on a device:
# lsof /dev/hd4

----------------------------------------------------------------------------------------------------------------

35. How to find the world-wide name (WWN) or network address of a fibre-channel (FC) card in IBM AIX ?

First find the name of your fibre-channel cards:
# lsdev -vp grep fcs

Then get the WWN (for fcs0 in this example):
# lscfg -vp -l fcs0 grep "Network Address"

----------------------------------------------------------------------------------------------------------------

36. How to change a server hostname with the uname command in IBM AIX ?

To display the current hostname
# uname -n
localhost

To change the hostname
# uname -S newhostname

Again display the hostname
# uname -n
newhostname

----------------------------------------------------------------------------------------------------------------
37. How can you find out when a system was installed?
Enter the following command:
lslpp -h bos.rte
The output of this command will show the history of when the operating system was installed. Read the entry for the AIX level (ie, 4.3.3.0).

----------------------------------------------------------------------------------------------------------------

38. How to make sure all of the user definitions are correct in the user database

#usrck -n ALL

Do the same for the groups:
#grpck -n ALL

----------------------------------------------------------------------------------------------------------------

39. Reduce the Size of a File System in Your Root Volume Group ? 

http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto/HT_baseadmn_rootvg_reduce.htm#baseadmn_rootvg_reduce
----------------------------------------------------------------------------------------------------------------

40.How to reset an Unknown Root Password ?
 http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto/HT_baseadmn_recoverrootpswd.htm#baseadmn_recoverrootpswd
----------------------------------------------------------------------------------------------------------------

41. How to configure Domain Name Servers ? 
http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto/HT_commadmn_dns.htm#commadmn_dns

-----------------------------------------------------------------------------------------------------------------

42. How to re-create corrupted boot image ?
 http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto/HT_baseadmn_bad_boot_img.htm#baseadmn_bad_boot_img
----------------------------------------------------------------------------------------------------------------

43. How to configure NIM master server using EZNIM ? 
http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto/HT_insgdrf_configure_eznim.htm#insgdrf_configure_eznim
----------------------------------------------------------------------------------------------------------------

44. How do I use network (For normal users) 

http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto_user/Use_Network_U.htm#category_use_network

----------------------------------------------------------------------------------------------------------------
45. How do I view system and environment information?
 http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto_user/AccessSys_Envir_U.htm#category_accesssys_envir
----------------------------------------------------------------------------------------------------------------

46. How do I use shell scripts ? 
http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto_user/Use_Shells_U.htm#category_use_shells
----------------------------------------------------------------------------------------------------------------

47. How do I redirect standard input, output, and error? 
http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto_user/RedirStand_IO_Error_U.htm#category_redirstand_io_error
------------------------------------------------------------------------------------------------

48. How do I make my system more secure? 
http://publib16.boulder.ibm.com/pseries/en_US/infocenter/howto_user/Security_U.htm#category_security 


----------------------------------------------------------------------------------------------------------------

49. How to configure network adapters for Redundancy ? 
http://users.ca.astound.net/~baspence/AIXtip/etherchannel.htm
----------------------------------------------------------------------------------------------------------------

50. Useful link about AIX Error Log codes, LED codes, 7-Digit Error codes.
 http://rainsux.dyndns.org/AIX5L-Messages-Codes.html


---------------------------------------------------------------------------------------------------------------- 

51. How to disable remote root login ? 

When multiple users have root access to a system, a common security question is who logged in as root? One alternative is to disable remote logins for the root id (chuser -rlogin=false root). This forces users to first login in with their regular user id, then "su -" to root. All "su" activity is captured in /var/adm/sulog, thus answering the question of "who logged in as root."
Comment: In general it is a good practice to disable root remote access as it provides two layers of password protection. 

----------------------------------------------------------------------------------------------------------------

52. Replacing a disk drive in AIX. 
http://users.ca.astound.net/~baspence/AIXtip/download/failed_disk.pdf

----------------------------------------------------------------------------------------------------------------

53. How to enabling Non-root Users to Administer Passwords ? 

The AIX pwdadm command can be used to offload password administration to non-root administrators. The pwdadm command allows the administrator to change anothers password, or force users to change their password at the next login. To enable a non-root administrator to use pwdadm, simply add their ID to the "security" group.
For more information: 
http://www.rs6000.ibm.com/doc_link/en_US/a_doc_lib/cmds/aixcmds4/pwdadm.htm 

----------------------------------------------------------------------------------------------------------------

54. Fun with device locations 

Here are a few commands to locate physical devices. These commands are useful in a partitioned environment where locations are virtual.
lsdev -Cc adapter -s pci - list all adapter slots lsdev -p adapter - lists devices owned by an adapter lsdev -Cl adapter -F parent lists the parent adapter for a device (like a disk drive) lsdev -Cl adapter - virtual device location (for LPARs) lscfg -vl adapter - actual device location So, for example, to locate the physical adapter connected to hdisk0:
# Identify the parent adapterlsdev -Cl hdisk0 -F parent
# Locate the parent adapter lscfg -vl parent---------------------------------------------------------------------------------------------------------------- 

55. How to automate setting passwords ?
The "chpasswd" command is easier to use than "passwd" when setting a list of user passwords. It can be used from the command line or shell script. For example, to change passwords for users listed in a file, type the following
cat mypasswords chpasswd
Where the mypasswords file contains
user1:password1user2:password2......

For more information see the following URL

http://publib16.boulder.ibm.com/doc_link/en_US/a_doc_lib/cmds/aixcmds1/chpasswd.htm

---------------------------------------------------------------------------------------------------------------- 

56. How to list files if 'ls' is missing or corrupt ?
echo *

----------------------------------------------------------------------------------------------------------------

57. How to change the timezone and language in /etc/environment ?
chtz (timezone eg GMT0BST)
chlang (language eg En_GB)

----------------------------------------------------------------------------------------------------------------
58. Find large files

How do you find really large files in a file system: 

find . -size +1024 -xdev -exec ls -l {} \;

The -xdev flag is used to only search within the same file system, instead of traversing the full directory tree. The amount specified (1024) is in blocks of 512 bytes.

---------------------------------------------------------------------------------------------------------------- 

59. Montoring a system without logging in 

Let's say you have a helpdesk, where they must be able to run a script under user-id root to check or monitor a system:

First, create a script, you wish your helpdesk to run. 

Modify your /etc/inetd.conf file and add:
check stream tcp wait root /usr/local/bin/script.sh
where script.sh is the script you've written. 

Modify your /etc/services file and add: 
check 4321/tcp

You may change the portnumber to anything you like, as long as it's not in use. 

Now, you may run:
telnet [system] 4321 
and your script will be magically run and it's output displayed on your screen. If the output of the script isn't displayed on your screen very long, just put a sleep command at the end of your script.----------------------------------------------------------------------------------------------------------------
60. Changing maxuproc requires a reboot?

When you change MAXUPROC (Maximum number of processes allowed per user), the smitty help panel will tell you that changes to this operating system parameter will take effect after the next system reboot.
This is wrong Help information. The change takes effect immediately, if MAXUPROC is increased. If it is decreased, then it will take effect after the next system reboot.
This help panel text from smitty will be changed in AIX 5.3. APAR IY52397.
----------------------------------------------------------------------------------------------------------------
61. Defunct processes
Defunct processes are commonly known as "zombies". You can't "kill" a zombie as it is already dead. Zombies are created when a process (typically a child process) terminates either abnormally or normally and it's spawning process (typically a parent process) does not "wait" for it (or has yet to "wait" for it) to return an exit status.
It should be noted that zombies DO NOT consume any system resources (except a process slot in the process table). They are there to stay until the server is rebooted.
Zombies commonly occur on programs that were (incompletely) ported from old BSD systems to modern SysV systems, because the semantics of signals and/or waiting is different between these two OS families.
------------------------------------------------------------------------------------------------
62. DLpar with DVD-ROM
Adding a DVD-ROM with DLpar is very easy. Removing however, can be somewhat more difficult, especially when you've run cfgmgr and devices have been configured.
This is how to remove it:
#rmdev -dl cd0
(Remove all cdrom devices found with lsdev -Cc cdrom)
#rmdev -dl ide0
Then remove the devices found with
# lsdev -C grep pci
All PCI devices still in use, can not be removed. The one not in use, is the PCI device where the DVD-ROM drive on was configured. You have to remove it before you can do a DLPAR remove operation on it.
Now do your DLPAR remove operation n HMC
------------------------------------------------------------------------------------------------
63. How do you send an attachment via mail from AIX ?
Uuencode is the answer:
uuencode [source-file] [filename].b64 mail -v -s "subject" [email-address]
For example:
# uuencode /etc/motd motd.b64 mail -v -s "Message of the day" email@hostname.comI
use the .b64 extension which gets recognized by Winzip. When you received your email in Outlook, you will have an attachment, which can be opened by Winzip.
------------------------------------------------------------------------------------------------
64. FTP umask
A way to change the default 027 umask of ftp is to change the entry in /etc/inetd.conf for ftpd:
ftp stream tcp6 nowait root /usr/sbin/ftpd -l -u 117
This will create files with umask 117 (mode 660).
Using the -l option will make sure the FTP sessions are logged to the syslogd. If you want to see these FTP messages in the syslogd output, then you should add in /etc/syslog.conf:
daemon.info [filename]
------------------------------------------------------------------------------------------------

1. How to configure the system and create a restricted shell user ?
Below example shows how to create a restricted shell user (this user can execute only "ls" and "vi" commands
a) Make a reduced bin directory to contain links to programs for the user or users: 
# mkdir /usr/rbin
b) Link the necessary commands and programs in the reduced bin directory.
For example, give access to the ls and vi commands:
# ln -s /usr/bin/ls /usr/rbin/ls
# ln -s /usr/bin/vi /usr/rbin/vi
c) Add Rsh as a valid shell in /etc/security/login.cfg:
# vi /etc/security/login.cfg
d) Add /usr/bin/Rsh to the list of shells in the usw stanza:
usw:
shells = /bin/sh,/bin/bsh,/bin/csh,/bin/ksh,/bin/tsh,/bin/ksh93,/usr/bin/sh,
/usr/bin/bsh,/usr/bin/csh,/usr/bin/ksh,/usr/bin/tsh,/usr/bin/ksh93,/usr/sbin/
uucp/uucico,/usr/sbin/sliplogin,/usr/sbin/snapp,/usr/bin/Rsh
e) Add the restricted shell user:
# mkuser shell="/usr/bin/Rsh" alex
f) Assign an initial password:
# passwd alex
g) Change the ownership of the users profile to root:
# chown root:system /home/alex/.profile
h) Change the permissions of the users profile to 755:
# chmod 755 /home/alex/.profile
i) Edit the users profile setting the PATH and Shell variables:
# vi /home/alex/.profile
Set PATH for the new bin directory and Set SHELL to rksh:
PATH=/usr/rbin; export SHELL=/usr/bin/Rsh
---------------------------------------------------------------------------­---------------------------------
2. How to change the default welcome (herald) message on the login display ?
Edit the file /etc/security/login.cfg and update the herald parameter ...
default:
herald = "Unauthorized use of this system is prohibited\n\nlogin: "
sak_enable = false
logintimes =
logindisable = 0
logininterval = 0
loginreenable = 0
logindelay = 0
You can also use the below command to change the herald value
# chsec -f /etc/security/login.cfg -a default -herald "Unauthorized use of this system is prohibited.\n\nlogin: "
---------------------------------------------------------------------------­---------------------------------
3. How to set automatic logoff (only for terminals) ?
Edit the /etc/security/.profile file to include an automatic logoff value for all users, as in the following example:
TMOUT=600 ; TIMEOUT=600 ; export readonly TMOUT TIMEOUT
The number 600, in this example, is in seconds, which is equal to 10 minutes. However, this method only works from the shell.
---------------------------------------------------------------------------­---------------------------------
4. How to auto forward the mails ?
Create $HOME/.forward file and add adresses or aliases.
When mail is sent to a local user, the sendmail command checks for the $HOME/.forward file.
If the file exists, the message is not sent to the user. The message is sent to the addresses or aliases in the $HOME/.forward file.
---------------------------------------------------------------------------­---------------------------------

5. How to set(define) and unset a variable in a shell or shell script ?
# x=3 -> Defines a vlue for a variable 'x'
# echo $x -> Displays the vlue of 'x' vairable
3
# unset x -> Unsets the variable
# echo $x -> Again display its value
#
---------------------------------------------------------------------------­---------------------------------

6. How to send file1 as a message to user alex ?
# mail alex <>
---------------------------------------------------------------------------­---------------------------------

7. How to display mail queue ?

Note: mailq is the queue where your mails are stored
# mailq (or) sendmail -bp
There is 1 request in the mail queue
---QID---- --Size-- -----Q-Time----- ----------Sender/ Recipient-----------
OAA 19258 * 29 Mon Jun 26 14:57 root
---------------------------------------------------------------------------­---------------------------------

8. Whats sendmail command?
It receives formatted messages and routes messages to one or more users. IT can deliver messages to users on local/remote machines. It will be started by tcpip sub-system . It uses /etc/mail/sendmail.cf as config file.
Once this daemon started, you can find its process id in
/etc/sendmail.pid.

---------------------------------------------------------------------------­---------------------------------

9. How to define mail aliases for users?
a) Add the aliases to /etc/aliases.
For Example,
nobody: /dev/null
certify: user02, user5801@server3, root@server4, user5911@se
b) Rebuild the aliases database using
newaliases (or) sendmail -bi
---------------------------------------------------------------------------­---------------------------------

10. If logging with telnet takes long time (for ex. 2 mins), what might be the issue?
There might be problem with DNS resolution. Check /etc/resolv.conf and check dns connection thru nslookup command.
---------------------------------------------------------------------------­---------------------------------
11. While attempting to log in, you see the below message. How you solve this issue ?
'All available login sessions are in use.'
Check the number of AIX user license using "lslicense"
If required increase the license using "chlicense" command.
---------------------------------------------------------------------------­---------------------------------
12. Oracle DBA says that his database is not able to go beyond certain limit. For example, oracle userid is not able to start more than 500 process's. Whats the issue?
This is because of the "maxuproc" value is 500. Check the value using "lsattr -El sys0 -a maxuproc"
If required change the value using
# chdev -l sys0 -a maxuproc=1000
Normally for Oracle Production machines, you have to consult with DBA's while installing the server and set an agreed value.
---------------------------------------------------------------------------­---------------------------------
13. Errpt is not displaying any reports. Found that /var/adm/ras/ errlog file is there in the location and errdemon is running fine. What might be the issue the issue?
errlog file seems to be corrupted. Delete the file and stop the errdemon (/usr/lib/errstop).
Start the errdaemon (/usr/lib/errdemon). While starting, daemon creates the errlog file automatically.
---------------------------------------------------------------------------­---------------------------------
14. How to list IDE controllers in your system ?
# lscfg -l ide*
DEVICE LOCATION DESCRIPTION
ide0 01-00-00 ATA/IDE Controller Device
ide1 01-00-01 ATA/IDE Controller Device
The following sample display from the lscfg -l ide command shows
There are 2 IDE I/O controllers configured in the server
Controller ide0 and ide1 are located on the system planar ( Notice 1st and 2nd digits in location code)

The planar indicator is the second digit in the location value with a value of 1.
6th digit indicates the controller number.
---------------------------------------------------------------------------­---------------------------------
15. After a successful login, the login command displays the message of the day, the date and time of the last successful and unsuccessful login attempts for this user, and the total number of unsuccessful login attempts for this user since the last change of authentication information (usually a password).
How do you suppress these messages?
You can suppress these messages by creating a “.hushlogin” file in your home directory.
For Example,
At the prompt in your home directory, type the following:
# touch .hushlogin
The touch command creates the empty file named .hushlogin if it does not already exist. The next time you log in, all login messages will be suppressed. You can instruct the system to retain only the message of the day, while suppressing other login messages.
---------------------------------------------------------------------------­---------------------------------
16. Whats the files system read once you login ?
First File : /etc/environment - contains variables specifying the basic environment for all processes.
Second File: /etc/profile - controls system-wide default variables
Third File : $HOME/.profile - lets you customize your individual working environment
Fourth File: $HOME/.env - lets you customize your individual working environment variables.
---------------------------------------------------------------------------­---------------------------------
17. How to override variables defined in /etc/environment for a particular user?
A fourth file that the operating system uses at login time is the
$HOME/.env file, if your .profile contains the following line:
export ENV=$HOME/.env
The .env file lets you customize your individual working environment variables. The .env file contains the individual user environment variables that override the variables set in the /etc/environment file. You can customize your environment variables as desired by modifying your .env file.
---------------------------------------------------------------------------­---------------------------------
18. How to change the font in AIX ?
To change the font to an italic, roman, and bold face of the same size, type the following:
# chfont -n /usr/lpp/fonts/It114.snf /usr/lpp/fonts/Bld14.snf /usr/lpp/
> fonts/Rom14.snf
You can also use smitty chfont.
---------------------------------------------------------------------------­---------------------------------
19. How to run a process in the background ?
For Ex, to run script1.sh in background run
# script1.sh &
But this script process gets killed if you close the terminal
So always practice to run using nohup,
# nohup script1.sh &
Usage of nohup doesn't kill the process if you close the telnet session. Output from the process/script will be stored in a file called nohup.out in the directory from where you started the process.
This will help you in case if you want to start backup using mksysb and close your terminal/ leaving office, you can safely use "nohup command &". Next day morning, you can view the contents of nohup.out to know the status of the backup job.
---------------------------------------------------------------------------­---------------------------------
20. What is the default priority for a process?
Default priority is 0. Priority numbers is in the range of -20 to 20. Highest number is the lowest priority and lowest number has high priority while using resources.
To set the priority while start a process, use nice command.
If the process is already running, you can use "renice" command to change its priority.
---------------------------------------------------------------------------­---------------------------------
21. How to stop, resume and to make it foreground process?
To stop(pause) a foreground process, use
Cntrol + Z keys ie., Ctrl+Z.
Note: Ctrl+Z works in the Korn shell (ksh) and C shell (csh), but not in the Bourne shell (bsh).
To restart a stopped process, you must either be the user who started the process or have root user authority.
To restart a stopped process, enter
# kill -19 pid
To run it in foreground, enter
# fg pid

where pid is the process id which can be obtained from the following command
ps -ef | grep precess_name | awk '{print $2}'
---------------------------------------------------------------------------­---------------------------------
22. How to display a program output as well as copying to a file ?
Normally usage of output redirection suppresses the output on screen.

Ex. ls -l > file1
If we want to redirect the output as well as show the output in screen use the tee command.
Ex: ls -l | tee -a file1
---------------------------------------------------------------------------­---------------------------------
23..How to capture your terminal screen to a file ?
To capture the screen of a terminal, at the prompt, type the following:
#script
The system displays information similar to the following:
Script command is started. The file is typescript.
Everything displayed on the screen is now copied to the "typescript" file.
To stop the script command, press Ctrl-D or type exit and press Enter.
The system displays information similar to the following:
^D

Script command is complete. The file is typescript.
Use the cat command to display the contents of your file.
---------------------------------------------------------------------------­---------------------------------
24. What are the supported file systems in AIX ?
a) JFS (or) JFS2 - Disk based file system
b) NFS - Network based File system
c) CDRFS - CDROM based file system
d) UDFS - DVD-ROM based file system
e) RAMFS - RAM based file system used while booting the system
---------------------------------------------------------------------------­---------------------------------

25. What are the different directory abbreviations?
Abbreviation Meaning
. The current working directory
.. The parent of the current working directory
~ Your home directory
$HOME Your home directory
---------------------------------------------------------------------------­---------------------------------
26. What are the different directory path names ?
Absolute path name:
Traces the path from the /(root) directory. Absolute path names always
begin with the slash (/) symbol.
Ex. /home/ raja/dir1

Relative path name:
Traces the path from the current directory through its parent or its
subdirectories and files. As user "raja", I can say ./dir1 since I'm already in /home/raja
---------------------------------------------------------------------------­---------------------------------
27. How to move a directory ?
# mvdir book manual
This moves the book directory under the directory named manual, if the
manual directory exists. Otherwise, the book directory is renamed to manual.
---------------------------------------------------------------------------­---------------------------------
28. What the RAID groups AIX LVM supports?
RAID-0 - Striping
RAID-1 - Mirroring
RAID-10 (or) RAID 0+1 - Mirroring and striping
---------------------------------------------------------------------------­---------------------------------
29. How to read and remove mails from my system mailbox?
At your system command line prompt, enter the mail command:
# mail
If there is no mail in your system mailbox, the system responds with a message:

No mail for YourID
If there is mail in your mailbox, the system displays a listing of the messages in your system mailbox:
# mail
Here Type ? for help.

"/usr/mail/lance": 3 messages 3 new
>N 1 karen Tue Apr 27 16:10 12/321 "Dept Meeting"
N 2 lois Tue Apr 27 16:50 10/350 "System News"
N 3 tom Tue Apr 27 17:00 11/356 "Tools Available"
The current message is always prefixed with a greater-than symbol (>).
Each one-line entry displays the following fields:
status - Indicates the class of the message.
number - Identifies the piece of mail to the mail program.
sender - Identifies the address of the person who sent the mail.
date - Specifies the date the message was received.
size - Defines the number of lines and characters contained in the
message (this includes the header).
subject - Identifies the subject of the message, if it has one.
The status can be any of the following:
N - A new message.
P - A message that will be preserved in
---------------------------------------------------------------------------­---------------------------------
30. After logging as an application user (oradba), when I issued "crontab -l" system throwed the below error
0481-103 Cannot open a file in the /var/spool/cron/crontabs directory.
What is the solution?
Here is the solution
a) Create an empty file /var/spool/cron/crontabs/oradba
b) Change the ownership of the file to root.cron
c) Login as oradba and issue "crontab -l" to verify the cron.
---------------------------------------------------------------------------­---------------------------------
31. How to identify the program listening in the given port ?
METHOD I: # lsof –P –n –i :505 (for port 505)
METHOD II:
# netstat -Aan|grep 9404
f100060006952b98 tcp 0 0 *.9404 *.* LIST
EN
f100060006a90b98 tcp 0 0 *.19404 *.* LIST
EN
# rmsock f100060006952b98 tcpcb
The socket 0x6952808 is being held by proccess 753870 (java).
---------------------------------------------------------------------------­---------------------------------
32. How to display non-printable characters in a text file ?
Lets create a file with non-printable characters.
# vi filename.txt
^I^I^I^I$
$
$
$
this is a test$
^I^I^I^I$
~
: set list
Now we will list the file so that non-printable chars are viewed
# cat -vet filename.txt
^I^I^I^I$
$
$
$
this is a test$
^I^I^I^I$
# od -c filename.txt
0000000 \t \t \t \t \n \n \n \n t h i s i s
0000020 a t e s t \n \t \t \t \t \n
0000034
---------------------------------------------------------------------------­---------------------------------
33. How to display specific lines in a text files ?
For illustration purposes, I'm using the cat -n filename to show the line numbers in this script.
# cat -n filename
...
8 for i in $*
9
10 do
11
12 typeset -i16 hex
13 hex=$i
14 print $i equals $hex in hexadecimal
15
16 typeset -i8 oct
17 oct=$i
18 print $i equals $oct in octal
19
20 typeset -i2 bin
21 bin=$i
22 print $i equals $bin in binary
23
24 print
25 done
...
Prints out the for loop without displaying the line numbers
# sed -n 8,25p filename | tee for_loop
---------------------------------------------------------------------------­---------------------------------
34. How to recover the root password in AIX ?
If you forgotten the root password, we can easily recover it but the system requires 2 recycles.
Here is the way I follow
Password recovery is one of the simplest troubleshooting procedure in
AIX. Once you boot from CD, you see a menu with 3 menu items.
In that select the 3rd item
ie., "Start Maintenance Mode for System Recovery" à
"Access a Root Volume Group" ->
"Access this volume group and start a shell".
This will open a shell prompt. The just use "passwd" command for
setting a new password for root.
Thats it. root password has been changed.
Now you can reboot the machine from rootvg hard disk (normally it should be hdisk0)
---------------------------------------------------------------------------­---------------------------------
34. How to find out the (real) memory usage ?
# svmon -G
size inuse free pin virtual
memory 2097152 2097026 126 195637 1237158
pg space 524288 61023
work pers clnt lpage
pin 195404 233 0 0
in use 1189840 906786 400 0
The size and inuse columns of the memory and pgspace output represent real memory and paging space usage respectively.
The size is measured as the number of 4K pages.
Here in this case used memory is
= ((2097026 x 4)/1024)/1024 GB of used memory
---------------------------------------------------------------------------­---------------------------------
35. Here are some of the errors you get when paging space is low.
INIT: Paging space is low!
ksh: cannot fork no swap space
Not enough memory
Fork function failed
fork () system call failed
Unable to fork, too many processes
Fork failure - not enough memory available
Fork function not allowed. Not enough memory available.
---------------------------------------------------------------------------­---------------------------------
36. How is the default paging space size determined ?
It follows the following standard
Set paging space to 2 times the amount of RAM
Paging space can use no more than 20% of total disk space in the root volume Group
Paging space can be no larger than 2 GB
------------------------------------------------------------------------------------------------
1. To list machines configured in a NIM Server,
# lsnim -c machines

2. To list networks configured in a NIM Server,
# lsnim -c networks

3. To reset a machine (return to ready state)
# nim -Fo reset MachineName

4. To list core file settings for a user,
# lscore user1

The output will look like:
compression: on
path specification: default
corefile location: default
naming specification: off

5. To list the default settings for the system,

# lscore -d

The output will look like:
compression: off
path specification: on
corefile location: /corefiles
naming specification: off

6. To make any process run by root dump compressed core files and restore the location of the core files to the system default,

# chcore -c on -p default root
Note: If no default is specified, cores will dump in the current directory.

7. To enable a default core path for the system, type:

# chcore -p on -l /corefiles -d

8. To scan logical volume lv01, report the status of each partition, and have every block of each partition read to determine whether it is capableof performing I/O operations, type:

# mirscan -l lv01

9. To do the above operation in a PV,

# mirscan -p hdisk1

10. To do the above operation in a VG,

# mirscan -v vg01

11. To determine if the 64-bit kernel extension is loaded,

# genkex grep 64

12. To list all JFS file systems,

# lsjfs

13. To list all JFS2 file systems

# lsjfs2

14. To mirror a terminal1 on terminal2
a. Open terminal 1 and find the pts value (ps -ef grep pts)

b. Open terminal 2 and enter 'portmir -t pts/1'
c. Now you will see commands and outputs from terminal 1 in terminal 2.
This is basically monitor a terminal.
d. Say "portmir -o" to end the mirroring after the use

15. To identify the current run level,

# cat /etc/.init.state

16. To list the available CD ROM drives,

# lsdev -Cc cdrom

17. To find out the speed of your network adapter,

# entstat -d ent0 grep "Media Speed"

18. To find out when your system was last installed/updated

# lslpp -f bos.rte

19. To list the status of your tape drive,

# tctl -f /dev/rmt0 status

20. How to setup anonymous ftp in AIX

Run the below script to setup anon ftp,
# /usr/lpp/tcpip/samples/anon.ftp

21. If telnet takes more time to produce a prompt, do the below checks

a. do nslookup of the client ip from the aix serverb. 
b. Check the nameservers in /etc/resolv.confc. 
c. Check the 'hosts' entry in /etc/netsvc.conf or NSORDER variable

This issue might be due to the DNS configuration issue. Pointing to a good nameserver should solve the problem.

22. How to shutdown the system to maintenance mode ?

# shutdown -Fm

23. How to log ftp accesses to a file

a. Add the below line in /etc/syslog.confdaemon.debug /tmp/daemon.log
b. # touch /tmp/daemon.log
c. # refresh syslogd
d. Modify your inetd.conf so that ftpd is called with the "-l" flag.

24. How to find a file name from inode number ?

# ncheck -i xxxx /mountpoint
where xxxx -> inode number of the file

25. How to redirect the system console to a file or tty temporarily

# swcons /tmp/console.out

or 

# swcons /dev/tty5

26. How to recreate a deleted /dev/null file ?

# /bin/mknod /dev/null c 2 2

27. How to add commands that should get executed during every system shutdown ?

Add them to /etc/rc.shutdown

28. How to reduce the size or do cleanup of /var/adm/wtmp ?

# > /var/adm/wtmp

29. How to find out the fileset a file belongs to ?

# which_fileset command_name

30. In which file, the mapping of file Vs fileset stored ?

# /usr/lpp/bos/AIX_file_list

31. How to set maximum logins for a user in a system ?

Change the value of "maxlogins" under "usw" stanza in /etc/security/login.cfg

32. How to change the initial message that prints while logging in ?

Change the value of "herald" in /etc/security/login.cfg

33. How to set the # of seconds the user is given to enter their password ?

Change the value of "logintimeout" under "usw" stanza in /etc/security/login.cfg

------------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------------

1. How to force a failover of an EtherChannel ?
# /usr/lib/methods/ethchan_config -f Etherchannel_Device

2. How to add a backup adapter to an existing etherchannel device ?
# /usr/lib/methods/ethchan_config -a -b Etherchannel_Device Ethernet_Adapter

3. How to change the address to ping attribute of an EtherChannel ?
# /usr/lib/methods/ethchan_config -c Etherchannel_Device netaddr New_Ping_IP_Addr

4. How to list the available major numbers in a system ?
# lvlstmajor

5. How to list the major number of a volume group ?
# lvgenmajor rootvg

6. Consider a situation where you have a VG in a PV. But you have not imported that.
Now you need to find a list of attributes of that volume group before importing/varyon it.
Answer the below questions :

a. How to list the maximum number of logical volumes allowed in the VG ?
# lqueryvg -p PVname -N

b. How to show the PP size ?
# lqueryvg -p PVname -s

c. How to show the number of free PPs in the VG ?
# lqueryvg -p PVname -F

d. How to show the current number of LVs in the VG ?
# lqueryvg -p PVname -n

e. How to list the current number of PVs in the VG ?
# lqueryvg -p PVname -c

f. How to list the total number of VGDAs for the VG ?
# lqueryvg -p PVname -D

g. How to list each LVID, LV name, state for each logical volume ?
# lqueryvg -p PVname -l

h. How to list each PVID, number of VGDAs and state for each PV in the VG ?
# lqueryvg -p PVname -P

i. How to list all the attributes with tags for the vG ?
# lqueryvg -p PVname -At

j. How to list the VGID from that physical volume ?
# lqueryvg -p PVname -v

7. How do you move a physical partition ( actually its just a data between PPs) ?
# lmigratepp -g VGID -p old_PVID -n old_PPNum -P new_PVID -N new_PPNum

8. How to retrive the VG name for a particular LV from ODM ?
# getlvodm -b LVID

9. How to retrive all configured PVs from ODM ?
# getlvodm -C

10. How to retrive the major number for a VGID from ODM ?
# getlvodm -d VGID

11. How to retrive the logical volume allocation characteristics for a LVID from ODM ?
# getlvodm -c LVID

12. How to retrive the free configured PVs from ODM ?
# getlvodm -F

13. How to retrive the strip size for a LVID from ODM ?
# getlvodm -F LVID

14. How to retrive the PV name for a PVID from ODM ?
# getlvodm -g PVID

15. How to retrive all VG names from the ODM ?
# getlvodm -h

16. How to retrive the VGID for a PVID from ODM ?
# getlvodm -j PVID

17. How to retrive the LVs and LVIDs for a VG name or VGID from ODM ?
# getlvodm -L VGDescriptor

18. How to retrive the LVID/LV Name for a LV Name or LVID from ODM ?
# getlvodm -l LVDescriptor

19. How to retrive the mount point for a LVID from ODM ?
# getlvodm -m LVID

20. How to retrive the stripe width for a LVID from ODM ?
# getlvodm -N LVID

21. How to retrive the PVID/PN name for a PV name or PVID from ODM ?
# getlvodm -p PVDesciptor

22. How to retrive the PV names, PVIDs and VGs of all configured PVs from ODM ?
# getlvodm -P

23. How to retrive the relocatable flag for a LVID from ODM ?
# getlvodm -r LVID

24. How to retrive the VG state for a VG from ODM ?
# getlvodm -s VGDescriptor

25. How to retrive the timestamp for a VG from ODM ?
# getlvodm -T VGDescriptor

26. How to retrive the VG name for a VGID from ODM ?
# getlvodm -t VGID

27. How to retrive the auto-on value for a VG name or VGID from ODM ?
# getlvodm -v VGDesciptor

28. How to retrive the VGID for a vG name ?
# getlvodm -v VGDesciptor

29. How to retrive the PV names and PVIDs for a VG from ODM ?
# getlvodm -w VGDesciptor

30. How to retrive the LV type ffor a LVID from ODM ?
# getlvodm -y LVID

31. How to retrive the concurrent capable flag for a VG from ODM ?
# getlvodm -X VGDescriptor

32. How to retrive the auto-on concurrent flag for a VG from ODM ?
# getlvodm -x VGDescriptor

33. How to display the contents of LVCB ?
# getlvcb -A LVName

34. How to list the number of copies of a LV from LVCB ?
# getlvcb -c LVName

35. How to list the file system name of a LV from LVCB ?
# getlvcb -f LVName

36. How to list the label of a LV from LVCB ?
# getlvcb -L LVName

37. How to display the type of the file system from LVCB ?
# getlvcb -t LVName

38. How to display the upper limit from LVCB ?
# getlvcb -u LVName

39. How to list the current defrag state of a file system ?
# defrag -q Filesystem

40. How to lsit the current and future (if degragmented) state of a file system ?
# degrag -r Filesystem

41. How to defragment a file system ?
# defrag Filesystem

42. How to run fsck on 2 filesystems simultaneously on different drives ?
# dfsck FileSystem1 FileSystem2

43. How to list the superblock, i-name map, disk map information for a file system ?
# dumpfs Filesystem

44. Where is the magic file located ?
/etc/magic

45. How do you remove a file system data from /etc/filesystems ?
# imfs -x -l LVName

46. How do you list inode, last update/modify/access timestamp of a file ?
# istat FileName

47. How do you update the i-node table and write buffered files to the hard disk ?
# sync

48. How do you list the filesystems in a volume group ?
# lsvgfs VGName

49. How do you redefine the set of PVs of a VG in the ODM ?
# redefinevg -d PVName VGName

50. How do you replace a PV in a VG ?
# replacepv SourcePV DestinationPV

------------------------------------------------------------------------------------------------

Adding a fileset to a SPOT

For example, if you wish to add the bos.alt_disk_install.rte fileset to a SPOT:

List the available spots:
# lsnim -t spot | grep 61
SPOTaix61tl05sp03     resources       spot
SPOTaix61tl03sp07     resources       spot
List the available lpp sources:
# lsnim -t lpp_source | grep 61
LPPaix61tl05sp03       resources       lpp_source
LPPaix61tl03sp07       resources       lpp_source
Check if the SPOT already has this file set:
# nim -o showres SPOTaix61tl05sp03 | grep -i bos.alt
No output is shown. The fileset is not part of the SPOT. Check if the LPP Source has the file set:
# nim -o showres LPPaix61tl05sp03 | grep -i bos.alt
  bos.alt_disk_install.boot_images 6.1.5.2                    I  N usr
  bos.alt_disk_install.rte    6.1.5.1                    I  N usr,root
Install the first fileset (bos.alt_disk_install.boot_images) in the SPOT. The other fileset is a prerequisite of the first fileset and will be automatically installed as well.
# nim -o cust -a filesets=bos.alt_disk_install.boot_images
-a lpp_source=LPPaix61tl05sp03 SPOTaix61tl05sp03
Note: Use the -F option to force a fileset into the SPOT, if needed (e.g. when the SPOT is in use for a client). 

Check if the SPOT now has the fileset installed:
# nim -o showres SPOTaix61tl05sp03 | grep -i bos.alt
  bos.alt_disk_install.boot_images
  bos.alt_disk_install.rte 6.1.5.1 C F Alternate Disk Installation

------------------------------------------------------------------------------------------------

AIX - Boot Tips
By Surya12:59No comments
AIX Boot process
Contents of Boot Logical Volume (/dev/hd5) 
How to change the current Boot device order 
Viewing AIX Boot and console Logs 
Open Firmware
Contents of Boot Logical Volume:
Kernal - Copy of /unix
LVM Commands
ODM Predefined Structure
ODM Customized Structure
rc.boot shell script
Listing and changing the current boot order:
bootlist -m normal -o          # Lists the current bootlist 
bootlist -m normal cd0 hdisk0  # To set cd0 and hdisk0 as first and second boot devices
bootlist -m service cd0 rmt0   # To change the bootlist for service mode
Viewing AIX Boot and Console Logs:
Boot and console messages can be used to identify and fix problems. These messages are automatically stored on disk by AIX. To view the stored messages, use the alog command. Here are a couple examples of the alog command:
 #alog -L        #  List the defined log types
 # alog -L
 boot
 bosinst
 nim
 console
 cfg
 dumpsymp

# alog -o -t boot  #  View the boot log
# alog -o -t console #  View the console log
To find out the properties of boot log file:
# alog -L -t boot
 file:size:verbosity
 /var/adm/ras/bootlog:131072:1
To find out whether a Hard drive is bootable:
 # ipl_varyon -i
 PVNAME          BOOT DEVICE     PVID                                    VOLUME GROUP ID
 hdisk0          YES             00c898eb372ea9410000000000000000        00c898eb00004c00
 hdisk1          YES             00c898eb38483a300000000000000000        00c898eb00004c00
 hdisk2          NO              00c898bbdd86318c0000000000000000        00c898bb00004c00
Open Firmware:
To get to open fimware, press F8 / 8 during system startup.
If the system hangs during boot, to get the detailed information of the boot messages, from the OK prompt:
OK> boot -s verbose

------------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------------

1. How to list IDE controllers in your system ?

lscfg -l ide*

Sample Output:

DEVICE LOCATION DESCRIPTION
ide0 01-00-00 ATA/IDE Controller Device
ide1 01-00-01 ATA/IDE Controller Device

It shows
Controller ide0 and ide1 are located on the system planar
(Notice 1st and 2nd digits in location code).
The planar indicator is the second digit in the location value with a value of 1.
6th digit indicates the controller number.

2. After a successful login, the login command displays the message of the day, the date and time of the last successful and unsuccessful login attempts for this user, and the total number of unsuccessful login attempts for this user since the last change of authentication information (usually a password).

How to supress these messages?

You can supress these messages by creating a .hushlogin file in your home directory.

At the prompt in your home directory, type the following:
# touch .hushlogin

The touch command creates the empty file named .hushlogin if it does not already exist. The next time you log in, all login messages will be suppressed. You can instruct the system to retain only the message of the day, while suppressing other login messages.

3. What are the files, system reads when you logon ?

First File : /etc/environment - contains variables specifying the basic environment for all processes.

Second File: /etc/profile - controls system-wide default variables

Third File : $HOME/.profile - lets you customize your individual working environment

Fourth File: $HOME/.env - lets you customize your individual working environment variables.


4. How to override variables defined in /etc/environment for a particular user?

A fourth file that the operating system uses at every user logon is the
$HOME/.env file, if your .profile contains the following line: export
ENV=$HOME/.env The .env file lets you customize your individual
working environment variables.

The .env file contains the individual user environment variables that override the variables set in the /etc/environment file. You can customize your environment variables as desired by modifying your .env file.

5. How to change the font in AIX ?

To change the font to an italic, roman, and bold face of the same size, type the following:

# chfont -n /usr/lpp/fonts/It114.snf /usr/lpp/fonts/Bld14.snf /usr/lpp/
fonts/Rom14.snf

You can also use smitty chfont.

6. How to run a process in the background ?

For Ex, to run script1.sh in background run

# script1.sh & -> But this script process gets killed if you close the terminal

So always run, # nohup script1.sh &

Usage of nohup doesn't kill the process if you close the telnet session.
Output from the process/script will be stored in a file called nohup.out in the directory from where you started the process.

So if you want to start backup using mksysb and close your terminal wihle leaving leaving office, you can safely use "nohup command &".

Next day morning, you can view the contents of nohup.out to know the status of the backup job.

7. Whats the default priority for a process?

Default priority is 0. Priority numbers is in the range of -20 to 20.
Highest number is the lowest priority and lowest number has hight priority.

To set the priority while start a process, use nice command.
If the process is already running, you can use "renice" command to change its priority.

8. How to stop, resume a process and to make it foreground process?

To stop(pause) a foreground process, use Cntrol + Z keys ie., Ctrl+Z.

Note: Ctrl+Z works in the Korn shell (ksh) and C shell (csh), but not in the Bourne shell (bsh). To restart a stopped process, you must either be the user who started the process or have root user authority.

To restart a stopped process, enter
# kill -19 pid

To run it in foreground, enter
# fg pid

where pid is the procedd id which can be obtained from "ps -ef | grep process_name"

9. How to display a program output as well as copying to a file ?

Normally usage of output redirection supresses the output on screen.
Ex. ls -l > file1

If we want to redirect the output as well as show the output in screen use the tee command.

Ex: ls -l | tee -a file1

10. How to capture the terminal screen to a file ?

To capture the screen of a terminal, at the prompt, type the following:

#script

The system displays information similar to the following:

Script command is started. The file is typescript.

Everything displayed on the screen is now copied to the "typescript" file.

To stop the script command, press Ctrl-D or type exit and press Enter.

The system displays information similar to the following:

^D
Script command is complete. The file is typescript.

Use the cat command to display the contents of your file.

11. How to number all lines in a file ?

# n1 -ba file1.txt

This will display all lines of file1.txt alongwith their line number.

12. What are the supported file systems in AIX ?

a) JFS (or) JFS2 - Disk based file system
b) NFS - Network based File system
c) CDRFS - CDROM based file system
d) UDFS - DVD-ROM based file system
e) RAMFS - RAM based file system used while booting the system

13. What are the different directory abbreviations ?

Abbreviation Meaning
. The current working directory
.. The parent of the current working directory
~ Your home directory
$HOME Your home directory

14. What are the different directory path names ?

Absolute path name - Traces the path from the /(root) directory.
Absolute path names always begin with the slash (/) symbol.
Ex. /home/raja/dir1

Relative path name - Traces the path from the current directory
through its parent or its subdirectories and files. As user "raja", I
can say ./dir1 since I'm already in /home/raja

15. How to move a directory ?

# mvdir book manual

This moves the book directory under the directory named manual, if the manual directory exists. Otherwise, the book directory is renamed to manual.

16. What the RAID groups AIX LVM supports?

RAID-0 - Striping
RAID-1 - Mirroring
RAID-10 (or) RAID 0+1 - Mirroring and striping

17. How to read and remove mails from my system mailbox?

At your system command line prompt, enter the mail command:
# mail

If there is no mail in your system mailbox, the system responds with a message:
No mail for YourID

If there is mail in your mailbox, the system displays a listing of the messages in your system mailbox:

Mail Type ? for help.
"/usr/mail/lance": 3 messages 3 new
>N 1 karen Tue Apr 27 16:10 12/321 "Dept Meeting"
N 2 lois Tue Apr 27 16:50 10/350 "System News"
N 3 tom Tue Apr 27 17:00 11/356 "Tools Available"

The current message is always prefixed with a greater-than symbol (>).

Each one-line entry displays the following fields:

status - Indicates the class of the message.
number - Identifies the piece of mail to the mail program.
sender - Identifies the address of the person who sent the mail.
date - Specifies the date the message was received.
size - Defines the number of lines and characters contained in the message (this includes the header).
subject- Identifies the subject of the message, if it has one.

The status can be any of the following:
N - A new message.
P - A message that will be preserved in your system mailbox.
U - An unread message. This is a message that was listed in the mailbox the last time you used the mail program, but the contents were not examined.
* - A message that was saved or written to a file or folder.

18. What is the difference between IBM system p5 570 and IBM System p570 Server models ?

IBM System p5 570 is the P5(Power5 Processor) server whereas System p
570 is the latest model from IBM containing POWER 6 Processor.

19. How to display the values of NFS tuning parameters?

# nfso -o

20. How to monitor the performance of file systems?

Use filemon command.

21. How to list the available memory slots (DIMM) in your pSeries box ?

# lscfg -vp | grep -e "Memory DIMM" -e "Size"

22. What are the login programs what do not need AIX license ?

ftp, rsh and recec.

23. Have you seen some people use rmt0.1 (or) rmt1.5 for tape device name. We know rmt0 or rmt5 is a tape drive name but whats the ".1" or ".5" that comes after the tape drive name.

Here is the logic

rmt0.x where x = A + B + C

A = density 0 = high 4 = low
B = retension 0 = no 2 = yes
C = rewind 0 = yes 1 = no

So rmt0.1 means tape drive rmt0 with no rewind.
Normally if we use rmt0 for taking backup, after the backup operaation
tape gets rewinded. IF you dont want to rewind, use rmt0.1

24. Tips on System Dump Device

a) Don't mirror the system dump device
b) Don't use compression on the dump device
c) Don't use a secondary dump device unless it is on a seperate device

25. How to monitor/obtain LVM performance?

Use lvmstat command.

26. How to monitor/obtain NFS performance statistics?

Use nfsstat command.

27. How to set the variables defined in a file to the current shell/ environment ?

Suppose you the following variable defined in file1.sh

LANG=jp_JP
TZ=CUT-5

To set them in current shell, run ". ./file1.sh"

28. How will you encode a binary file ?

uuencode command converts a binary file to ascii data. This is mainly used for sending a file thru mail.

For Ex.,
uuencode source_file output_file

29. How you decode a file (which was encoded using uuencode command) ?

# uudecode source_file

30. How to view a a compressed file without uncompressing it ?

Use "zcat file1.Z"

31. How to configure the system to send mails each time an error is added to error report

a. Create a file /tmp/mailtoroot

errnotify:
en_name = "mailtoroot"
en_persistenceflg = 1
en_method = "/usr/bin/errpt -a -l $1 | mail -s \"errpt: $9\" root"

b. odmadd /tmp/mailtoroot

c. Verify by creating a error message

# errlogger 'Test Error Message"

You can always remove this ODM entry using the below command:

# odmdelete -q 'en_name=mailtoroot' -o errnotify

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------
AIX- Devices
By Surya13:04No comments
Devices information is  stored in ODM. There are two device configuration databases in AIX

Predefined Database contains data for all the supported devices based on the system configuration.
Customized Database contains configuration database for all currently defined and configured (available) devices.
The devices in AIX can be in any of the following states
01. Available  - Device is ready and can be used
02. Defined    - Device is unavailable
03. Unknown    - Undefined
04. Stopped    - Configured but unavailable
To list the devices:
lsdev
      -C  to list customized database
      -P  to list predefined database
      -c (class) 
      -t (type) 
      -s (subtype)
To list all customised devices ie installed
 # lsdev -C  
To list all the Hard Drives in a system
 # lsdev -Cc disk
To list all the adapters in a sytem
 # lsdev -Cc adapter
To find out the type of Fibre adapter
 # lsdev -Ct df1000f* -F "type" -l fcs1
To find out the parent of ent0 device
 # lsdev -Cl ent0 -F parent
To list the supported device classes from the Predefined Devices object class,
 # lsdev -P -r class
            PCM
            adapter
            aio
            array
            bus
            cdrom
            .......
            ......
To list the name, class, subclass, and type of every device in the Available state in the Customized Devices object class with column headers:
 # lsdev -C -H -S a -F 'name class subclass type'
            name       class     subclass type
            sys0       sys       node     chrp
            sysplanar0 planar    sys      sysplanar_rspc
            mem0       memory    sys      totmem
            L2cache0   memory    sys      L2cache_rspc
            proc0      processor sys      proc_rspc
            pci0       bus       chrp     pci
            pci1       bus       chrp     pci
            isa0       bus       pci      isac
            siota0     adapter   isa_sio  isa_tablet
            ppa0       adapter   isa_sio  chrp_ecp
            sa0        adapter   isa_sio  pnp501
            sa1        adapter   isa_sio  pnp501
            paud0      adapter   isa_sio  baud4232
To display configuration and vital product data (VPD) about the system:
lscfg
      -v   Displays the VPD found on customized Database
      -p   display paltform specifig device info. 
      -l <device_name>
To list all installed devices in detail
 # lscfg -v  
To find out the WWN, FRU #, firmware level of fibre adapter fcs0

# lscfg -vpl fcs0
 lscfg -vpl fcs0
  fcs0             U7879.001.DQDRDGG-P1-C4-T1  FC Adapter

        Part Number.................03N7069
        EC Level....................A
        Serial Number...............1B64304D32
        Manufacturer................001B
        Customer Card ID Number.....280B
        FRU Number.................. 03N7069
        Device Specific.(ZM)........3
        Network Address.............10000000C95C98D3
        ROS Level and ID............02881955
        Device Specific.(Z0)........1001206D
        Device Specific.(Z1)........00000000
        Device Specific.(Z2)........00000000
        Device Specific.(Z3)........03000909
        Device Specific.(Z4)........FF801413
        Device Specific.(Z5)........02881955
        Device Specific.(Z6)........06831955
        Device Specific.(Z7)........07831955
        Device Specific.(Z8)........20000000C95C98D3
        Device Specific.(Z9)........TS1.91A5
        Device Specific.(ZA)........T1D1.91A5
        Device Specific.(ZB)........T2D1.91A5
        Device Specific.(ZC)........00000000
        Hardware Location Code......U7879.001.DQDRDGG-P1-C4-T1


  PLATFORM SPECIFIC

  Name:  fibre-channel
    Model:  LP10000
    Node:  fibre-channel@1
    Device Type:  fcp
    Physical Location: U7879.001.DQDRDGG-P1-C4-T1
To display attributes and possible values of attributes for devices:
lsattr
       -E Displays the effective value
       -D Displays the Default Value
       -R Displays the range of legal values
       -a <Attribute>
       -l <Device_name>
Examples:
To find out the possible media_speed values for ethernet card ent0
# lsattr -El ent0 -a media_speed -R
  10_Half_Duplex
  10_Full_Duplex
  100_Half_Duplex
  100_Full_Duplex
  Auto_Negotiation
To find out the effective attribute of a device "mem0"
 # lsattr -El mem0 
 goodsize 512 Amount of usable physical memory in Mbytes False
 size     512 Total amount of physical memory in Mbytes  False
To list the defaults in the pre-defined db for device ent0
 # lsattr -El sys0
To Change the attributes of devices:
-
chdev
       -l <device name>
       -a <attribute=new_value>
       -T to change the value temporarily
       -P to make the change permanent after reboot if the 
          device is currently in use and can not be changed
To change the SCSI ID of adapter scsi0 that cannot be changed made unavailable due to available disk drives connected to it
 # chdev  -l scsi0 -a id=6 -P
To change the maximum number of processes allowed per user
Find out the valid range of values using lsattr command
 # lsattr -l sys0 -a maxuproc -R
 40...131072 (+1)

Change the maxuproc value using chdev command
 # chdev -l sys0 -a maxuproc=10000
To remove the devices:
rmdev
       -d removes the device from Customized DB
       -l <device_name>
       -R Unconfigure device and its chidren
       -S Makes deviec un-availabel by using stop method
To change device state from available to defined
 # rmdev -l (device)  
To delete the device
 # rmdev -l (device) -d 
To delete the scsi adapter scsi0 and all its child devices
 # rmdev -Rdl scsi0
Add device to the system:
mkdev
      -d  define
      -c  class
      -l <logical device name>
      -p  parent name
      -s  subclass
      -t  type
Examples:
To define a tape device
 # mkdev -d -c tape -t 8mm -s scsi -p scsi0  -w 5,0
To make the predefined rmt0 tape to available status
 # mkdev -l rmt0
Configuring New Devices using cfgmgr:
cfgmgr configures devices and optionally installs device software by running the programs specified in the Configuration Rules object class.

cfgmgr
       -v   To give detailed output
       -l <Device_name>   To configure the device and
                          all it's chidren
       -i <device>   Location of installation medium
To search for new devices and configure them
 #cfgmgr
To configure detected devices attached to the fcs0 adapter
 # cfgmgr -l fcs0
To install device drivers which is in /tmp/drivers automatically during configuration
 # cfgmgr -i /tmp/drivers
Getting System configuration variable values
getconf, bootinfo commands can be used to collect the system configuration variable values such as kernel bit, hardware bit, boot device, real mem present, disk size etc... bootinfo command is not supported on Aix V5.2 onwards.
Using bootinfo command
To find out the Kernel whether it is 32-bit or 64bit
 # bootinfo -K      ---- > for Kernel  
 # bootinfo -y      ---- > for Hardware 

 # bootinfo -s hdiskx ----> to find out the size of the hard drive
Some useful getconf command examples
 # getconf KERNEL_BITMODE  
 64
 # getconf HARDWARE_BITMODE
 64
 # getconf DISK_SIZE /dev/hdisk0
 8678
 # getconf REAL_MEMORY
 524288
 # getconf BOOT_DEVICE
 hdisk0
 # getconf DISK_DEVNAME hdisk0
 10-60-00-4,0
 # getconf MP_CAPABLE
 0
Displaying system configuration information
prtconf command displays system Configuration information. If run without any flags, it displays the system model, machine serial, processor type, number of processors, processor clock speed, cpu type, total memory size, network information, filesystem information, paging space information, and devices information

Flags:-
 -c Displays cpu type, for example, 32-bit or 64-bit.
 -k Display the kernel in use, for example, 32-bit or 64-bit.
 -L Displays LPAR partition number and partition name if this is an LPAR partition, 
    otherwise returns "-1 NULL".
 -m Displays system memory.
 -s Displays processor clock speed in MHz.
 -v Displays the VPD found in the Customized VPD object class for devices.
Examples:-
 # prtconf -c
 CPU Type: 64-bit

 # prtconf -m
 Memory Size: 4096 MB

 # prtconf -s
 Processor Clock Speed: 1654 MHz

 # prtconf
 System Model: IBM,9119-595
 Machine Serial Number: 02898EB
 Processor Type: PowerPC_POWER5
 Number Of Processors: 2
 Processor Clock Speed: 1654 MHz
 CPU Type: 64-bit
 Kernel Type: 64-bit
 LPAR Info: 5 sapnims
 Memory Size: 4096 MB
 Good Memory Size: 4096 MB
 Platform Firmware level: Not Available
 Firmware Version: IBM,SF235_209
 Console Login: enable
 Auto Restart: true
 Full Core: false

 Network Information
        Host Name: sapnims
        IP Address: 10.253.1.24
        Sub Netmask: 255.255.255.0
        Gateway: 10.253.1.253
        Name Server: 128.137.24.4
        Domain Name: gene.com

 Paging Space Information
        Total Paging Space: 512MB
        Percent Used: 1%

 Volume Groups Information
 
 rootvg:
 PV_NAME           PV STATE          TOTAL PPs   FREE PPs    FREE DISTRIBUTION
 hdisk0            active            546         1           00..00..00..00..01
 hdisk1            active            546         1           00..00..00..00..01
 
 .......................
 .......................
 ......................
List firmware and microcode level
lsmcode command display the firmware and microcode level

-A to list microcode information for all supported devices
-c To display levels without using menus
-r To display levels in tabular format
-d <device Name> to display mictocode level for a device
 lsmcode -c 
 The current permanent system firmware image is AM730_035
 The current temporary system firmware image is AM730_035
 The system is currently booted from the temporary firmware image.

 lsmcode -A
 sys0!system:AM730_035 (t) AM730_035 (p) AM730_035 (t) 
 hba0!2514300014108c03.RR0120
 hba1!2514300014108c03.RR0120
 sissas0!53495320.04200029
 sissas1!53495322.04220029
 hdisk0!ST91468.A1700D26.43413036
 hdisk1!ST91468.A1700D26.43413036
 fcs0!df1000fe-0002.271315
 fcs1!df1000fe-0002.271315

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------
AIX Disk Queue Depth Tuning for Performance

Purpose

The purpose of this document is to describe how IOs are queued the disk device driver and the adapter device driver, SDD, and SDDPCM and to explain how these can be tuned to increase performance. And this also includes the use of VIO. This information is also useful for AIX LPARs using other multi-path code as well. 

Where this stuff fits in the IO stack

Following is the IO stack from the application to the disk:

Application
File system (optional)
LVM device driver (optional)
SDD or SDDPCM or other multi-path driver (if used)
hdisk device driver
adapter device driver
interconnect to the disk
Disk subsystem
Disk

Note that even though the disk is attached to the adapter, the hdisk driver code is utilized before the adapter driver code. So this stack represents the order software comes into play over time as the IO traverses the stack.

Why do we need to simultaneously submit more than one IO to a disk?

This improves performance. And this would be performance from an application's point of view. This is especially important with disk subsystems where a virtual disk (or LUN) is backed by multiple physical disks. In such a situation, if we only could submit a single IO at a time, we'd find we get good IO service times, but very poor thruput. Submitting multiple IOs to a physical disk allows the disk to minimize actuator movement (using an "elevator" algorithm) and get more IOPS than is possible by submitting one IO at a time. The elevator analogy is appropriate. How long would people be waiting to use an elevator if only one person at a time could get on it? In such a situation, we'd expect that people would wait quite a while to use the elevator (queueing time), but once they got on it, they'd get to their destination quickly (service time). So submitting multiple in-flight IOs to a disk subsystem allows it to figure out how to get the most thruput and fastest overall IO service time.

Theoretically, the IOPS for a disk is limited by queue_depth/(average IO service time). Assuming a queue_depth of 3, and an average IO service time of 10 ms, this yields a maximum thruput of 300 IOPS for the hdisk. And for many applications this may not be enough thruput. 

Where are IOs queued?

As IOs traverse the IO stack, AIX needs to keep track of them at each layer. So IOs are essentially queued at each layer. Generally, some number of in flight IOs may be issued at each layer and if the number of IO requests exceeds that number, they reside in a wait queue until the required resource becomes available. So there is essentially an "in process" queue and a "wait" queue at each layer (SDD and SDDPCM are a little more complicated). 

At the file system layer, file system buffers limit the maximum number of in flight IOs for each file system. At the LVM device driver layer, hdisk buffers limit the number of in flight IOs. At the SDD layer, IOs are queued if the dpo device's attribute, qdepth_enable, is set to yes (which it is by default). Some releases of SDD do not queue IOs so it depends on the release of SDD. SDDPCM on the other hand does not queue IOs before sending them to the disk device driver. The hdisks have a maximum number of in flight IOs that's specified by its queue_depth attribute. And FC adapters also have a maximum number of in flight IOs specified by num_cmd_elems. The disk subsystems themselves queue IOs and individual physical disks can accept multiple IO requests but only service one at a time. Here are an ESS hdisk's attributes:

# lsattr -El hdisk33
PR_key_value none Reserve Key True
location Location Label True
lun_id 0x5515000000000000 Logical Unit Number ID True
lun_reset_spt yes Support SCSI LUN reset True
max_transfer 0x40000 N/A True
node_name 0x5005076300c096ab FC Node Name False
pvid none Physical volume identifier False
q_type simple Queuing TYPE True
qfull_dly 20 delay in seconds for SCSI TASK SET FULL True
queue_depth 20 Queue DEPTH True
reserve_policy single_path Reserve Policy True
rw_timeout 60 READ/WRITE time out value True
scbsy_dly 20 delay in seconds for SCSI BUSY True
scsi_id 0x620713 SCSI ID True
start_timeout 180 START unit time out value True
ww_name 0x5005076300cd96ab FC World Wide Name False

The default queue_depth is 20, but can be changed to as high as 256 for ESS, DS6000 and DS8000. One can display allowable values with:

# lsattr -Rl hdisk33 -a queue_depth
1...256 (+1)

indicating the value can be anywhere from 1 to 256 in increments of 1. One can use this command to see any allowable value for attributes which can be changed (showing a value of True in the last field of "lsattr -El <device>" for the device using:

# lsattr -Rl <device> -a <attribute>

Here's a FC adapter's attributes:

# lsattr -El fcs0
bus_intr_lvl 65703 Bus interrupt level False
bus_io_addr 0xdec00 Bus I/O address False
bus_mem_addr 0xe8040000 Bus memory address False
init_link al INIT Link flags True
intr_priority 3 Interrupt priority False
lg_term_dma 0x800000 Long term DMA True
max_xfer_size 0x100000 Maximum Transfer Size True
num_cmd_elems 200 Maximum number of COMMANDS to queue to the adapter True
pref_alpa 0x1 Preferred AL_PA True
sw_fc_class 2 FC Class for Fabric True

The default queue depth (num_cmd_elems) for FC adapters is 200 but can be increased up to 2048 for most adapters.

Here's the dpo device's attributes for one release of SDD:

# lsattr -El dpo
Enterpr_maxlun 600 Maximum LUNS allowed for Enterprise Products True
Virtual_maxlun 512 Maximum LUNS allowed for Virtualization Products False
persistent_resv yes Subsystem Supports Persistent Reserve Command False
qdepth_enable yes Queue Depth Control True

When qdepth_enable=yes, SDD will only submit queue_depth IOs to any underlying hdisk (where queue_depth here is the value for the underlying hdisk's queue_depth attribute). When qdepth_enable=no, SDD just passes on the IOs directly to the hdisk driver. So the difference is, if qdepth_enable=yes (the default), IOs exceeding the queue_depth will queue at SDD, and if qdepth_enable=no, then IOs exceed the queue_depth will queue in the hdisk's wait queue. In other words, SDD with qdepth_enable=no and SDDPCM do not queue IOs and instead just pass them to the hdisk drivers. Note that at SDD 1.6, it's preferable to use the datapath command to change qdepth_enable, rather than using chdev, as then it's a dynamic change, e.g., datapath set qdepth disable will set it to no. Some releases of SDD don't include SDD queueing, and some do, and some releases don't show the qdepth_enable attribute. Either check the manual for your version of SDD or try the datapath command to see if it supports turning this feature off. 

If you've used both SDD and SDDPCM, you'll remember that with SDD, each LUN has a corresponding vpath and an hdisk for each path to the vpath or LUN. And with SDDPCM, you just have one hdisk per LUN. Thus, with SDD one can submit queue_depth x # paths to a LUN, while with SDDPCM, one can only submit queue_depth IOs to the LUN. If you switch from SDD using 4 paths to SDDPCM, then you'd want to set the SDDPCM hdisks to 4x that of SDD hdisks for an equivalent effective queue depth. And migrating to SDDPCM is recommended as it's more strategic than SDD.

Both the hdisk and adapter drivers have an "in process" and "wait" queues. Once the queue limit is reached, the IOs wait until an IO completes, freeing up a slot in the service queue. The in process queue is also sometimes referred to as the "service" queue

It's worth mentioning, that many applications will not generate many in flight IOs, especially single threaded applications that don't use asynchronous IO. Applications that use asynchronous IO are likely to generate more in flight IOs.

What tools are available to monitor the queues?

For AIX, one can use iostat (at AIX 5.3 or later) and sar (5.1 or later) to monitor the hdisk driver queues. The iostat -D command generates output such as:

hdisk6 xfer: %tm_act bps tps bread bwrtn 
4.7 2.2M 19.0 0.0 2.2M
read: rps avgserv minserv maxserv timeouts fails
0.0 0.0 0.0 0.0 0 0
write: wps avgserv minserv maxserv timeouts fails
19.0 38.9 1.1 190.2 0 0
queue: avgtime mintime maxtime avgwqsz avgsqsz sqfull
15.0 0.0 83.7 0.0 0.0 136

Here, the avgwqsz is the average wait queue size, and avgsqsz is the average service queue size. The average time spent in the wait queue is avgtime. The sqfull value has changed from initially being a count of the times we've submitted an IO to a full queue, to now where it's the rate of IOs per second submitted to a full queue. The example report shows the prior case (a count of IOs submitted to a full queue), while newer releases typically show decimal fractions indicating a rate. It's nice that iostat -D separates reads and writes, as we would expect the IO service times to be different when we have a disk subsystem with cache. The most useful report for tuning is just running "iostat -D" which shows statistics since system boot, assuming the system is configured to continuously maintain disk IO history (run # lsattr -El sys0, or smitty chgsys to see if the iostat attribute is set to true). And the author's favorite iostat command flags are "iostat -RDTl <interval> <#intervals>".

From the application's point of view, the length of time to do an IO is its service time plus the time it waits in the hdisk wait queue. 

The sar -d command changed at AIX 5.3, and generates output such as:

16:50:59     device    %busy    avque    r+w/s    Kbs/s   avwait   avserv
16:51:00     hdisk1      0      0.0        0        0      0.0      0.0
             hdisk0      0      0.0        0        0      0.0      0.0

The avwait and avserv are the average times spent in the wait queue and service queue respectively. And avserv here would correspond to avgserv in the iostat output. The avque value changed; at AIX 5.3, it represents the average number of IOs in the wait queue, and prior to 5.3, it represents the average number of IOs in the service queue.

SDDPCM provides the "pcmpath query devstats" and "pcmpath query adaptstats" commands to show hdisk and adapter queue statistics. SDD similarly has "datapath query devstats" and "datapath query adaptstats". You can refer to the SDD/SDDPCM manual for syntax, options and explanations of all the fields. Here's some devstats output for a single LUN:

Device #: 0
=============
Total Read Total Write Active Read Active Write Maximum
I/O: 29007501 3037679 1 0 40
SECTOR: 696124015 110460560 8 0 20480

Transfer Size: <= 512 <= 4k <= 16K <= 64K > 64K
21499 10987037 18892010 1335598 809036

and here's some adaptstats output:

Adapter #: 0
=============
Total Read Total Write Active Read Active Write Maximum
I/O: 439690333 24726251 7 0 258
SECTOR: 109851534 960137182 608 0 108625

Here, we're mainly interested in the Maximum field which indicates the maximum number of IOs submitted to the device since system boot. 

For SDD, the Maximum for devstats will not exceed queue_depth x # paths when qdepth_enable=yes. But Maximum for adaptstats can exceed num_cmd_elems as it represents the maximum number of IOs submitted to the adapter driver and includes IOs for both the service and wait queues. If, in this case, we have 2 paths and are using the default queue_depth of 20, then the 40 indicates we've filled the queue at least once and increasing queue_depth can help performance. 

For SDDPCM, if the Maximum value equals the hdisk's queue_depth, then the hdisk driver queue was filled during the interval, and increasing queue_depth is usually appropriate.

One can similarly monitor adapter IOPS with # iostat -at <interval> <# of intervals> and for adapter queue information, run # iostat -aD, optionally with an interval and number of intervals. For FC adapters, the fcstat command provides information on the adapter queue and resource use, and can tell us if we need to increase its queue sizes. 

For adapter queues, the fcstat command is used and is discussed below. 

How to tune

First, one should not indiscriminately just increase these values. It's possible to overload the disk subsystem or cause problems with device configuration at boot. So the approach of adding up the hdisk's queue_depths and using that to determine the num_cmd_elems isn't necessarily the best approach. Instead, it's better to use the maximum number of submitted IOs to each device for tuning. When you increase the queue_depths and number of in flight IOs that are sent to the disk subsystem, the IO service times are likely to increase, but throughput will also increase. If IO service times start approaching the disk timeout value, then you're submitting more IOs than the disk subsystem can handle. If you start seeing IO timeouts and errors in the error log indicating problems completing IOs, then this is the time to look for hardware problems or to make the pipe smaller. 

A good general rule for tuning queue_depths, is that one can increase queue_depths until IO service times start exceeding 15 ms for small random reads or writes or one isn't filling the queues. Once IO service times start increasing, we've pushed the bottleneck from the AIX disk and adapter queues to the disk subsystem. Two approaches to tuning queue depth are 1) base the queue depths on actual IO requests your application generate or 2) use a test tool to see what the disk subsystem can handle and tune the queues based on what the disk subsystem can handle. The ndisk tool (part of the nstress package available on the internet at http://www-941.ibm.com/collaboration/wiki/display/WikiPtype/nstress) can be used to stress the disk subsystem to see what it can handle. The author's preference is to tune based on your application IO requirements, especially when the disk is shared with other servers. 

For tuning, we can categorize the situation into four categories:
We're filling up the queues and IOs are waiting in the hdisk or adapter drivers
We're not filling up the queues, and IO service times are good
We're not filling up the queues, and IO service times are poor
We're not filling up the queues, and we're sending IOs to the storage faster than it can handle and it loses the IOs

We want to tune the queues to be in either situation 2 or 3. If we're in situation 3, that indicates a bottleneck beyond the hdisk driver which will typically be in the disk subsystem itself, but could also be in the adapter driver or SAN fabric. 

Situation 4 is something we do want to avoid. All disks and disk subsystem have limits regarding the number of in-flight IOs they can handle, mainly due to memory limitations to hold the IO request and data. When the storage loses IOs, the IO will eventually time out at the host, recovery code will be used and resubmit the IO, but in the meantime transactions waiting on that IO will be stalled. This isn't a desirable situation, as the CPU ends up doing more work to handle IOs than necessary. If the IO eventually fails, then this can lead to an application crash or worse. So be sure to check your storage documentation to understand its limits. 

Then after running your application during peak IO periods look at the statistics and tune again. 


Regarding the qdepth_enable parameter for SDD, the default is yes which essentially has SDD handling the IOs beyond queue_depth for the underlying hdisks. Setting it to no results in the hdisk device driver handling them in its wait queue. In other words, with qdepth_enable=yes, SDD handles the wait queue, otherwise the hdisk device driver handles the wait queue. There are error handling benefits to allowing SDD to handle these IOs, e.g., if using LVM mirroring across two ESSs. With heavy IO loads and a lot of queueing in SDD (when qdepth_enable=yes) it's more efficient to allow the hdisk device drivers to handle relatively shorter wait queues rather than SDD handling a very long wait queue by setting qdepth_enable=no. In other words, SDD's queue handling is single threaded where each hdisk driver has its own thread. So if error handling is of primary importance (e.g. when LVM mirroring across disk subsystems) then leave qdepth_enable=yes. Otherwise, setting qdepth_enable=no more efficiently handles the wait queues when they are long. Note that one should set the qdepth_enable parameter via the datapath command as it's a dynamic change that way (using chdev is not dynamic for this parameter).

If error handling is of concern, then it's also advisable, assuming the disk is SAN switch attached, to set the fscsi device attribute fc_err_recov to fast_fail rather than the default of delayed_fail, and also change the fscsi device dyntrk attribute to yes rather than the default of no. These attributes assume a SAN switch that supports this feature.


What are reasonable average IO service times?

What is good or reasonable is somewhat a factor of the technology of the storage and the storage cache sizes. Assuming no IOs are queued to a disk, a typical read will take somewhere from 0 to 15 ms, or so, depending on how far the actuator has to travel (seek time), how long it takes the disk to rotate to the right sector (rotation time), and how long it takes to read the data (transfer time). Then the data must move from the storage to the host. Typically the time is dominated by seek time + rotation time, though for large IOs transfer time also can be significant. Sometimes the data will be in disk subsystem read cache, in which case the IO service time is around 1 ms. Typically for large disk subsystems that aren't overloaded, IO service times will average around 5-10 ms. When small random reads start averaging greater than 15 ms, this indicates the storage is getting busy. 

Writes typically go to write cache (assuming it exists) and then these average typically less than about 2.5 ms. But there are exceptions. If the storage is synchronously mirroring the data to a remote site, writes can take much longer. And if the IO is large (say 64 KB or larger) then the transfer time becomes more significant and the average time is slightly worse. If there's no cache, then writes take about the same as reads. 

If the IO is large block sequential, then besides the increased transfer time, we expect IOs to queue at the physical disk, and IO service times to be much longer on average. E.G., if an application submits 50 IOs (say 50 64 KB IOs reading a file sequentially) then the first few IOs will have reasonably good IO service times, while the last IO will have had to wait for the other 49 to finish first, and will have a very long IO service time. 

IOs to SSDs are typically less than 1 ms, and for SSDs in disk subsystems, typically less than 2 ms, and on occasion higher. 

Tuning the FC adapter num_cmd_elems

The fcstat command is perhaps the easiest tool to look for blocked IOs in the adapter's queues, e.g.: 

# fcstat fcs0

FIBRE CHANNEL STATISTICS REPORT: fcs0
...
FC SCSI Adapter Driver Information
No DMA Resource Count: 0 
No Adapter Elements Count: 104848 
No Command Resource Count: 13915968 
...

The values for "No Adapter Elements Count" and "No Command Resource Count" are the number of times since boot that an IO was temporarily blocked due to an inadequate num_cmd_elems attribute value. Non-zero values indicate that increasing num_cmd_elems may help improve IO service times. Of course if the value increments slowly, then the improvement may be very small, while quickly incrementing values means tuning is more likely to have a measurable improvement in performance. 

Like the hdisk queue_depth attribute, changing the num_cmd_elems value requires stopping use of the resources or a reboot. 


Queue depths with VSCSI VIO

When using VIO, one configures VSCSI adapters (for each virtual adapter in a VIOS, known as a vhost device, there will be a matching VSCSI adapter in a VIOC). These adapters have a fixed queue depth that varies depending on how many VSCSI LUNs are configured for the adapter. There are 512 command elements of which 2 are used by the adapter, 3 are reserved for each VSCSI LUN for error recovery and the rest are used for IO requests. Thus, with the default queue_depth of 3 for VSCSI LUNs, that allows for up to 85 LUNs to use an adapter: (512 - 2) / (3 + 3) = 85 rounding down. So if we need higher queue depths for the devices, then the number of LUNs per adapter is reduced. E.G., if we want to use a queue_depth of 25, that allows 510/28= 18 LUNs. We can configure multiple VSCSI adapters to handle many LUNs with high queue depths. each requiring additional memory. One may have more than one VSCSI adapter on a VIOC connected to the same VIOS if you need more bandwidth. 

Also, one should set the queue_depth attribute on the VIOC's hdisk to match that of the mapped hdisk's queue_depth on the VIOS.

For a formula, the maximum number of LUNs per virtual SCSI adapter (vhost on the VIOS or vscsi on the VIOC) is =INT(510/(Q+3)) where Q is the queue_depth of all the LUNs (assuming they are all the same).

Note that to change the queue_depth on an hdisk at the VIOS requires that we unmap the disk from the VIOC and remap it back, or a simpler approach is to change the values in the ODM (e.g. # chdev -l hdisk30 -a queue_depth=20 -P) then reboot the VIOS. 

For LV VSCSI hdisks, where multiple VIOC hdisks are created from a single VIOS hdisk, then one may take a dedicated resource, shared resource or an in between approach to the VIOS hdisk queue slots. See the section below entitled Further theoretical thoughts on shared vs. dedicated resources.


Queue depths with NPIV VIO

When using NPIV, we have virtual FC adapters (vFC) and real FC adapters, and often have multiple vFCs tied to a single real FC adapter. 

If you increase num_cmd_elems on the virtual FC (vFC) adapter, then you should also increase the setting on the real FC adapter. 

You can use the fcstat command for both the virtual adapter as well as the real adapter for tuning purposes. 


A special note on the FC adapter max_xfer_size attribute

This attribute for the fscsi device, which controls the maximum IO size the adapter device driver will handle, also controls a memory area used by the adapter for data transfers. When the default value is used (max_xfer_size=0x100000) the memory area is 16 MB in size. When setting this attribute to any other allowable value (say 0x200000) then the memory area is 128 MB in size. At AIX 6.1 TL2 or later a change was made for virtual FC adapters so the DMA memory area is always 128 MB even with the default max_xfer_size. This memory area is a DMA memory area, but it is different than the DMA memory area controlled by the lg_term_dma attribute (which is used for IO control). The default value for lg_term_dma of 0x800000 is usually adequate. 

So for heavy IO and especially for large IOs (such as for backups) it's recommended to set max_xfer_size=0x200000.

The fcstat command can also be used to examine whether or not increasing num_cmd_elems or max_xfer_size could increase performance

# fcstat fcs0
...
FC SCSI Adapter Driver Information
No DMA Resource Count: 0 
No Adapter Elements Count: 0 
No Command Resource Count: 0 

This shows an example of an adapter that has sufficient values for num_cmd_elems and max_xfer_size. Non zero value would indicate a situation in which IOs queued at the adapter due to lack of resources, and increasing num_cmd_elems and max_xfer_size would be appropriate. 

Note that changing max_xfer_size uses memory in the PCI Host Bridge chips attached to the PCI slots. The salesmanual, regarding the dual port 4 Gbps PCI-X FC adapter states that "If placed in a PCI-X slot rated as SDR compatible and/or has the slot speed of 133 MHz, the AIX value of the max_xfer_size must be kept at the default setting of 0x100000 (1 megabyte) when both ports are in use. The architecture of the DMA buffer for these slots does not accommodate larger max_xfer_size settings" 

If there are too many FC adapters and too many LUNs attached to the adapter, this will lead to issues configuring the LUNs. Errors will look like:

LABEL: DMA_ERR
IDENTIFIER: 00530EA6

Date/Time: Mon Mar 3 10:48:09 EST 2008
Sequence Number: 863
Machine Id: 00C3BCB04C00
Node Id: p595back
Class: H
Type: UNKN
Resource Name: PCIDMA
Resource Class: NONE
Resource Type: NONE
Location:

Description
UNDETERMINED ERROR

Probable Causes
SYSTEM I/O BUS
SOFTWARE PROGRAM
ADAPTER
DEVICE

Recommended Actions
PERFORM PROBLEM DETERMINATION PROCEDURES

Detail Data
BUS NUMBER
FFFF FFFF 9000 00E4
CHANNEL UNIT ADDRESS
0000 0000 0000 018B
ERROR CODE
0000 0000 1000 0003

So if you get these errors, you'll need to change the max_xfer_size back to the default value. Also note that if you are booting from SAN, if you encounter this error, you won't be able to boot, so be sure to have a back out plan if you plan to change this and are booting from SAN.

Further theoretical thoughts on shared vs. dedicated resources

The astute reader will have considered the fact that typically we have many hdisk drivers sharing multiple adapters and adapter drivers, thus, the FC queue slots are a shared resource for the hdisk drivers:



Thus, it's possible to ensure that we never fill the adapter queues, by making SUM(hdisk0 queue_depth, hdisk1 queue_depth, ... hdiskM queue_depth) <= SUM (fcs0 num_cmd_elems, fcs1 num_cmd_elems, ... fcsN num_cmd_elems). This assumes that IO are evenly spread across the adapters. And most multi-path code does balance IOs across the adapters (or at least can). 

Though often, environments have many more hdisks than FC ports, and ensuring we won't fill the adapter drivers can lead to small values for queue_depth, and full queues on the hdisk drivers. 

So there is the dedicated resource approach, the shared resource approach, and in between dedicated and shared. Taking this simple example where Q represents the queue depth for the device driver:



This would be considered a dedicated resource approach, where 10 of the adapter driver queue slots are dedicated to each hdisk driver. Here we know we'll never submit an IO to a full queue on the adapter driver. 

Alternatively:



This would be considered a shared resource approach where the 10 adapter queue slots could be filled up from a single hdisk driver. 

And here's an example of something in between:



Here, there will always be at least 5 queue slots available in the adapter driver for either hdisk driver. 


There are pros and cons to each approach. The benefit of the dedicated resource approach is that the resources allocated will always be available but typically there will be fewer resources available to each user of the resource (here the resource we're considering is the adapter queue slots, and the users of the resource are the hdisk drivers). The benefit of the shared resource approach is that we'll have more resources for an individual user of the resource when it needs it and it will be able to get greater thruput than in the dedicated resource approach. The author generally prefers a shared resource approach, as generally provides the best thruput and price performance. 

Note that this situation of shared resources occurs in several possible ways beyond hdisk drivers using adapter drivers. It is also involved when:
Several LV VSCSI hdisks for a single hdisk on a VIOS
Several vFC adapters using a single real FC adapter
Several LPARs using the same disk subsystem

Source:https://www-03.ibm.com/support/techdocs/atsmastr.nsf/WebIndex/TD105745

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX Install packages, upgrade, patching commands

To see the details of installed file sets:
#lslpp -l
To list the installation history of all file set in bos.net packages:
#lslpp -ha bos.net.*
To list the files in the bos.rte package:
#lslpp -f bos.rte
To list the file set which contain /etc/hosts file:
#lslpp -w /etc/hosts
To list the pre requisites for bos.net.nfs.server file set:
#lslpp -p bos.net.nfs.server
To list the installable products on the device rmt0:
#installp -L -d /dev/rmt0.1
To install all filesets within bos.net and expands file system if it requires:
#installp -aX -d /dev/rmt0.1 bos.net
To remove bos.net:
#installp -u bos.net
To reject the applied software:
#installp -r
To commit the <package>:
#installp -c -f <package>
To cleanup an incomplete installation:
#installp -C
To check the <package>:
#lppchk -c <package> Verifies that the / (root), /usr and /usr/share parts of the system are valid with each other: #lppchk -v
To install the file set associated with fix IX9999 from rmt0:
#instfix -k IX9999 -d /dev/rmt0.1
To verify fix IY6969 installed:
#instfix -ik IY6969
How to display missing filesets from service pack:
#instfix -icqv | grep ':-:'
To verify if you have all packages installed for the current ML and why after upgrade you cannot see the newer version:
# instfix -i |grep ML
    All filesets for 6100-00_AIX_ML were found.
    All filesets for 6100-01_AIX_ML were found.
    All filesets for 6100-02_AIX_ML were found.
    All filesets for 6100-03_AIX_ML were found.
    All filesets for 6100-04_AIX_ML were found.
    All filesets for 6100-05_AIX_ML were found.
    All filesets for 6100-06_AIX_ML were found.
    All filesets for 6.1.0.0_AIX_ML were found.
    Not all filesets for 6100-07_AIX_ML were found.
	
# oslevel -s
6100-06-05-1115

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX LVM Cheat Sheet
By Surya20:51No comments
This is a quick and dirty cheat sheet on LVM using AIX, I have highlighted many of the common attributes for each command however this is not an extensive list, make sure you look up the command.

First a quick review on some of the terminology that AIX LVM uses
Examples
What it means
PHYSICAL VOLUME (PV)
Represents a hard disk (hdisk0).
PHYSICAL PARTITION (PP)
The smallest allocation unit in the LVM. All PPs within a VG are the same size, usually 4 or 8 MB.
VOLUME GROUP (VG)
A set of one or more PVs which form a single storage pool. You can define multiple VGs on each AIX system.
LOGICAL VOLUME (LV)
One or more PPs. A file system resides on top of an LV. Only one LV is mapped to a file system. A LV can't span across a VG. Up to 255 LVs in a VG
LOGICAL PARITITION (LP)
One or more PPs. LP represents a mirrored copy of a PP. Up to two copies of a PP can be mirrored resulting in a LP count of three (2 mirrors plus original).
Volume Group Descriptor Area(VGDA)
Information about all the LVs and PVs within a VG. The first 64K of a PV is reserved for this area - defined in <sys/bootrecord.h>.

The VGDA consists of
·BOOTRECORD: - first 512 bytes. Allows the Read Only System (ROS) to boot system
·  BAD BLK DIRECTORY - found in <sys/bddir.h>
·  LVM RECORD - found in <lvmrec.h>
Volume Group Status Area(VGSA)
Information about which PPs that are stale and which PVs are missing within a VG. The LVM and SCSI driver reserves somewhere between 7-10% of the available disk space for LVM maps, etc.
Physical Volume ID (PVID)
The PVID is an amalgamation of the machine’s serial number (from the systems EPROMs) and the date that the PVID is being generated. This combination insures the extremely low chance of two disks being created with the same PVID. Finally, when a system is booted, the disk conﬁgurator goes and looks at the PVID sitting on each disk platter and then compares that to an entry in ODM. If the entry is found, then the disk is given the hdiskX name that is associated with the ODM entry for the PVID.
Quorum
Quorum is a sort of “sanity” check that LVM uses to resolve possible data conﬂiction and prevent data corruption. Quorum is a method by which 51% or more quorum votes must be available to a volume group before LVM actions can continue. Quorum is issued to a disk in a volume group according to how the disk was created within the volume group. When a volume group consists of one disk, there are two VGDA’s on that disk. Thus, this single disk volume group has a quorum vote of 2. When another disk is added to the volume group with an “extendvg”, then this new disk gets one VGDA, but the original, ﬁrst disk still retains the two VGDA’s. When the volume group has been extended to three disks, the third disk gets the spare VGDA sitting on the ﬁrst disk and then each disk has a quorum vote of 1. Every disk after the third disk is automatically given one VGDA, and thus one vote.
Volume Group ID (VGID)
Just as the PVID is a soft serial number for a disk, the VGID is the soft serial number for the volume group. It is this serial number, not the volume group’s ascii name, which all low level LVM commands reference. Additionally, it is the basis for the LVIDs created on that VGID.
Logical Volume Control Block (LVCB)
The logical volume control block (lvcb) consists of the ﬁrst 512 bytes of a logical volume. This area holds important
information such as the creation date of the logical volume, information about mirrored copies, and possible mount points in a journaled  ﬁlesystem.
Logical Volume ID (LVID)
The LVID is the soft serial number used to represent the logical volume to the LVM libraries and low level commands. The LVID is created from the VGID of the volume group, a decimal point, and a number which represents the order which the logical volume was created on the volume group.
Now for the cheat sheet
Directory and Files
Directories and Files
Tools
diagnostic
diag - used to hot swap the disk
cfgmgr - used mak sure the new disk is seen

# to add new disk from the scsi0 controller
cfgmgr -l scsi0
Create/Remove hard disk
cfgmgr -l scsi0
mkdev -c disk -l <pv>
rmdev -dl <pv>
Physical Volumes
display
lspv
lspv <pv> (detailed)
lspv -l <pv> (list logical volumes)
lspv -p <pv> (physical partition usage)
PVID
chdev -l <pv> -a pv=yes
chdev -l <pv> -a pv=clear

Note: PVID's are automatically added when the disk is placed into a vg
adding
chdev -l <pv> -a pv=yes (new)
chpv -v a <pv> (adds back the removed disk)
removing
chpv -v r <pv>
change physical attributes
chpv -a y <pv> (changes allocatable state to YES)
chpv -a n <pv> (changes allocatable state to NO)
moving
migratepv <old pv> <new pv>
Volume Groups
display
lsvg
lsvg <vg> (detailed)
lsvg -l <vg> (list all logical volumes in goup)
lsvg -p <vg> (list all physical volumes in group)
lsvg -o (lists all varied on)
lsvg -M <vg> (lists assicated disks and state)

## Details volume group info for the hard disk
lqueryvg -Atp <pv>
lqueryvg -p <disk> -v (Determine the VG ID# on disk)
lqueryvg -p <disk> -L (Show all the LV ID#/names in the VG on disk)
lqueryvg -p <disk> -P (Show all the PV ID# that reside in the VG on disk)
varyon
varyonvg <vg>
varyonvg -f <vg> (force)
varyonvg -s <vg> (maintenance mode can use VG commands but lv 's cannot be opened for i/o access)
varyoffvg <vg>
Note: the varyon command activiates the volume goup which means it is available for use
ODM related
## Determine if the ODM and VGDA are correct (in sync)
getlvodm -u <vg>

## tries to resync VGDA, LV control blocks and ODM
synclvodm <vg>

## If the message 0516-366 lsvg: Volume group <vg> is locked is ever seen
putlvodm -K `gtlvodm -v <vg>`
creating
mkvg -y <vg> -s <PP size> <pv>

mkvg -y datavg -s 4 hdisk1

Note: the PP size will be the size of the physical partition size you want 4MB, 8MB
extending
extendvg <vg> <pv>
reducing
reducevg -d <vg> <pv>

## removes the PVID from the VGDA when a disk has vanished without using the reducevg command
reducevg <vg> <PVID>
removing
varyoffvg <vg>
exportvg <vg>

Note: the export command nukes everything regardingthe volume goup in the ODM and /etc/filesystems
checking
## check to see if underlying disk has grown in size
chvg -g <vg>
Note: use this command if you are using SAN LUN's that have increased in size
change volume attributes
## auto vary on a volume at system start
chvg -a y

# Turns on/off quorum checking on a volume group
chvg -Q [y|n] <vg>
renaming
varyoffvg <old vg name>
lsvg -p <old vg name> (obtain disk names)
exportvg <old vg name>
import -y <new vg name> <pv>
varyonvg <new vg name>
mount -a
importing
importvg -y <vg> <pv>
importvg <pv> (will use rootvg as default vg)
exporting
varyoffvg <vg>
exportvg <vg>

Note: if the volume has an active paging space this must be turned off before
Logical Volumes
display
lslv <lv>
lslv -l <lv> (list all physical volumes in logical volume)
lslv -m <lv> (list ppartition mapping)

## Display lv control block information
getlvcb -AT <lv>
creating
mklv <vg> <# of PP's> <pv>
mklv -y <lv name> <vg> <# of PP's> <pv>
## Create a mirrored named logical volume
mklv -y <lv> -c <copies 2 or 3> <vg> <# of PP's> <pv>

## create a JFSlog logical Volume
mklv -y <lv name> -t jfslog <vg> <# of PP's> <pv>
extending
extendlv <lv> <additonal # of PP's>
extendlv <lv> <size of volume in B||M|G>
reducing/resizing
see filesystem below
removing
rmlv <lv>
moving
migratepv -l <lv> <old pv> <new pv>
adding a mirror to a non-mirrored volume
mklvcopy -s n <lv> <copies 2 or 3> <pv>
removing a mirror copy from a mirrored volume
rmlvcopy <lv> <copies 1 or 2>
rmlvcopy <lv> <copies 1 or 2> <pv> (specified pv)

unmirrorvg <vg> <pv>
synchronize logical volume
syncvg -p <pv>
syncvg -v <vg>
syncvg -l <lv>
mirror any unmirrored volumes
mirrorvg <vg> <pv>
change volume attributes
## Enable the bad-block relocation policy

chlv -b [y|n] <lv>
renaming
chlv -n <new lv name> <old lv name>
Miscellaneous
## Initialises an LV for use as an JFSlog
logform </dev/lv>
Filesystems
display
lsfs
lsfs -q <fs> (detailed)

Note: use the '-q' to see if the logical volume size is bigger than the filesystem size
create
## create new filesystem, -A means to mount after restart
crfs -v jfs -d <lv> -m <mountpoint> -A yes

## Create logical volume, filesystem, mountpoint, add entry to /etc/filesystems at the specified size
crfs -v jfs2 -g <vg> -m <mountpoint> -a size=<size in 512k blocks|M|G) -A yes

Note: there are two types of filesystems jfs and jfs2, jfs2 allows you to decrease the filesystem size , you cannot reduce a jfs filesystem
remove
rmfs <fs>

Note: if all filesystems have been removed from a logical volume then the logical volume is removed as well.
resize
chfs -a size=<new size> <fs>

chfs -a size=1G /var (specific size, can be used to increase and decrease)
chfs -a size=+1G /var (increase by 1GB)
chfs -a size=-1GB /var (reduce by 1GB)
Note: this will automatically increase or decrease the underlying logical volume as well
freeze/unfreeze
chfs -a freeze=<time in seconds> <fs>
chfs -a freeze=off <fs>
split mirrored copy
chfs -a splitcopy=<split copy mountpoint>-a copy=2 <fs>

chfs -a splitcopy=/backup -a copy=2 /testfs
change
## Change the mountpoint
chfs -m <new mountpoint> <fs>

## Do not mount after a restart
chfs -A no <fs>

## Mount read-only
chfs -p ro <fs>
mount
mount
mount [<fs>|<lv>]
mount -a
mount all
defrag
defragfs -q <fs> (report defrag status)
defragfs -r <fs> (runs in report only mode - no action)
defragfs <fs> (actually defrags the filesystem)
checking and repairing
fsck [-y|-n] <fs> (check a filesystem)
fsck -p <fs> (restores primary superblock from backup copy if corrupt)
Miscellaneous
Complete VG, LV and FS with mirroring example
## Create the volume group
mkvg -s 256 -y datavg hdisk2
## Create the jfs2 log logical volume and initialize it this for the volume group
mklv -t jfs2log -y dataloglv datavg 1
logform /dev/dataloglv

## Create the logical volume
mklv -t jfs2 -y data01lv datavg 8

## Create the filesystems that will use the logical volume
crfs -v jfs -d data01lv -m /data01 -A yes

## Add an additional hard disk to the volume group
extendvg datavg hdisk3

## Now mirror both the volume group log logical volume and the logical volume
mklvcopy dataloglv 2
mklvcopy data01lv 2

## Make sure everything is sync'ed both the log and the logical volume
syncvg -v datavg

## Make sure everything is OK
lsvg -l datavg

## a quick way to perform the above in two steps
mklv -c 2 -t jfs2 -y data02lv datavg 8
crfs -v jfs -d data02lv -m /data02 -A yes

## mount everything and check
mount -a
Replaced failed mirror drive
## break the mirror (two ways to do this)
rmlvcopy <lv name> 1 <broken disk>
unmirrorvg <lv> <broken pv >
## remove the disk from the vg
reducevg <vgname> <broken pv >
## remove the hdisk from ODM
rmdev -dl <broken pv>

## physically replace the disk
diag -> function select -> task selection -> hot plug task -> scsi and scsi raid hot plug manager -> replace/remove a device attached to an scsi hot swap enclosure device -> select disk and follow instructions

## configure new disk an check the new number (hopefully the same)
cfgmgr -v
lsdev -Cc <pv>
## add back to volume group
extendvg <vg> <pv>
## create mirror (two ways to do this)
mklvcopy <lv> 2 <pv>
mirrorvg <lv>

## sync mirror
syncvg -l <lv>

## If this is the rootvg there are additonal steps to take
bosboot -ad /dev/<pv>
bootlist -m normal <pv> <pv>
bootlist -m normal -o
Accidently remove a mirrored disk or SAN LUN disappeared off the network
## This procedure places back a mirror disk that you have accidently pulled or that a SAN LUN disappeared off the network
## and its states is classed as "missing"

## see that the disk is in a missing state (see PV state column), also see stale volumes
lsvg -p <vg>
lsvg -M <vg>

## To make the disk active again we use the varyonvg command
varyonvg <vg>

## see that the disk is in a active state (see PV state column)
lsvg -p <vg>

## Now re-sync the volumes in that volume group
syncvg -v <vg>

## Make sure that no volumes are stale
lsvg -M <vg>

## Determine if the ODM and VGDA are correct (in sync)
getlvodm -u <vg>
www.unixmantra.com

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX Misc Commands

To list all the records in the /var/adm/wtmp file:
aix@um# last
To show the shutdown sessions:
aix@um# last | grep shutdown
To show how long the system has been up:
aix@um# uptime
aix@um# w -u
To enter the entry tty002:23:respawn:/usr/sbin/getty /dev/tty in inittab:
aix@um# chitab tty002:23:respawn:/usr/sbin/getty /dev/tty
To list the operating system level:
aix@um# oslevel
To see the number of license:
aix@um# lslicense
To change the fixed user license to 30:
aix@um# chlicense -u30
To enable floating user license:
aix@um# chlicense -f on
To display complete summary of report:
aix@um# errpt
To list complete detailed report:
aix@um# errpt -a
To list all hardware related errors:
aix@um# errpt -d H
To list all software related errors:
aix@um# errpt -d S
To list detailed error report of error id 88965309:
aix@um# errpt -a -j 88965309
To list all events for which reporting is currently disabled, type: aix@um# errpt -t -F Report=0
To disable the reporting of the ERRLOG_OFF event (error ID 192AC071):
aix@um# errupdate <Enter>
=192AC071: <Enter>
Report=False <Enter>
<Ctrl-D>
<Ctrl-D>
Example:
aix@um# errpt -t -F Report=0  
Id       Label               Type CL Description
1850F542 MINIDUMP_INFO       INFO O  NVRAM WAS RE-INITIALIZED
45E4E066 DUPCHECK_OFF        TEMP O  Duplicate checking turned off
86DC0701 DUPCHECK_ON         TEMP O  Duplicate checking turned on
B0787F02 NVRAM_ERRDATA       UNKN U  CORRUPT DATA DETECTED
aix@um# errupdate
=BFE4C025:
Report=False
0 entries added.
0 entries deleted.
1 entries updated.
aix@um# errpt -t -F Report=0  
Id       Label               Type CL Description
1850F542 MINIDUMP_INFO       INFO O  NVRAM WAS RE-INITIALIZED
45E4E066 DUPCHECK_OFF        TEMP O  Duplicate checking turned off
86DC0701 DUPCHECK_ON         TEMP O  Duplicate checking turned on
B0787F02 NVRAM_ERRDATA       UNKN U  CORRUPT DATA DETECTED
BFE4C025 SCAN_ERROR_CHRP     PERM H  UNDETERMINED ERROR
To enable the reporting of the ERRLOG_OFF event (error ID 192AC071) in case it was turned off:
aix@um# errupdate <Enter>
=192AC071: <Enter>
Report=True <Enter>
<Ctrl-D>
<Ctrl-D>
To delete the ERRLOG_OFF event (error ID 192AC071) from the Error Record Template Repository:
aix@um# errupdate <Enter>
-192AC071:
<Ctrl-D>
<Ctrl-D>
To add an entry to the errorlog:
aix@um# /usr/bin/errlogger "The desired message"
To dispay the HMC information (hmc ip is on HostName field of "resource N" stanza):
aix@um# lsrsrc "IBM.ManagementServer" or
aix@um# lsrsrc IBM.MCP
Sometimes you may get error on the above command, like:
aix@um# /usr/sbin/rsct/bin/lsrsrc-api: 2612-010 Resource class IBM.ManagementServer is not defined.
In this case, you can search for the hostname or ip of hmc on the file:
/var/ct/cfg/ctrmc.acls
How to list partition information:
aix@um# lparstat -i aix@um# lsattr -El sys0
How to display the processors available in the partition:
aix@um# bindprocessor -q
How to turn off SMT:
aix@um# smtctl -m off
How to turn on SMT:
aix@um# smtctl -m on
How to display SMT configuration:
aix@um# smtctl
How to set the number of hardware threads per core:
aix@um# smtctl -t N
How to turn on SMT:
aix@um# smtctl -m on
Details volume group info for the hard disk:
aix@um# lqueryvg -Atp /dev/hdisk
Find a file after the inode number:
aix@um# find /usr -xdev -inum INODE -print
aix@um# ncheck -i INODE /dev/hd2 <- warning: the path starts with the FS (eg /usr/bin/ksh = /bin/ksh in our example)
How to list the kernel processes:
aix@um# ps -ekl
How to list the threats of a given process:

aix@um# ps -ef|grep sshd <- get the pid of sshd
aix@um# ps -lmp <PID>
How to get the serial number of a vio disk from the lpar client (DS disk in this example):
aix@um# odmget CuAt | grep -p hdisk25 | grep -p "unique_id" | grep value
        value = "234324324324375992817EE807210790003IBMfcp05VDASD03AIXvscsi"
or better,
for DS disks:
aix@um# odmget -q "name=hdisk0 and attribute=unique_id" CuAt | awk '/value/ {print substr($3,14,11)}'
75992817EE8

for SVC disks:
aix@um# odmget -q "name=hdisk0 and attribute=unique_id" CuAt | awk '/value/ {print substr($3,11,32)}'
6005076801810514A800000000000853
How to check the error log size:
aix@um# /usr/lib/errdemon -l
How to display the current control key settings:
aix@um# stty -a
How to put a system in maintenance mode without reboot:
aix@um# telinit m
HMC Led Codes:
0c54 = An AIX install is in progress
0552 = varyon of the root volume group failed
0c31 = waiting for user to define console type vty0
How to get the last modification date of a file:
aix@um# $ istat loop.pl
Inode 120 on device 10/8        File
Protection: rwxr-xr-x   
Owner: 205(florian)             Group: 1(staff)
Link count:   1         Length 74 bytes

Last updated:   Tue May 15 03:55:23 2012
Last modified:  Tue May 15 03:55:23 2012
Last accessed:  Tue May 15 04:06:31 2012

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX Network commands

Resolve umserv01 to ip address (from /etc/hosts file):
#host umserv01
To change the host name to umserv01:
#hostname umserv01
To the status of ethernet device en0:
#entstat en0
To list the detailed status of device en0:
#entstat -d en0
To list all net configurable attributes and their values:
#no -a
To change umserv01wall parameter to its default value:
#no -d umserv01wall
To make the machine as router in tcpip networks:
#no -o ipforwarding=1
To trace the route to umserv01:
#traceroute umserv01
To tcp ping to the machine umserv01:
#ping umserv01
To show the status of all network interfaces:
#ifconfig -a
To show the status of en0:
#ifconfig en0
Turns on network card en0:
#ifconfig en0 up
Turns off network card en0:
#ifconfig en0 down
Removes en0 card from the network interface list:
#ifconfig en0 detach
Configure en0 starts immediately:
Temporarily:# ifconfig en0 inet 192.168.100.9 netmask 255.255.255.0 up
Permanently:# chdev -l en0 -a netaddr=192.168.100.10 -a netmask=0xffffff00
Create alias ip address for en0:
Temporarily:# ifconfig en0 alias 192.168.100.10 netmask 255.255.255.0
Permanently:# chdev -l en0 -a alias4=192.168.100.10,255.255.255.0
Remove a permanently added alias:
# chdev -l en0 -a delalias4=192.168.100.10,255.255.255.0
Via SMIT:
# smitty tcpip -> further Configuration -> Network Interfaces -> Network Interface Selection -> Configure Aliases
To make 192.168.100.1 as default gateway for entire network:
Temporarily:#route add 0 192.168.100.1
Permanently:#chdev -l inet0 -a route=0,192.168.100.1
To make 200.7 as gateway for 300.0 network:
#route add 192.100.300.0 192.100.200.7
To clear the gateway table:
#route -f
To change the host name to umserv01 permanently:
#chdev -l inet0 -a hostname=umserv01
To set the MTU to 1500 on en69:
#chdev -l en69 -a mtu=1500
To show the state of all sockets:
#netstat -a
To show the network buffers cache:
#netstat -c
To show the net drops of packets:
#netstat -D
To display interface statistics:
#netstat -i
To show the routing table:
#netstat -r
To show routing table (ip will be given instead of host names)
#netstat -rn
To show the statistics of the protocols
#netstat -s
To show the statistics of respective protocols
#netstat -s -p < tcp/udp/ipv6>


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Basic ODM Commands:
ODM is object database Manager

NOTE: VERY IMPORTANT!

Use these commands with EXTREME CAUTION!!! You should make backup copies of the individual ODM Class files (CuAt, CuDv, CuDvDr, CuDep,and CuVPD), before you attempt to use these commands.

First, take a backup of the ODM files by issuing:
cd /etc/objrepos
for i in CuAt CuDv CuDvDr CuDep
do
odmget $i > /tmp/$i.orig
done
1. How to find disk drive in ODM customized database:
odmget -q name=hdisk# CuAt           ==> CuAt = Customized Attribute
odmget -q value=hdisk# CuAt
odmget -q name=hdisk# CuDv           ==> CuDv = Customized Device
odmget -q value3=hdisk# CuDvDr      ==> CuDvDr = Customized Device Driver
odmget -q name=hdisk# CuDep        ==> CuDep = Customized Dependency
odmget -q name=hdisk# CuVPD       ==> CuVPD = Customized Vital Product Database
2. How to remove disk drive entries from ODM customized database:
odmdelete -q name=hdisk# -o CuAt
odmdelete -q value=hdisk# -o CuAt
odmdelete -q name=hdisk# -o CuDv
odmdelete -q value3=hdisk# -o CuDvDr
odmdelete -q name=hdisk# -o CuDep
odmdelete -q name=hdisk# -o CuVPD
3. How to find VG (rootvg) in ODM database:
odmget -q name=rootvg CuAt
odmget -q name=rootvg CuDv
odmget -q parent=rootvg CuDv
odmget -q value1=rootvg CuDvDr
odmget -q value3=rootvg CuDvDr
odmget -q name=rootvg CuDep
4. How to find LV in ODM database:
odmget -q name=LV CuAt
odmget -q name=LV CuDv
odmget -q value3=LV CuDvDr
odmget -q dependency=LV CuDep
5. How to find an object in CuDvDR by major, minor number:
Example: if major num=10 & minor=1
odmget -q "value=10 and value=1" CuDvDr
6. How to find value (may be pvid of an old disk left in CuAt):
odmget -q value=00001165d6faf66b0000000000000000 CuAt
(Add 16 zeros after the PVID number. This value
should be 32 characters in lenght.)
7. To search the ODM for a specific Item.
odmget CuAt | grep (Specific Item) -> record the number of items
odmget CuDv | grep (Specific Item) -> record the number of items
odmget CuDvDr | grep (Specific Item) -> record the number of items
odmget CuDep | grep (Specific Item) -> record the number of items
odmget CuVPD | grep (Specific Item) -> record the number of items

Now you can use the odmdelete command above to remove the specific item that you searched for.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX Page Space Commands

To list out all paging spaces:
#lsps -a
To display the details of the paging space hd6:
#lsps hd6
To turn on the paging space paging69:
#chps -a y paging69
To turn off the paging space paging69:
#chps -a n paging69
To increase the size of the paging space in 6 LP blocks:
#chps -s6 paging69
To create a paging space on VG pagevg of 6 LP size (-s6) and activate it immediately (-n) and activate it at every restarts:
#mkps -a -n -s6 pagevg
To remove the paging space paging69:
#rmps paging69
To invoke all entries in /etc/swapspaces file:
#swapon -a
To make available swap space paging69:
#swapon /dev/paging69

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX performance tips and tricks

The following commands can be used in order to debug performance problems on an AIX machine.
Nmon tools
nmon performance -- free tool to analyze AIX performance
This free tool gives you a huge amount of information all on one screen. Even though IBM doesn't officially support the tool and you must use it at your own risk, you can get a wealth of performance statistics. Why use five or six tools when one free tool can give you everything you need? The tool can be found here.

nmon analyser -- free tool to produce AIX performance reports
This free tool is designed to take files produced by the NMON performance tool and turn them into spreadsheets containing high quality graphs ready to cut and paste into performance reports. The tool also produces analyses for ESS and EMC subsystems. It is available for both Lotus 1-2-3 and Microsoft Excel. The tool can be found here.
Determine your AIX level
oslevel -r
[root@sys /] oslevel -r
5100-07
[root@sys /]
Determine the load of your system
By executing uptime, you get the load on your system. The load indicates the amount of programs that are being executed @ the same time.
[root@sys /] uptime
  04:19PM   up 62 days,   1:57,  3 users,  load average: 12.26, 11.86, 8.77
[root@sys /]
Determine the cpu usage (user/sys/idle/wait)
Use the command vmstat 10 10.
[root@sys /] vmstat 10 10
kthr     memory             page              faults        cpu
----- ----------- ------------------------ ------------ -----------
 r  b   avm   fre  re  pi  po  fr   sr  cy  in   sy  cs us sy id wa
 4  1 257816  2166   0   0   0 315  287   0 615 10202 1030  9 19 51 22
 8  1 257579  2412   0   0   0 147 1407   0 588 32601 1745 17 81  1  1
11  1 259625   171   0   0   0 494 10911   0 647 31634 1440 18 82  0  0
11  1 259720   270   0   0   0 281 2413   0 593 34101 1652 21 79  0  0
11  1 259282   555   0   0   0 246 2619   0 669 33614 1814 16 84  0  0
...
[root@sys /]
Determine the memory/swap usage of an AIX system
Use the commands svmon and lsps.
[root@sys /] lsps -a
Page Space  Physical Volume   Volume Group    Size   %Used  Active  Auto  Type
hd6         hdisk0            rootvg         768MB      47     yes   yes    lv
[root@sys /] svmon
               size      inuse       free        pin    virtual
memory       262128     260139        288      66603     258643
pg space     196608      91566

               work       pers       clnt      lpage
pin           66609          0          0          0
in use       228672       7884      23583          0
[root@sys /]
Svmon uses frames, multiply every frame by 1024 to get the size in bytes. Also be sure to install the packages bos.perf.tools in order to get svmon work.
Determine the IO load on your systems disks
Use the command iostat, do know thet the first entry is the entry since boot.
[root@sys /] lslpp -w /usr/bin/svmon
  File                                        Fileset               Type
  ----------------------------------------------------------------------------
  /usr/bin/svmon                              bos.perf.tools        File
[root@sys /] iostat 5 2

tty:      tin         tout   avg-cpu:  % user    % sys     % idle    % iowait
          0.1          4.8               8.7     18.5       51.2      21.6

Disks:        % tm_act     Kbps      tps    Kb_read   Kb_wrtn
hdisk1           1.6      16.4       3.5    6873724  81062953
hdisk0           1.8      16.9       3.7   10202425  80417825
cd0              0.0       0.0       0.0          0         0

tty:      tin         tout   avg-cpu:  % user    % sys     % idle    % iowait
          0.0        135.2              17.4     82.6        0.0       0.0

Disks:        % tm_act     Kbps      tps    Kb_read   Kb_wrtn
hdisk1           0.0       0.0       0.0          0         0
hdisk0           2.4      15.2       3.4         76         0
cd0              0.0       0.0       0.0          0         0
[root@sys /]
If you get as output:
[root@sys /] iostat

tty:      tin         tout   avg-cpu:  % user    % sys     % idle    % iowait
          0.1          4.8               8.7     18.5       51.2      21.6
                " Disk history since boot not available. "

[root@sys /]
you have to activate iostat counters by typing the following command: /usr/sbin/chdev -l sys0 -a "iostat=true"
AIX temperature sensors
By executing the command /usr/lpp/diagnostics/bin/uesensor, you can, on supported platform, get the fan speeds and temperature of your system:
[root@sys /] /usr/lpp/diagnostics/bin/uesensor -a
3 0 11 31 P1
9001 0 11 2100 F1
9001 1 11 2760 F2
9001 2 11 1890 F3
9001 3 11 1890 F4
9002 0 11 5129 P1
9002 1 11 3129 P1
9002 2 11 5129 P1
9002 3 11 12077 P1
9004 0 11 3 P3-V1
9004 1 11 3 P3-V2
9004 2 11 3 P3-V3
[root@sys /]

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX PowerHA (HACMP) Commands


Most commands should work on all PowerHA (HACMP prior to 5.5) versions.
If there is some syntax error, please consult the manual page for that command.

Sometimes path to cluster commands not included in default PATH variable ,to overcome it run below command before running ha commands

export PATH=$PATH:/usr/es/sbin/cluster:/usr/es/sbin/cluster/utilities:/usr/es/sbin/cluster/sbin:/usr/es/sbin/cluster/cspoc
PowerHA(HACMP) Commands
How to start cluster daemons (options in that order:
 clstrmgr, clsmuxpd, broadcast message, clinfo, cllockd)
clstart -m -s -b -i -l
How to show cluster state and substate (depends on clinfo)
 clstat
SNMP-based tool to show cluster state
 cldump
Similar to cldump, perl script to show cluster state
 cldisp
How to list the local view of the cluster topology
 cltopinfo
How to list the local view of the cluster subsystems
 clshowsrv -a
How to show all necessary info about HACMP
 clshowsrv -v
How to show HACMP version
 lslpp -L | grep cluster.es.server.rte
How to verify the HACMP configuration
 /usr/es/sbin/cluster/diag/clconfig -v -O                                                                                                    
How to list app servers configured including start/stop scripts
 cllsserv
How to locate the resource groups and display their status
 clRGinfo -v
How to rotate some of the log files
 clcycle
A cluster ping program with more arguments
 cl_ping
Cluster rsh program that take cluster node names as argument
 clrsh
How to find out the name of the local node
 get_local_nodename
rHow to check the HACMP ODM
 clconfig
How to put online/offline or move resource groups
 clRGmove
How to list the resource groups
 cllsgrp
How to create a large snapshot of the hacmp configuration
 clsnapshotinfo
How to show short resource group information
 cllsres
How to list the cluster manager state
 lssrc -ls clstrmgrES
Cluster manager states

ST_NOT_CONFIGURED Node never started
ST_INIT Node configured but down - not  running
ST_STABLE Node up and running
ST_RP_RUNNING 
ST_JOINING 
ST_BARRIER 
ST_CBARRIER 
ST_VOTING 
ST_RP_FAILED Node with event error         

How to show heartbeat information
 lssrc -ls topsvcs
How to check logs related to hacmp
 odmget HACMPlogs
How to list all information from topology HACMP
 lssrc -ls topsvcs
How to show all info about group
  lssrc -ls grpsvcs
How to list the logs
 cllistlogs
How to list the resources defined for all resource group
 clshowres
How to show resource information by resource group
 clshowres -g'RG'
How to show resource information by node
 clshowres -n'NODE'
How to locate the resource groups and display status (-s)    
 clfindres
How to list interface name/interface device   name/netmask      associated with a specified ip label / ip address of a specific 
node
 clgetif
Cluster verification utility
 clverify
How to list cluster topology information
 cllscf
X utility for cluster configuration
 xclconfig
X utility for hacmp management 
 xhacmpm
X utility for cluster status
 xclstat
How to force shutdown cluster immediately without releasing resources
 lclstop -f -N
How to do graceful shutdown immediately with no takeover
 clstop -g -N
How to do graceful shutdown immediately with takeover
 clstop -gr -N
How to sync the cluster topology
 cldare -t
How to do the mock sync of topology	
 cldare -t -f
How to sync the cluster resources
 cldare -r
How to do the mock sync of resources
 cldare -r -f
How to list the name and security level of the cluster
 cllsclstr
How to list the info about the cluster nodes
 cllsnode
How to list info about node69
 cllsnode -i node69
How to list the PVID of the shared hard disk for resource group dataRG
 cllsdisk -g dataRG
How to list all cluster networks
 cllsnw
How to list the details of network ether1
 cllsnw -n ether1
How to show network ip/nonip interface information
 cllsif
How to list the details of network adapter node1_service
 cllsif -n node1_service
How to list the shared vgs which can be accessed by all nodes
 cllsvg
How to list the shared vgs in resource group dbRG
 cllsvg -g dbRG
How to list the shared lvs
 cllslv
How to list the shared lvs in the resource group dbRG
 cllslv -g dbRG
How to list the PVID of disks in the resource group appRG
 cllsdisk -g appRG
How to list the shared file systems
 cllsfs
How to list the shared file systems in the resource group sapRG
 cllsfs -g sapRG
How to show info about all network modules
 cllsnim
How to show info about ether network module
 cllsnim -n ether
How to list the runtime parameters for the node node1
 cllsparam -n node1
How to add a cluster definition with name dcm and id 3
 claddclstr -i 3 -n dcm
How to create resource group sapRG with nodes n1,n2 in cascade
 claddgrp -g sapRG -r cascading -n n1 n2
Creates an application server ser1 with startscript as /usr/start and stop script as /usr/stop
 claddserv -s ser1 -b /usr/start -e /usr/stop
How to change cluster definitions name to dcmds and id to 2
 clchclstr -i 2 -n dcmds
How to change the cluster security to enhanced
 clchclstr -s enhanced
How to delete the resource group appRG and related resources
 clrmgrp -g appRG
How to remove the node node69
 clrmnode -n node69
How to remove the adapter named node69_svc
 clrmnode -a node69_svc
How to remove all resources from resource group appRG
 clrmres -g appRG
How to remove the application server app69
 clrmserv app69
How to remove all applicaion servers
 clrmserv ALL
How to list the nodes with active cluster manager processes from cluster manager on node node1clgetaddr node1 returns a pingable address from node node1
 clgetactivenodes -n node1
How to list the info about resource group sapRG
 clgetgrp -g sapRG
How to list the participating nodes in the resource group sapRG
 clgetgrp -g sapRG -f nodes
How to get the ip label associated to the resource group
  clgetip sapRG
How to list the network for ip 192.168.100.2, netmask 255.255.255.0
 clgetnet 192.168.100.2 255.255.255.0
How to list the VG of LV nodelv
 clgetvg -l nodelv
How to add node5 to the cluster
 clnodename -a node5
How to change the cluster node name node5 to node3
 clnodename -o node5 -n node3

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


AIX Print commands

To display the default queue:
#qchk -q
To display the status of the printer lp69:
#qchk -P lp69
To display the status of job number 969:
#qchk -# 969
To display the status of all queues:
#qchk -A
To cancel the print job 969:
#qcan -x 969
To cancel all jobs submitted to lp69:
#qcan -X -P lp69
To change the priority of the job to 50:
#qpri -#570 -a 50
To hold the job 969:
#qhld # 969
To remove holding from 969:
#qhld -r -#969
To move the job 30 to queue lpa:
#qmov -m lpa -#30
To enable queue blah:
#enable blah
To disable queue blah:
#disable blah
To cancel job 969:
#cancel -#969
To display the status all queues:
#lpstat
To display the status of print queue lp69:
#lpstat -p lp69
To display the jobs submitted by user root:
#lpstat -u root
To display the status of queue lp69:
#lpq -P lp69
How to add lp69 as remote standard processing printer, custom backend entry:
#/usr/sbin/piomisc_base mkpq_other -q'lp69' -d 'lp69.dev' -b'/usr/lib/lpd/rembak' -u'TRUE' -h'lp69' -r'remotelp69'
How to add lp69 as remote bsd printer queue:
#/usr/lib/lpd/pio/etc/piomisc_ext mkpq_remote_ext -q 'lp69' -h 'lp69.example.com' -r 'remotelp69' -t 'bsd' -C 'FALSE'
How to add lp69 as remote ascii jetdirect printer:
#/usr/lib/lpd/pio/etc/piomkjetd mkpq_jetdirect -p 'generic' -D asc -q lp69 -h lp69.example.com -x '9100'


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------



AIX Scheduling commands

Cron How to	Command
To list the crontab entries:	#crontab –l
To edit the crontab entries:	#crontab -e
To copies the entries of crontab to crontab.txt file:	#crontab -l > crontab.txt
To remove all crontab entries:	#crontab -r
To list the submission time:	#crontab -v
File containing users who allowed cron service:	#/var/adm/cron/cron.allow
File containing users denied cron service:	#/var/adm/cron/cron.deny
To list the jobs scheduled via at command:	#at -l
To remove the scheduled job root.dofsdofsd.69:	#at -r root.dofsdofsd.69
To run the command when the system load permits:	#batch
To list all the jobs submitted by user umuser:	#atq umuser
To start a job with at:	
at now <- [ENTER]
/some/script.sh <- [ENTER]
<- CTRL+d
job 4 at Sat Oct 15 21:15:00 2011
#
How to list your background jobs:	
core:~# jobs
[1]   Running  sleep 1000 &
[2]   Running  sleep 1000 &
[3]-  Running  sleep 1000 &
[4]+  Running  sleep 1000 &
How to kill a background job:	
core:~# kill %2

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX Subsystem Commands

To list the status of all subsystems:
#lssrc -a
To list the status of all subsystems on foreign host gznode:
#lssrc -h gznode -a
To list the status of the subsystem gzadmind:
#lssrc -s gzadmind
To get the status of the subsystem group tcpip:
#lssrc -g tcpip
To add a subsystem:
#mkssys
To remove the subsystem kerberos:
#rmssys -s kerberos
To rename the subsystem ying to yang:
#chssys -s ying -s yang
To start the subsystem gzadmin:
#startsrc -s gzadmin
To start the subsystem group tcpip:
#startsrc -g tcpip
To stop the subsystem gzadmin:
#stopsrc -s gzadmin
To stop the subsystem group tcpip:
#stopsrc -g tcpip
To refresh nfsd subsystem:
#refresh -s nfsd
To refresh tcpip subsystem group:
#refresh -g tcpip

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX System Dump Commands

To list the current dump destination:
#sysdumpdev -l
List the details of the previous dump:
#sysdumpdev -L
Starts dump in the primary dump device:
#sysdumpstart -p
Starts dump in the secondary dump device:
#sysdumpstart -s
To make lv69 as primary dump device:
#sysdumpdev -p /dev/lv69
To make lv69 as primary dump device permanently:
#sysdumpdev -P -p /dev/lv69
To make rmt69 as secondary dump device:
#sysdumpdev -s /dev/rmt69
To determine a new system dump occurred:
#sysdumpdev -z


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------
AIX System Recovery Tips and Techniques




An AIX recovery can be necessary as a result of a number of events: the loss of some system files, an unexplained system crash, a site environmental problem, or simply a request for a system recovery test. Either way, be prepared to hit the ground running and get the recovery done—or be ready to pack your bags and say goodbye.

AIX recovery is a basic skill; there are no excuses for not having it or not being prepared to use it as part of a disaster recovery (DR) plan. AIX system recovery isn’t rocket science, but you need to have your wits about you. This article will help you prepare to perform a recovery quickly and with  confidence. 
Prepare, Prepare, Prepare
Key requirements for a successful recovery are an up-to-date configuration listing of the target machine, a current system backup, and application backups or re-installation media. Whether you’re dealing with a full or partial restore, or a simulated or real disaster, the processes involved are the same. If you’re prepared with these prerequisites, your recovery will go smoothly; if not, you’re in for a difficult time.

The best way to ensure that you’re prepared is to routinely (at least weekly) create a system-bootable backup of your AIX servers to capture the sort of periodic changes that occur on a regular basis, such as PTFs and minor file changes. Also, track the status of applications and data being backed up daily, because these components are much more volatile than the OS itself. Typically, application backup is the responsibility of an operational team, but as an AIX systems admin, you should be informed that the data is being backed up successfully; after all, the applications do reside on your machine. You should also take a configuration report for each server. At minimum, this should include the output of the following commands:
lspv
lsvg -l <vgname>, lsvg -p <vgname>, lsvg <vgname>(for all volume groups)
lsslot -c slot
lscfg -vp
lsdev
lsattr -El sys0
A script can collect this information for you automatically and archive it off machine by, for example, emailing its output file to you. With the information these commands provide, you’ll be on a good footing to a confident recovery.
Expect the Unexpected
Recovering a system to a new server at a remote site typically involves restoring the OS from a tape or DVD bootable backup. You can perform a boot restore via the network if you’ve taken remote network system saves with netboots (e.g., Storix or NIM), but this process is much slower than restoring from a tape or DVD, and only the largest “hot site” facilities have netboot host capabilities. The rest of us must make do with bare-bones recovery from the trenches.

The restore-from-bootable-media process is straightforward. First, because it’s best to start up without a network attachment, make sure all Ethernet and other network cables (other than storage) are unplugged. Next, insert the bootable media—tape or DVD—into a boot-capable drive and start the system. It’s best if the server you’re restoring to closely matches the specs of the failed server, but some differences can be accommodated. For example, the root volume group (rootvg) disk(s) might not be the same size, but as long as they’re larger, not smaller, the restore will complete. You should be prepared to alter some of the logical volume copies or re-size the logical volumes during the AIX recovery process if your restore product allows.
Confirm Settings in New Environment
Confirm from the networks team or DR manager what IPs you’ll be using for the following:
Host and gateway IP addresses (IPv4 and IPv6)
Subnet mask
DNS servers
DNS entries (forward and reverse for all addresses owned by the host)
Firewall, ipfilter, and/or tcpwrapper rules
Printed copies of all customized directories showing ownership and permission settings
Mail relay host (if your machine forwards mail)
xntpd server
You might be on a different LAN or VLAN for the duration of the disaster, so be sure to document the IP environment for the recovery site so that you’re not fighting network issues during recovery operations. And, of course, if your system interacts with other servers or services, ensure that those are accessible from the recovery site.
Review Operational Parameters
Remember that all Ethernet cables should be disconnected at startup. If the machine comes up with the network interface disabled, that’s good; if it comes up enabled, you forgot to take out the Ethernet cables, which can complicate startup troubleshooting. (You don’t want some automated application process kicking off uncontrolled sessions.) When the AIX recovery boot-up completes, it’s time to check all the operational parameters, and then check them again. Review the /etc/inittab file, comment out any non-required services you don’t want started, then refresh the inittab with telinit -q. Check out root’s crontab and review any non-required periodic jobs that might start. Once you’re satisfied that all application processes and undesired mail sending processes are commented out, stop or kill any processes that might have been kicked off before you reviewed /etc/inittab and crontabs. You might want to delete any outbound queued email files held in /var/spool/mqueue because the mail system might try to send those messages, which you might not want until you’re ready for full production operation.

Next, stop and re-start sendmail so you have a clean mail agent running. Review any firewall, ipfilter, and tcp wrapper rules you have; these will undoubtedly have to be amended now that you’re in recovery mode and in a geographically different environment. If your machine’s database applications use raw devices, be sure to check the ownerships of these devices in /dev, because these likely would have been changed on a system restore. Most databases use async I/O; check that your databases are running using pstat -a. If your machine is on AIX 6.1 or later, database processes are started automatically. On AIX 5.3, you’ll probably need to start them up.
On the Network
Bring the machine onto the network by connecting the Ethernet cables (you should have already configured the net interfaces). Verify that you can ping the network gateway (both IPv4 and IPv6 if you use it), your DNS server, and any necessary collaborative servers. Validate that your configured DNS correctly resolves local and global names, and give special attention to reverse name resolution for the IP addresses owned by the AIX system you’re recovering. One of the most common root causes of startup failure is missing DNS entries for the new network environment.

If static routes are required to reach any internal or WAN networks other than through the default gateway, use the netstat -rn command to verify that the routes exist, and add them if needed. Stop and start the sshd service if it’s present (from the console, or you’ll cut off your command-line session). Test a remote connection, such as Telnet or ssh, to ensure you have remote access capabilities. Next, begin the xntpd service to start getting the machine time synced, and verify it with the date command. You should now be able to send a test email to make sure sendmail forwarding works:
#echo "test mail" | mail admin@unixmantra.com
Now you're ready to configure your data volumes.
Bring In the Disks
Internal data volumes won’t typically be saved with the system bootable backup. You must restore them separately, so be sure your DR plan includes the instructions for this step. If you use a Storage Area Network (SAN), the SAN volumes might reside at a remote site. If so, be sure to get iSCSI or FC zoning correct—there’s no time to mess around—then run cfgmgr to bring them in. The same goes for locally attached disks. Be sure to create your disk raid configuration, if required. If you’re only going to be at DR for a few days, you can generally forgo RAID altogether—the complexity isn’t worth the risk of a disk failure during DR operations.

Create the volume groups and file systems based on the configuration reports you captured previously. It might be advantageous to create a script when you're gathering your reports of the host configurations; this lets you automatically create the file systems and saves you a lot of time, as I’ve learned from experience.
Restore the Application Data
As I noted earlier, your application data must be backed up separately from the bootable OS media, and thus must be restored separately. If you’re using a third-party product for your application backups, check that the client is running and talking back to the remote backup server. Next, restore the applications and the data (if you do incremental backups, ensure the operational team has the full list of tapes required). This is typically the operational team’s responsibility, so be sure to hurry them along. When all the data is recovered, review the permissions of the base directories or file systems, then review them again. Once you’re satisfied, prepare to start up the services in a controlled manner, one by one. If you have databases to restore, make sure you have the latest dumps before restoring them. Review the processes running and consult with the applications’ support teams so that there are no issues. If everything looks good, stop all applications.
A reboot with Pause
Now’s the time to test that the machine can reboot. You might be thinking, “Why do this; let’s just get the machine recovered?” Well, if the machine goes down at a working DR site, it doesn’t reflect well on you or your team, so run this test now before you release the machine to the users. There are many factors that could stop an automatic boot, and because your initial boot was closely attended, you might not have encountered or noticed them. Simple things such as an incorrectly seated Ethernet cable or an IP address conflict can cause a reboot to stop and wait for manual intervention, so a trial reboot is essential.

First, clear the errorlog with errclear 0 so that you have a clean error logging sheet. Issue the bosboot and then the reboot commands. You should always issue a bosboot before any reboot or shut down because it’s a good habit to have. If for some reason the boot hangs, count your lucky stars that you discovered the problem now.
A Final Cross-Check, Please
Once the machine comes back up, check that all services are up. Get the support team to connect to the applications. Then relax and wait for the phone calls to come in on some other tinkering that needs to be done. This is inevitable, I’m afraid; however, the bulk of your work is now done.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX Technology Level update strategies

AIX Technology Level update strategies-Different supported ways of updating AIX to a new Technology Level (TL) version
Summary: As an AIX® system administrator, you know the importance of keeping the systems up to date. Unfortunately, this is always a little tricky and, sometimes, due to the size of the environments, very hard to accomplish. This article shows the many ways available to update an AIX server.
Introduction
Staying current with the latest AIX Technology Level (TL) is always the best option to better availability, reliability and security. TL is a set of fixes, and new features added to an AIX version or new hardware support.
You should considered moving to a new TL version for the following reasons:
A new function provided in a new TL is needed.
If the existing TL is out or is about to go out of new fixes and service packs.
The system currently has a need for a fix, which is present on the new TL.
This article goes through the multiple ways of doing a TL update and the fallback options, as well. It shows the approved and supported TL upgrades methods provided by IBM.

Read on:  AIX Technology Level update strategies
Or download PDF here: AIX Technology Level update strategies PDF

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX Toolbox for Linux Applications

AIX® Toolbox for Linux® Applications contains a collection of open source and GNU software built for AIX IBM Systems. These tools provide the basis of the development environment of choice for many Linux application developers. All the tools are packaged using the easy to install RPM format. There is a strong affinity between Linux and AIX for applications. The AIX operating system (OS) has a long history of standards compliance and it is generally straightforward to rebuild Linux applications for AIX. The AIX Toolbox for Linux Applications demonstrates the strong affinity between Linux and AIX operating systems.

Uses of AIX Toolbox for Linux Applications:

Build and package Linux applications for use on AIX
Run Gnome and KDE desktops
Run other popular software commonly found in Linux distributions
Manage open source software using the popular RPM package management system
Develop new applications for the AIX OS using GNU and Linux application development tools
The AIX Toolbox for Linux Applications contains a wide variety of software, including but not limited to :

Application Development - gcc, g++, gdb, rpm, cvs, automake, autoconf, libtool, bison, flex, gettext
Desktop Environments - Gnome and KDE
GNU base utilities - gawk, m4, indent, sed, tar, diffutils, findutils, grep, coreutils
Programming Languages - guile, python, tcl/tk, rep-gtk
System Utilities - emacs, vim, bzip2, gzip, git, elm, ncftp, rsync, wget, lsof, less, samba, zip, unzip, zoo
Graphics Applications - ImageMagick, transfig, xfig, xpdf, ghostscript, gv, mpage,Gimp
Libraries - ncurses, readline, libtiff, libpng, libjpeg, slang, fnlib, db, gtk+, qt
System Shells - bash, tcsh, zsh
Window Managers - metacity, enlightenment
For more information and to download the AIX Toolbox for Linux Applications.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


AIX User Attributes In Depth
By Surya01:53No comments
I have gone through a good article by Brian to distinguish the difference between the user set and default attriubutes of an AIX user accounts . Here are the details about the article.

Every account in AIX has several attributes.   These can be shown with the lsuser command:
 # lsuser surya
app01 id=204 pgrp=staff groups=staff home=/home/app01 shell=/usr/bin/ksh login=true su=true rlogin=true daemon=true admin=false sugroups=ALL admgroups= tpath=nosak ttys=ALL expires=0 auth1=SYSTEM auth2=NONE umask=22 registry=files SYSTEM=compat logintimes= loginretries=0 pwdwarntime=0 account_locked=false minage=0 maxage=0 maxexpired=-1 minalpha=0 minother=0 mindiff=0 maxrepeats=8 minlen=0 histexpire=0 histsize=0 pwdchecks= dictionlist= default_roles= fsize=2097151 cpu=-1 data=262144 stack=65536 core=2097151 rss=65536 nofiles=2000 roles=
These attributes are stored in several files including /etc/passwd, /etc/security/user, /etc/security/passwd, and /etc/security/limits.  All of these files except for /etc/passwd are in the AIX stanza format which looks like:
root:
        admin = true
        SYSTEM = "compat"
        registry = files
        loginretries = 0
        account_locked = false

daemon:
        admin = true
        expires = 0101000070
Each stanza starts with a account name followed by a colon.  The attributes for that account are on the lines below and indented.

At the top of each of these files (/etc/security/user, /etc/security/passwd, and /etc/security/limits) is a "default" stanza.   This stanza defines the default attributes for that file that will be applied for users who don't have the attribute set themselves.

For example, here is part of the /etc/security/user file:
default:
        admin = false
        login = true
        su = true
        daemon = true
        rlogin = true
        sugroups = ALL
        admgroups =
        ttys = ALL
        auth1 = SYSTEM
        auth2 = NONE
        tpath = nosak
        umask = 022
        expires = 0
        SYSTEM = "compat"
        logintimes =
        pwdwarntime = 0
        account_locked = false
        loginretries = 0
        histexpire = 0
        histsize = 0
        minage = 0
        maxage = 0
        maxexpired = -1
        minalpha = 0
        minother = 0
        minlen = 0
        mindiff = 0
        maxrepeats = 8
        dictionlist =
        pwdchecks =
        default_roles =

root:
        admin = true
        SYSTEM = "compat"
        registry = files
        loginretries = 0
        account_locked = false
Notice that the "default" stanza has more attributes defined than the "root" user.  Any attributes not defined for the root user (for example maxage) will take on the value of the default attribute.   If the root user had maxage set, then it would override the default value.

Any time a default attribute is changed it takes effect for all users who don't have the attribute defined for themselves.  In the above example if we changed the default maxage to be 26, then the root user would automatically have its maxage be 26 since the root user doesn't have a maxage attribute defined.   If another account had a maxage defined, changing the default value would have no affect on that account.

In general you want to have as many users as possible use the default values so that if you ever need to change a setting you can just change the default and have it apply to everyone.

You can set a default attribute with the chsec command using a command such as:
chsec -f /etc/security/user -s default -a maxage=26
This would change the default attribute for maxage to be 26.

If a user has a attribute defined (such as maxage) and you want to change them to use the default value, you can run "chuser maxage= app01".   Since a value wasn't defined in the chuser command for maxage it has app01 use the default attribute.

There are some difficult questions to answer though when it comes to users and default attributes:
When I'm looking at a user, which attributes are actually set for the user and which are getting defaults?
If I change a default attribute, which users will it apply to?  
Below is a script called "userattr" that can answer these questions.  
#!/usr/bin/ksh
#userattr
#Copyright 2012 Brian Smith

tab=`printf "\t"`

if [ -n "$1" ]; then
  printf "# \033[37mDEFAULT For User  \033[32m SET For User  \033[33m Unknown";
  lsuser -f $* | grep -v "^$" | while read line; do
    if echo "$line" | grep ":$" >/dev/null; then
      printf "\n\033[0m$line " | tr -d ":"
      user=`echo "$line"  | tr -d ":"`
      continue
    fi

    if echo "$line" | egrep "id=|pgrp=|groups=|home=|shell=|gecos=" > /dev/null && ! echo "$line" | egrep "sugroups|admgroups" >/dev/null; then
      printf "\033[32m$line "
      continue
    fi

    if echo "$line" | egrep "time_last_login=|time_last_unsuccessful_login=|tty_last_login=|tty_last_unsuccessful_login=|host_last_login=|host_last_unsuccessful_login=|unsuccessful_login_count" > /dev/null; then
      continue
    fi

    #lsuser umask doesn't show umask with padded zeros, so add these in for comparison
    if echo "$line" | grep "umask=" > /dev/null; then
      mask=`echo $line | awk -F= '{print $2}'`
      line=`printf "umask=%03d" $mask`
    fi
    if cat /etc/security/user /etc/security/passwd /etc/security/limits | sed "s/[ $tab]=[ $tab]*/=/g" | grep -p "^${user}:" | tr -d '"' | grep "$line$" >/dev/null; then
      printf "\033[32m$line "  #Set
    else
      if cat /etc/security/user /etc/security/passwd /etc/security/limits | sed "s/[ $tab]=[ $tab]*/=/g" | grep -p "^default:" | tr -d '"' | grep "$line$" >/dev/null; then
        printf "\033[37m$line "  #default
      else
        printf "\033[33m$line "  #other
      fi
    fi
  done
printf "\033[0m\n";
else
  printf "\033[0m\n";
  printf "Specify user account or ALL\n"
fi
This script filters through the lsuser output and color codes what attributes are set for a user and which are being defaulted.

For example, if you run "./userattr surya" it shows this:



Anything in green is an attribute that has been explicitly set for this account.   Anything in white is any attribute that is a default attribute.   Anything in orange is unknown (i.e. it isn't set for the user or in the default section.. in these cases AIX has a hard coded default).   So in this example we can see most of the attributes for this user are defaulting, and that it has several attributes set such as maxage and minother.

If you are going to change a default attribute and would like to know which accounts it will affect, you can run "./userattr -a maxage ALL".   This will show the maxage attribute for all users and whether or not each user has a default attribute or if the attribute has been set for that user.  Below is an example screenshot:



All of the users listed in white text have a default attribute and they would all be affected if the default attribute value was changed.   The users with green text have had the maxage attribute set for them and would not be affected by a default attribute value change.

You can also run "./userattr ALL" to list the attributes of all users:



More infomation

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX User commands
By surya aix05:341 comment
To list all system identifications for current user:
#id
To list the default group for current user:
#id -gn
To list all system groups for current user:
#id -Gn
To list the attribute of user root:
#lsuser root
To list the attributes of all users:
#lsuser ALL
To list the home directory of all users:
#lsuser -a HOME ALL
To list all usernames:
#lsuser -a ALL
To list the authentication method for all users:
#lsuser -a auth1 auth2 ALL
To list expiry date:
#lsuser -a expires ALL
To check account lock status of all users:
#lsuser -a account_locked ALL
To enable the user suyar:
#chuser -a login=true surya
Enable surya to login remotely:
#chuser -a rlogin=true surya
Creates user lame with default values in /usr/lib/security/mkuser.defalault:
#mkuser lame
Create user lame without su facility:
#mkuser su=false lame
To remove user pinky:
#rmuser pinky
To remove user lame and his all attributes:
#rmuser -p pinky
List users with tty nos and ip numbers:
#who
Lists history of login logout system startup and shutdowns:
#who /var/adm/wtmp
To list the run level:
#who -r
To list the current user:
#who am i /who -m
To create the group lamers:
#mkgroup lamers
To add users l1 l2 and l3 to lamers group:
#chgroup users=l1,l2,l3 lamers
To delete the group lamers:
#rmgroup lamers
To change the authentication methods:
#chauthent
To change the unsuccessful login count:
#chuser unsuccessful_login_count=0 pinky
To verify user:
#usrck -n lame
To change lame's password (you can easily do this also via ssh if it's needed):
#echo "lame:new_password" | chpasswd -c


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


AIX Version 7.1 -features & benifits

Feature	Benefits
Virtualization	 
AIX Workload Partitions	
Reduced administration, improved system efficiency
AIX 5.2 WPARs for AIX 7 (separate product)	
Easy consolidation of older workloads on new systems
Live Application Mobility	
Increased application availability, enhanced workload manageability and energy savings
AIX Live Partition Mobility	
Increased application availability, enhanced workload manageability and energy savings1,2
Multiple Shared Processor Pools	
Greater resource management flexibility and reduced application software expense1,2
Shared Dedicated Processors	
Improved server utilization1,2
Security
Role Based Access Control	
Improved security, decreased administration costs
Domain support for Role Based Access Control	
Improved security. Enhanced support for multitenant environments
Encrypting Filesystem with hardware acceleration	
Improved security
Trusted AIX	
Highest level of security for critical government and business workloads
AIX Security Expert	
Improved security, decreased administration costs by enabling federated management of security across multiple AIX systems
Secure by Default	
Improved security on initial installations of AIX 7
Trusted Execution	
Improved security
Filesystem Permissions Tool	
Improved security
Near-continuous Availability
Cluster Aware AIX	
Improved availability though improved failover. Increase administrator manageability for scale out workload
Firmware Assisted Dump	
Improved reliability
Concurrent AIX Updates	
Greater system availability, improved security by enabling critical security patches to be installed without causing an outage
Storage Keys	
Improved AIX availability1 and improved application availability2
Dynamic Tracing	
Easier resolution to application execution and performance problems
Enhanced First Failure Data Capture	
Increased AIX reliability and quicker problem resolution
Nonintrusive Service Aids	
Increased AIX reliability and quicker problem resolution
Functional Recovery Routines	
Increased AIX and application reliability and availability
Manageability
1024 thread/256 core scalability	
Capability to support for extremely large workloads
AIX Workload Partitions	
Reduced administrative expense by reducing the number of AIX operating systems to maintain. Greater flexibility to deploy and manage workloads
Live Application Mobility	
Improved flexibility to improve application availability and performance and to reduce energy costs
PowerVM Workload Partitions Manager	
Reduced management costs by providing federated management of workload partitions across the enterprise
AIX Live Partition Mobility	
Improved flexibility to improve application availability and performance and to reduce energy costs1,2
IBM System Director Console for AIX	
Reduced administrative costs and improved administrative effectiveness by enabling web-based administration across multiple AIX instances
Automatic Variable Page Size	
Improved performance with reduced administrative effort
Terabyte Segment Size	
Improved performance
AIX Profile Manager	
Simplifies providing consistent configuration of multiple AIX systems
IBM Systems Director agent included in base AIX installation	
Enables AIX systems for immediate management by IBM Systems Director
AIX Event Infrastructure	
Simple to use interface for system event monitoring
Supported versions of openssh and openssl included on base AIX installation media	
Simplified installation of the commonly used open source tools




------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX-Backup and Recovery

Backup rootvg using mksysb
mksysb
Creates an installable image of the root volume group either in a file or on to a bootable tape
Bootable tape is created in backup format
Can be restored individual files/directories using restore command
mksysb
        -e  /excludes files in /etc/exclude.rootvg 
        -i  to create image.data file
        -v  verbose mode 
        -X  extend /tmp filesystem if necessory for storing boot image
-i option calls mkszfile command which inturn creats /image.data file.
The bootable mksysb volume contains four images
Boot image
bosinstall image (image.data, bosinst.data, tapeblksz, etc..)
An empty table of contents
System Backup Image in Back up format
/bosinst.data file contains answer for questions during installation time such as Console name, Installation methode, locale seetings, etc.. If there is no /bostinst.data file present, then a sample file /usr/lpp/bosinst/bosinst.template is copied as /bosinst.data during backup process.

/image.data file contains logical volume and filesystem information of root volume group which is used by BOS install for creating target rootvg. If you want to create a custom image.data file, create the file using mkszfile, modify the file as per your requirement and call the mksysb command without -i option.
With these two files, it is possible to carry out an un-attended installation.
Examples:
To create system backup and create an /image.data file
 # mksysb -i /dev/rmt0
To exclude files and directories stored in /etc/exclude.rootvg file
 # mksysb -i -e /dev/rmt0
To store the mksysb image to a file called /stage/backp/mksysb.img
 # mksysb /stage/backp/mksysb.img
Backup or restore VGs using savevg and restvg
savevg command is used to backup volume groups other than rootvg
restvg command is used to restore volume groups other than rootvg
savevg
   -e excludes files/directories being backed in /etc/exclude.<vgname> file
   -i creates /tmp/vgdata/<vgname>/<vgname>.data file
   -f <device>  device or filename on which the image to be stored
   -v verbose mode
   -X automatically expand /tmp filesystem if required
-i option calls mkvgdata command which inturn creates /tmp/vgdata/<vgname>/<vgname>.data file
restvg
Backing up a filesytem or files
Restore files
restore
       -q  tells restore commnad that volume is ready
       -t, -T  to list the list of files in the backup archive
       -v  verbose
       -r  restores all files in the filesystem archive
       -x  to restore specifig files/directories
       -d  to restore all files in a directory if the File parameter is a directory
       -s <number>  To seek and restore the multiple backup tapes
To list the names of files in either a file-name or file-system archive
  # restore -Tq -f /dev/rmt0
To list all the files in a mksysb tape backup
  # restore -Tvqs 4 -f /dev/rmt0.1      
To restore an entire file-system archive, enter:
  # restore -rvqdf /dev/rmt0
To restore a specific file
  # restore -xvqf myhome.bkup system.data
To restore a specific file "/etc/passwd" from mksysb image file "mksysb.host1"
  # restore -xvqdf mksysb.host1 ./etc/passwd
Extracting data from mksysb tape
 a. Rewind the tape using the command:
    # tctl -f /dev/rmt0 rewind
 b. Move the tape forward to the third tape marker (beginning of fourth image):
    # tctl -f /dev/rmt0.1 fsf 3
 c. Restore data:
    # restore -xqvf /dev/rmt0.1 /tmp/my_file


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Automatically e-mail error report entries

You can automatically forward all error report entries to your email. This next part describes how to do that.
Create a file like this:
# cat /tmp/mailgeorge
errnotify:
  en_name="mailgeorge"
  en_persistenceflg=1
  en_method="errpt -a -l $1|mail -s \"errpt: $9\" abc@email.com"
Add this to the ODM:
# odmadd /tmp/mailgeorge
Now log an entry in the error report:
# errlogger "My coffee is cold"
You will see in the error report:
# errpt -a
----------------------------------------------------
LABEL:          OPMSG
IDENTIFIER:     AA8AB241

Date/Time:       Tue Oct  6 15:57:58 CDT 2009
Sequence Number: 585
Machine Id:      0004D6EC4C00
Node Id:         hostname
Class:           O
Type:            TEMP
Resource Name:   OPERATOR

Description
OPERATOR NOTIFICATION

User Causes
ERRLOGGER COMMAND

        Recommended Actions
        REVIEW DETAILED DATA

Detail Data
MESSAGE FROM ERRLOGGER COMMAND
My coffee is cold
Clear the error log again (because we logged a fake test-entry in the error report):
# errclear 0
By the way, you can delete this from the ODM like this:
# odmdelete -q 'en_name=mailgeorge' -o errnotify 



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


Backup commands in AIX

mksysb -i -X /dev/rmt0        Creates image.data and system backup (-X expands /tmp if required)

mksysb -m /dev/rmt0        Creates image.data file with map file and system backup


mksysb -e /dev/rmt0        Creates system data but excludes the files listed in /etc/exclude.rootvg


mkszfile                Creates /image.data file


mkcd -d /dev/cd1            Creates system boot backup to the CD-R device /dev/cd1    (mksysb)


mkcd -d /dev/cd1 -v datavg        Creates  backup of VG datavg to CD-R device /dev/cd1   (savevg)

savevg -i -f /dev/rmt0 datavg    Creates datavg.data image file and backup vg datavg (path = /tmp/vgdata/datavg/datavg.data)


savevg -ef  /dev/rmt0 datavg        Creates datavg backup but excludes files listed in the /etc/exclude.datavg


find / -print | backup -ivf /dev/rmt0    Backup entire system to rmt0


backup -0vf /dev/rmt0 /home    Backup /home directory to rmt0 with backup level 0


restore -Tvf /dev/rmt0        List the archive in rmt0


restore -xvf /dev/rmt0 /home    Restore /home from archive in device rmt0


restore –xvf /export/mksysb ./etc/sshd.conf    Restores particular file from /export/mksysb image

restore -Pa -vf /dev/rmt0 ./etc/passwd    Restore only a file attribute from tape

 find ./home -print |cpio -ocvumB > /dev/rmt0  Archives /home directory 

cpio -icvdumB < /dev/rmt0  Restores cpio archive from rmt0

cpio -ivt < /dev/rmt0      List the contents of cpio archive from rmt0

cpio -icvd < /dev/rmt0 /home  Restores /home directory from rmt0


tar -cvf /dev/rmt0 /home        Archives /home to rmt0 device


tar -tvf /dev/rmt0            List the archives in rmt0


tar -xvf /dev/rmt0 /home        Extract /home from rmt0


dd if=file1 of=file2 conv=ebcdic    Convert and copy ascii file to ebcdic file2


dd count=1 bs=4k skip 31 seek=1 if=/dev/hd4 of=/dev/hd4    copy 31st block and paste to 1st block in the hd4 ( ie.to fix currupted superblock by restoring it's backup copy to original location)


dd if=/dev/rmt0 ibs=512 obs=1024 of=/dev/rmt1  To copy blocks from rmt0 with 512 blocks to rmt1 with 1024 blocks 


tctl -f /dev/rmt0 rewind        To rewind the tape


tctl -f /dev/rmt0 offline        To eject the tape


tctl -f /dev/rmt0 status        To show the status of tape

tcopy /dev/rmt0.0 /dev/rmt1.0   to copy contents of 1st tape(tape0) to 2nd tape(tape1). It is useful when the size of the tapes are different.


tcopy /dev/rmt0     to show no. of files and block size in the tape


chdev -l rmt0 -a block_size=512    To change the block size of the tape to 51201


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

BOOT PROCESS IN AIX



Loading the boot image of AIX
After POST, the firmware (System Read Only Storage) detects the 1st bootable device stored in the bootlist. (here it is hdisk0)
Then the bootstrap code (software ROS) i.e. 1st 512 bytes of the hard disk loads to RAM.
Bootstrap code locates the Boot Logical Volume (BLV = hd5) from the harddisk
BLV contains AIX kernel, rc.boot Script, Reduced ODM andBoot commands.
Then BLV in the RAM uncompresses and Kernel releases from it.
Then AIX Kernel gets control.
AIX Kernel creates a RAM File System (Rootvg not activated now).
Kernel starts init process from the BLV.
init executes rc.boot script from the BLV in the RAM.
Init with rc.boot 1 configures base devices.
rc.boot 1 in detail
init process from RAMFS executes rc.boot 1 (if any error LED=c06)
restbase command copies ODM from BLV to RAMFS.(success LED=510, error LED=548)
cfgmgr -f calls Config_rules ( which are phase=1) and activatesall base devices.
run command bootinfo -b to check last boot device ( success LED=511).
Then
rc.boot 2 activates rootvg from hard disk.

rc.boot 2 in detail


rc.boot 2 (LED 551)
ipl_varyon to activate rootvg ( success LED= 517, error LED=552,554,556).
run command fsck -f /dev/hd4 to check whether "/" unmounted uncleanely in the last shutdown ( error LED=555).
mount /dev/hd4 (/) to RAMFS (error LED=557 due to corrupted jfslog..)
 fsck -f /dev/hd2  i.e.  "/usr" ( error LED=518).
mount /dev/hd2 in RAMFS.
fsck -f /dev/hd9var  i.e. check "/var"
mount /var
copycore command checks whether dump occured. then copy dump from primary dump device paging space (/dev/hd6) to/var/adm/ras/.
unmount /var
swapon /dev/hd6  i.e. activate primary paging space.

Now the condition is /dev/hd4 is mounted on / in the RAMFS;

cfgmgr -f configured all base devices . so configuration data has been written to ODM of RAMFS.
mergedev is called and copy /dev from RAMFS to disk.
copy customized ODM from RAMFS to hard disk(at this stage both ODM from hd5 and hd4 are sync now)
mount /var.
Boot messages copy to file on the hard disk (/var/adm/ras/bootlog)    alog -t boot -o to view bootlog

Now / , /usr and /var are mounted in rootvg on the hard disk. Then

Kernel removes RAMFS
init process start from / in the rootvg
Here completes rc.boot 2, Now the condition is kernel removed RAMFSand accessing rootvg filesystems from hard disk. init from BLV replacedby init from hard disk
in rc.boot 3, init process /etc/inittab file and remaining devicesare configured.
rc.boot 3 in detail
 /etc/init starts and reads /etc/inittab ( LED=553)
 runs /sbin/rc.boot 3 
fsck -f /dev/hd3 i.e. check /tmp.
mount /tmp
sysncvg rootvg &;    i.e. run syncvg in background and reportstale PPs.
cfgmgr -P2  i.e. run cfgmgr in phase 2 in normal startup. (cfgmgr -P3 in service mode)
All remaining devices are configured now.
cfgcon configures console ( LED= c31 select console, c32 lft, c33tty, c34 file on disk). If CDE mentioned in /etc/inittab we will getgraphical console.
savebase calls to sync ODM from BLV with / FS (i.e./etc/objrepos).
syncd daemon started. All data from cache memory to disksaves in every 60 seconds.
starts errdaemon for error logging.
LED display turned OFF.
rm /etc/nologin i.e. if the file is not removed, then login is not possible.
If any device are in missed state, (in Cudv chgstatus=3)display it.
Display "system initialization completed"
Then execute next line from /etc/inittab 
DETAILED
=======
I. The boot process in AIX
As a system administrator you should have a general understanding of theboot process. This knowledge is useful to solve problems that can prevent asystem from booting properly. These problems can be both software or hardware.We also recommend that you be familiar with the hardware configuration of your system. 

Booting involves the following steps:

The initial step in booting a system is named Power On Self Test (POST). Its purpose is to verify that basic hardware is in functional state.The memory, keyboard, communication and audio devices are also initialized. You can see an image for each of these devices displayed on the screen. It is during this step that you can press a function key to choose a different boot list. TheLED values displayed during this phase are model specific. Both hardware and software problems can prevent the system from booting.

System Read Only Storage (ROS) is specific to each system type. It is necessary for AIX 5L Version 5.3 to boot, but it does not build the datastructures required for booting. It will locate and load bootstrap code.System ROS contains generic boot information and is operating systemindependent. Software ROS (also named bootstrap) forms an IPL control block which is compatible with AIX 5L Version 5.3, takes control and builds AIX 5L

specific boot information. A special file system located in memory and named RAMFS file system is created. Software ROS then locates, loads, and turns control over to AIX 5L Boot Logical Volume (BLV). Software ROS is AIX 5L information created based on machine type and is responsible for completing machine preparation to enable it to start AIX 5L kernel. A complete list of files that are part of the BLV can be obtained from directory/usr/lib/boot.

The most important components are the following:

- The AIX 5L kernel

- Boot commands called during the boot process such as bootinfo, cfgmgr
- A reduced version of the ODM. Many devices need to be configured hd4 (/) made available, so their corresponding methods have to be stored in the BLV. These devices are marked as base in PdDv.
- The rc.boot script

Note: Old systems based on MCI architecture execute an additional stepbefore this, the so called Built In Self Test (BIST). This step is no longer required for systems based on PCI architecture.

The AIX 5L kernel is loaded and takes control. The system will display0299 on the LED panel. All previous codes are hardware-related. The kernelwill complete the boot process by configuring devices and starting the initprocess. LED codes displayed during this stage will be generic AIX 5L codes. So far, the system has tested the hardware, found a BLV, created theRAMFS, and started the init process from the BLV. The rootvg has not yet been activated. From now on the rc.boot script will be called three times,each timebeing passed a different parameter.
1.Boot phase 1
During this phase, the following steps are taken:

The init process started from RAMFS executes the boot script rc.boot 

If init process fails for some reason, code c06 is shown on LED display. At this stage, the restbase command is called to copy a partial image of ODM from the BLV into the RAMFS. If this operation is successful LED display shows 510, otherwise LED code 548 is shown.

After this, the cfgmgr -f command reads the Config_Rules class from the reduced ODM. In this class, devices with the attribute phase=1 are considered base devices. Base devices are all devices that are necessary to access rootvg.For example, if the rootvg is located on a hard disk all devices starting from motherboard up to the disk will have to be initialized.The corresponding methods are called so that rootvg can be activated in the nextboot phase 2. At the end of boot phase 1, the bootinfo -b command is called to determine the last boot device. At this stage, the LED shows511.
2.Boot phase 2
In this phase , the rc.boot script is passed to the parameter 2. During this phase the following steps are taken.

a) The rootvg volume group is varied on with the special version of the varyonvg command ipl_varyon. If this command is successful the system displays 517. otherwise one of the following LED will appear 552,554,556and the boot process is halted.

b) Root file system hd4 is checked using the fsck -f command. This will verify only whether the filesystem was unmounted cleanly before the last shutdown. If this command fails, the system will display code 555.

c) The root file system ( /dev/hd4 ) is mounted on a temporary mount point /mnt in RAMFS. If this fails 557 will appear in LED.

d) The /usr file system is verified using fsck -f command and then mounted. the copycore command checks if a dump occured. if it did, it is copied from default dump devices, /dev/hd6 to the default copy directory/var/adm/ras. After this /var is unmounted.

e) The primary pagingspace from rootvg, /dev/hd6 will be activated.

f) The mergedev process is called and /dev files from RAMFS are copiedto disk.

g) All customized ODM files from the RAMFS are copied to disk.Both ODM versions from hd4 and hd5 are synchronized.

h) Finaly, the root file system from rootvg (disk) is mounted over the root file system from the RAMFS. The mount points for the root filesystems become available. now the /var and /usr file systems from the rootvg aremounted again on their ordinary mount points. There is no consoleavailable at this stage; so all boot messages will be copied to alog. The alog command maintains and manages logs.
3.Boot Phase 3
After phase 2 is completed rootvg is activated and the following steps are taken,

a. /etc/init process is started. It reads /etc/inittab file and calls rc.bootwith argument 3

b. The /tmp filesystem is mounted.

c. The rootvg is synchronized by calling the synchvg command and launching it as background process. As a result all stale partitions from rootvg are updated.At this stage LED code 553 is shown.

d. At this stage the cfgmgr command is called.if the system is booted innormal mode the cfgmgr command is called with option -p2; in servicemode, option -p3. The cfgmgr command reads the Config_rules files fromODM and calls all methods corresponding to either phase 2 or 3. All otherdevices that are not base devices are configured at this time.

e. Next the console is configured by calling the cfgcon command. After the configuration of the console , boot messages are send to the console if no STDOUT redirection is made. However all missed messages can be found in/var/adm/ras/conslog. LED codes that can be displayed at this time are :

c31 = console not yet configured.

c32 = console is an LFT terminal.
c33 = console is a TTY.
c34 = console is a file on the disk.

f. finally the synchronization of the ODM in the BLV with the ODM from the/ (root) filesyatem is done by the savebase command.

g. The syncd daemon and errdaemon are started.

h. LED display is turned off.

i. if the /etc/nologin exists, it will be removed.

j. If there are devices marked as missing in CuDv a message is displayed on the console.

I. the message system initialization completed is send to the console. the execution of the rc.boot has completed. init process will continueprocessing the next command from /etc/inittab.
II. system initialization
During system startup, after the root file system has been mounted in the pre-initialization process, the following sequence of events occurs:

1. The init command is run as the last step of the startup process.

2. The init command attempts to read the /etc/inittab file.
3. If the /etc/inittab file exists, the init command attempts to locate aninitdefauult entry in the /etc/inittab file.

a. If the initdefault entry exists, the init command uses the specifiedrunlevel as the initial system run level.

b. If the initdefault entry does not exist, the init command requests that the user enter a run level from the system console (/dev/console).
c. If the user enters an S, s, M, or m run level, the init command enters themaintenance run level. These are the only runlevels that do not require a properly formatted /etc/inittab file.

4. If the /etc/inittab file does not exist, the init command places the system in the maintenance run level by default.

5. The init command rereads the /etc/inittab file every 60 seconds. If the /etc/inittab file has changed since the last time the init command read it, the new commands in the /etc/inittab file are executed.
III. The /etc/inittab file
The /etc/inittab file controls the initialization process.

The /etc/inittab file supplies the script to the init command's role as a general process dispatcher. The process that constitutes the majority of the init command's process dispatching activities is the /etc/getty line process, which initiates individual terminal lines. Other processes typically dispatched by the init command are daemons and the shell.

The /etc/inittab file is composed of entries that are position-dependent and have the following format,

/etc/inittab format = Identifier:RunLevel:Action:Command

Each entry is delimited by a newline character. A backslash (\) preceding a new line character indicated the continuation of an entry. There are no limits(other than maximum entry size) on the number of entries in the /etc/inittab file.

The maximum entry size is 1024 characters.

The entry fields are : 

Identifier

A one to fourteen character field that uniquely identifies an object.

RunLevel

The run level at which this entry can be processed. The run level has the following attributes: 

-Run levels effectively correspond to a configuration of processes in the system.

-Each process started by the init command is assigned one or more run levels in which it can exist.

-Run levels are represented by the numbers 0 through 9. 

Eg: if the system is in run level 1, only those entries with a 1 in the run-level field are started.

-When you request the init command to change run levels, all processes without a matching entry in the run-level field for the target run level receive a warning signal (SIGTERM). There is a 20-second grace period before processes are forcibly terminated by the kill signal (SIGKILL).

-The run-level field can define multiple run levels for a process by selecting more than one run level in any combination from 0 through 9. If no run levelis specified, the process is assumed to be valid at all run levels.

-There are four other values that appear in the run-level field, even though they are not true run levels: a, b, c and h. Entries that have these characters in the run level field are processed only when the telinit command requests them to be run (regardless of the current run level of the system). They differ from run levels in that the init command can never enter run level a, b, c or h. Also, a request for the execution of any of these processes does not change the current run level. Furthermore, a process started by an a, b,or c command is not killed when the init command changes levels. They are only killed if their line in the /etc/inittab file is marked off in the action field, their line is deleted entirely from /etc/inittab, or the init command goes into single-user mode.

Action

It tells the init command how to treat the process specified in the process field. The following actions are recognized by the init command:

respawn If the process does not exist, start the process. Do not wait forits termination (continue scanning the /etc/inittab file). Restart the process when it dies. If the process exists, do nothing and continue scanning the /etc/inittab file.

wait When the init command enters the run level that matches the entry's run level, start the process and wait for its termination. All subsequent reads of the /etc/inittab file, while the init command is in the same run level, will cause the init command to ignore this entry.

once When the init command enters a run level that matches the entry's run level, start the process, and do not wait for termination. When it dies, do not restart the process. When the system enters a new run level, and the process is still running from a previous run level change, the program will not be restarted.

boot Process the entry only during system boot, which is when the init command reads the /etc/inittab file during system startup. Start the process, do not wait for its termination, and when it dies, do not restart the process. In order for the instruction to be meaningful, the run level should be the default or it must match the init command's run level at boot time. This action is useful for an initialization function following a hardware reboot of the system.

bootwait Process the entry the first time that the init command goes fromsingle-user to multi-user state after the system is booted. Start the process, wait for its termination, and when it dies, do not restart the process. If the initdefault is 2, run the process right after boot.

powerfail Execute the process associated with this entry only when the init command receives a power fail signal ( SIGPWR).

powerwait Execute the process associated with this entry only when the init command receives a power fail signal (SIGPWR), and wait until itterminates before continuing to process the /etc/inittab file. 

off If the process associated with this entry is currently running, send thewarning signal (SIGTERM), and wait 20 seconds before terminating the process with the kill signal (SIGKILL). If the process is not running, ignore this entry.

ondemand Functionally identical to respawn, except this action applies to the a, b, or c values, not to run levels.

initdefault An entry with this action is only scanned when the init command is initially invoked. The init command uses this entry, if it exists, to determine which run level to enter initially. It does this by taking the highest run level specified in the run-level field and using that as its initial state. If the run level field is empty, this is interpreted as 0123456789. therefore, the init command enters run level 9. Additionally, if the init command does not find an initdefault entry in the /etc/inittab file, it requests an initial run level from the user at boot time. 

sysinit Entries of this type are executed before the init command tries toaccess the console before login. It is expected that this entry will only be used to initialize devices on which the init command might try to ask the run level question. These entries are executed and waited for before continuing. 

Command

A shell command to execute. The entire command field is prefixed with exec and passed to a forked sh as sh -c exec command. Any legal sh command syntax can appear in this field. Comments can be inserted with the # comment syntax. 

The getty command writes over the output of any commands that appear before it it in the /etc/inittab file. To record the output of these commands to the boot log, pipe their output to the alog -tboot command. The stdin,stdout, and stderr file descriptors may not be available while the init command is processing inittab entries. Any entries writing to stdout or stderr may not work predictably unless they redirect their output to a file or to /dev/console.

The following commands are the only supported methods for modifying the records in the /etc/inittab file. 

lsitab Lists records in the /etc/inittab file.

mkitab Adds records to the /etc/inittab file.
chitab Changes records in the /etc/inittab file.
rmitab Removes records from the /etc/inittab file.

Eg:

If you want to add a record on the /etc/inittab file to run the find command on the run level 2 and start it again once it has finished: 

1. Run the ps command and display only those processes that contain the word find: 

# ps -ef | grep find
root 19750 13964 0 10:47:23 pts/0 0:00 grep find
#
2. Add a record named xcmd on the /etc/inittab using the mkitab command:
# mkitab "xcmd:2:respawn:find / -type f > /dev/null 2>&1"
3. Show the new record with the lsitab command:
# lsitab xcmd
xcmd:2:respawn:find / -type f > /dev/null 2>&1
#
4. Display the processes:
# ps -ef | grep find
root 25462 1 6 10:56:58 - 0:00 find / -type f
root 28002 13964 0 10:57:00 pts/0 0:00 grep find
#
5. Cancel the find command process:
# kill 25462
6. Display the processes:
# ps -ef | grep find
root 23538 13964 0 10:58:24 pts/0 0:00 grep find
root 28966 1 4 10:58:21 - 0:00 find / -type f
#

Since the action field is configured as respawn, a new process (28966 in this example) is started each time its predecessor finishes. The process will continue re-spawning, unless you change the action field,

Eg: 

1. Change the action field on the record xcmd from respawn to once:

# chitab "xcmd:2:once:find / -type f > /dev/null 2>&1"
2. Display the processes:
# ps -ef | grep find
root 20378 13964 0 11:07:20 pts/0 0:00 grep find
root 28970 1 4 11:05:46 - 0:03 find / -type f
3. Cancel the find command process:
# kill 28970
4. Display the processes:
# ps -ef | grep find
root 28972 13964 0 11:07:33 pts/0 0:00 grep find
#

To delete this record from the /etc/inittab file, you use the rmitab command.

Eg:

# rmitab xcmd

# lsitab xcmd
#

Order of the /etc/inittab entries

The base process entries in the /etc/inittab file is ordered as follows:

1. initdefault

2. sysinit
3. Powerfailure Detection (powerfail)
4. Multiuser check (rc)
5. /etc/firstboot (fbcheck)
6. System Resource Controller (srcmstr)
7. Start TCP/IP daemons (rctcpip)
8. Start NFS daemons (rcnfs)
9. cron
10.pb cleanup (piobe)
11.getty for the console (cons)

The System Resource Controller (SRC) has to be started near the begining of the etc/inittab file since the SRC daemon is needed to start other processes. Since NFS requires TCP/IP daemons to run correctly, TCP/IP daemons are started ahead of the NFS daemons. The entries in the /etc/inittab file are ordered according to dependencies, meaning that if a process (process2) requires that another process (process1) be present for it to operate normally, then an entry for process1 comes before an entry for process2 in the /etc/inittab file. 




------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Booting in Maintenance Mode
By Surya15:57No comments
 
Prerequisites
You want to boot your system for Maintenance Mode.
All hardware is installed.
The AIX Version 4 Base Operating System (BOS) is installed.
Your system unit is set to Off.
Locate the key for the key lock on your system unit.
Accessing the System

1. Turn the system key, if present, to the Service position.

2. Turn on all attached external devices, such as terminals, CD-ROM drives, tape drives, monitors, and external disk drives before turning on the system unit. Do not turn the system unit on until step 5. Turning on the external devices first is necessary so that the system unit can identify them during the startup (boot) process.

3. Insert the installation media into the tape or CD-ROM drive. If you are using CD-ROM that utilizes a separate disc caddy, insert the CD-ROM into the disc caddy and then insert the caddy into the CD-ROM drive.

4. If you are not using an ASCII terminal, skip to step 5. If you are using an ASCII terminal, set the communications options as follows:

5. Turn the system unit power switch to the On position. The system begins booting from the installation media. If your system is booting from tape, it is normal for the tape to move back and forth. After several minutes, c31 is displayed in the three-digit LED.

6. Select option 3, start Maintenance Mode for system recovery, from the Welcome to the Base Operating System Installation and Maintenance screen when it is displayed.

7. Select option 1, Access a Root Volume Group, from the Maintenance screen. The Warning screen is displayed

8. Read through the information displayed on the Warning screen. When you are ready to continue, type 0 and press Enter. The Access a Root Volume Group screen is displayed

9. Select the option for the root volume group whose logical volume information you want to display. The Access a Root Volume Group screen lists all of the volume groups (root and otherwise) on your system. After entering your selection, the Volume Group Information screen is displayed.

10. Select one of the options from the Volume Group Information screen and press Enter. Each option does the following:

Choice 1

Access this volume group and start a shell. Selecting this choice imports and activates the volume group and mounts the file systems for this root volume group before providing you with a shell and a system prompt.

Choice 2

Access this volume group and start a shell before mounting file systems. Selecting this choice imports and activates the volume group and provides you with a shell and system prompt before mounting the file systems for this root volume group.

Choice 99

Entering 99 returns you to the Access a Root Volume Group screen.

11. After either choice 1 or 2 is selected and processed, a shell and system prompt are displayed.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Brian Smith's AIX Projects
By Surya00:59No comments

prdiff - Shows differences between LPAR profiles and their running configs.  You should run this before you shutdown any LPAR's to ensure the LPAR profile is in sync with the running configuration.   http://prdiff.sourceforge.net/

pslot - Validates and optionally visualizes Virtual Fibre Channel and Virtual SCSI slots.   If you have a medium to large PowerVM environment this will almost certainly find issues with your configuration that you want to fix.   It can optionally produce nice diagrams of your virtual slot layouts as well.  http://pslot.sourceforge.net/

EZH - The Easy HMC command line interface.   If you would like to use the HMC command line interface more instead of the HMC GUI but you are frustrated with the native HMC command line interface then EZH is for you.   It provides a very simple command line interface to the most common HMC functions and also provides a lot of new functionality not available in the native HMC command line interface.  http://ezh.sourceforge.net/

npivgraph - This utility produces detailed visual diagrams of your PowerVM NPIV environment.   This is extremely useful for troubleshooting, understanding, and architecting NPIV systems.   Plus the graphs will totally impress your boss!    http://npivgraph.sourceforge.net/

graphlvm - This one generates visual diagrams of your physical volumes, volume groups, logical volumes, and filesystems.  Makes it very easy to see where your data is stored and to understand how everything relates to each other in the LVM.  http://graphlvm.sourceforge.net/

vethgraph - This utility visualizes your Virtual Ethernet VLAN's.  Again, these graphs will totally impress your boss and make it easier for you to troubleshoot the environment.  http://vethgraph.sourceforge.net/




------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Capped Mode Vs Uncapped Mode
By Surya12:42No comments

Capped Mode

In capped mode the processing units given to a partition can not exceed the assigned processing units (entitled capacity) even though there may be resources in the shared pool.


Uncapped Mode 

In uncapped mode the processing units can exceed the entitled capacity of the partition if enough resources are available in the shared resource pool. At this point of time the assigned uncapped weight of the partition comes into picture.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------
Cloning rootvg using alt_disk_copy
By Surya19:31No comments
Using alt_disk_copy (see the Resources section) to clone your rootvg disks for ease of back-out when doing AIX® upgrades or applications upgrades that resided on the rootvg disks. In that article, I did not cover hardware migrations as this was out of scope. In this article, I discuss how this can be achieved. The man page on alt_disk_copy states (by using the 'O' option), "Performs a device reset on the target altinst_rootvg. This causes the alternate disk install to not retain any user-defined device configurations. This flag is useful if the target disk or disks become the rootvg of a different system."

In a nutshell, this means that any devices that have had their attributes changed, typically by the system administer, are reset to the default value(s). This could mean any changes to the following, but not restricted to:
Ethernet cards—reset of IP addresses /hostname
Fibre (SAN) cards—reset of any attributes changes, like fc_err_recov
sys0—reset of any attributes changes, like maxuproc
Reset of the diag hardware email notification list
The process of the migration or move using the cloned rootvg disk method is down to your operating requirements. The most common use is to clone a rootvg disk and insert it onto the new machine for a new base build. This process can be done with the source machine still running. Indeed, it is practical that once the cloned disk is across, you get that disk mirrored, then insert a new disk on the source, and re-mirror that one so you have no down time on the source machine.

However, in this demonstration, I will point out procedures one could use to migrate to new hardware. Taking fibre cards from the source machine to the new machine, as well as the SAN attached disks. As a general rule, there is no need to remove the Ethernet cards, as any new machine, should already have these present.

Review your existing configuration

If you are only concerned about cloning rootvg to build a base new machine, then there is no point in gathering current configurations. Only if you are migrating to new hardware from the current hardware do you have to take config listings to change attributes on the new system.
When migrating to new hardware, review your inittab setting, comment out the services that you do not want to come up until the migration is complete. It is also advisable to take configuration listing of the current AIX machine, so any changes that are reset by the alt_disk_copy and be changed once the new system is brought up.

The following is not an exhaustive list of configuration listing you need to check and amend on the new system when migrating, but it is a good starting point:
Listings of all VGs and their LV contents
Listing of all the PVs
lsattr -El output of all fibre and scsi cards
For aio servers, on AIX 6 and 7, ioo -a
For aio server, on 5.3 and below use: lsattr -El aio0
Listings of Ethernet cards (including ether-channel if present)
Take note of IPs and gateway addresses
lscfg -vp output
lsdev output (ie: lsdev -Cc disk)
Prepare to move
In this demonstration, you can assume:
alpha is the source host.
bravo is the destination host.
Be mirrored up
On host alpha, make sure the rootvg is mirrored. In this demonstration, we can see that rootvg is not fully mirrored, /opt/db2_09_01, only has one copy. So you need to fix that before unmirroring rootvg.
# lsvg -l rootvg
rootvg:
LV NAME             TYPE       LPs     PPs     PVs  LV STATE      MOUNT POINT
hd5                 boot       1       2       2    closed/syncd  N/A
hd6                 paging     4       8       2    open/syncd    N/A
hd8                 jfs2log    1       2       2    open/syncd    N/A
hd4                 jfs2       8       16      2    open/syncd    /
hd2                 jfs2       36      72      2    open/syncd    /usr
hd9var              jfs2       3       6       2    open/syncd    /var
hd3                 jfs2       16      32      2    open/syncd    /tmp
hd1                 jfs2       8       16      2    open/syncd    /home
hd10opt             jfs2       6       12      2    open/syncd    /opt
hd11admin           jfs2       1       2       2    open/syncd    /admin
lg_dumplv           sysdump    8       16      1    open/syncd    N/A
livedump            jfs2       2       4       2    open/syncd    /var/adm/ras/l
ivedump
fwdump              jfs2       1       2       2    open/syncd    /var/adm/ras/p
latform
fslv01              jfs2       8       8       1    open/syncd    /opt/db2_09_01
loglv01             jfslog     1       2       2    open/syncd    N/A

# mklvcopy fslv01 2
# syncvg -l fslv01
# lsvg -l rootvg
rootvg:
LV NAME             TYPE       LPs     PPs     PVs  LV STATE      MOUNT POINT
hd5                 boot       1       2       2    closed/syncd  N/A
hd6                 paging     4       8       2    open/syncd    N/A
hd8                 jfs2log    1       2       2    open/syncd    N/A
hd4                 jfs2       8       16      2    open/syncd    /
hd2                 jfs2       36      72      2    open/syncd    /usr
hd9var              jfs2       3       6       2    open/syncd    /var
hd3                 jfs2       16      32      2    open/syncd    /tmp
hd1                 jfs2       8       16      2    open/syncd    /home
hd10opt             jfs2       6       12      2    open/syncd    /opt
hd11admin           jfs2       1       2       2    open/syncd    /admin
lg_dumplv           sysdump    8       16      1    open/syncd    N/A
livedump            jfs2       2       4       2    open/syncd    /var/adm/ras/l
ivedump
fwdump              jfs2       1       2       2    open/syncd    /var/adm/ras/p
latform
fslv01              jfs2       8       16      2    open/syncd    /opt/db2_09_01
loglv01             jfslog     1       2       2    open/syncd    N/A 

Confirm your boot image is good and mirrored, if not alt_disk_copy will fail:
# lslv -m hd5
hd5:N/A
LP    PP1  PV1               PP2  PV2               PP3  PV3
0001  0001 hdisk0            0001 hdisk1

Identify the disk to move
Before alt_disk is executed, it is good prudence to identify physically the disk that will be removed. Depending on how your disks are placed, use either the hot-swap smit utility or smit diag to identify the disk location using the menu selections:
smit diag
task selection
identify /attention indicator

Make sure you know which is hdisk0 and hdisk1. A useful tip here is to put a small sticker of each drive with their corresponding hdisk names, so you can be sure you do not remove the wrong disk. In this demonstration, we will initially be moving hdisk1 to the new hardware, so first locate hdisk1 location code, using:
# lscfg -vp |grep -w hdisk1
  hdisk1           U787F.001.DPM0Y7F-P1-T10-L4-L0   16 Bit LVD SCSI Disk Drive (
18200 MB)

Now using smit diag, use the above hdisk1 location code to match up with the device location code you want to identify. Once the hdisk1 light comes on, label it, for reference.
Next, do the following:
run bosboot
unmirrorvg rootvg
reducevg rootvg to remove hdisk1
# bosboot -a
# unmirrorvg rootvg hdisk1
0516-1246 rmlvcopy: If hd5 is the boot logical volume, please run 'chpv -c <disk
name>'
        as root user to clear the boot record and avoid a potential boot
        off an old boot image that may reside on the disk from which this
        logical volume is moved/removed.
0516-1804 chvg: The quorum change takes effect immediately.
0516-1144 unmirrorvg: rootvg successfully unmirrored, user should perform
        bosboot of system to reinitialize boot records.  Then, user must modify
        bootlist to just include:  hdisk0.
# reducevg rootvg hdisk1
# lspv
hdisk0          00c23bed7c1b3d4b                    rootvg          active
hdisk1          00c23bedf2976238                    None
hdisk2          00525c6a888e32cd                    apps_vg         active

Start the alt_disk_copy
Now we can clone hdisk1 from the current AIX in rootvg which is hdisk0. The format for the alt_disk_copy is:
alt_disk_copy -Od hdisk1

Where:
O, described earlier, removes all user defined ODM entries.
d is the destination disk when the cloned rootvg disk is to go; in this example, it is hdisk1.
You can also specify bootlist options, but I prefer to control this myself as part of the checklist during the migration. Listing 1 below contains the full output from running the alt_disk_copy command.


Listing. 1 alt_disk output

# alt_disk_copy -Od hdisk1
Calling mkszfile to create new /image.data file.
Checking disk sizes.
Creating cloned rootvg volume group and associated logical volumes.
Creating logical volume alt_hd5
Creating logical volume alt_hd6
Creating logical volume alt_hd8
Creating logical volume alt_hd4
Creating logical volume alt_hd2
Creating logical volume alt_hd9var
Creating logical volume alt_hd3
Creating logical volume alt_hd1
Creating logical volume alt_hd10opt
Creating logical volume alt_hd11admin
Creating logical volume alt_lg_dumplv
Creating logical volume alt_livedump
Creating logical volume alt_fwdump
Creating logical volume alt_fslv01
Creating logical volume alt_loglv01
Creating logical volume alt_lv00
Creating /alt_inst/ file system.
/alt_inst filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/admin file system.
/alt_inst/admin filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/home file system.
/alt_inst/home filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/opt file system.
/alt_inst/opt filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/opt/db2_09_01 file system.
/alt_inst/opt/db2_09_01 filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/storix file system.
Creating /alt_inst/tmp file system.
/alt_inst/tmp filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/usr file system.
/alt_inst/usr filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/var file system.
/alt_inst/var filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/var/adm/ras/livedump file system.
/alt_inst/var/adm/ras/livedump filesystem not converted.
        Small inode extents are already enabled.
Creating /alt_inst/var/adm/ras/platform file system.
/alt_inst/var/adm/ras/platform filesystem not converted.
        Small inode extents are already enabled.
Generating a list of files
for backup and restore into the alternate file system...
Backing-up the rootvg files and restoring them to the
alternate file system...
Modifying ODM on cloned disk.
Building boot image on cloned disk.
Resetting all device attributes.
NOTE: The first boot from altinst_rootvg will prompt to define the new
system console.
Resetting all device attributes.
NOTE: The first boot from altinst_rootvg will prompt to define the new
system console.
forced unmount of /alt_inst/var/adm/ras/platform
forced unmount of /alt_inst/var/adm/ras/platform
forced unmount of /alt_inst/var/adm/ras/platform
forced unmount of /alt_inst/var/adm/ras/livedump
forced unmount of /alt_inst/var/adm/ras/livedump
forced unmount of /alt_inst/var
forced unmount of /alt_inst/var
forced unmount of /alt_inst/usr
forced unmount of /alt_inst/usr
forced unmount of /alt_inst/tmp
forced unmount of /alt_inst/tmp
forced unmount of /alt_inst/storix
forced unmount of /alt_inst/opt/db2_09_01
forced unmount of /alt_inst/opt/db2_09_01
forced unmount of /alt_inst/opt
forced unmount of /alt_inst/opt
forced unmount of /alt_inst/home
forced unmount of /alt_inst/home
forced unmount of /alt_inst/admin
forced unmount of /alt_inst/admin
forced unmount of /alt_inst
forced unmount of /alt_inst
Changing logical volume names in volume group descriptor area.
Fixing LV control blocks...
Fixing file system superblocks...
Bootlist is set to the boot disk: hdisk1 blv=hd5

# lspv
hdisk0          00c23bed7c1b3d4b                    rootvg          active
hdisk1          00c23bedf2976238                    altinst_rootvg

After executing alt_disk_copy, unless otherwise specified, the default action is to set its bootlist to the disk alt_disk it resides on; in this case, it is hdisk1. We need to err to caution and make sure host alpha will still reboot back to hdisk0 in case we have to backout of the migration. So change the bootlist to hdisk0:
# bootlist -m normal hdisk0

Then shut down host alpha.

At this point, we could have kept host alpha up and dynamically remove the disk by using:
# rmdev -dl hdisk1 

However, eventually we will need to shut host alpha down to remove the remaining rootvg hdisk. So we might as well shut it down now.

Booting the cloned disk
In this scenario, we are moving the current hardware cards from host alpha and inserting them into host bravo. Host alpha and bravo are currently down.
Remove the network cable and the SAN fibre cables, if present, along with the fibre cards and insert these cards on the host bravo; then plug the cables in.
On host bravo remove the existing, if present, internal boot disks as we will be replacing these from host alpha.
On host alpha remove, hdisk1 and insert it into host bravo in the location that was previously populated with the boot disks.
Bring up host bravo; upon boot up, go into the SMS menu.
When host bravo comes, it will display the firmware/SMS menu prompts. Hit 1 to enter SMS menu, as shown below in Figure 1.


Figure 1. SMS
Screen shot of the SMS menu 

Go to the boot order list and select the disk to boot up on. There should only be one disk to boot up. Figure 2 shows the newly cloned disk to boot up on.


Figure 2. SMS boot list
Screen shot of the SMS boot list 

Upon booting off that disk, the AIX kernel starts to load as shown in Figure 3. The disk comes up and loads AIX.


Figure 3. Booting up
Screen shot of the AIX kernel booting up 

You are then prompted to define the system console, select 1 for this console, as shown in Figure 4. The console definition has been reset, because it is a ODM user defined attribute.


Figure 4. Identify new console
Screen shot of the system console 

Once AIX is booted up, log in and check your disk:
# lspv
hdisk0          00c23bedf2976238                    rootvg          active

Notice that the formally named hdisk1 on host alpha is now hdisk0 on host bravo. Change the bootlist to boot of this disk, until the migration is complete:
# bootlist -m normal hdisk0

Configure the network card to the IP that was used on host alpha and the card speed, if required. Confirm you are connected onto the network, test to ensure that you can ping outside your gateway, and ensure you can connect to the DNS via any of the following commands:
nslookup
dig
host

Confirm that you can connect to the host bravo via telnet/ssh from a remote session. You may have to start manually ssh on host bravo as this may not be running:
# startsrc -s sshd

Bring in the other rootvg disk
If all is OK at this point, we can bring in the other rootvg disk from host alpha:
Remove the last boot disk (hdisk0) from host alpha.
Insert the disk in host bravo; this disk is now hdisk1.
Run cfgmgr to discover the disk.
We are not mirroring the disk just yet. First, we need to make sure we get all the SAN disks discovered. If we have issues with this, we can take the newly insert disk back to the original box in case we need to back out of the migration.
If bravo comes up with old_rootvg, just remove the definition with:# alt_rootvg_op -X old_rootvg




Review hardware attributes and bring in the VGs
On host bravo, check for any changes that may need to be done from the listings taken from the output of the aio, sys0, scsi/fibre card(s). Adjust these setting, either via smit or the chdev command.

Discover the WWNs for the fibre cards. This is obtained looking at the output from the lscfg -vp command and searching for the SAN cards fcs0, fcs1, etc. Once obtained, use these to re-zone in the SAN disks from the switch, then import the VGs. If you have more than one SAN VG across different switches, then I recommend only leaving in the cable for the switch that holds one of the VGs. Pull the disks in using cfgmr; then import that VG. Once imported, plug in the other fibre cable and re-run cfgmgr and import that VG. The reason for this is if you do not, all the disks will come down the fibre paths. When you import the VGs, all the disks will be imported onto that one VG, which is probably not what you want. (You do not get this issue with scsi raid controllers that have more than one VG).

If you have problems with importvg, be sure to check out the cables attached. You may have to run varyonvg afterwards, as AIX does not automatically varyonvg if it gets issues with the importvg.
Next, mount the file-systems.
# mount -a

Check to ensure that all file-systems are mounted and all LVs are open.
# lsvg -l <vg name>

Uncomment the changes that was made to the inittab.
Refresh iniitab, so it is re-read.
# init q

Now start the applications up and test.
Mirror up
If all looks good at this point and the sanity checks are good, mirror up the other disk. You need to use the force option when bringing it into rootvg.
# extendvg -f rootvg hdisk1 
# mirrorvg rootvg hdisk1


Oh no, it's all gone terribly wrong!

If the migration or move fails, remove the second (boot) disk from host bravo. Remember this should have not been put into rootvg on host bravo until all the applications are tested OK. So this disk still holds the ODM setting from host alpha, so you are good to go for a back-out process. Using the procedures described in the article about moving the cards/cables, simply do it in reverse.

In some situations, it maybe the case the disk will be shown with the alt_disk tag still associated with it. Simply remove this tag before bringing it into rootvg and mirroring up.
# alt_rootvg_op -X altinst_rootvg


Conclusion
I have highlighted just one method of a hardware migration. Though this has not been a step-by-step guide, it does provide one way you can approach a migration. There are different variations you can employ to do a hardware migration or move using alt_disk_copy. The alt_disk_copy utility is a good tool to use when you wish to migrate to new hardware, and the machines are located in the same location room.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------
Compressing files under Linux or UNIX cheat sheet


Both Linux and UNIX include various commands for Compressing and decompresses (read as expand compressed file). To compress files you can use gzip, bzip2 and zip commands. To expand compressed file (decompresses) you can use and gzip -d, bunzip2 (bzip2 -d), unzip commands.

Compressing files

Syntax	Description	Example(s)
gzip {filename}	Gzip compress the size of the given files using Lempel-Ziv coding (LZ77). Whenever possible, each file is replaced by one with the extension .gz.	gzip mydata.doc
gzip *.jpg
ls -l
bzip2 {filename}	bzip2 compresses files using the Burrows-Wheeler block sorting text compression algorithm, and Huffman coding. Compression is generally considerably better than that achieved by bzip command (LZ77/LZ78-based compressors). Whenever possible, each file is replaced by one with the extension .bz2.	bzip2 mydata.doc
bzip2 *.jpg
ls -l
zip {.zip-filename} {filename-to-compress}	zip is a compression and file packaging utility for Unix/Linux. Each file is stored in single .zip {.zip-filename} file with the extension .zip.	zip mydata.zip mydata.doc
zip data.zip *.doc
ls -l
tar -zcvf {.tgz-file} {files}
tar -jcvf {.tbz2-file} {files}	The GNU tar is archiving utility but it can be use to compressing large file(s). GNU tar supports both archive compressing through gzip and bzip2. If you have more than 2 files then it is recommended to use tar instead of gzip or bzip2.
-z: use gzip compress
-j: use bzip2 compress	tar -zcvf data.tgz *.doc
tar -zcvf pics.tar.gz *.jpg *.png
tar -jcvf data.tbz2 *.doc
ls -l
Decompressing files

Syntax	Description	Example(s)
gzip -d {.gz file}
gunzip {.gz file}	Decompressed a file that is created using gzipcommand. File is restored to their original form using this command.	gzip -d mydata.doc.gz
gunzip mydata.doc.gz
bzip2 -d {.bz2-file}
bunzip2 {.bz2-file}	Decompressed a file that is created using bzip2command. File is restored to their original form using this command.	bzip2 -d mydata.doc.bz2
gunzip mydata.doc.bz2
unzip {.zip file}	Extract compressed files in a ZIP archive.	unzip file.zip
unzip data.zip resume.doc
tar -zxvf {.tgz-file}
tar -jxvf {.tbz2-file}	Untar or decompressed a file(s) that is created using tar compressing through gzip and bzip2 filter	tar -zxvf data.tgz
tar -zxvf pics.tar.gz *.jpg
tar -jxvf data.tbz2
List the contents of an archive/compressed file

Some time you just wanted to look at files inside an archive or compressed file. Then all of the above command supports file list option.
Syntax	Description	Example(s)
gzip -l {.gz file}	List files from a GZIP archive	gzip -l mydata.doc.gz
unzip -l {.zip file}	List files from a ZIP archive	unzip -l mydata.zip
tar -ztvf {.tar.gz}
tar -jtvf {.tbz2}	List files from a TAR archive	tar -ztvf pics.tar.gz
tar -jtvf data.tbz2




------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Configure NTP on AIX

The following information outlines the steps necessary to configure a basic NTP setup between an NTP client and server on AIX.

On server execute below commands in sequence
1) Verify that you have a suitable NTP server. Enter:
# lssrc -ls xntpd
NOTE: Sys peer should show a valid server or 127.127.1.0.

If the server is "insane", you will need to correct it by adding a server line to /etc/ntp.conf and restarting xntpd.
This can be done by following these steps:
# vi /etc/ntp.conf
Add:
server 127.127.1.0
Double check that "broadcast client" is commented out.
# stopsrc -s xntpd
# startsrc -s xntpd
NOTE: If the server runs databases, use the -x flag to prevent the clock from changing in a negative direction. Enter the following:
# startsrc -s xntpd -a "-x"
2) Repeat Step 1 to verify that the server is synced. This process can take up to 12 minutes.
On client verify that you have a server suitable for synchronization
Enter:
# ntpdate -d ip.address.of.server
The offset must be less than 1000 seconds for xntpd to sync.
If the offset is greater than 1000 seconds, change the time manually on the client and run the ntpdate -d again
If you get the message, "no server suitable for synchronization found", verify xntpd is running on the server(see above) and that no firewalls are blocking port 123.
3) Specify your xntp server in /etc/ntp.conf, enter:
# vi /etc/ntp.conf
(Comment out the "broadcastclient" line and add server ip.address.of.server prefer.)
Leave the drift file and trace file at their defaults.
4) Start the xntpd daemon:
# startsrc -s xntpd
(Use the -x flag if it is appropriate for your environment.)
Uncomment xntpd from /etc/rc.tcpip so it will start on a reboot.
# vi /etc/rc.tcpip
Uncomment the following line:
5) start /usr/sbin/xntpd "$src_running"
If using the -x flag, add "-x" to the end of the line. You must include the quotes around the -x.
Verify that the client is synced.
# lssrc -ls xntpd
NOTE: Sys peer should display the IP address or name of your xntp server. This process may take up to 12 minutes.




------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Console Emulation commands in AIX

lscons                             To list the current console

lscons -b                          To list the console at next boot

chcons /dev/tty3                   To change the console to tty3

chcons -a login=enable /dev/tty3   Redirect console to tty3 and provide login prompt

swcons /dev/tty3                   To change system console to tty3 temporarily


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


Conversion Between Inline and Outline JFS2 Filesystem Logs

Question
Can you convert a JFS2 filesystem with an outline log (i.e. external log logical volume) to one with an inline log?
Answer
No, JFS2 filesystems using one type of log cannot be changed to use another. If a filesystem is created to use a log logical volume, for example /dev/loglv00, it cannot be changed to use an inline log.

In the same respect, a JFS2 filesystem using an inline log cannot be successfully changed to point to an outline log. While this may seem to work it will not survive exportvg/importvg.

The chfs man page has this to say about inline and outline logs:

For a file system using INLINE log, this option does not support switching logs between INLINE and OUTLINE log. Currently, to switch from inline log to outline log (or vise versa), the file system has to be removed and recreated.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Conversion of a JFS to JFS2 filesystem
By Surya11:56No comments
Question
Is it possible to convert from a JFS to a JFS2 filesystem?
Answer
No, a JFS filesystem cannot be converted to become a JFS2 filesystem.

The two types of filesystems have completely different structures and inode allocation methods. There are three recognized methods to move data from a JFS to a JFS2 filesystem.
1. Copy With Parallel Filesystems
If you have the space, creating a second filesystem and simply copying the data is the easiest way.
# crfs -v jfs2 -g myvg -a size=20G -A yes -m /newfilesystem
This will create a 20GB filesystem in volume group "myvg" with mount point "/newfilesystem".
Mount the filesystem:
# mount /newfilesystem
Copy the data from your existing filesystem to it, with a command similar to:
# cd /mydata; pax -w * | (cd /newfilesystem; pax -v -r )
(Using pax will preserve sparseness that may exist in database files. See technote T1000145 "About Sparse Files" for more information on this topic)
Unmount the current filesystem and rename it:
# unmount /mydata
# chfs -m /oldfilesystem /mydata
Rename the mount point of the new filesystem and mount it::
# chfs -m /mydata /newfilesystem
# mount /mydata
At this point test your application or check over your data. If all is well remove the old filesystem:
# rmfs /oldfilesystem
2. Backup and Recreate
Back up your data on the original filesystem, remove it and recreate as JFS2. Use this when you do not have enough disk space to have the same filesystem existing in parallel.
Back up the data using whatever command you usually use to back up the files.
Unmount and remove the old filesystem:
# umount /mydata
# rmfs /mydata
Create the filesystem again:
# crfs -v jfs2 -g myvg -a size=20G -A yes -m /mydata
# mount /mydata
Restore your data to /mydata
3. Alternate Disk Copy for Rootvg
If your filesystems are rootvg ones, neither of these methods will work. However you can use alt-disk copy to create a new rootvg. Using the -T flag will recreate the filesystems as JFS2:
-T
Indicates that you want to convert JFS file systems to JFS2 file systems during the process of recreating the rootvg volume group on target disks.
# alt_disk_copy -T -d hdiskX
where hdiskX is an unused disk not belonging to any volume group.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Copying a complete logical volume

Copying a complete logical volume
The AIX logical volume manager (LVM) provides the cplv command, which you can use to copy logical volumes within volume groups or to different volume groups.
Procedure
Identify the logical volume that you want to migrate and the target volume group.
Use the cplv command to migrate data from one logical volume to another.
Results
When the command completes processing, a copy of the logical volume is created in the target location.
Example
Here are two examples that show how to use the cplv command to create a new logical volume to overwrite an existing logical volume.
# cplv -v datavg -y newlv oldlv
In this example, the cplv command copies data from the existing logical volume oldlv and creates the new logical volume newlv (-y) in the volume group datavg (-v). If you omit the -v option, the new logical volume is added to the same volume group that contained the original logical volume. New volumes that are created by the cplv command maintain the same characteristics as the existing logical volume.
# cplv -e existinglv oldlv
In this example, the cplv command copies data from existing logical volume oldlv to existing logical volume existinglv (-e). When you use the -e option, data in the existing target-logical volume is overwritten with the data from the source-logical volume and the characteristics of the existing target-logical volume are maintained. Use this option with caution.

The cplv command provides a good method for copying or migrating a single logical volume. Sometimes, however, you might need to migrate all of the data from a physical volume.
These are the steps I follow for copying logical volumes:
Step 1:     umount [filesystem]

Step 2:     cp [oldLV] [newLV]

            cplv –v VG(destination) –y [newLV] [sourceLV]

Step 3:     chfs to recognize [newLV]

            chfs –a dev=/dev/[newLV] –a log=/dev/[logdev] /[filesystem]

Step 4:     fsck –p /dev/[newLV]

Step 5:     mount [filesystem]

Step 6:      rm [oldLV]

           


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Creating and restoring a savevg backup without preserving mirrors

Question
How to create and/or restore an existing savevg backup without preserving mirrors.
Answer
This document describes how to restore a savevg image without preserving mirrors.
WARNING: This procedure is valid only with a savevg image and will not work with a Sysback 6000 system backup.

Creating a savevg without mirroring
Breaking mirrors on an existing savevg 
If the ability to rerun the savevg is available, the following procedure will allow you to create a savevg without preserving mirroring.

To create a new /tmp/vgdata/<vgname>/<vgname>.data file, execute the following command.
            mkvgdata <vgname>
<vgname> is the name of the volume group to be backed up.
Change directories to /tmp/vgdata/<vgname> and, using your favorite editor, edit the <vgname>.data file.
For example:
            cd /tmp/vgdata/<vgname>
            vi <vgname>.data
The following examples show an lv_data stanza of a <vgname>.data file. The first example is with mirroring, while the second example shows the edited version without mirroring. The lines that need changes are marked by -->. In the second example, the changes are made to those lines.
To view and edit the file, using your favorite editor, open <vgname>.data:
   Example 1
                        lv_data:
                                VOLUME_GROUP= <vgname>
                                LV_SOURCE_DISK_LIST=  hdisk1
                                LV_IDENTIFIER= 00000001113f3c62.5
                                LOGICAL_VOLUME= lv00
                                VG_STAT= active/complete
                                TYPE= jfs
                                MAX_LPS= 512
                       -->      COPIES = 2
                                LPs = 70
                                STALE_PPs= 0
                                INTER_POLICY= minimum
                                INTRA_POLICY= center
                                MOUNT_POINT= /apps
                                MIRROR_WRITE_CONSISTENCY= on
                                LV_SEPARATE_PV= yes
                                PERMISSION= read/write
                                LV_STATE= opened/syncd
                                WRITE_VERIFY= off
                                PP_SIZE= 4
                                SCHED_POLICY= parallel
                       -->      PP = 140
                                BB_POLICY= relocatable
                                RELOCATABLE= yes
                                UPPER_BOUND= 32
                                LABEL= /apps
                                MAPFILE=
                                LV_MIN_LPS= 68
   Example 2
                        lv_data:
                                VOLUME_GROUP= <vgname>
                                LV_SOURCE_DISK_LIST=  hdisk1
                                LV_IDENTIFIER= 00000001113f3c62.5
                                LOGICAL_VOLUME= lv00
                                VG_STAT= active/complete
                                TYPE= jfs
                                MAX_LPS= 512
                       -->      COPIES = 1
                                LPs = 70
                                STALE_PPs= 0
                                INTER_POLICY= minimum
                                INTRA_POLICY= center
                                MOUNT_POINT= /apps
                                MIRROR_WRITE_CONSISTENCY= on
                                LV_SEPARATE_PV= yes
                                PERMISSION= read/write
                                LV_STATE= opened/syncd
                                WRITE_VERIFY= off
                                PP_SIZE= 4
                                SCHED_POLICY= parallel
                        -->     PP = 70
                                BB_POLICY= relocatable
                                RELOCATABLE= yes
                                UPPER_BOUND= 32
                                LABEL= /apps
                                MAPFILE=
                                LV_MIN_LPS= 68
NOTE: In Example 2, the COPIES value has been changed to 1, and the PP value is set equal to the LPs value. Make these changes to each of the lv_datastanzas in the <vgname>.data file. Once you make the changes, save the file and exit.

Run another savevg from the command line that will utilize your edited <vgname>.data file.
# savevg -f /dev/rmtX <vgname>  
X is the number of your tape device. You may also use a filename.

WARNING: Do not run the savevg in SMIT because this will update the <vgname>.data file and overwrite any changes made.

WARNING: Do not run the savevg with the -i flag because this will update the <vgname>.data file as well.
If another savevg cannot be run, the following procedure can be used to restore a savevg without mirroring.
All references to the tape device in the next section are as rmt0. You may also write the savevg backup to file.

On the target system, place the savevg tape in the tape drive.
Remove the /tmp/vgdata directory:
                rm -r /tmp/vgdata 
Restore the /tmp/vgdata directory from the savevg tape:
               cd /
               restore -xqvdf /dev/rmt0 ./tmp/vgdata                
Edit the /tmp/vgdata/<vgname>/<vgname>.data file, and make changes to each of the lv_data stanzas as indicated in the examples that follow. The lines that need changes are marked by a -->. In Example 4, the changes are made to those lines.

To view and edit the file, using your favorite editor, open /tmp/vgdata/<vgname>/<vgname>.data:
     Example 3
                        lv_data:
                                VOLUME_GROUP= <vgname>
                                LV_SOURCE_DISK_LIST=  hdisk1
                                LV_IDENTIFIER= 00000001113f3c62.5
                                LOGICAL_VOLUME= lv01
                                VG_STAT= active/complete
                                TYPE= jfs
                                MAX_LPS= 512
                        -->     COPIES = 2
                                LPs = 120
                                STALE_PPs= 0
                                INTER_POLICY= minimum
                                INTRA_POLICY= center
                                MOUNT_POINT= /apps2
                                MIRROR_WRITE_CONSISTENCY= on
                                LV_SEPARATE_PV= yes
                                PERMISSION= read/write
                                LV_STATE= opened/syncd
                                WRITE_VERIFY= off
                                PP_SIZE= 4
                                SCHED_POLICY= parallel
                        -->     PP = 240
                                BB_POLICY= relocatable
                                RELOCATABLE= yes
                                UPPER_BOUND= 32
                                LABEL= /apps2
                                MAPFILE=
                                LV_MIN_LPS= 68
     Example 4
                        lv_data:
                                VOLUME_GROUP= <vgname>
                                LV_SOURCE_DISK_LIST=  hdisk0
                                LV_IDENTIFIER= 00000001113f3c62.5
                                LOGICAL_VOLUME= lv01
                                VG_STAT= active/complete
                                TYPE= jfs
                                MAX_LPS= 512
                        -->     COPIES = 1
                                LPs = 120
                                STALE_PPs= 0
                                INTER_POLICY= minimum
                                INTRA_POLICY= center
                                MOUNT_POINT= /apps2
                                MIRROR_WRITE_CONSISTENCY= on
                                LV_SEPARATE_PV= yes
                                PERMISSION= read/write
                                LV_STATE= opened/syncd
                                WRITE_VERIFY= off
                                PP_SIZE= 4
                                SCHED_POLICY= parallel
                        -->     PP = 120
                                BB_POLICY= relocatable
                                RELOCATABLE= yes
                                UPPER_BOUND= 32
                                LABEL= /apps2
                                MAPFILE=
                                LV_MIN_LPS= 120
NOTE: In Example 4 the COPIES value has been changed to 1, and the PP value is set equal to the LPs value. Make these changes to each of the lv_datastanzas in the <vgname>.data file. Once you make the changes, save the file and exit.

After making the changes to the <vgname>.data file, create a backbyname of /tmp/vgdata to run restvg against.
#  cd /
# find ./tmp/vgdata -print |backup -iqvf /tmp/vg.back
This should back up the following files:
 ./tmp/vgdata
  ./tmp/vgdata/vgdata.files
  ./tmp/vgdata/<vgname> 
  ./tmp/vgdata/<vgname>/filesystems
  ./tmp/vgdata/<vgname>/<vgname>.data 
<vgname> is the name of your volume group.

Verify that the files were backed up, and that the file can be read:
                restore -Tqvf /tmp/vg.back
Run the restvg command to recreate the volume group on the hdisks you want:
  restvg -f /tmp/vg.back hdisk# hdisk# 
This should complete fairly quickly (depending on how many logical volumes and file systems are being created) and return to the command line. Verify that the volume group and file systems were re-created:
  lsvg -l <vgname>
And verify the file systems mounted:
  mount 
If all looks good, restore the files from the tape:
  cd /
  restore -xqvdf /dev/rmt0


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Decoding hdisk PVID's on AIX

When you add disks into volume groups, AIX generates a unique PVID number for each hdisk.   You can view these PVID's by running "lspv" and looking at the second column:
# lspv
hdisk0          00cc202e7db580dd                    rootvg          active
hdisk1          00cc202e93b711f7                    datavg          active
hdisk2          00cc202e93bad24b                    datavg          active
hdisk3          00cc202e93bad31c                    datavg          active
hdisk4          00cc202e93bb219c                    testvg          active
hdisk5          00cc202e93bb226d                    testvg          active
hdisk6          00cc202e93bb5f1a                    appvg           active
hdisk7          00cc202e93bb5fe6                    appvg           active
hdisk8          00cc202e93bb60bd                    appvg           active
hdisk9          00cc202e93bb619c                    appvg           active
hdisk10         00cc202e8f4ac23d                    None                    
Let's take hdisk10 for example.  Its PVID is "00cc202e8f4ac23d".   As you can see this is a hexadecimal number.   If you split it right down the middle and take the first 8 characters, these are the same as the first 8 characters of the servers machine ID.   

You can see this by running "uname -m":
# uname -m
00CC202E4C00
# lspv | grep hdisk10
hdisk10         00cc202e8f4ac23d                    None
As you can see, the first 8 characters of the machine ID is the same as the first 8 characters of the PVID.  If you have some PVID's on your server that don't match the first 8 characters of the machine ID this means the PVID's were generated on a different machine.  This can happen if you export volume groups and move them between servers. 

Decoding the second half of the PVID is more tricky.  The second half represents a timestamp, but I have never been able to find out any more information than that.

I set out to dediv this second half of the PVID in hopes that it would be possible to use it to determine the date/time that a volume group was created. 

To figure this out, I wrote a script that would increment the date on the server one day at a time, then clear the PVID and create a new one.    By doing this, I am hoping to see how much the PVID number changes in a day's time by subtracting the old PVID from the new one.  

Here is the script (NOTE: this changes the date and clears/recreates PVID's so this is NOT something you want to run on your AIX server :)

#!/bin/ksh
for day in 01 02 03 04 05 06 07 08 09 10; do
        date "12${day}000012" > /dev/null
        lastpvid=`lspv | grep hdisk10 | awk '{print $2}' | tr 'a-z' 'A-Z'`
        chdev -a pv=clear -l hdisk10 >/dev/null;
        chdev -a pv=yes -l hdisk10 >/dev/null;
        newpvid=`lspv | grep hdisk10 | awk '{print $2}' | tr 'a-z' 'A-Z'`
        [ "$day" -eq "01" ] && continue
        printf "`date +%D` "
        printf "New PVID:  $newpvid   Old PVID:  $lastpvid   New-Old="
        echo "ibase=16; $newpvid - $lastpvid" | bc
done

Here is the output of the script:

 # ./pvid4
12/02/12 New PVID:  00CC202E5A339113   Old PVID:  00CC202E550D3516   New-Old=86399997
12/03/12 New PVID:  00CC202E5F59ED0D   Old PVID:  00CC202E5A339113   New-Old=86399994
12/04/12 New PVID:  00CC202E64804912   Old PVID:  00CC202E5F59ED0D   New-Old=86400005
12/05/12 New PVID:  00CC202E69A6A50D   Old PVID:  00CC202E64804912   New-Old=86399995
12/06/12 New PVID:  00CC202E6ECD0113   Old PVID:  00CC202E69A6A50D   New-Old=86400006
12/07/12 New PVID:  00CC202E73F35D0C   Old PVID:  00CC202E6ECD0113   New-Old=86399993
12/08/12 New PVID:  00CC202E7919B90E   Old PVID:  00CC202E73F35D0C   New-Old=86400002
12/09/12 New PVID:  00CC202E7E401512   Old PVID:  00CC202E7919B90E   New-Old=86400004
12/10/12 New PVID:  00CC202E83667118   Old PVID:  00CC202E7E401512   New-Old=86400006
Again, since the PVID's are just hex numbers you can do math with them.   You can see as the date was increased 1 day at a time, and then yesterday's PVID was subtracted from today's PVID, the results were always about  86,400,000.    So based on this, we can determine that this timestamp counter increases by 86,400,000 per day.  If you do the math, you can figure out that this is 1,000 times per second (60 seconds * 60 minutes * 24 hours * 1000 = 86,400,000).

We also know that this second part of the PVID is 8 hex digits long.  The largest 8 digit hex number is FFFFFFFF, which equals 4,294,967,295 in decimal.  If we take this number, and divide it by 86,400,000 we get about 49.7.  This means that about every 49 days the generated PVID numbers overflow and start over.   Based on this, it is unfortunately not possible to determine the date/time a PVID was generated because the numbers wrap around (start over) every 49 days.

Here is the output of another script that generated a new PVID on every date across several months.   As you can see every 49 days the timestamp recorded in the last 8 digits fills up and starts over:

01/02/13 New PVID:  00CC202EF9D88250   Old PVID:  00CC202EF4B22654   New-Old=86399996
01/03/13 New PVID:  00CC202EFEFEDE4A   Old PVID:  00CC202EF9D88250   New-Old=86399994
01/04/13 New PVID:  00CC202E04253A4A   Old PVID:  00CC202EFEFEDE4A   New-Old=-4208567296    First wrap
01/05/13 New PVID:  00CC202E094B964A   Old PVID:  00CC202E04253A4A   New-Old=86400000
01/06/13 New PVID:  00CC202E0E71F24B   Old PVID:  00CC202E094B964A   New-Old=86400001
01/07/13 New PVID:  00CC202E13984E45   Old PVID:  00CC202E0E71F24B   New-Old=86399994
01/08/13 New PVID:  00CC202E18BEAA45   Old PVID:  00CC202E13984E45   New-Old=86400000
01/09/13 New PVID:  00CC202E1DE5064A   Old PVID:  00CC202E18BEAA45   New-Old=86400005
01/10/13 New PVID:  00CC202E230B624A   Old PVID:  00CC202E1DE5064A   New-Old=86400000
01/11/13 New PVID:  00CC202E2831BE4A   Old PVID:  00CC202E230B624A   New-Old=86400000
01/12/13 New PVID:  00CC202E2D581A50   Old PVID:  00CC202E2831BE4A   New-Old=86400006
01/13/13 New PVID:  00CC202E327E764A   Old PVID:  00CC202E2D581A50   New-Old=86399994
01/14/13 New PVID:  00CC202E37A4D251   Old PVID:  00CC202E327E764A   New-Old=86400007
01/15/13 New PVID:  00CC202E3CCB2E49   Old PVID:  00CC202E37A4D251   New-Old=86399992
01/16/13 New PVID:  00CC202E41F18A46   Old PVID:  00CC202E3CCB2E49   New-Old=86399997
01/17/13 New PVID:  00CC202E4717E64A   Old PVID:  00CC202E41F18A46   New-Old=86400004
01/18/13 New PVID:  00CC202E4C3E4245   Old PVID:  00CC202E4717E64A   New-Old=86399995
01/19/13 New PVID:  00CC202E51649E4B   Old PVID:  00CC202E4C3E4245   New-Old=86400006
01/20/13 New PVID:  00CC202E568AFA46   Old PVID:  00CC202E51649E4B   New-Old=86399995
01/21/13 New PVID:  00CC202E5BB15647   Old PVID:  00CC202E568AFA46   New-Old=86400001
01/22/13 New PVID:  00CC202E60D7B246   Old PVID:  00CC202E5BB15647   New-Old=86399999
01/23/13 New PVID:  00CC202E65FE0E4A   Old PVID:  00CC202E60D7B246   New-Old=86400004
01/24/13 New PVID:  00CC202E6B246A48   Old PVID:  00CC202E65FE0E4A   New-Old=86399998
01/25/13 New PVID:  00CC202E704AC647   Old PVID:  00CC202E6B246A48   New-Old=86399999
01/26/13 New PVID:  00CC202E75712245   Old PVID:  00CC202E704AC647   New-Old=86399998
01/27/13 New PVID:  00CC202E7A977E46   Old PVID:  00CC202E75712245   New-Old=86400001
01/28/13 New PVID:  00CC202E7FBDDA4B   Old PVID:  00CC202E7A977E46   New-Old=86400005
01/29/13 New PVID:  00CC202E84E4364A   Old PVID:  00CC202E7FBDDA4B   New-Old=86399999
01/30/13 New PVID:  00CC202E8A0A924A   Old PVID:  00CC202E84E4364A   New-Old=86400000
01/31/13 New PVID:  00CC202E8F30EE46   Old PVID:  00CC202E8A0A924A   New-Old=86399996
02/01/13 New PVID:  00CC202E94574A4A   Old PVID:  00CC202E8F30EE46   New-Old=86400004
02/02/13 New PVID:  00CC202E997DA680   Old PVID:  00CC202E94574A4A   New-Old=86400054
02/03/13 New PVID:  00CC202E9EA40248   Old PVID:  00CC202E997DA680   New-Old=86399944
02/04/13 New PVID:  00CC202EA3CA5E4A   Old PVID:  00CC202E9EA40248   New-Old=86400002
02/05/13 New PVID:  00CC202EA8F0BA4A   Old PVID:  00CC202EA3CA5E4A   New-Old=86400000
02/06/13 New PVID:  00CC202EAE171650   Old PVID:  00CC202EA8F0BA4A   New-Old=86400006
02/07/13 New PVID:  00CC202EB33D724B   Old PVID:  00CC202EAE171650   New-Old=86399995
02/08/13 New PVID:  00CC202EB863CE45   Old PVID:  00CC202EB33D724B   New-Old=86399994
02/09/13 New PVID:  00CC202EBD8A2A4A   Old PVID:  00CC202EB863CE45   New-Old=86400005
02/10/13 New PVID:  00CC202EC2B08644   Old PVID:  00CC202EBD8A2A4A   New-Old=86399994
02/11/13 New PVID:  00CC202EC7D6E24A   Old PVID:  00CC202EC2B08644   New-Old=86400006
02/12/13 New PVID:  00CC202ECCFD3E4A   Old PVID:  00CC202EC7D6E24A   New-Old=86400000
02/13/13 New PVID:  00CC202ED2239A45   Old PVID:  00CC202ECCFD3E4A   New-Old=86399995
02/14/13 New PVID:  00CC202ED749F64A   Old PVID:  00CC202ED2239A45   New-Old=86400005
02/15/13 New PVID:  00CC202EDC70524A   Old PVID:  00CC202ED749F64A   New-Old=86400000
02/16/13 New PVID:  00CC202EE196AE50   Old PVID:  00CC202EDC70524A   New-Old=86400006
02/17/13 New PVID:  00CC202EE6BD0A45   Old PVID:  00CC202EE196AE50   New-Old=86399989
02/18/13 New PVID:  00CC202EEBE3664A   Old PVID:  00CC202EE6BD0A45   New-Old=86400005
02/19/13 New PVID:  00CC202EF109C24A   Old PVID:  00CC202EEBE3664A   New-Old=86400000
02/20/13 New PVID:  00CC202EF6301E4A   Old PVID:  00CC202EF109C24A   New-Old=86400000
02/21/13 New PVID:  00CC202EFB567A46   Old PVID:  00CC202EF6301E4A   New-Old=86399996
02/22/13 New PVID:  00CC202E007CD658   Old PVID:  00CC202EFB567A46   New-Old=-4208567278  Second wrap, 49 days later
02/23/13 New PVID:  00CC202E05A33246   Old PVID:  00CC202E007CD658   New-Old=86399982
02/24/13 New PVID:  00CC202E0AC98E46   Old PVID:  00CC202E05A33246   New-Old=86400000
02/25/13 New PVID:  00CC202E0FEFEA4A   Old PVID:  00CC202E0AC98E46   New-Old=86400004
02/26/13 New PVID:  00CC202E1516464B   Old PVID:  00CC202E0FEFEA4A   New-Old=86400001
02/27/13 New PVID:  00CC202E1A3CA24A   Old PVID:  00CC202E1516464B   New-Old=86399999
02/28/13 New PVID:  00CC202E1F62FE50   Old PVID:  00CC202E1A3CA24A   New-Old=86400006
03/01/13 New PVID:  00CC202E24895A4B   Old PVID:  00CC202E1F62FE50   New-Old=86399995
03/02/13 New PVID:  00CC202E29AFB64B   Old PVID:  00CC202E24895A4B   New-Old=86400000
03/03/13 New PVID:  00CC202E2ED61245   Old PVID:  00CC202E29AFB64B   New-Old=86399994
03/04/13 New PVID:  00CC202E33FC6E50   Old PVID:  00CC202E2ED61245   New-Old=86400011
03/05/13 New PVID:  00CC202E3922CA4B   Old PVID:  00CC202E33FC6E50   New-Old=86399995
03/06/13 New PVID:  00CC202E3E49264A   Old PVID:  00CC202E3922CA4B   New-Old=86399999
03/07/13 New PVID:  00CC202E436F824B   Old PVID:  00CC202E3E49264A   New-Old=86400001
03/08/13 New PVID:  00CC202E4895DE4B   Old PVID:  00CC202E436F824B   New-Old=86400000
03/09/13 New PVID:  00CC202E4DBC3A4A   Old PVID:  00CC202E4895DE4B   New-Old=86399999
03/10/13 New PVID:  00CC202E52E2964A   Old PVID:  00CC202E4DBC3A4A   New-Old=86400000
03/11/13 New PVID:  00CC202E57D203CA   Old PVID:  00CC202E52E2964A   New-Old=82800000
03/12/13 New PVID:  00CC202E5CF85FCB   Old PVID:  00CC202E57D203CA   New-Old=86400001
03/13/13 New PVID:  00CC202E621EBBCA   Old PVID:  00CC202E5CF85FCB   New-Old=86399999
03/14/13 New PVID:  00CC202E674517CB   Old PVID:  00CC202E621EBBCA   New-Old=86400001
03/15/13 New PVID:  00CC202E6C6B73C5   Old PVID:  00CC202E674517CB   New-Old=86399994
03/16/13 New PVID:  00CC202E7191CFC5   Old PVID:  00CC202E6C6B73C5   New-Old=86400000
03/17/13 New PVID:  00CC202E76B82BC6   Old PVID:  00CC202E7191CFC5   New-Old=86400001
03/18/13 New PVID:  00CC202E7BDE87CB   Old PVID:  00CC202E76B82BC6   New-Old=86400005
03/19/13 New PVID:  00CC202E8104E3CA   Old PVID:  00CC202E7BDE87CB   New-Old=86399999
03/20/13 New PVID:  00CC202E862B3FCA   Old PVID:  00CC202E8104E3CA   New-Old=86400000
03/21/13 New PVID:  00CC202E8B519BC5   Old PVID:  00CC202E862B3FCA   New-Old=86399995
03/22/13 New PVID:  00CC202E9077F7CB   Old PVID:  00CC202E8B519BC5   New-Old=86400006
03/23/13 New PVID:  00CC202E959E53C9   Old PVID:  00CC202E9077F7CB   New-Old=86399998
03/24/13 New PVID:  00CC202E9AC4AFC9   Old PVID:  00CC202E959E53C9   New-Old=86400000
03/25/13 New PVID:  00CC202E9FEB0BD0   Old PVID:  00CC202E9AC4AFC9   New-Old=86400007
03/26/13 New PVID:  00CC202EA51167D1   Old PVID:  00CC202E9FEB0BD0   New-Old=86400001
03/27/13 New PVID:  00CC202EAA37C3CA   Old PVID:  00CC202EA51167D1   New-Old=86399993
03/28/13 New PVID:  00CC202EAF5E1FCB   Old PVID:  00CC202EAA37C3CA   New-Old=86400001
03/29/13 New PVID:  00CC202EB4847BCB   Old PVID:  00CC202EAF5E1FCB   New-Old=86400000
03/30/13 New PVID:  00CC202EB9AAD7CA   Old PVID:  00CC202EB4847BCB   New-Old=86399999
03/31/13 New PVID:  00CC202EBED133CA   Old PVID:  00CC202EB9AAD7CA   New-Old=86400000
04/01/13 New PVID:  00CC202EC3F78FCA   Old PVID:  00CC202EBED133CA   New-Old=86400000
04/02/13 New PVID:  00CC202EC91DEBCA   Old PVID:  00CC202EC3F78FCA   New-Old=86400000
04/03/13 New PVID:  00CC202ECE4447CB   Old PVID:  00CC202EC91DEBCA   New-Old=86400001
04/04/13 New PVID:  00CC202ED36AA3C5   Old PVID:  00CC202ECE4447CB   New-Old=86399994
04/05/13 New PVID:  00CC202ED890FFCA   Old PVID:  00CC202ED36AA3C5   New-Old=86400005
04/06/13 New PVID:  00CC202EDDB75BCB   Old PVID:  00CC202ED890FFCA   New-Old=86400001
04/07/13 New PVID:  00CC202EE2DDB7CB   Old PVID:  00CC202EDDB75BCB   New-Old=86400000
04/08/13 New PVID:  00CC202EE80413CA   Old PVID:  00CC202EE2DDB7CB   New-Old=86399999
04/09/13 New PVID:  00CC202EED2A6FD1   Old PVID:  00CC202EE80413CA   New-Old=86400007
04/10/13 New PVID:  00CC202EF250CBCB   Old PVID:  00CC202EED2A6FD1   New-Old=86399994
04/11/13 New PVID:  00CC202EF77727C5   Old PVID:  00CC202EF250CBCB   New-Old=86399994
04/12/13 New PVID:  00CC202EFC9D83D0   Old PVID:  00CC202EF77727C5   New-Old=86400011
04/13/13 New PVID:  00CC202E01C3DFC5   Old PVID:  00CC202EFC9D83D0   New-Old=-4208567307   Third wrap, 49 days later
04/14/13 New PVID:  00CC202E06EA3BC6   Old PVID:  00CC202E01C3DFC5   New-Old=86400001
04/15/13 New PVID:  00CC202E0C1097CC   Old PVID:  00CC202E06EA3BC6   New-Old=86400006
04/16/13 New PVID:  00CC202E1136F3C6   Old PVID:  00CC202E0C1097CC   New-Old=86399994
04/17/13 New PVID:  00CC202E165D4FCA   Old PVID:  00CC202E1136F3C6   New-Old=86400004
04/18/13 New PVID:  00CC202E1B83ABCA   Old PVID:  00CC202E165D4FCA   New-Old=86400000
04/19/13 New PVID:  00CC202E20AA07CB   Old PVID:  00CC202E1B83ABCA   New-Old=86400001
04/20/13 New PVID:  00CC202E25D063CB   Old PVID:  00CC202E20AA07CB   New-Old=86400000
04/21/13 New PVID:  00CC202E2AF6BFCB   Old PVID:  00CC202E25D063CB   New-Old=86400000
04/22/13 New PVID:  00CC202E301D1BCB   Old PVID:  00CC202E2AF6BFCB   New-Old=86400000
04/23/13 New PVID:  00CC202E354377C6   Old PVID:  00CC202E301D1BCB   New-Old=86399995
04/24/13 New PVID:  00CC202E3A69D3C5   Old PVID:  00CC202E354377C6   New-Old=86399999
04/25/13 New PVID:  00CC202E3F902FCA   Old PVID:  00CC202E3A69D3C5   New-Old=86400005
04/26/13 New PVID:  00CC202E44B68BC9   Old PVID:  00CC202E3F902FCA   New-Old=86399999
04/27/13 New PVID:  00CC202E49DCE7CC   Old PVID:  00CC202E44B68BC9   New-Old=86400003
04/28/13 New PVID:  00CC202E4F0343CA   Old PVID:  00CC202E49DCE7CC   New-Old=86399998
04/29/13 New PVID:  00CC202E54299FCB   Old PVID:  00CC202E4F0343CA   New-Old=86400001
04/30/13 New PVID:  00CC202E594FFBCA   Old PVID:  00CC202E54299FCB   New-Old=86399999
Conclusion
The first 8 digits of the PVID match the first 8 digits of the machine id (which can be displayed with uname -m).   The last 8 digits of the PVID is a timestamp, but this timestamp overflows every 49.7 days and starts over, so it is not possible to determine the date/time a PVID was generated based on the PVID number.   


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Decommission AIX partition

This activity depends and changes according the company environment , but also these are the common steps that can be helpful to decommission a server( say AIX LPAR)

Take a mksysb image from a partition.
Make sure that filesystem and applications backups are up to date and backups can be found from TSM or from any backup Tool used in the Environment ( llike Veritas Backup etc..)
Inform monitoring team that partition is going to be removed and monitoring should be stopped.
Stop applications on lpar.
Inform storage team that partition is going to be removed, they will handle the backups.
Inform Monitoring team that ip-addresses from that partition can be freed.
Inform network team that partition is going to be removed .Also inform network team if there is any physical cabling, switch ports needs to be shut down.
Update documentation  (other system documentation) for the Future reference.
Remove volumegroups, filesystems and logical units from server.
Remove logical units from disk systems.
Stop lpar.
Remove lpar profile with HMC.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Delete Multiple Default Gateways
By Surya18:16No comments
gateway: 
A network gateway is an internetworking system capable of joining together two networks that use different base protocols. A network gateway can be implemented completely in software, completely in hardware, or as a combination of both. Depending on the types of protocols they support, network gateways can operate at any level of the OSI model.
First, obtain how many gateways there are: 
# odmget -q "attribute=route" CuAt

CuAt:
        name = "inet0"
        attribute = "route"
        value = "net,-hopcount,0,,0,192.168.0.2"
        type = "R"
        generic = "DU"
        rep = "s"
        nls_index = 0

CuAt:
        name = "inet0"
        attribute = "route"
        value = "net,-hopcount,0,,0,192.168.0.1"
        type = "R"
        generic = "DU"
        rep = "s"
        nls_index = 0
If there are more than one, you need to remove the excess route: 
# chdev -l inet0 -a delroute="net,-hopcount,0,,0,192.168.0.2"
Method error (/usr/lib/methods/chginet):
        0514-068 Cause not known.
0821-279 writing to routing socket: The process does not exist.
route: not in table or multiple matches
0821-207 chginet: Cannot add route record to CuAt.
Then verify again: 
# odmget -q "attribute=route" CuAt

CuAt:
        name = "inet0"
        attribute = "route"
        value = "net,-hopcount,0,,0,192.168.0.1"
        type = "R"
        generic = "DU"
        rep = "s"
        nls_index = 0



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Device Administration-AIX


This post will discuss about device administration and their management.

Last post we looked at information about the devices and their states. You can refer that post here.

This post is a step closer to device management.
The main command to list all devices present in the system is:

# lsdev


This command will list all the devices present in ODM in the system.
# lscfg















Command is used to list the configuration of all the devices present on the system.
# lscfg -vp




















Command is used to list the complete hardware information.
# lscfg –vpl hdisk0

















Will give complete hardware information about hdisk0.

If lscfg is used with flags for eg:
# lscfg –v


















Command will give complete information in form of list of all the devices installed on the system. This information output will be detailed information available for each device installed on the machine.

Other commands like,

# lscgf –vl <device name>

Will give complete information about the device installed on the machine.

You can make use of help command to know more about the flags associated with lscfg command.

As we have already seen devices connected to the system can have 4 states, we will discuss these states in detail now.
Undefined means devices may be connected to the system but not defined.

Defined means devices connected and defined but still unavailable to the system.

Available means devices are defined and present in the system.
Stopped means devices are unavailable but defined and not known to the system by a device number.

Command to convert the state of a device from DEFINED to AVAILABLE is:

# mkdev –l  <device name>

This command will convert the raw device which is in defined state to available state after execution.
Another command to change the state of the device from DEFINED to AVAILABLE is:

# cfgmgr

This command changes the state from defined to available for the device.

This performs the same functionality as mkdev command does. This command is basically used to configure plug & play devices. Freshers in AIX must remember this command from interview point of view.

Once the device state is changed from DEFINED to AVAILABLE, admin can always revert back to DEFINED state by running the following command:

# rmdev –l <device name>

This command will remove the device and its information from the AVAILABLE state of devices and put the device back in DEFINED state.

For eg:

# rmdev –l hdisk4







This command will show hdisk4 in defined state not available state.

To remove the device completely from the system, command used is:
# rmdev –dl <device name>

Another command can be used if the devices installed are having child devices (dependencies attached to it), command to remove the device completely in such a situation is:

# rmdev –SR <device name>

S flag will stop the device
And
R flag will unconfigure all the child devices connected to the parent device.

To list all the PRE-DEFINED devices, command used is:

# lsdev –Pc hdisk
Or
# lsdev –Pc tape
Or
# lsdev –Pc cdrom






Where

P stands for predefined and c stands for class of the device whether tape, cdrom, hdisk etc.

Remember: pre-defined devices are those which are in undefined/supported state.

For eg: to check pre-defined supported adapter:

# lsdev –Pc adapter




















Command to list all the customized devices, command used is:
# lsdev –Cc hdisk
Or
# lsdev –Cc tape
Or
# lsdev –Cc cdrom

Where
C stands for customized and c for class.
Remember: customized devices means devices are defined and available to the system.

For eg: to check customized adapter (to check Ethernet adapter (NIC Cards) availability)

# lsdev –Cc adapter
# lsdev –CH




















Command is used to list entire information about customized devices.

# lsdev –PH





















Command will list entire information about all pre-defined devices.

To check total number of CPUs, command used is:

# lsdev –Pc processor
# lsdev –Cc processor

To check how many interfaces are available, command used is:
# lsdev –Cc if

lsdev adapter & if commands
Each adapter will have 2 interfaces.

For eg:

Ent0 will have 2 interfaces, en0 and et0
En0 is used for assigning ip and et0 is used for IEEE Ethernet interface (for research).

IP is never assigned directly to the adapter, it is assigned to the interface. 256 ip’s can be assigned to a single interface.
We will discuss about all these concepts in network administration as well.

To check speed and attributes of processor, command used is:
# lsattr –EH –l proc0

lsattr commands
This will generally give speed as 332 mhz.

To check system attributes:
# lsattr –EH –l sys0
Command used to check real memory is:
# lsattr –EH –l sys0 –a realmem

Real memory can also be checked by using this command:
# bootinfo –r

Various bootinfo commands we have already discussed in this post.
Some other commands:

# lsattr -EH -l sys0 -a autostart

# lsattr -EH -l tty0 -a speed

# lsattr – EH -l mem0

# lsattr -EH -l inet0



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Device Management in AIX
By Surya21:01No comments
Device Management in AIX
In order to attach peripherals such as terminals and printers to an AIX system, we must tell AIX the characteristics of these devices so that the operating system can send the correct signals to the adapter to which the device is connected. A number of pieces of hardware and software must interact correctly for the device to function correctly. 

1) Physical Devices 
2) Ports 
3) Device Drivers 
4) Logical Devices 
5) /dev 
1) Physical Devices -
Actual hardware that is connected in some way to the system.
2) Ports -
The physical connectors/adapters in the system where physical devices are attached. Most ports are programmable by the system software to allow attachment of many different types of devices.
3) Device Drivers -
Software in the kernel that controls the activity on a port and the format of the data that is sent to the device.
Eg: /dev/hdisk0 = device driver of hard disk 0
4) Logical Devices -
Software interfaces (special files) that present a means of accessing a physical device to the users and application programs. Data read from logical devices will be read from the appropriate device driver.
Eg: /dev/datalv = logical volume for data
5) /dev -
The directory which contains all of the logical devices that can be directly accessed by the user. (Some of the logical devices defined are only referenced in the ODM customized database and cannot be accessed by users.) 

Listing of /dev directory
#ls -l /dev

The ls -l command allows you to see the type of a file. A special file (in the /dev directory) will be indicated by a b in the first column for a block device or a c for a character device. 

b = Block device is a structured random access device. Buffering is used to provide a block-at-a-time method of access. Usually only disk file systems. 

Eg: cd0 CD-ROM
      hdisk0 Physical Volume

c = Character (raw) device is a sequential, stream-oriented device which provides no buffering. 

Eg: console, lft, tty0 Terminal
       rhdisk0 Physical Volume

Most block devices also have an equivalent character device. For example, /dev/hd1 provides buffered access to a logical volume whereas /dev/rhd1 provides raw access to the same logical volume.Normally the fifth field contains a numeric value indicating the number of bytes in the file. Fordevices, it shows the major and minor device numbers. The device rmt0 shown in the listing has a major device number of 22 and a minor device number of 1. This indicates that the code to handle major device 22 must already be in the kernel, and it must handle device number 1 correctly. Clearly, the major number refers to the software section of code in thekernel which handles that type of device, and the minor number to theparticular device of that type or the operation mode of a device of that type. 

ODM - Object Data Manager
Device Configuration Database

1) Pre-Defined Configuration Databse
2) Customized Configuration Databcse

The predefined and customized databases store information about all of the logical devices in the system and their attributes managed by the ODM (Object Data Manager).

The predefined database contains configuration data for all possible devices supported by the system. The SMIT menus have options to install non-supported drivers. The contents of the predefined database is largely defined at installation time, ensuring that you always have support for devices in your system.

The customized database contains configuration data for all currently defined and configured (available) devices.
cfgmgr
The Configuration Manager is a program that automatically configures devices on your system during system boot and run time. The Configuration Manager uses the information from the predefined and customized databases during this process, and updates the customized database afterwards.

List all supported Devices 

PdDv = pre-defined Database

#lsdev -P -H
or
smit devices -> List Devices -> List All Supported Devices

Devices are classified by Class, Type and Subclass where Class indicates what the device does, Type indicates what model it is and Subclass indicates how it can be attached to the system.To find out what devices are listed in the predefined database, use the SMIT option List All Supported Deviceswhich runs the command lsdev -P. To find out the attributes of a predefined device, use the SMIT option Show Characteristics of a Supported Device which runs the command lsattr -D

The -P option pulls information from the predefined database in the ODM.
The -H option shows the headers for the output.
The -c option specifies the class of device.

List all Defined Devices
#lsdev -C -H

The devices that have been customized in the system are described in the ODM customized database. Each device has a logical device name, a status, a location and various attributes.The lsdev -CH command provides information on the resource name, its status (or state), the address or location, and a brief description of all devices in the customized database.

Available: The device is ready and can be used

Defined: The device is unavailable

Devices may appear in a defined state after a restart. If this is the case, it may be due to the fact that the device is powered off or the fact that the device no longer exists on the system.

Devices with a location code are physical devices. Devices without a location code are logical devices.


#lsattr -EH -l sys0

The lsattr -E -l [resource name] command provides detailed information on the effective attributes currently configured for specified devices. In the example, it provides configuration information on the system itself.

The -C option for lsdev pulls the customized information from the ODM.
The -E option for lsattr shows the effective attributes.
The -l option for both commands is the logical device name.
The -c option for both commands is the class of device.
The -a attribute option for the lsattr command displays information for aspecific attribute.


Eg: #lsattr -E -l sys0 -a realmem


lscfg


Another command that can be used to list information about devices found in the ODM customized database is lscfg -v. The listing is sorted by parent, child and device location. Specific hardware information about devices will be listed such as EC level, FRU number, part number, and so forth. The output also displays the model architecture and bus type.

DEVICE STATES




The Most Common Device States are:-


Undefined - 


The device is a supported device but is not configured. It does not reside in the customized database.


Defined - 


The device has been added to the customized database. It has been allocated a logical device name, a location code and attributes have been assigned to it. But, it is still unavailable for use.


Available - 


The device resides in the customized database. The device is fully configured and is ready for use.

When a device is first identified, it is configured and put into the Availablestate. If a device that has been configured in the past is powered off and the machine is rebooted, the device will appear in the Defined state. This indicates that the system knows it is supposed to be there, but because it was not powered on, it cannot be used. You can control the device states by using smit or the commands mkdev and rmdev.

To put a defined tape into an available state , 
in the smit devices area, use Configure a Defined Tape Device or #mkdev -l rmt0

To move an available tape device to defined ,  
In the smit devices area, use Remove a Tape Device and set Delete from Database to no or #rmdev -l rmt0

To permanently remove an available or define tape device , 
In the smit devices area, use Remove a Tape Device and set Delete from Database to yes or #rmdev -dl rmt0

Remember, most Defined devices are the result of not powering on the device before booting. Or, it could be the device was physically removed, but you never ran rmdev -dl xxxx to remove the device from the ODM.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Device Related Commands in AIX
By Surya21:18No comments

cfgmgr                 To configure devices and installs device software in system

cfgmgr -l vscsi0     To configure the components connected to the vscsi0 interface

lscfg                          To display config, diagnostics and vital product definition info

lscfg -l mem0         Display info about device mem0

lscfg -l ent*            Display info about all Ethernet cards

lscfg -v                   Display vpd

lscfg -v -l hdisk0       Display vpd of hdisk0

mkdev -l rmt0         To change device rmt0 from defined state to available state

lsdev -P                  To lists all supported devices

lsdev -P -c disk        To list all supported disks

lsdev -P -r class        To display supported class

lsdev -P -r subclass  To display all sub class

lsdev -C                  To lists all configured devices

lsdev -C -l mem0     To display the properties of mem0

chdev -l sys0 -a maxproc=100   To change default maxproc value to 100/user

chdev -l rmt0 -a blocksize=512  To change the block size to 512

chdev -l rmt0 -a ret=no            To avoid tape retension

rmdev -l rmt0                           To remove the device rmt0

rmdev -dl rmt0                         To remove the device totally from database

rmdev -l rmt0 -S                           To change the state of the device stopped

lsparent -C -k rs232                 To display possible parent devices which accept rs232 devices

lsparent -C -l hdisk0                 To display parent devices which accept child device hdisk0

lsattr -Dl rmt0                         To see the default values of the device rmt0

lsattr -El rmt0                         To see the current values of the device rmt0

lsattr -El tty0 -a login -R           To see all possible values of the login attribute of tty0

lsconn -p scsi0                        To list all possible connection scsi0 can accept

lvlstmajor                               To list the available major numbers

mknod /dev/null c 2 2              Create null device with major (2) and minor (2) nos. (c - char device)



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Difference between major and minor number
By Surya12:00No comments
Major number:
A major number refers to a type of device, and a minor number specifies a particular device of that type or sometimes the operation mode of that device type.

Example:
    # lsdev -Cc tape
    rmt0 Available 3F-08-02 IBM 3580 Ultrium Tape Drive (FCP)
    rmt1 Available 3F-08-02 IBM 3592 Tape Drive (FCP)
    smc0 Available 3F-08-02 IBM 3576 Library Medium Changer (FCP)

In the list above:

rmt1 is a standalone IBM 3592 tape drive;

rmt0 is an LTO4 drive of a library;

smc0 is the medium changer (or robotic part) of above tape library.

Now look at their major and minor numbers:
    # ls -l /dev/rmt* /dev/smc*
    crw-rw-rwT 1 root system 38, 0 Nov 13 17:40 /dev/rmt0
    crw-rw-rwT 1 root system 38,128 Nov 13 17:40 /dev/rmt1
    crw-rw-rwT 1 root system 38, 1 Nov 13 17:40 /dev/rmt0.1
    crw-rw-rwT 1 root system 38, 66 Nov 13 17:40 /dev/smc0

All use IBM tape device driver (and so have the same major number of 38), but actually they are different entities (with minor number of 0, 128 and 66 respectively). Also, compare rmt0 and rmt0.1. It's the same device, but with different mode of operation.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Easy Ways to Trace VSCSI Configuration with AIX

Virtual SCSI (VSCSI) disks are great for sharing physical disks without requiring physical adapters, but mapping the configuration can be painful. I recently came across a couple of tools for tracing and mapping out the VSCSI configuration that have been huge time savers.
Identify VSCSI Adapters Using kdb Command
There's a quick way of checking which Virtual I/O Server (VIOS) Virtual SCSI (VSCSI) adapter is being used for a VSCSI client adapter. You can do it all from the VIO client logical partition in one line:
# echo "cvai" | kdb | grep vscsi
read vscsi_scsi_ptrs OK, ptr = 0x59A03C0
?vscsi0 0x000007 0x0000000000 0x0 vios1->vhost9?
vscsi1 0x000007 0x0000000000 0x0 vios2->vhost9

# echo "cvai" | kdb | grep vscsi read vscsi_scsi_ptrs OK, ptr = 0x59A03C0 vscsi0     0x000007 0x0000000000 0x0 vios1->vhost9 vscsi1 0x000007 0x0000000000 0x0 vios2->vhost9.
As you can see, the command not only shows you the VIOS host names -- in this example, vios1 and vios2 -- it also tells you which vhost number you're using on each VIO server. This is especially helpful when the vhost number on VIOS1 is different from VIOS2's vhost.

If you've ever tried to walk through the procedure to trace virtual disks, you'll quickly see the benefit of this shortcut. To get the information the slow way, you have to run several commands on the VIO client, then some more on the Hardware Management Console (HMC), then log onto the VIOS and run some more commands.

Instead of all of that, the command:
# echo "cvai" | kdb
gives you all you want. Pipe it to “grep vscsi” and you've got the VIOS and the vhost adapter.
vhosts for Dual VIOS
If you're using dual VIOS, sometimes the vhost adapter on VIOS2 doesn't correspond to the vhost adapter number on VIOS2. Not a problem:
# echo "cvai"|kdb|grep vscsi
read vscsi_scsi_ptrs OK, ptr = 0x4240398
vscsi0 0x000007 0x0000000000 0x0 vios1->vhost8
vscsi1 0x000007 0x0000000000 0x0 vios2->vhost5
Here you can see that vscsi0 (on the AIX client) corresponds to vios1's VSCSI server adapter known as vhost8. But vios2's adapter is called vhost5.

Armed with this information, you can log onto the VIOS restricted shell as the userpadmin and list the devices using the lsmap command. You can use lsmap -vadapter to identify a single Virtual SCSI server adapter.

In this example, on vios1, you would list the disks on vhost8. Here's an extract from oneIBM system admin I was working on:
lsmap -vadapter vhost8
SVSA                            Physloc                                                                 Client Partition ID
--------------- ---------------------------------- ------------------
vhost8                        U9119.595.021A34E-V30-C36                        0x00000024
VTD tst_boot_a
Status Available
LUN 0x8100000000000000
Backing device hdisk53
Physloc U5791.001.9920070-P2-C10-T1-W500507680130239F-L32000000000000
And then on vios2, you'd run the lsmap command for vhost5.
Mapping VSCSI Configuration via a Script
If you're looking to map out all the VSCSI disks presented to AIX clients from Storage Area Network (SAN) LUNs, have a read of this blog post written by Brian Smith on IBM developerWorks. It includes a Perl script that presents the output in an HTML page. You can put that page on a web server or view it locally on your PC or laptop. The script takes very little time to install, and you don't need to be a Perl expert to do it.

You can download the script from a link in the blog post I noted above, and it's always best to check the original blog post in case there are updates. There's a disclaimer that you should read, and because the script accesses vital parts of your infrastructure, the author warns that you use it at your own risk.

If, like me, you hesitate to create a new spreadsheet to document your configuration, you'll find utilities such as these are worth looking into. They can make a huge difference to the time and effort it takes you to trace your VSCSI configuration.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

entstat equivalent for FC adapters in AIX.
By Surya13:41No comments
The entstat -d ent# commands delivers a lot of useful information about a network adapter. We often used it to determine if the adapter has “LINK” and with what speed it move the data from and to the host. Its equivalent for FC adapters is called fcstat and it works for both physical and virtual FC adapters.

# fcstat -e fcs0 | grep -E "Type|fcs|Port Name|Port Speed"
FIBRE CHANNEL STATISTICS REPORT: fcs0
Device Type: 8Gb PCI Express Dual Port FC Adapter (df1000f333108a03) (adapter/pciex/df1000f114108a0)
World Wide Port Name: 0x10000220C985EA6B
Port Speed (supported): 8 GBIT
Port Speed (running):   8 GBIT
Port Type: Fabric
# fcstat -e fcs0 | grep -E "Type|fcs|Port Name|Port Speed"
FIBRE CHANNEL STATISTICS REPORT: fcs0
Device Type: Virtual Fibre Channel Client Adapter (adapter/vdevice/IBM,vfc-client)
World Wide Port Name: 0xC05076039B790032
Port Speed (supported): UNKNOWN
Port Speed (running):   8 GBIT
Port Type: Fabric
Even more FC adapter statistics can be obtained using the -D option like for example  #fcstat -D fcs0. The last command generates almost twice as much information than the fcstat -e fcs0.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Erasing disks AIX
By Surya21:43No comments

During a system decommission process, it is advisable to format or at least erase all drives. There are 2 ways of accomplishing that:

If you have time:

AIX allows disks to be erased via the Format media service aid in the AIX diagnostic package. To erase a hard disk, run the following command:
# diag -T format
This will start the Format media service aid in a menu driven interface. If prompted, choose your terminal. You will then be presented with a resource selection list. Choose the hdisk devices you want to erase from this list and commit your changes according to the instructions on the screen.

Once you have committed your selection, choose Erase Disk from the menu. You will then be asked to confirm your selection. Choose Yes. You will be asked if you want to Read data from drive or Write patterns to drive. Choose Write patterns to drive. You will then have the opportunity to modify the disk erasure options. After you specify the options you prefer, choose Commit Your Changes. The disk is now erased. Please note, that it can take a long time for this process to complete.

If you want to do it quick-and-dirty:

Becarefull while giving if & of values. If you  give wrongly you will end-up in disasters.

For each disk, use the dd command to overwrite the data on the disk. For example:

for disk in $(lspv | awk '{print $1}') ; do
   dd if=/dev/zero of=/dev/r${disk} bs=1024 count=10
   echo $disk wiped
done

This does the trick, as it reads zeroes from /dev/zero and outputs 10 times 1024 zeroes to each disk. That overwrites anything on the start of the disk, rendering the disk useless



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Ether Channel Setup AIX
By Surya13:47No comments
ETHERCHANNEL:
EtherChannel is a trademark registered by Cisco Systems and is generally called multi-port trunking or link aggregation. If your Ethernet switch device has this function, you can exploit the support provided in AIX. In this case, you must configure your Ethernet switch to create a channel by aggregating a series of Ethernet ports.

On AIX with "smitty etherchannel", in the same menu, depending how the fields are filled out, 2 distinctly separate functioning devices can be created. This can be seen:

ent2   Available  EtherChannel / IEEE 802.3ad Link Aggregation

1. EtherChannel (Network Interface Backup, NIB)
2. Link Aggregation (802.3ad)
1.Etherchannel (NIB):
Network Interface Backup (NIB) can be used to achieve network redundancy. Two adapters are used to create an EtherChannel that consists of one primary adapter and one backup adapter. The interface is defined on the EtherChannel. If the primary adapter becomes unavailable, the Network Interface Backup switches to the backup adapter. 
2. Link Aggregation
Link Aggregation is a network port aggregation technology that allows several Ethernet adapters to be aggregated together to form a single pseudo Ethernet adapter. (There are for example 2 primary adapters). 

The main benefit of a Link Aggregation is that it has the network bandwidth of all of its adapters. If an adapter fails, the packets are automatically sent on the next available adapter without disruption to existing user connections. A link or adapter failure will lead to a performance degradation, but not a disruption.

Link Aggregation is not a complete high-availability networking solution because all the aggregated links must connect to the same switch. 

For me once in order to work correctly the Link Aggregation (with LACP) I had to set these:
smitty etherchannel --> Change/Show Characteristics...:
Mode          8023ad
Hash Mode     src_dst_port

(I used smitty, but chdev works as well)
How to check which one is configured on the server:
entstat -d <etherchannel device> | head
Etherchannel for Network Interface Backup (primary - standby):
    ETHERNET STATISTICS (ent6) :
    Device Type: EtherChannel
    Hardware Address: 00:11:25:a5:9b:2a
    Elapsed Time: 0 days 12 hours 10 minutes 35 seconds
Etherchannel for Link Aggregation (primary - primary):
    ETHERNET STATISTICS (ent4) :
    Device Type: IEEE 802.3ad Link Aggregation
    Hardware Address: 00:11:25:c5:bf:1d
    Elapsed Time: 45 days 2 hours 37 minutes 55 seconds
Link Aggregation with NIB:
By using a backup adapter you can add a single additional link to the Link Aggregation, which is connected to a different Ethernet switch. This single link will only be used as a backup. ------------------------
man ethchan_config            manual for configuring etherchannel with commands
smitty etherchannel           smitty menu for configuring etherchannel
lsattr -El entX               it will show the adapters belongin to the etherchannel (and other useful settings
entstat -d entX | grep Act    shows which adapter (Primary or Backup) is the active in the etherchannel (enX)
------------------------
Creating an EtherChannel:
1. before creating make sure no ip on either adapter 
(easiest way: first remove enX/etX/entX before starting to configure, then cfgmgr)

2. when you have clean adapters: smitty etherchannel
    - choose the adapters which you want as primary adapter
    - add additional adapter if needed a backup adapter
    - set mode and hash mode if needed (for Link Aggreagtion once I needed  8023ad and src_dst_port)

------------------------
Add /Remove and adapter from EtherChannel:
Beginning with the 5200-03, Dynamic Adapter Membership functionality is available. This functionality allows you to add or remove adapters from an EtherChannel without having to disrupt any user connections.
Removing adapter from etherchannel without stopping etherchannel: 
smitty etherchannel -> Delete Main/Backup Adapter
/usr/lib/methods/ethchan_config -d <etherchannel physical device> <physical device>
/usr/lib/methods/ethchan_config -d ent4 ent0
Adding adapter to etherchannel:
(make sure no ip is configured, if needed put to detach state)
smitty etherchannel -> Add Main/Backup Adapter
/usr/lib/methods/ethchan_config -a -b <etherchannel physical device> <physical device>         <--adding as backup adapter
/usr/lib/methods/ethchan_config -a <etherchannel physical device> <physical device>            <--adding as primary adapter
/usr/lib/methods/ethchan_config -a ent4 ent0

(For me once, only command line worked, when smitty has been used for removing, it always said: resource is busy...)
Testing adapter failover:
Etherchannel: ent2
Primary Adapter: ent0 (connected on VLAN with VIOS1)
Backup Adapter: ent1 (connected on VLAN with VIOS2)

(IOCTL error message during creation of an etherchannel can be ignored)

1. check active channel:
    entstat -d ent2| grep Active                    <--Active channel: primary channel
2. unplug cable from primary channel or testing it with command:
    /usr/lib/methods/ethchan_config -f ent2         <--it will do a failover
3. checking:
    entstat -d ent2 | grep Active                   <--Active channel: backup adapter
    errpt | head                                    <--ETHERCHANNEL FAILOVER
4. switch back:    
    /usr/lib/methods/ethchan_config -f ent2         <--it will do a switch again
5. checking:
    entstat -d ent2 | grep Active                   <--Active channel: primary channel
    errpt | head                                    <--ETHERCHANNEL RECOVERY



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------
Export a Share in Windows to AIX using CIFS

Question
How to export a share in Windows and mount the share on AIX using CIFS.
Answer
Share the directory on the Windows server.
NOTE: Windows menus might vary, depending on the version of windows you are running.Right click on the directory you want to share, Select the "Sharing" tab and "Share this folder" and
Click "Ok" or "APPLY".



To check the directory was correctly shared open a DOS prompt and type "net share".














Install the CIFS client filesets for AIX, and reboot the system, since they are "bos" base operating system filesets.
The AIX client should have the following filesets installed.
# lslpp -L |grep cifs
bos.cifs_fs.rte Runtime for SMBFS
bos.cifs_fs.smit SMIT Interface for SMBFS
The following ports must be allowed through all Firewalls: 137,138,139 and 445.
To mount the share you could either use the command below or smitty cifs_fs.
# mount -v cifs -n <server>/<user>/<passwd> -o wrkgrp=<work_group_name>,fmode=755 /<share> /<mount_point>
The user must exist on Windows, and you must provide the workgroup or domain that windows is using.
If you are not sure of the windows workgroup or domain, check the following in windows.

Right Click on "My Computer" and select Properties.





















To mount the directory using smit menus.
#smitty cifs_fs
>>Add/Mount a CIFS File System
Remove/Unmount a CIFS File System
Change a CIFS File System
List CIFS File Systems
Credential configuration
* Pathname of mount point [/mnt]
* SERVER Name [pc-hostname]
* USER Name [userwin]
Password [testpass]
* Share name [/testcifs]
* Mount READ-ONLY [no]
uid [0]
gid [0]
fmode [755]
Domain to Authenticate against [WORKGROUP]
* Mount now, add entry to /etc/filesystems, or both [Both]
* /etc/filesystems entry will mount on start [no]
Mount type name [ ]
Now the AIX client will be able to access the shared directory from windows.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

fuser Command

Purpose
Identifies processes using a file or file structure.
Syntax
fuser [[-c | -f ][-x ] |-d ] [ -k | -K { SignalNumber | SignalName }] [ -u ] [ -V ]File ...
Description
The fuser command lists the process numbers of local processes that use the local or remote files specified by the File parameter. For block special devices, the command lists the processes that use any file on that device.
Each process number is followed by a letter indicating how the process uses the file:
Item	Description
c	Uses the file as the current directory.
e	Uses the file as a program's executable object.
r	Uses the file as the root directory.
s	Uses the file as a shared library (or other loadable object).
The process numbers are written to standard output in a line with spaces between process numbers. A new line character is written to standard error after the last output for each file operand. All other output is written to standard error.
The fuser command will not detect processes that have mmap regions where that associated file descriptor has since been closed. Also, processes using FIFOs (named pipes) will not be detected until the FIFO is fully opened. For example, a process waiting for an open system call to complete will not be seen by the fuser command.
Flags
Item	Description
-c	Reports on any open files in the file system containing File.
-d	Reports on any open files which have been unlinked (deleted) from the file system containingFile. When used in conjunction with the -V flag, it also reports the inode number and size of the deleted file.
-f	Reports on open instances of File only.
-K SignalNumber | SignalName	Sends the specified signal to each local process. Only the root user can kill a process of another user. Signal can be specified as either a SignalName, such as KILL for the SIGKILL signal or a SignalNumber, such as 9. Valid values for SignalName are those which are displayed by the kill -l command.
-k	Sends the SIGKILL signal to each local process. Only the root user can kill a process of another user.
Note: fuser -k or -K might not be able to detect and kill new processes that are created immediately after the program starts to run.
-u	Provides the login name for local processes in parentheses after the process number.
-V	Provides verbose output.
-x	Used in conjunction with -c or -f, reports on executable and loadable objects in addition to the standard fuser output.
Security
Attention RBAC users and Trusted AIX users: This command can perform privileged operations. Only privileged users can run privileged operations. For more information about authorizations and privileges, see Privileged Command Database in AIX® Version 7.1 Security. For a list of privileges and the authorizations associated with this command, see the lssecattr command or the getcmdattr subcommand.
Examples
To list the process numbers of local processes using the /etc/passwd file, enter:
fuser /etc/passwd
To list the process numbers and user login names of processes using the /etc/filesystems file, enter:
fuser -u /etc/filesystems
To terminate all of the processes using a given file system, enter:
fuser -k -x -u -c /dev/hd1 
or
fuser -kxuc /home
Either command lists the process number and user name, and then terminates each process that is using the /dev/hd1 (/home) file system. Only the root user can terminate processes that belong to another user. You might want to use this command if you are trying to unmount the /dev/hd1 file system and a process that is accessing the /dev/hd1 file system prevents this.
To list all processes that are using a file which has been deleted from a given file system, enter:
fuser -d /usr
Files
Item	Description
/dev/kmem	Used for the system image.
/dev/mem	Also used for the system image.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

HEAD command examples in UNIX / Linux

The head command in Unix or Linux system is used to print the first N lines from the file to the terminal. The syntax of head command is
head [options] [files]
The head command options are:
c : Prints the first N bytes of file; With leading -, prints all but the last N bytes of the file.
n : Prints first N lines; With leading - print all but the last N lines of each file.
Head Command Examples:
Create the following file in your linux or Unix operating system for practising the examples:
# cat example.txt
linux storage
ubuntu os
fedora
1. Display first 10 lines
By default, the head command prints the first 10 lines from a file.
# head example.txt
2. Display first N lines
Use the -n option to print the first n lines from a file. The following example prints the first 2 lines from the file:
# head -n2 example.txt
linux storage
ubuntu os
3. Skip last N lines
You can skip the last N lines from a file and print the remaining lines. The following example skips the last 2 lines and prints the remaining lines.
# head -n-2 example.txt
linux storage
4. Print the first n bytes
use the -c option to print the first N bytes from the file. The following example prints the first 5 bytes from the file.
# head -c5 example.txt
linux
5. Skip printing last n bytes
Use the leading "-", to skip printing last N bytes.
# head -c-7 example.txt
linux storage
ubuntu os
6. Print line between M and N lines
You can combine the head command with tail command to print lines between the line numbers M and N. The following command prints the lines between numbers 5 and 10.
# head -n10 filename | tail -5



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


How can I apply an efix or ifix?


You don't apply interim fixes (ifix) or emergency fixes (efix) with installp - instead you do it with the Efix Manager. IBM provides these fixes in a compressed epkg format (suffix: .epkg.Z). And that's how it's been applied:
# emgr -e <EFIX>.epkg.Z

You get a list of all installed fixes with
# emgr -l
ID  STATE LABEL    INSTALL TIME      UPDATED BY ABSTRACT
=== ===== ======== ================= ========== ================
1    S    IZ79677  09/16/10 16:09:52            iFix for IZ79677

The Label from the table above is needed when you ever want to remove an efix from the system:
# emgr -r -L <LABEL>

With a TL or SP upgrade installp will automatically remove an interim fix only if the service pack already contains it. If not the upgrade will fail and you have to remove it with the efix manager before upgrading.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

How can I directly read out the VGDA of a PV (hdisk)?

Information about VGx, LVx, filesystems, etc. are stored in the ODM. But these information are also written to the VGDA of the disks itself. You can read the information directly from the disk's VGDA with a command like this:
# lqueryvg -Atp hdisk100
You can use
# redefinevg -d hdisk100 myvg
to synchronize the ODM with the information of the VGDA. You can also synchronize the VGDA with the information stored in the ODM:
# synclvodm myvg



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

How to Add a Disk on AIX LVM


How to Add a Disk on AIX Logical Volume Manager (LVM)

1) Add the physical or virtual disk to the logical partition.

2) Rescan your hardware so that the OS is aware of your new disk.

# cfgmgr

3) Check to see your disk. For the purpose of this example, let’s say the new disk is hdisk2.

# lsdev -Cc disk
# lspv

4) Associate your new disk to a volume group. In this case, let’s create a new group called myvg and put hdisk2 in there.

# mkvg -y myvg hdisk2

5) Now you can look at the size of hdisk2. (This command won’t work if it’s not associated with a volume group).

# lspv hdisk2

6) Create a log logical volume for jfs2. This needs to be part of myvg. Note: in the example below, the type is jfs2log and we’re giving it 1 physical partition (PP).

# mklv -t jfs2log myvg 1

7) Look for your new logical volume (lv). Chances are that AIX named it loglv00.

# lsvg
# lsvg -l myvg

8) Create your production logical volume. Let’s make it about 30GB? I’ll name it mylv1.

# lsvg myvg
# mklv -t jfs2 -y mylv1 myvg 30G

9) Lay down your file system on mylv1.

# mkfs -o log=/dev/loglv00 -V jfs2 /dev/mylv1

10) Mount your filesystem.

# mkdir /myfs1
# mount -o log=/dev/loglv00 /dev/mylv1 /myfs1

11) Edit /etc/filesystems and change the dev and log stanzas to match your dev and log names from above.




------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

How to determine if AIX uses a 32-bit kernel or 64-bit kernel ?

Problem:
This technote explains how to establish if an IBM® AIX® host is 32-bit or 64-bit capable in order to determine which version of IBM® Rational® ClearCase® to install.
Resolving the problem
The getconf command is available in AIX 5L and enhanced in Version 5.2. The command provides information about system configuration variables. The main information intended from the enhancement refers to memory, disk size, last boot device, and hardware check for 32-bit or 64-bit, and the same for the kernel. The getconf command is enhanced to provide extra information that is currently available with the unsupported bootinfo command. The getconf command uses the ODM library routines to extract information from the device configuration database. The getconf command issues a setuid root to access privileged configuration variables.
The syntax of the command is as follows:
getconf [ -v specification ] [ SystemwideConfiguration | PathConfiguration PathName ] [ DeviceVariable DeviceName]

Where the variable names are defined as provided in the following table:

Table 1. System wide configuration names

Variable	Description
System wide configuration names	
BOOT_DEVICE	Displays last boot device
MACHINE_ARCHITECTURE	Displays machine architecture type (chrp)
MODEL_CODE	Displays model code
KERNEL_BITMODE	Bit mode of the kernel, 32-bit or 64-bit
REAL_MEMORY	Real memory size in KB
HARDWARE_BITMODE	Bit mode of the machine hardware, 32-bit or 64-bit
MP_CAPABLE	MP Capability of the machine
Path configuration names	
DISK_PARTITION	Physical partition size of the disk
DISK_SIZE	Disk size in MB
Device variables names	
DISK_DEVNAME	Device name or location of the device

An example of the getconf command is shown in the following:
# getconf KERNEL_BITMODE
64
# getconf HARDWARE_BITMODE
64
# getconf DISK_SIZE /dev/hdisk0
140013
The size is reported in MB, so the disk above is a 140 GB disk.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

How to exit system console from HMC?
By Surya10:081 comment
Its quite often we ended up in giving wrong  user name when  it promptedHMC console for a lpar.
Instead closing the console use this tip to  exit from the prompt.

Its the Key Combination of   ~. (tilt+dot)



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

How to fix Boot Logical Volume(BLV) of AIX

 How to fix Boot Logical Volume(BLV) of AIX ?
If a boot logical volume is corrupted (for example, bad blocks on a disk might cause a corrupted BLV), a machine will not boot.

To fix this situation, you must boot your machine in maintenance mode, from a CD or tape. If NIM has been set up for a machine, you can also boot the machine from a NIM master in maintenance mode. By the way, that's what you would do on an SP node if an SP node does not boot.

The boot lists are set using the bootlist command or the System Management Services (SMS) program. Some machines support a normal and service boot list. If your model supports this, you will use a function key during bootup to select the appropriate list. Normally, pressing F5 when you hear the first tones during bootup, will force the machine to check for a bootable CD. More on this later.

After booting from CD, tape or NIM an Installation and Maintenance Menu is shown and you can startup the maintenance mode. We will cover this later in this unit. After accessing the rootvg, you can repair the boot logical volume with the bosboot command. You need to specify the corresponding disk device, for example hdisk0:

# bosboot -ad /dev/hdisk0

It is important that you do a proper shutdown. All changes need to be written from memory to disk.

The bosboot command requires that the boot logical volume hd5 exists. If you ever need to re-create the BLV from scratch - maybe it had been deleted by mistake - the following steps should be followed:
Boot your machine in maintenance mode (from CD or tape).
Create a new hd5 logical volume: one physical partition in size, must be in rootvg. Specify boot as logical volume type.
Run the bosboot command as described.
Reboot the server run command

# shutdown -Fr

The following is an example of re-creating boot logical volume (BLV)

1. Boot your machine in maintenance mode (from CD, tape, or NIM).

2. Create a new hd5 logical volume: one physical partition in size, must be in rootvg. Specify boot as logical volume type. if needed, remove hd5 using # rmlv -f hd5

# mklv -y hd5 -t boot -a e rootvg 1

3. Run the bosboot command as described below.

# bosboot -ad /dev/hdisk0

4. Shutdown -Fr.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

How to Set Up sar AIX
By Surya01:45No comments
How to Set Up sar
Error messages
Error messages regarding the sar command and data files include the following:
The following errors indicate that the data collection programs have not been set up to collect the data that sar reports. If you see either of the following errors, follow the procedure in the "How to set up sar data files" section in this document.
  sar:0551-201 cannot open /usr/adm/sa/sa12 
  or
  sar:0551-213 try running /usr/lib/sa/sa1  
If on bootup (or when running the sar command) you see the following error, go to Step 4 of the "How to set up sar data files" procedure and follow Steps 4 and 5.
  sar: 0511-211 specify a positive integer for the time change 
How to set up sar data files
1) Log in as root and enter su - adm.
2) Enter crontab -e.
3) Uncomment the following lines by removing the # sign from the front of each line:
 # 0 8-17 * * 1-5 /usr/lib/sa/sa1 1200 3 & 
 # 0 * * * 0,6 /usr/lib/sa/sa1 & 
 # 0 18-7 * * 1-5 /usr/lib/sa/sa1 & 
 # 5 18 * * 1-5 /usr/lib/sa/sa2 -s 8:00 -e 18:01 -i 3600 -ubcwyaqvm & 
4) Uncomment the following line in the /etc/rc file:
# /bin/su - adm -c /usr/lib/sa/sadc /usr/adm/sa/sa`date  +%id`
Reboot the system. This will turn on the data collection programs the sar command uses for displaying data.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


How to setup user managed GPFS cluster using db2cluster utility.

QUESTION
1. How to setup GPFS cluster using db2cluster utility on your system.
2. How to clean the GPFS cluster manually from your system.
ANSWER
Creating a user managed GPFS cluster and FS using db2cluster command

    db2cluster -cfs -create -host -domain
    db2cluster -cfs -add -host -domain
    mmstartup -a
    db2cluster -cfs -create -filesystem -disk -mount
    mmshutdown -a
    mmstartup -a
    Run ‘mount’ command on both the hosts in the cluster and check if the new filesystem is mounted on both machines.
             db2cluster -cfs -create -host Machine 1 -domain gpfsdomain
             db2cluster -cfs -add -host Machine 2 -domain gpfsdomain
             mmstartup -a
             db2cluster -cfs -create -filesystem gpfs1 -disk /dev/hdisk8 -mount /gpfs1
Manually cleaning a DB2 Managed Clustered File System and uninstalling GPFS
1. Unmount all GPFS file systems using the following command:
 /usr/lpp/mmfs/bin/mmumount all -a
2. Ensure the GPFS cluster is online:
 /usr/lpp/mmfs/bin/mmgetstate
 The output of this command should be similar to the following:

Node Number  Node Name    GPFS state
-----------   ----------     -----------
1        Machine 1      active
3. Find the available file system(s):
/usr/lpp/mmfs/bin/mmlsnsd

The output of this command should be similar to the following:

File system   Disk name     NSD servers
-----------     ---------    -------------------
db2fs1         db2disk1    (directly attached)
4. Delete the file system:
/usr/lpp/mmfs/bin/mmdelfs db2fs1

The output of this command should be similar to the following:
All data on the following disks of db2fs1 will be destroyed: db2disk1
Completed deletion of file system /dev/db2fs1.
mmdelfs: Propagating the cluster configuration data to all affected
nodes: This is an asynchronous process.
5. Confirm that the file system has been deleted by rerunning the following command:
/usr/lpp/mmfs/bin/mmlsnsd
The output of this command should be similar to the following:
File system    Disk name    NSD servers
(free disk)    db2disk1    (directly attached)
6. Stop the entire GPFS cluster:
/usr/lpp/mmfs/bin/mmshutdown -a
7. Unset tiebreaker disk if the quorum type is tiebreaker:
/usr/lpp/mmfs/bin/mmchconfig tiebreakerDisks=no
8. Delete NSD:
/usr/lpp/mmfs/bin/mmdelnsd
9. Verify the removal of NSD:
/usr/lpp/mmfs/bin/mmlsnsd
The output of this command should be similar to the following:
mmlsnsd: No disks were found.
10. Delete the GPFS cluster:
/usr/lpp/mmfs/bin/mmdelnode -a

The output of this command should be similar to the following:
Verifying GPFS is stopped on all affected nodes …
mmdelnode: Propagating the cluster configuration data to all affected nodes.
This is an asynchronous process.
mmdelnode: Command successfully completed.
11. Ensure that the GPFS has been removed:
/usr/lpp/mmfs/bin/mmlscluster

The output of this command should be similar to the following:
mmlscluster: This node does not belong to a GPFS cluster.
mmlscluster: Command failed. Examine previous error messages to determine cause.
12.Uninstall the GPFS binaries
Run the db2_deinstall -a command to uninstall the GPFS binaries along with DB2 SD and TSA binaries.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

How to tell which PowerVM Editions feature was ordered

Problem(Abstract)
PowerVM Editions (Formerly Advanced POWER Virtualization - APV) comes in three options:
Express, Standard, Enterprise. How do you know which one you have when reviewing the VET code on the POD website?
Symptom
The VET code from the Capacity on Demand Activation Code website (http://www-912.ibm.com/pod/pod) has been entered but you still don't see the option to create a VIO server from the HMC
Cause
The wrong PowerVM Editions feature has been ordered.
Environment
HMC attached systems
Resolving the problem
In order for a system to be VIO Server capable for use on an HMC-managed system, it must have at least the Standard PowerVM code. Systems with the Express PowerVM code are non-HMC managed only but can be used for Integrated Virtualization Manager (IVM) with up to three partitions on the server.

Here's how you can tell which PowerVM Edition feature has been ordered from the VET code listing in the Capacity on Demand Activation Code website found here: http://www-912.ibm.com/pod/pod

Use bits 25-28 from the VET code listed on that website.
Sample VET codes:
450F28E3D581AF727324000010500041FA
B905E3D284DF097DCA1F00002C0000418F
0F0DA0E9B40C5449CA1F00002c20004102

0000 = Reset to base defaults (No PowerVM)
1xxx = Express
2c00 = Standard
2c20 = Enterprise
More information about each PowerVM Editions can be found here:

http://www-03.ibm.com/systems/power/software/virtualization/editions/index.html

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

HOW TO determine installed Technology Level

Introduction
The new IBM methodology dictates two Technology Level (TL) releases per year. The first Technology Level includes hardware features, enablement, and software services. The second includes software features in the release, which means the second release is larger and more comprehensive. Finally, there is also now support for new hardware on older Technology Levels. This page is dedicated about finding information about AIX systems versions.
Determine machine type
To determine the machine type of an IBM AIX server use the uname command:
Command: determining the machine type

# uname -MuL
IBM,9133-55A IBM,0365B005G 3 65-B005G

The options:
-M: gives the machine type and model.
-u: gives the plant code and machine identifier.
-L: show the LPAR number and name.

so in the example:

The machine type: is 9113,
The model is: 55A,
OF prefix IBM: 0365B005G,
Plant code is 3,
Sequence number, 65-B005G
Determine OS level and maintenance level
To determine the AIX OS level and maintenance level use the instfix command with the option -i:
Command: determining the operating system level
# instfix -i | grep AIX_ML
    All filesets for 5.3.0.0_AIX_ML were found.
    All filesets for 5300-01_AIX_ML were found.
    All filesets for 5300-02_AIX_ML were found.
    All filesets for 5300-03_AIX_ML were found.
    All filesets for 5300-04_AIX_ML were found.
    All filesets for 5300-05_AIX_ML were found.
    All filesets for 5300-06_AIX_ML were found.
    All filesets for 5300-07_AIX_ML were found.
    All filesets for 5300-08_AIX_ML were found.

You can also use the command oslevel to determine the current AIX version, the -r option determines the highest recommended technology level.
Command: determining the highest technology level
# oslevel -r
5300-08

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

HOWTO determine the MAC address of a network interface

Introduction
Sometimes it can be useful to know the physical address of a network interface (MAC address), to perform some configuration and/or troubleshooting.
Find the MAC address
On the most of the systems this information can be retrieved using the ifconfig or the netstat commands but this is not true for IBM AIX.

To get the MAC address, use the lscfg as root as follow:

Command: displaying the MAC address of the interface <INTERFACE>

# lscfg -vpl <INTERFACE>

Example

To retrieve the MAC address of the interface ent0:
Command: displaying the MAC address of the interface ent0

# lscfg -vl ent0
  ent0             U787B.001.DNW7722-P1-T9  2-Port 10/100/1000 Base-TX PCI-X Adapter (14108902)
      2-Port 10/100/1000 Base-TX PCI-X Adapter:
        Network Address.............000D604DFA2A
        ROM Level.(alterable).......DV0210
        Hardware Location Code......U787B.001.DNW7722-P1-T9
  PLATFORM SPECIFIC
  Name:  ethernet
    Node:  ethernet@1
    Device Type:  network
    Physical Location: U787B.001.DNW7722-P1-T9


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

HOW TO Recreate boot logical volume (BLV)

Introduction
If a Boot Logical Volume (BLV) is corrupted, a machine will not boot. By example bad block in a disk might cause a corrupted BLV. This page threats how to resote that BLV.
Recreate boot logical volume
To fix this issue, boot the server in maintenance mode, from a CD ROM, a tape or a NIM if available.

The bootlists are set using the bootlist command or through the System Management Services progam (SMS). pressing F1 will go to SMS Mode. If you have an HMC, then at the time of booting select boot as SMS in the properties of that partition.

Note that the bosboot command requires that boot logical volume hd5 exists. To create a BLV (that may had been deleted by mistake), create a new hd5 logical volume of one PP size that must be in rootvg, specify boot as logical volume type using the following command:
Command: creating the BLV
# mklv -y hd5 -t boot rootvg 1
Then change the bootlist for service (maintenance) mode as 1st device to the CD ROM using the following command:
Command: changing the bootlist
# bootlist -m service cd0 hdisk0 hdisk1
Then start maintenance mode for system recovery, access the volume group rootvg to start a shell and recreate the BLV using the bosboot command as following:
Command: recreating the BLV
# bosboot -ad /dev/hdisk0
it's important to perform a proper shutdown, all changes need to be written from the memory to the disks.
Command: rebooting the system
# shutdown -Fr

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

IBM AIX LPAR Performance
By Surya18:15No comments

TABLE OF CONTENT

1.  THE POWER VM HYPERVISOR
2.  LOGICAL PARTITION (LPAR)
2.1  LOGICAL PARTITION
2.2  MICRO-PARTITION
2.3  CAPPED AND UNCAPPED MODE
2.4  LOGICAL AND VIRTUAL PROCESSORS
2.5  IBM AIX PERFORMANCE MANAGEMENT
2.6  SYSLOAD FOR IBM AIX AND PSERIES
3.  ABOUT ORSYP

http://www.enterprisemanagement360.com/wp-content/files_mf/white_paper/en_ibm_aix_lpar_performance.pdf

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

AIX TCP Traffic Regulation
Introduction
TCP network services and subsystems running on AIX automatically and transparently take advantage of this powerful DoS mitigation technology using simple administrative tuning. This new feature provides a simplified approach to increased network security by leveraging centralized management and firewall-based customization. 

In addition to providing effective service-level and system-level TCP DoS mitigation, IBM AIX TCP Traffic Regulation provides system-wide TCP connection resource diversity across source Internet protocol addresses initiating connections. 

Due to the mass adoption of Internet technology by governments, banks, universities, hospitals, and businesses around the world, our society has transformed to depend on the availability of network services for daily operation. It is imperative that our society's network infrastructure become resilient to active attacks on this availability. 

IBM AIX TCP Traffic Regulation provides a low-cost solution for network service attack resiliency. Availability is assured at the operating system level, allowing for transparent mitigation of active and passive network denial-of-service attacks. To activate protection, an administrator defines a firewall profile and customizes it to protect the specific TCP ports handling critical services. These centralized custom firewall profiles provide the security administrator greater power and flexibility in tailoring network security solutions.
Operation system architecture
IBM AIX TCP Traffic Regulation provides a new architectural layer within the AIX operating system. The goal of this new layer is two-fold: 
Provide a centralized management framework for defining custom TCP firewall profiles.
Actively manage incoming TCP socket connections and resource diversity in accordance to the current firewall policy.

Figure 1. IBM AIX TCP Traffic Regulation (TR) Architecture 




The firewall policy itself is governed by the profile definitions added, removed, or modified by a systems administrator.

 Each profile consists of three elements: 
TCP port or port-range requiring protection.
Maximum number of incoming socket connections allowed for this profile's TCP port(s).
Diversity value (a numerical quantity used to tune the overall diversity of shared TCP resources across the pool of maximum incoming socket connections).
This system of mitigation works transparently, requiring no change to existing applications. TCP TR actively manages incoming socket connection requests at the kernel level, allowing the mitigation to work transparently- requiring no change to existing applications (See Figure 1). Thus, any network service software running on AIX and operating on the TCP ports covered by these firewall profiles are automatically protected from denial-of-service attacks.

Firewall profiles are defined using the tcptr command-line utility. This utility provides interactive administration and scripted manipulation of TCP TR policies. The entire TCP TR system can be turned on or off with the tcptr_enable network option. For example, to activate the subsystem, use the following no command:

no -p -o tcptr_enable=1

The tcptr command assigns a maximum limit of incoming TCP connections to a given network port or a range of ports. Administrative users control system resources related to TCP TR by adding or removing pools of connection resources to be shared collectively by incoming socket requests remotely accessing the AIX TCP layer.

Optionally, a diversity tunable can be specified allowing for increased resource sharing policy control.
Once in effect, these TCP TR profiles become the active policy governing connections. The operating system automatically ensures that resources are shared across multiple remote IP addresses that are attempting to connect through TCP to a specific port. 
Attack overview
Network services are generally agnostic to the underlying operating system resources available and allocated for their benefit of TCP communication. Most TCP services simply attempt to accept new socket connection requests as they are received. If left uncapped, a continuous barrage of TCP connection requests and subsequent consumption of TCP resources by these network services will eventually use up all the available system resources.

Figure 2. Topology for TCP resource exhaustion


A malicious attacker can make use of this behavior and launch a remote denial-of-service attack against a vulnerable network service over the Internet. The attack eventually makes the service unavailable by establishing thousands of socket connection requests with the vulnerable system. This occurs either from bringing down the system itself or maxing out socket availability for the vulnerable service. Once the system or service has been made unavailable, legitimate clients are blocked from using the network service hosted by the system under attack (See Figure 2).
TCP TR utility
The TCP TR utility configures or displays TCP TR policy information to control the maximum incoming socket connections for ports. The syntax of the utility follows:
tcptr -add <start port> <end port> <max connection> [divisor]
tcptr -delete <start port> <end port>
tcptr -show

where:
-add adds new TCP TR policies to the system. You should specify the maximum allowable connections for the current policy, the start port, and the end port with this flag. The start port and the end port can be the same port when a port range is not specified. Optionally, you can specify a divisor to allow a greater diversity of resource sharing on the pool of available TCP connections.
-delete deletes existing TCP TR policies that are defined for the system. This flag requires the user specify the maximum allowable connections for the current policy, the start port, and the end port (can be the same as start port if not specifying a port-range).
-show displays all existing TCP TR policies defined on the system. You might use the -show flag to see the active policies before using the -delete flag.
The parameters are:

<max connection>	Specifies the maximum incoming TCP connections for the given TR policy.
<start port>	Specifies the beginning port for the current TR policy.
<end port>	Specifies the end port for the current TR policy. If the port is a range, the value specified must be larger than the start port. If the TR policy is for a single port, the value specified must be equal to the value specified for the start port.
<divisor>	Specifies a divisor to compare the number of available incoming TCP connections with the number of consumed incoming TCP connections for an IP, and corresponds to a division of the overall available connections by a power of two. The divisor is the power of two that is used in the division. This parameter is optional, and if it is not specified, the default value is one. In that case, half of the number of available connections are used.
Examples
To add a TCP Traffic Regulation Policy that covers only TCP port 23, and to set a maximum incoming connection pool of 256 with an available connections divisor of 3, enter the following command: 
# tcptr -add 23 23 256 3
To add a TCP Traffic Regulation Policy that covers a TCP port that ranges from 5000 to 6000, and to set a maximum incoming connection pool of 5000 with an available connections divisor of 2, enter the following command: 
# tcptr -add 5000 6000 5000 2
To show TCP Traffic Regulation Policies set for the system, enter the following command:
# tcptr -show 
To delete the TCP Traffic Regulation Policy that covers a TCP port that ranges from 5000 to 6000, enter the following command: 
# tcptr -delete 5000 6000
Summary
IBM AIX TCP Traffic Regulation provides a low-cost solution for network service attack resiliency. Availability is assured at the operating system level allowing for transparent mitigation of active and/or passive network denial-of-service attacks. Network services requiring security and availability should benefit from this powerful operating system technology.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Home » AIX » Important Files In AIX
Important Files In AIX

Important Files In Aix...!!!
Files:
/etc/security/environ  
 lists environment attributes for each user
/etc/security/lastlog  
 lists last login attributes for each user
/etc/security/limits  
  lists process resource limits for each user
/etc/security/user  
 lists extended user attributes for  each user
/usr/lib/security/mkuser.default  
 lists default attributes for new users
/usr/lib/security/mkuser.sys  
 script that sets up the user's environment
/etc/passwd  
 lists basic user attributes for each user
/etc/security/passwd  
  contains password information for each user
/etc/security/login.cfg  
  lists login security information for each user
/etc/utmp  
 contains users that are logged into the system, used by the "who" command
/var/adm/wtmp  
  contains connect time information for users
/etc/security/failedlogin  
 contains unsuccessful login attempts
/etc/motd  
  message of the day that is displayed when the user logs in.
/etc/environment  
 lists the default environment that new processes will use.
/etc/profile  
  environment settings for all  users
$HOME/.profile  
  environment settings for a specific user
/etc/group  
  lists attributes for each group
/etc/security/group  
  lists extended attributes for each group
Important /etc/security/user attributes to know about:
account_locked  
true or false
expires 
Expiration time for a user account.  MMDDHHMMYY,  a value of 0 indicates no expiration
loginretires  
Number of invalid login attempts before a users is not allowed to login.  A value of 0 indicates this attribute is disabled.
maxage  
Maximum number of weeks a password is valid, a value of 0 indicates unlimited
minage  
Minimum number of weeks between password changes.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Home » AIX » Install AIX from scratch with screenshots
Install AIX from scratch with screenshots
By Surya09:32No comments
Install AIX 7.1v from scratch
The screenshots are from an installation of AIX 7.1 onto a partition Image
Boot
Image
Installation starts with booting from media. In this case, from the AIX 7.1 DVD media. 
Select Install Screen
Image
First we have to tell AIX which screen we are installing from. AIX sends a message to each screen - whether it is a tty or lft (low function graphic terminal) with a number. Press that number followed by the Enter key. The other displays clear and AIX continues with the selected screen. 
Install Language
Image
The first choice you need to make is language. English is pre-selected so just press enter.
Welcome to AIX
Image
Although you could go through life accepting defaults, I prefer option 2 when installing AIX.
Installation Settings
Image
Use option 1 to ensure it is a New & Overwrite install - let's be fresh!
Then use option 2 to select your language of choice. I prefer using the USA English.
Set Primary Language
Image
After you select option 2 note that the default choice is the next screen. Continue scrolling and enter your language number.
The screen after that is the keyboard selection. I always choose the "smaller" keyboard - option 1. 
Image
Security
Image
For an initial install the defaults are probably fine, but let's take a peek. 
Option 3 please.
Security Models
Image
Do not start with Trusted AIX. That is an advanced topic we shall cover on another day. Since we are looking at options - Option 2 please.
Standard Security Options
Image
Install Options
Image

Normally you will leave all these options at yes.
Option 1. Graphics Software. X11 applications can run in client mode. This does not, by default, enable an X11 server. Unless security policy specifically prohibits it, leave this option at yes.
Option 2. System Management Client Software. Highly recommended to leave this at yes for ease of remote management of this system.
Option 3. AIX6 and higher is 64-bit kernel. JFS2 is optimized for an 64 bit-kernel. The is really no reason not to use JFS2. Leave this at yes. You will need to reinstall AIX to get it into JFS2 if you do not.
Option 4. Enable System Backups to install to any system. This is an aid to system cloning. Leaving it to yes means AIX installs many more filesets (nearly 500) and the install time takes longer. 
Sooner or later all the filesets will be installed. Why, how and/or when you ask? When you update AIX to a (new) technology level one of the side-effects is that all device drivers get installed. This is to prevent a mixture of device drivers coming from different TL and or service-pack combinations. The recommendation is to leave it at yes.
Press Enter please (option 5 pre-selected) 
Install More Software
Image

These options are all no by default.
Option 1: Firefox. If you want to work with Firefox on AIX change this to yes. The install process will prompt you for the correct DVDs at the appropriate time to install Firefox. You can also do this later using the smitty easy_install option to install the Firefox bundle.
Option 2: Not many people need Kerberos. If you do - switch to yes and the installation procedure prompts you at the correct moment for the expansion DVD. What expansion DVD you ask? Then leave this at no. Again,smitty easy_install will install the kerberos bundle later.
Option 3: Server. Back in the CDROM days you would install extra software from the second CDROM. It all fits on one DVD now so you want get prompted for Volume 2 anymore.
 Why this option then? Think of it as the opposite of "Secure by Default". This options installs the optional server filesets.

Take note: the next default action is to start installation. Press Enter!
Installation Summary
Image

IBM would not be IBM (I guess) if it did not provide a summary screen (rather than a simple "Are you sure Y/N".
This screen summarizes what you have chosen. Default (option 1) is to really start installation, but you can go back to the main installation menu (option 99) and make any changes you desire.
Installing Base Operating System
Image

Once you see a screen like this, AIX installation has really started. A lot of information will scroll over the screen, but basically, you are done. Installing AIX from a DVD takes from 30 to 60 minutes - depending largely on the speed of the disks being written to. But then I test on systems that are 5+ years old. When I am on new hardware (at customers) installs take about 20 minutes. 

When the installation is finished AIX reboots and configuration begins

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Install openssh on AIX 7.1

Installing openssh on AIX 7.1 is pretty much straight forward.  Finding the right openssh version can be the worse part of installing on AIX 7.x.  The below is a small doc so that I can remember where I placed this version and hopefully help others as well looking to install openssh on AIX 7.x.

AIX 7.x comes bundled with openssl, to verify, type openssl in command prompt, then version and you should have something similar.
OpenSSL> version
OpenSSL 0.9.8r 8 Feb 2011
OpenSSL>
If you do not have the above, then you can do two things.  Insert the AIX expansion pack media and do:
smitty install_software or
geninstall -d/dev/cd0 R:openssl-version
Download the this package to the tmp dir on your server and run: geninstall -I”Y” -d/tmp I:openssh.base

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Installation specific commands in AIX
By Surya21:24No comments

lslpp -l                              To see the details of installed file sets

lslpp -ha bos.net.*             To list the installation history of all file set in bos.net packages

lslpp -f bos.rte                   To list the files in the bos.rte package

lslpp -w /etc/hosts            To list the file set which contain /etc/hosts file (parent fileset)

lslpp -p bos.net.nfs.server  To list the pre requisites for bos.net.nfs.server file set 

lslpp -d                To show dependancies of fileset
          
installp -L -d /dev/rmt0.1  To list the installable products on the device rmt0

installp -aX -d /dev/rmt0.1 bos.net   To install all filesets within bos.net and expands file system if it requires

installp -u bos.net       To remove bos.net

installp -r                      To reject the applied software

installp -c -f                  To commit the applied fileset

installp -C                     To cleanup an incomplete installation

lppchk -c                      To check the fileset items and verifies that the checksum and filesize are consistent with SWVPD

lppchk -v                      verify that all filesets have required requisites and are completely installed

instfix -k IX9999 -d /dev/rmt0.1 To install the file set associated with fix IX9999 from rmt0

instfix -ik IX9999         To verify fix IX9999 installed


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Introducing SMIT

What is SMIT?
The System Management Interface Tool (more commonly known as SMIT) is an interactive tool bundled with AIX®. Virtually any system administration-related task can be completed using a SMIT screen; the screens are logically grouped in a hierarchal manner for easy navigation. Fast paths associated with every function can be used to go directly to the relevant screen.
One of the best features of SMIT is that you can see exactly what commands it performs either before or after it runs those commands. SMIT doesn't use any special hooks into the operating system. Everything it does, it does through standard AIX commands and Korn shell functions. This feature is especially useful when you need to automate a repetitive task; you can have SMIT create the proper command-line sequence, and you can then use those commands in your own script.
Basic usage
SMIT is part of the base operating system; the actual /usr/bin/smit command is in the bos.sysmgt.smit fileset. There are actually two versions of SMIT: a full-screen text-mode version and a graphical X Windows® client. If the DISPLAY variable is set, AIX automatically runs the GUI version. To use the text-mode version -- even if your DISPLAY variable is set -- run the smittycommand , or you can run smit -a.
When SMIT is started without a fast path specified, the main menu is displayed. In all SMIT screens, the arrow keys are used to move up and down through the choices displayed. The Return key selects the currently highlighted item. To go back one level, press F3 or Esc + 3.
The four screen types
There are four types of screens that SMIT uses to interact with and display information to the user: menus, dialogs, selectors, and command status screens.
Menus
A menu screen displays a list of tasks, only one of which can be selected. When no fast path exists at SMIT startup, the main menu is displayed (see Listing 1 for the text-mode version).

Listing 1. The main System Management screen, as seen in the text-mode version of SMIT

                               System Management

Move cursor to desired item and press Enter.

  Software Installation and Maintenance
  Software License Management
  Devices
  System Storage Management (Physical & Logical Storage)
  Security & Users
  Communications Applications and Services
  Print Spooling
  Problem Determination
  Performance & Resource Scheduling
  System Environments
  Processes & Subsystems
  Applications
  Installation Assistant
  Using SMIT (information only)
            
F1=Help             F2=Refresh          F3=Cancel           F8=Image
F9=Shell            F10=Exit            Enter=Do                    

Figure 1 shows SMIT's main menu in the GUI version of the tool.

Figure 1. The main System Management screen, as seen in the GUI version of SMIT





Dialogs
A dialog screen results from the selection of a specific task. Various symbols indicate the type of information entry that each field accepts. The data that you enter into those fields are used to form the command that SMIT executes.

Listing 2. A SMIT dialog screen. Specifically, the Change/Show Characteristics of a User screen

               
Change / Show Characteristics of a User

Type or select values in entry fields.
Press Enter AFTER making all desired changes.
  
[TOP]                                           [Entry Fields]
* User NAME                                    root
  User ID                                     [0]                     #
  ADMINISTRATIVE USER?                         true                   +
  Primary GROUP                               [system]                +
  Group SET                                   [system,bin,sys,securi> +
  ADMINISTRATIVE GROUPS                       []                      +
  ROLES                                       []                      +
  Another user can SU TO USER?                 true                   +
  SU GROUPS                                   [ALL]                   +
  HOME directory                              [/]
  Initial PROGRAM                             [/usr/bin/ksh]
  User INFORMATION                            [palatino root]
  EXPIRATION date (MMDDhhmmyy)                [0]
[MORE...37]

F1=Help             F2=Refresh          F3=Cancel           F4=List
F5=Reset            F6=Command          F7=Edit             F8=Image
F9=Shell            F10=Exit            Enter=Do

Selectors
A select screen requires the user to choose a target, usually a device that will be used in the subsequent dialog screen. Selectors usually appear as a pop-up window, overlaying the text from the previous screen.

Listing 3. A SMIT select screen, requesting the selection of a single Logical Volume

 
                       LOGICAL VOLUME name                            
                                                                          
 Move cursor to desired item and press Enter. Use arrow keys to scroll.   
                                                                          
 [TOP]                                                                    
   fslv00            jfs        64    128   2    open/syncd    /ora-dat 
   fslv01            jfs        64    128   2    open/syncd    /u06     
   fslv02            jfs        64    128   2    open/syncd    /u07     
   lv07              jfs        11    22    2    open/syncd    /SUL_ora 
   paging05          paging     32    32    1    open/syncd    N/A      
   fslv05            jfs        320   640   4    open/syncd    /u08     
   fslv06            jfs        24    48    2    open/syncd    /w01     
   fslv07            jfs        16    32    4    open/syncd    /local/a 
   lv11              jfs2       128   128   1    open/syncd    /mkcd/mk 
   fslv09            jfs        128   256   2    open/syncd    /u02     
 [MORE...51]                                                            
                                                                        
 F1=Help               F2=Refresh              F3=Cancel                
 Esc+8=Image           Esc+0=Exit              Enter=Do                 
 /=Find                n=Find Next                                      

Command Status
The Command Status screen displays the output from the commands that SMIT executed. The top of the screen indicates the current status (Running, OK, or Failed), and it also shows whether there was anything written to STDOUT or STDERR.

Listing 4. A SMIT Command Status screen, displaying the output of the List Fileset Containing File

 
                           COMMAND STATUS

Command: OK            stdout: yes           stderr: no

Before command completion, additional instructions may appear below.

File                                  Fileset               Type
------------------------------------------------------------------
/usr/bin/smit                         bos.sysmgt.smit       File




F1=Help          F2=Refresh       F3=Cancel        Esc+6=Command
Esc+8=Image      Esc+9=Shell      Esc+0=Exit       /=Find 
n=Find Next                                                         

Navigation
Because of the hierarchal nature of SMIT's functions, it is fairly simple to drill down into the task you wish to accomplish. If you find that you've selected the wrong item from a menu, pressing F3 (or Esc + 3) brings you back to the previous screen.
Fast paths 
Every menu and dialog screen in SMIT has a fast path that can be used to go directly to that screen. To determine the fast path for a particular screen, navigate to that screen, and then press F8 or Esc + 8. A pop-up window lists the fast path and puts a print of the current screen into the SMIT log file.

Listing 5. A SMIT select screen, requesting the selection of a single Logical Volume

 
             PRINT SCREEN                 

 Press Enter to save the screen image              
     in the log file.                                
 Press Cancel to return to the application.      

   Current fast path:                           
       "mkuser"                                   

F1=Help          F2=Refresh       F3=Cancel    
Esc+8=Image      Esc+0=Exit       Enter=Do

Shortcuts
SMIT has several key commands that can be used to quickly navigate through long, scrolling screens of output. While most useful in Command Status screens, these keystrokes work in all screens (see Table 1).

Table 1. Key command for navigation

Keystroke	Action
Down arrow	Scroll down one line
Up arrow	Scroll up one line
Control + V (or PageDown)	Scroll down one page
Escape + V (or PageUp)	Scroll up one page
Escape + > (or End)	Jump to the bottom of the output or list
Escape + < (or Home)	Jump to the top of the output or list
Logging
Every SMIT session records entries in two files: smit.log and smit.script. These files will be written to the directory specified by the value of the HOME environment variable (not to the actual home directory for the user as specified in /etc/passwd.)

SMIT never overwrites existing log files; it always tries to append to those files if they exist and can be written to by the current user. If SMIT cannot write to those files, it displays a warning, but it continues to function without logging.

Note that while any user can run the SMIT executable, many of the AIX commands it runs to perform the tasks requested of it do require root or other restricted privileges. If a non-authorized user attempts to complete one of these tasks, the task fails. Since SMIT is most commonly run by root, the SMIT log files should be monitored and cleaned up so that they don't grow unmanageably large and consume all available space in the / filesystem.

smit.log

The smit.log file contains detailed information about activity performed using SMIT. For each SMIT session, it logs the date and time SMIT started, a record of every menu screen visited (along with that screen's fast path), all commands executed by SMIT, and any output from those commands.

Monitoring smit.log might be useful in determining what changes have been made to the system and when those changes were made. That log file will not have any indication of changes made by running system commands directly, however.

smit.script

The smit.script file contains the actual AIX commands that SMIT runs in order to execute a task. The file is written in Korn shell syntax, so it can be executed as is; doing so repeats all of the tasks originally done through SMIT.

One common use of the smit.script is to duplicate a number of tasks across several systems. If SMIT is used to make all of the changes to one system, the smit.script can be copied to the other systems and executed, performing all of the system changes without writing a single line of code.

An example using a SMIT script
Let's now apply SMIT to a real-world AIX example. Imagine a situation in which you need to add a four gigabyte file system on ten, or one hundred, AIX systems. You could do this manually, though your hands would probably be tired at the end, and repetitive typing increases the chance of an error. You could put together the proper command, with all of the arguments and flags, and then run that on each system. Or, you could let SMIT write that command for you.

In the below example, use SMIT to create a four gigabyte Enhanced JFS (JFS2) filesystem to be automatically mounted at system restart on the mount point /fs01, using an inline JFS log. Then, copy the script that SMIT writes to the other systems, and run it to create the file systems there.

The first step is to start SMIT, using the command: smit -s /tmp/mknewfs.ksh crjfs2std. The -s flag tells SMIT to write its script output to the file /tmp/mknewfs.ksh, instead of the default file /smit.script. The activity will still be logged into /smit.log. By specifying the fast path crjfs2std, you jump directly to the Add an Enhanced Journaled File System dialog screen. Before that screen (shown in Listing 6) is displayed, you will be required to choose a Volume Group in which to create the new file system.

Listing 6. The Add an Enhanced Journaled File System SMIT dialog screen

Add an Enhanced Journaled File System

Type or select values in entry fields.
Press Enter AFTER making all desired changes.

                                               [Entry Fields]
  Volume group name                          datavg
  SIZE of file system
          Unit Size                          Gigabytes    +
*         Number of units                   [4]           #
* MOUNT POINT                               [/fs01]
  Mount AUTOMATICALLY at system restart?     yes          +
  PERMISSIONS                                read/write   +
  Mount OPTIONS                             []            +
  Block Size (bytes)                         4096         +
  Inline Log?                                yes          +
  Inline Log size (MBytes)                  []            #
 
F1=Help          F2=Refresh       F3=Cancel      F4=List
F5=Reset         F6=Command       F7=Edit        F8=Image          
F9=Shell         F10=Exit         Enter=Do

After pressing Enter to have SMIT execute the commands above in Listing 6, the following script in Listing 7 will be written to the file /tmp/mknewfs.ksh.
Listing 7. /tmp/mknewfs.ksh.

#
#     [Sep 06 2006, 17:46:28]
#
x() {
LIST=
FLAG=0
for i in "$@"
do
        case "$i" in
        Megabytes)      FLAG=1;;
        Gigabytes)      FLAG=2;;
        512bytes)       ;;
        size=*) case "$FLAG" in
                1)      LIST="$LIST \"$i\"M"
                        FLAG=0;;
                2)      LIST="$LIST \"$i\"G"
                        FLAG=0;;
                0)      LIST="$LIST \"$i\""
                        ;;
                esac
                ;;
        *)      LIST="$LIST \"$i\""
                ;;
        esac
done
eval crfs -v jfs2 $LIST
}
x -g'datavg' 'Gigabytes' -a size='4' -m'/fs01' 
-A''`locale yesstr | awk -F: '{print $1}'`'' 
-p'rw' -a agblksize='4096' '-a logname=INLINE'

All that remains is to copy the above script to each of the remaining AIX systems, and to run it. There are numerous methods in which to do this. The simplest (though insecure) way to do this would be to loop through the systems, 'rcp'ing the script, and then use rsh to execute it (see Listing 8).

Listing 8. rcping the script and using rsh to execute it

For host in host1 host2 ... hostN; do \
rcp /tmp/mknewfs.ksh $host:/tmp/mknewfs.ksh ; \
rsh $host ksh /tmp/mknewfs.ksh ; \
done

This is just one example, but it illustrates the advantages and time savings of using SMIT as an AIX administrator.
Next steps
SMIT is a powerful tool for any AIX administrator. As with most tools, the best way to become familiar with its operation is to use it. It is important, though, to understand that SMIT does perform its actions on the live system, and there is no undo functionality. For some, but not all actions, SMIT issues a warning that it's going to permanently delete information, and it requires confirmation to continue.
A safer way to explore the SMIT application is by invoking it with the -x flag. When the -x flag is specified on the command line, SMIT appears to function normally, but it will not actually execute any commands. Instead, it writes to the smit.script file the commands it would have run under normal operation.
Many of the options and input fields on SMIT menu and dialog screens have a built-in help feature, accessible by using the arrow keys to highlight or select the item, and pressing F1 (or Esc + 1). If available, a detailed explanation of that item will be shown in apop-up window.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

j2restore:Restore your mistakenly deleted files in jfs2 file system
By Surya11:001 comment
Sometimes we mistakenly delete files under AIX.

In fact I do have such awkward experience that I run "rm foo *" although my intention is "rm foo*".
Now I want to provide my tool named j2restore which can help you if your deleted file is in a jfs2 file system.
# ./j2restore

Usage: j2restore [-r] [-i inode-number] [-v]
-r means report mode. It will report detail info for those deleted files under this file system and do nothing else.
-i inode-number means only restore/report the specific file whose inode number is inode-number
-v print j2restore version and author info file system name, for example:  /home, /dev/hd1, etc. 
Examples:
1. To restore all deleted files under /home, type:
 j2restore /home
2. To restore inode 81  under /usr, type:
 j2restore -i 81 /usr
3. To report what files are deleted under /dev/hd3, type:
  j2restore  -r /dev/hd3
Note:
1.  The fs must be unmounted before run j2restore.
2.  After restore files using j2restore, the fs will be corrupted unless you use "-r" option, so we must run "fsck -y  ".
     Then we will find the restored files under  lost+found directory.
3.  j2restore could not restore deleted files if their disk block is re-used by other file. So you'd better un-mount fs as soon as possible when you find some files are mistakenly deleted.
4.  Pls do not test this tool in your important system. I will take NO responsibility for any possible damage caused by j2restore.
5.  Pls give me recommendation or comment if you have any problem when you use j2restore.
Update: since v1.2 is available, I delete this old version)
Changelog:  version 1.1  2013-02-13

New function of v1.1:
Check disk blocks of deleted file.
If any block has been reused by other file,
j2restore will not restore it since it is not complete.        
Downloads: j2restore v1.3.2
New function of j2restore v1.3:
1. provide all possible directory and file name info for restored inodes.
2. restore partial over-written inodes, and report what blocks were over-written.
3. intelligently scan disk blocks thus j2restore can restore all un-overwritten inodes
4. support online restore(i.e, without umount)
For aix 5.3:
j2restore1.3.2    j2restorelist 1.3.2
For aix6.1/7.1:
j2restore 1.3.2   j2restorelist 1.3.2

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

KDB Commands
By Surya12:13No comments

KDB kernel debugger and kdb command

This artcile  describes the KDB kernel debugger and kdb command.
The KDB kernel debugger and the kdb command are the primary tools a developer or admin uses for debugging device drivers, kernel extensions, and the kernel itself.

KDB kernel debugger
The KDB kernel debugger is integrated into the kernel and allows full control of the system while a debugging session is in progress.
The KDB kernel debugger allows for traditional debugging tasks such as setting breakpoints and single-stepping through code.
kdb command
This command is implemented as an ordinary user-space program and is typically used for post-mortem analysis of a previously-crashed system by using a system dump file. The kdb command includes subcommands specific to the manipulation of system dumps.

Invoking the KDB kernel debugger:

Loading and starting the KDB kernel debugger:
The KDB kernel debugger must be loaded at boot time. This requires that a boot image be created with the debugger enabled. To enable the KDB kernel debugger, use either the -I or -D options of the bosboot command.

Examples of bosboot commands are as follows:

To disable the KDB kernel debugger, use the following command:
bosboot -a -d /dev/ipldevice

To enable the KDB kernel debugger, but not invoke it during system initialization, use the following command:
bosboot -a -d /dev/ipldevice -D

To enable the KDB kernel debugger, and invoke it during system initialization, use the following command:
bosboot -a -d /dev/ipldevice -I

Entering the KDB kernel debugger:
You can enter the KDB kernel debugger using several different procedures.

Enter the KDB kernel debugger using one of the following procedures:

  On a tty keyboard, press the Ctrl+4 key sequence for IBM® 3151 terminals or the Ctrl+\ key sequence for BQ 303, BQ 310C, and WYSE 50 terminals.
  On other keyboards, press the Ctrl+Alt+Numpad4 key sequence.
  Set a breakpoint using one of the Breakpoint and steps subcommands.


  Call the brkpoint subroutine from the C code. The syntax for calling this subroutine is the following:
  brkpoint();

You can use the kdb command with the dw subcommand to determine whether the KDB kernel debugger is available by typing the following:

     # kdb
     (0)> dw kdb_avail
     (0)> dw kdb_wanted
 
kdb command
The kdb command is an interactive utility for examining an operating system image or the running kernel. The kdb command interprets and formats control structures in the system and provides miscellaneous functions for examining a dump.

The SystemImageFile parameter specifies the file that contains the system image. The value can indicate a system dump, the name of a dump device, or the /dev/pmem special file. The default SystemImageFile is /dev/pmem.

The KernelFile parameter specifies the AIX® kernel that kdb will use to resolve kernel symbol definitions. A kernel file must be available. When examining a system dump it is imperative that the kernel file be the same as the kernel that was used to take the system dump. The default for the KernelFile is /unix.

The KernelModule parameters specify the file names of any additional kernel modules which the kdb command uses to resolve symbol definitions not found in the kernel file itself.

Root permissions are required for use of the kdb command on the active system. This is required because the special file /dev/pmem is used. To run the kdb command on the active system, type the following:

kdb

To invoke the kdb command on a system image file, type:

kdb SystemImageFile

Examples
The following examples demonstrate invocation options for the kdb command

To invoke the kdb command with the default system image and kernel image files, type:
kdb

The kdb program returns a (0)> prompt and waits for entry of a subcommand.

To invoke the kdb command using a dump file named /var/adm/ras/vmcore.0 and the UNIX kernel file named /unix, type:

kdb /var/adm/ras/vmcore.0 /unix
The kdb program returns a (0)> prompt and waits for entry of a subcommand.

Check VSCSI adapter mapping:

With the next command, we can find out which VHOST is mapped to which VSCSI in the VIOS level (show vscsi <–> vhost mappings).

Run on LPAR Client (not on VIO Server):

root@um_lpar: / # echo "cvai" | kdb | grep vscsi                        
 vscsi0 0x000008 0x0000000001 0x0 VIOa->vhost1
 vscsi1 0x000008 0x0000000002 0x0 VIOb->vhost1

Check NPIV adapter mapping

To check the connection between your VFCHOST and FC physical port in the VIOS level (show vfchost <–> fcs mappings).

Run on LPAR Client (not on VIO Server):

root@um_lpar: / # echo "vfcs" | kdb                                      
 NAME ADDRESS STATE HOST HOST_ADAP OPENED NUM_ACTIVE
 fcs0 0xF1000A000032C123 0x0008 VIO1 vfchost1 0x01 0x0000
 fcs1 0xF1000A000032D543 0x0008 VIO2 vfchost2 0x01 0x0000


To View  how many Vitrual Process are Active  
        #  echo "vpm" | kdb

To View Filesystem Details
       # echo vfs | kdb

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Listing mksysb image details

lsmksysb
There's a simple command to list information about a mksysb image, called lsmksysb:
# lsmksysb -lf mksysb.image
VOLUME GROUP:      rootvg
BACKUP DATE/TIME:  Mon Jun 6 04:00:06 MST 2011
UNAME INFO:        AIX testaix1 1 6 0008CB1A4C00
BACKUP OSLEVEL:    6.1.6.0
MAINTENANCE LEVEL: 6100-06
BACKUP SIZE (MB):  49920
SHRINK SIZE (MB):  17377
VG DATA ONLY:      no

rootvg:
LV NAME    TYPE     LPs  PPs  PVs  LV STATE      MOUNT POINT
hd5        boot     1    2    2    closed/syncd  N/A
hd6        paging   32   64   2    open/syncd    N/A
hd8        jfs2log  1    2    2    open/syncd    N/A
hd4        jfs2     8    16   2    open/syncd    /
hd2        jfs2     40   80   2    open/syncd    /usr
hd9var     jfs2     40   80   2    open/syncd    /var
hd3        jfs2     40   80   2    open/syncd    /tmp
hd1        jfs2     8    16   2    open/syncd    /home
hd10opt    jfs2     8    16   2    open/syncd    /opt
dumplv1    sysdump  16   16   1    open/syncd    N/A
dumplv2    sysdump  16   16   1    open/syncd    N/A
hd11admin  jfs2     1    2    2    open/syncd    /admin

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

How the login takes place in AIX?
You need to download and install putty to connect to the server if the server is remotely available. You need to mention the ip address, port number and connection type (telnet, SSH, rlogin etc) and connect to the server.




Once connected, the black session screen will appear/open up and will ask for user to login (settings available in /etc/security/login.cfg ).

Login sequence:
As the user enters the username and password, system verifies the same from /etc/passwd and/etc/security/passwd file.
If valid, the user is logged into the system else the user is asked to re-enter the username and password on every invalid entry (records a log entry in /etc/security/failedlogin).
Once logged in, the system setup user’s environment. This is available in /etc/environment, /etc/security/environment, /etc/security/user, /etc/security/limits.
It sometimes displays the “Message of the Day” configured by the administrator on login. This is available in /etc/motd? File.
Login shell will appear.
User’s profile (/etc/profile) will be setup and user will be placed in HOME directory.
Now the user can run any commands on the screen.

So the main steps for users to login are:

Login -> /etc/environment -> /etc/profile -> HOME directory

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

LPAR facts
By Surya13:21No comments
For initially configuring a P-Series system for installtion in LPAR mode, the system should be placed on Partion Stand-By mode

To list all the PCI slots allocated to an LPAR
 # lsslot -c pci
 # lsslot -c pci -a
To dynamically reallocate an adapter

Determine the PCI slot for the adapter using lsslot -c slot and get the "pciX' device name
Remove the device from AIX using rmdev -l pciX -R (-R to remove all the child to parent)
On HMC dynamically allocate the device to another
On the destination box, run 'cfgmgr' to configure the allocated device
The HMC itself can be rebooted by loging to HMC with SSH, as user hscroot, and issueing the command
 $ hmcshutdown -r -t0
To shutdown a LPAR
 chsysstate -r lpar -m MACHINE_NAME -o shutdown --immed --restart --id LPARID (or -n LPARNAME)
To findout which HMC an LPAR is connected
 # lsrsrc IBM.ManagementServer   (Name and Hostname are HMC's Name and hostname of HMC)       
 Resource Persistent Attributes for IBM.ManagementServer 
 resource 1:
        Name             = "10.253.1.22"
        Hostname         = "10.253.1.22"
        ManagerType      = "HMC"
        LocalHostname    = "10.253.1.54"
        ClusterTM        = "9078-160"
        ClusterSNum      = ""
        ActivePeerDomain = ""
        NodeNameList     = {"err3qdb0"}
 resource 2:
        Name             = "128.137.44.205"
        Hostname         = "128.137.44.205"
        ManagerType      = "HMC"
        LocalHostname    = "10.253.1.54"
        ClusterTM        = "9078-160"
        ClusterSNum      = ""
        ActivePeerDomain = ""
        NodeNameList     = {"err3qdb0"}
To disable/enable processor simultaneous multi-threading mode
 smtctl -m off

If dynamic LPAR is not working

Start rsct daemons if not already started
lssrc -a | grep rsct
startsrc -g rsct
Try re-booting HMC
Console Using HMC Command Line
vtmenu
vtmenu is a Perl script which displays a list of partitions, opening a virtual terminal on the one selected. If more than one managed systems exists, a list of them is displayed first. After a managed system is selected, a list of all logical partitions on that managed system is displayed. The vtmenu command does not accept any flags or parameters and ignores all that are specified.

Escape sequence to leave vtmenu terminal session is:

    ~. 
mkvterm: mkvterm opens a virtual terminal session for an AIX, Linux, or virtual I/O server partition
To open a console terminal:

  $ mkvterm -m <machine> -p <partition> 
This can be exited with ~~.

To remove a terminal someone else is using:
 $ rmvterm -m <machine> -p <partition> 
 # lsslot -c phb
 PHB Name  Description               Device(s)
 PHB 1     Logical PCI Host Bridge   pci0
           U7879.001.DQDGTGK-P1-T14  pci3 sisscsia0
           U7879.001.DQDGTGK-P1-T4   pci4 usbhc0 usbhc1
           U7879.001.DQDGTGK-P1-T6   pci5 ent0 ent1
 PHB 2     Logical PCI Host Bridge   pci1
           U7879.001.DQDGTGK-P1-C3   pci6 ent2 ent3
           U7879.001.DQDGTGK-P1-C4   pci7 ent4 ent5
           U7879.001.DQDGTGK-P1-C5   pci8 fcs0
 PHB 3     Logical PCI Host Bridge   pci2
           U7879.001.DQDGTGK-P1-T12  pci10 sisscsia1
           U7879.001.DQDGTGK-P1-T15  pci11 ide0
           U7879.001.DQDGTGK-P1-C1   pci12 fcs1
To list the system connections
 # lssysconff -r all 
lssysconn lists connection information for all of the systems and frames managed by this Hardware Management Console (HMC). Connection information for all systems and frames to which this HMC is connected or attempting to connect is listed.
ssysconn also lists IP addresses that cannot be automatically discovered by this HMC when using DHCP. If this HMC is set up as a DHCP server on a private network, whenever the Remove Connection task or the rmsysconn command is run to remove a managed system or a managed frame from the HMC, the HMC places the IP address(es) of that system or frame in a list of removed IP addresses. Any IP address in that list will not be rediscovered when reattached to the HMC. The lssysconn -r nondiscover command can be used to display the contents of that list of removed IP addresses.
To list All the managed systems attached to the HMC
 $ lssyscfg -r sys
 name=Server-9119-595-SN02898EB,type_model=9119-595,serial_num=02898EB,ipaddr=10.128.253
 ndary=10.128.255.252,state=Operating,sys_time=10/13/2006 20:15:55,power_off_policy=1,co
 cod_proc_capable=1,hca_capable=1,huge_page_mem_capable=unavailable,micro_lpar_capable=1
 ,5250_application_capable=0,redundant_err_path_reporting_capable=1,shared_eth_failover
 g_passing_capable=1,sp_failover_capable=1,vet_activation_capable=1,virtual_io_server_c
 250_cpw_percent=0,max_lpars=254,max_power_ctrl_lpars=1,service_lpar_id=3,service_lpar_n
 ...............................
 ...............................
 ,pend_mfg_default_boot_mode=norm,sp_failover_enabled=1,sp_failover_state=Ready
To list only name, Serial number, IP address and state alone,
 $ lssyscfg -r sys -F name,type_model,serial_num, ipaddr,state --header
 name,type_model,serial_num,ipaddr,state
 Server-9119-595-SN02898EB,9119-595,02898EB,10.128.253.255,Operating
 Server-9119-595-SN02898BB,9119-595,02898BB,10.128.255.250,Operating
To list all the Lpar in the managed system
 $ lssyscfg -r lpar -m Server-9119-595-SN02898EB
lssyscfg -r lpar -m Server-9119-595-SN02898EB
name=eraprci0,lpar_id=8,lpar_env=aixlinux,state=Running,resource_config=1,os_version=0.
0.0.0.0.0,logical_serial_num=02898EB8,default_profile=eraprci0,curr_profile=eraprci0,
work_group_id=none,shared_proc_pool_util_auth=0,power_ctrl_lpar_ids=none,boot_mode=norm,
lpar_keylock=norm,auto_start=0,redundant_err_path_reporting=0

name=eraptci0,lpar_id=7,lpar_env=aixlinux,state=Running,resource_config=1,os_version=0.
0.0.0.0.0,logical_serial_num=02898EB7,default_profile=eraptci0,curr_profile=eraptci0,
work_group_id=none,shared_proc_pool_util_auth=0,power_ctrl_lpar_ids=none,boot_mode=norm,
lpar_keylock=norm,auto_start=0,redundant_err_path_reporting=0

name=erep2ci0,lpar_id=6,lpar_env=aixlinux,state=Running,resource_config=1,os_version=0.
0.0.0.0.0,logical_serial_num=02898EB6,default_profile=erep2ci0,curr_profile=erep2ci0,
work_group_id=none,shared_proc_pool_util_auth=0,power_ctrl_lpar_ids=none,boot_mode=norm,
lpar_keylock=norm,auto_start=0,redundant_err_path_reporting=0

 $ lssyscfg -r lpar -m Server-9119-595-SN02898EB  -Fname,curr_profile,state
 eraprci0,eraprci0,Running
 eraptci0,eraptci0,Running
 erep2ci0,erep2ci0,Running

 lshwres -r mem --level sys                           
 configurable_sys_mem=32768,curr_avail_sys_mem=30208,pend_avail_sys_mem=30208,installed_sys_mem=32768,deconfig_sys_mem=0,sys_firmware_mem=512,
 mem_region_size=128,pend_mem_region_size=128,"possible_mem_region_sizes=auto,16,32,64,128,256",auto_mem_region_size=128,max_mem_pools=0,
 max_paging_vios_per_mem_pool=1
Upgrading the machine code on HMC
01. Backup the managed system's profile data
 Server and Partition --> Server Management --> Profile data --> Backup 
 Type the filename and save the information. Do this for each Managed system.
02. Backup critical console information so that previous levels can be restored in the event of a problem while upgrading the software. Do not use this critical console data after a successful upgrade to a new version of the HMC software. We can backup the console data in DVD-RAM media
03. Record the current HMC configuration

04. Save upgrade data. You can save the current HMC configuration in a designated disk partition on the HMC. Only save upgrade data immediately prior to upgrading your HMC software to a new release. This action allows you to restore HMC configuration settings after upgrading
 HMC Code update --> Save Upgrade Data --> Save on Hard Drive --> Finish
05. Upgrade HMC Software
 HMC Management --> Shutdown or Restart HMC --> Restart HMC 
After HMC restarts, in the login screen, select
 upgrade --> upgrade from Media -- Finish


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

lsof - List open files
By Surya23:47No comments
This lists information about files opened by processes. It is great, especially when you are troubleshooting an issue and need more information about process or connection details. Linux treats most everything as a file. An open file may be a regular file, a directory, a block special file, a character special file, an executing text reference, a library, a stream or a network file (Internet socket, NFS file or UNIX domain socket.) A specific file or all the files in a file system may be selected by path. When a process or application interacts with these files it has to "open" them. Using this command you can dig into and see what your process is doing.

To show all the open TCP files - This will give you what service is running, who is running it, the process ID and the connections on all TCP ports:

# lsof -i TCP
Show open files or programs that is running on TCP port 80

# lsof -i TCP:80
COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME
httpd 21867 root 3u IPv4 98670393 TCP *:http (LISTEN)
httpd 21891 apache 3u IPv4 98670393 TCP *:http (LISTEN)
httpd 21892 apache 3u IPv4 98670393 TCP *:http (LISTEN)
httpd 21893 apache 3u IPv4 98670393 TCP *:http (LISTEN)
httpd 21894 apache 3u IPv4 98670393 TCP *:http (LISTEN)
httpd 21895 apache 3u IPv4 98670393 TCP *:http (LISTEN)
httpd 21896 apache 3u IPv4 98670393 TCP *:http (LISTEN)
To list which user is actively using /tmp/

# lsof /tmp/ COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME
bash 4756 root cwd DIR 8,2 36864 212577 /tmp/


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Managing Disks and File Systems on AIX


Determine the size and type of disks, change a file system size, or add or remove a VG. It's all right here for you.

Managing disk or data storage is a common task for system administrators. As data grows on the disks or file systems, you have to expand the storage area. In some cases, you have to reduce storage from one area and give it to another data area. To be able to do this, you must understand the information presented to you when you run any commands related to disk or file system data.

In this article, I will cover how to determine the type of disks being used and the size of the disks. I will also demonstrate how to add a disk to or remove a disk from a Volume Group (VG). File systems that are contained in the VGs can also be increased or reduced in their size; this will be demonstrated as well.

Assume a couple of new disks have been added to the AIX system. To bring the disks in (and by that I mean to ensure that AIX recognizes each disk and adds it to its internal Object Database Manager (ODM), use this command:
# cfgmgr
The disks will now be presented as shown below. Use the lspv command to view the disks:

# lspv
hdisk0         00c23bed42b3aefe                   rootvg         active
hdisk1         00c23bed42b3afff                   rootvg         active
hdisk2         00525c6a888e32cd                   None
hdisk3         00c23bed32883598                   None
WHAT TYPE OF DISK IS PRESENT
In this example, the new disks come in as hdisk2 and hdisk3. New disks will not necessarily come in sequential order. This is particularly true if the disks use disk slots and you do not populate them one after the other. Notice that the new disks have not yet been assigned to a VG, so the third column states None. We can tell what sort of disk each is by querying the ODM using the lsdev command:
# lsdev -Cc disk
hdisk0 Available 04-08-00-3,0 16 Bit LVD SCSI Disk Drive
hdisk1 Available 04-08-00-4,0 16 Bit LVD SCSI Disk Drive
hdisk2 Available 04-08-00-5,0 16 Bit LVD SCSI Disk Drive
hdisk3 Available 04-08-00-8,0 16 Bit LVD SCSI Disk Drive
The new disks are SCSI disks as are the others.
DISK SIZES: HOW TO TELL
Let's now determine the size of the disks. There are a few methods you can use to see the disk size. Let's look at the most common methods. First, we'll use the lsattr command, which returns device information on the system. The format of the command is this:
lsattr -El < device>
# lsattr -El hdisk2
PCM             PCM/friend/scsiscsd               Path Control Module
False
algorithm       fail_over                        Algorithm
True
…
…
size_in_mb     18200                             Size in Megabytes
False
unique_id       21080006CB0A0AST318305LC03IBMscsi Unique device identifier
False
The above lsattr output states that the disk is 18200 MB or 17.7 GB.
You can also use the undocumented command bootinfo. Though this is discouraged by IBM, it will return the usable amount of disk that can be used by the system after formatting. Here's the format of the command:
bootinfo -s <device>
# bootinfo -s hdisk2
17357
The above output states we have a 17357 MB disk or 16.9 GB.
The best and recommended way to determine the size of a disk is to use the getconf command. The getconf will extract the systemwide variables from the kernel. Here's the format:
getconf DISK_SIZE <path_to_device>
# getconf DISK_SIZE /dev/hdisk2
17357
In the above output, the getconf returns 17357MB or 16.9 GB.
We have used three commands to get the disk sizes. Two of them agree on the size. Not bad, I guess. To get the correct disk size, use getconf, as this comes from the kernel, the heart of the AIX system.
CREATING A VOLUME GROUP
For a disk to be used for storage, it needs to be added to an existing VG or a new VG. Let's first add it to a new VG called testvg. The format for the command I am now going to run is this:
mkvg -B -y <vg_name> <hdiska, hdiskb,..., hdiskn>
here, -B means it should be a big VG. It will be able to have up to 128 disks if required in the VG. The vg_name is the name you are going to call it, followed by a list of hdisks you wish to assign to the VG. Here is the command:
# mkvg -B -y testvg hdisk2
testvg
Viewing the current VGs on the system, we can see that it is present.
# lsvg
rootvg
holdvg
testvg
You can see that hdisk2 is now assigned to the VG testvg. Use the lspv command to confirm:
# lspv
hdisk0         00c23bed42b3aefe                   rootvg         active
hdisk1         00c23bed42b3afff                   rootvg        active
hdisk2         00525c6a888e32cd                   testvg         active
hdisk3         00c23bed32883598                   None
You can also query the disks contained in a VG by issuing the lsvg command:
# lsvg -p testvg
testvg:
PV_NAME           PV STATE         TOTAL PPs   FREE PPs   FREE DISTRIBUTION
hdisk2           active           542         542         109..108..108..108..109
VOLUME GROUP MAINTENANCE
Let's now add another disk, hdisk3 to the volume group testvg. First, though, determine the disk size:
# getconf DISK_SIZE /dev/hdisk3
70006
It's 70 GB or thereabouts. Now, let's add the disk to the existing VG testvg, using the extendvg comamnd. The format for the command I am now going to run is this:
extendvg <vg_name>   <hdiska, hdiskb,..., hdiskn>
Here, vg_name is the name of the VG, followed by a list of hdisks you wish to add to the VG. Here's the command:
# extendvg testvg hdisk3
Now let's view the disks and to see what VG is assigned to them. The following output states that hdisk2 and hdisk3 are assigned to the VG testvg:
# lspv
hdisk0         00c23bed42b3aefe                   rootvg         active
hdisk1         00c23bed42b3afff                   rootvg         active
hdisk2         00525c6a888e32cd                   testvg         active
hdisk3         00c23bed32883598                   testvg         active
Now that we've added the extra disk, let's get the size of the VG. In the following output, we can determine the size of the VG by locating the TOTAL PP value (total number of physical partitions on the disks). In this example, it's 87328 MB or 85.2 GB.
# lsvg testvg
VOLUME GROUP:       testvg                   VG IDENTIFIER: 00c23bed00004c00000
0013805b7d417
VG STATE:               active             PP SIZE:       32 megabyte(s)
VG PERMISSION:     read/write               TOTAL PPs:     2729 (87328 megabytes
To calculate the size of the VG, you can also use the following formula, using the values from the above lsvg command:
PP SIZE * TOTAL PP
Like so:
# expr 2729 \* 32
87328
To remove a disk from a VG, first be sure you have removed all data from that disk. You will be warned if there is data on the disk and you try to remove it, which is a good reminder in my books.
Typically, you would unmount any file systems and remove them using the rmfs command on the disk you want to remove. Alternatively, you could use migratepv to literally migrate the data from that disk to another disk contained in that VG. Let's assume all data has been removed from that disk. To remove a hdisk from a VG, use the reducevg command. The format for this example is this:
reducevg <vg_name> <hdiska, hdiskb,..., hdiskn>
Here, the vg_name is the name of the VG, followed by a list of hdisks you wish to remove from the VG. Here's the command:
# reducevg testvg hdisk2
The VG testvg now has only hdisk3 assigned to it:
# lsvg -p testvg
testvg:
PV_NAME           PV STATE         TOTAL PPs  FREE PPs   FREE DISTRIBUTION
hdisk3           active           2187       1866       438..116..437..437..438
DYNAMICALLY CHANGING FILE SYSTEM SIZES
In our VG, we also now have some data. A file system called /data_fs is present with a size of 8 GB. The file system has data residing in it; it's 71% used and has only 2.38 GB of free space left:
# df -g
Filesystem   GB blocks     Free %Used   Iused %Iused Mounted on
….
….
/dev/fslv00       8.00     2.38   71%       27     1% /data_fs
That file is getting pretty full, so let's now increase that file system to 12G. The format for increasing or decreasing a file system in GB or MB increments in this example is this:
chfs -a size=<size_in_units_of_gigabyte|megabyte M|G> /file_filesystem
So to increase the file system from 8 GB to 12 GB, I could use this:
# chfs -a size=12G /data_fs
Filesystem size changed to 25165824
Looking at the newly change file system size, we see the change:
# df -g| grep data_fs
Filesystem   GB blocks     Free %Used   Iused %Iused Mounted on
…
...
/dev/fslv00       12.00     6.38   47%       27     1% /data_fs
Now suppose we wanted to reduce the file system size by 2G, so the new size would be 10G. We could use this:
# chfs -a size=10G /data_fs
Filesystem size changed to 20971520
Let's view the new file system size:
# df -g| grep data_fs
Filesystem   GB blocks     Free %Used   Iused %Iused Mounted on
..
...
/dev/fslv00       10.00     4.38   57%       27     1% /data_fs

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Migrate Data using mirroring to migrate data


You can use the logical volume manager (LVM) mirroring function to migrate data from one logical volume to another (the LVM mirroring function cannot migrate data between physical volumes).
Procedure
Identify the data that you want to migrate from one volume to another.
Use the mklvcopy command to migrate data from one logical volume to another.
Results
When the command completes processing, a mirrored copy of the logical volume is created.
Example
Mirroring is an LVM task that you perform only on logical volumes to migrate data. The following example shows how to create a mirror copy of a logical volume using the mklvcopy command:
# mklvcopy -e m -s y -k datalv 2 hdisk3 hdisk7
 .
 .
 .
# splitlvcopy -y splitlv datalv 1
The mklvcopy command options specify the following values:

(-e m) ==> To use minimum inter-disk allocation policy
(-s y) ==> To strictly allocate mirror copies on separate physical volumes
(-k) ==> To synchronize new copies immediately
datalv ==> The name of the logical volume where you want to start a mirroring operation
2 ==> The number of copies that you want to make of the data (a maximum of 3)
hdisk3 and hdisk7 ==> The physical volumes where the logical volume resides
hdisk3 ==> The physical volume that already holds the data of logical volume datalv.
hdisk7 ==> The physical volume that will hold the mirror copy and where you want to move the data

The second example is like example 1. The mklvcopy command starts mirroring the infxlv logical volume.
# mklvcopy -e m -s y -k infxlv 2 hdisk4 hdisk10
 .
 .
 .
# rmlvcopy infxlv 1 hdisk4
In this example, logical volume infxlv is initially located on physical volume hdisk4 and the mirrored copy resides on physical volumehdisk10. When the operation is complete, this is new location of the logical volume.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Migrate data using the direct copy method

Sometimes you must use the direct copy method to migrate data. This method uses the logical volume manager, which utilizes the UNIX find and cpio commands.
About this task
The find command generates the list of files that are to be migrated. The cpio command migrates the files that are on the list. The example below assumes that you created a file system on the /dev/lv00 logical volume. AIX LVM uses this file system to view part or all the virtual disks that the storage unit has made available to the system.
Procedure
Mount the logical volume on a temporary mount point (/mnt in the example).
Change directories to the directory at the top of the file system that you want to move (cd/data in the example).
Issue the find command to produce a list of file names, which a pipe (|) passes as standard output to the standard input of the cpiocommand.
Unmount both file systems and mount the new file system over the original mount point directory when the migration is complete.
Example
# mount /dev/lv00 /mnt
# cd /data
#print | cpio -pdmuv /mnt . . .
# find . -
# umount /mnt
# umount /data
# mount /dev/lv00 /data
What to do next
You might be unable to use the volume management methods if the database uses volume serial numbers in its licensing code or uses validity checking. In either of these cases, you might be limited to exporting the database from its old locations or importing the database to its new location.

The database software provides the mechanism to move the data. This can take the form of a standard database backup and restore if it does not have any specific tools for moving data.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Migrate data using the migratepv command
By Surya11:582 comments
You can use the logical volume manager (LVM) migratepv command to migrate data that is located on physical volumes. Because you can use this command while the system is active, users are not disrupted.
About this task
The migratepv command moves allocated physical partitions and the data they contain from the source physical volume to one or more destination physical volumes and has the following syntax: migratepv [ -lv LogicalVolume] SourcePhysicalVolumeDestinationPhysicalVolume. The specified physical volumes must all be in the same volume group. The specified source physical volume cannot be included in the list of destination physical volume parameters.

The migratepv command migrates data by performing these actions:
Creates a mirror of the logical volumes that you are moving
Synchronizes the logical volumes
Removes the original logical volume
Procedure
Identify the source disk that contains the data and its volume group.
# lsdev -Cc disk
hdisk0    Available 04-08-00-8,0 16 Bit LVD SCSI Disk Drive  <== choose hdisk0 as source disk
hdisk1    Available 04-08-01-8,0 16 Bit LVD SCSI Disk Drive
hdisk2    Available 06-09-02     IBM FC 2107
Calculate the amount of space that is currently in use on the disk. This is the total number of physical partitions (PPs) minus the number of free partitions on the disk. In the following example, disk hdisk0 is a member of the rootvg volume group and is using 279 PPs (542 - 263 = 279).
# lsvg -p rootvg
rootvg:
PV_NAME           PV STATE          TOTAL PPs   FREE PPs    FREE DISTRIBUTION
hdisk0            active            542         263         78..00..00..76..109
Identify destination disk or disks that have enough empty space to accommodate the copied data. If the destination disk or disks are not in same volume group as the source disk, add the destination disk to the source disk volume group using the extendvg command, for example, extendvg rootvg hdisk1. In the following example, disks hdisk0 and hdisk1 are in same volume group and destination disk hdisk1 has 542 free PPs, which is more than the 279 PPs that are required.
# lsvg -p rootvg;date
rootvg:
PV_NAME           PV STATE          TOTAL PPs   FREE PPs    FREE DISTRIBUTION
hdisk0            active            542         263         78..00..00..76..109
hdisk1            active            542         542         109..108..108..108..109
You must verify whether the volume group boot image is located on the physical volume that you are moving. You must first Identify the name of the logical volume that contains the boot image. Issue the lsvg -l rootvg command to identify the name of the logical volume that contains the volume group boot image. In this example, partial output listing for the lsvg -l rootvg command shows that for the rootvg volume group, logical volume hd5 has the type boot.
LV NAME    TYPE   Ps   PPs  PVs  LV STATE        MOUNT POINT 
hd5        boot   1    1    1    closed/syncd    N/A 
Issue the lslv -l command. to determine whether the boot image is on the source disk. The following example displays the output generated by the lslv -l command. In this case, logical hd5 is located on disk hdisk0, which is the source disk.
# lslv -l hd5 
   hd5:N/A 
   PV          COPIES         IN BAND       DISTRIBUTION 
   hdisk0      001:000:000    100%          001:000:000:000:000
If the source disk contains the boot image, complete these sub-steps to transfer that boot image to the destination disk.
Issue migratepv -lv hd5 hdisk0 hdisk1 to move the physical partitions in logical volume hd5 that contain the boot image from source disk hdisk0 to destination disk hdisk1.
Issue chpv -c hdisk0 as root user to delete the boot record from the source disk to avoid a potential boot from the old boot image.
Issue the bosboot command to establish disk hdisk1 as the new boot disk.
Issue the bootlist command to designate disk hdisk1, which now contains the boot image, as the boot disk in the boot list.
# migratepv -l hd5 hdisk0 hdisk1
0516-1011 migratepv: Logical volume hd5 is labeled as a boot logical volume.
0516-1246 migratepv: If hd5 is the boot logical volume, please run 'chpv -c hdisk0'
        as root user to clear the boot record and avoid a potential boot
        off an old boot image that may reside on the disk from which this
        logical volume is moved/removed.
migratepv: boot logical volume hd5 migrated. Please remember to run
        bosboot, specifying /dev/hdisk1 as the target physical boot device.
        Also, run bootlist command to modify bootlist to include /dev/hdisk1.

<<< the following commands taken based on the warning after migrated the boot device 

# chpv -c hdisk0
# echo $?
0

# bosboot -ad /dev/hdisk1

bosboot: Boot image is 49180 512 byte blocks.
# echo $?
0


# bootlist -m normal -o hdisk1
hdisk1 blv=hd5 pathid=0
Issue the migratepv command to migrate the data from one physical volume to another. Subsequently, you can issue the lsvg -pcommand to verify the results. In this example, after the migration is complete, volume hdisk0 shows 0 PPs because all data that was previously located on physical volume hdisk0 has been moved to physical volume hdisk1.
# migratepv hdisk0 hdisk1
# echo $?
0

# lsvg -p rootvg
rootvg:
PV_NAME           PV STATE          TOTAL PPs   FREE PPs    FREE DISTRIBUTION
hdisk0            active            542         542         109..108..108..108..109
hdisk1            active            542         263         30..15..01..108..109
After the operation completes, issue the reducevg command to remove the source physical volume from the volume group. In this example, remove physical volume hdisk0 from volume group rootvg.
# reducevg rootvg hdisk0
# echo $?
0

# lsvg -p rootvg
rootvg:
PV_NAME           PV STATE          TOTAL PPs   FREE PPs    FREE DISTRIBUTION
hdisk1            active            542         263         30..15..01..108..109
Results
After processing is complete, the physical volume is copied to the new location and the LVM no longer accesses the original volume to locate the data that was stored there.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Migrating data

Migrating data
Copying filesystems
Introduction
Migrating or moving data is a common task. Whether it is copying data across the network to a new filesystem, or copying logical volumes within the same volume group or to a different volume group or maybe just creating a backup of a filesystem. The reasons for moving or copying data could be for performance issues, or general growth of data where there is not enough space in its current environment. There are different tools that can be used for the above-mentioned data movement tasks, such as migratepv, cplv, tar, cpio, cp or rsync. For jfs, you can use splitcopy or, for jfs2, use snapshot to take a copy of a filesystem. There is no golden rule on what method would best suit a certain data movement. In this article, I demonstrate different methods to move or copy data at a filesystem and logical volume level focusing on the following AIX utilities: cplv, tar, and cp.
Using tar and cp to copy data to a new filesystem
When applying updates to an application filesystem, a backup would be taken first, most probably to tape. However if space allows, a copy of the filesystem where the application resides can also be carried out. The advantage of this is that it allows a quick recovery. By swapping over the mount points, it is also advantageous because you can quickly compare the upgraded files to the original ones. Lets assume a filesystem called /opt/pluto holds an application that is to be upgraded:
# df -g
…
/dev/fslv00        1.00      0.03   97%       22     1% /opt/pluto
Let's look at three ways we could copy the application files across to another filesystem, using cp, tar, and cplv.

First, the backup (copied) filesystem needs to be created. This is carried out using the crfs command, making sure it is the same filesystem type and at least the same size. The current /Pluto filesystem is 1G in size and is of jfs2 type. The new filesystem is called /opt/pluto_bak. The following command achieves this:
# crfs -v jfs2 -g rootvg -m /opt/pluto_bak -A yes -p rw -a agblksize=40
96 -a size=1G
File system created successfully.
524068 kilobytes total disk space.
New File System size is 1048576
In the example the input parameters mean the following:
-v jfs2	Specifies a jfs2 filesystem type.
-g rootvg	Creates the filesystem rootvg
-m /opt/pluto_bak	Specifies the actual mount point.
-A yes	Specifies that the filesystem is mounted automatically upon a reboot.
-p rw	Specifies read write permissions
-a agblksize=4096	Specifies the block size in bytes
-a size=1G	Specifies the size of the filesystem to be created at, in this example it is 1GB.
Next, mount the filesystem /opt/pluto_bak:
# mount /opt/pluto_bak
After creating a filesystem, do not forget to apply the correct ownership and permissions on the mount point of the filesystem, if required.

Now using the cp command, making sure we copy the permissions/modifications and any symbolic links, we use the Rph flags.

The following cp command copies all files and symbolic links (if any) from /opt/pluto to /opt/pluto_bak:
# cd /opt/pluto
# pwd
/opt/pluto
# cp -Rph * /opt/pluto_bak
Be sure to test that the copy was done correctly by listing the number of files and running du of both the original and copied filesystem. For /opt/pluto, we have:
# pwd
/opt/pluto
# du -ms .
988.46  .
# ls |wc
      17      17     146
For /opt/pluto_bak, we have:
# cd ../pluto_bak
# ls |wc
      17      17     146
# du -ms .
988.46  .
All of the previous outputs match up from the original to the copied filesystem, so all went OK (the copy completed successfully).

Now we will do the same operation again, but this time using the tar utility.

Using tar is generally quicker when dealing with lots of smaller files. If your files are greater than 2GB, then be sure to use the GNU tar utility.
# cd /opt/pluto
# pwd
/opt/pluto
# tar cpf - . | (cd /opt/pluto_bak; tar xpf - )
In the previous output, tar creates the archives with the modifications times/permissions from the current directory; tar archives this to standard output. The output is then piped thru to a sub-shell, then cd to /opt/pluto_bak and then untar (extract) from standard output into the /opt/pluto_bak filesystem.

As before, be sure to check the original and copied filesystem on the total size and the number of files match up.

If you wish to see the files being archived and extracted, add the verbose (v) option:
# cd /opt/pluto
# tar cvpf - . | (cd /opt/pluto_bak; tar xvpf - )
a .
a ./lost+found
a ./myfile.dat 0 blocks.
a ./pop 1 blocks.
a ./test100M.bin 195313 blocks.
x .
x ./lost+found
x ./myfile.dat, 0 bytes, 0 media blocks.
x ./pop, 139 bytes, 1 media blocks.
x ./test100M.bin, 100000000 bytes, 195313 media blocks.
a ./myfile1 195313 blocks.
x ./myfile1, 100000000 bytes, 195313 media blocks.
a ./mprep 195313 blocks.
x ./mprep, 100000000 bytes, 195313 media blocks.
a ./chklp 195313 blocks.
x ./chklp, 100000000 bytes, 195313 media blocks.
a ./poplt 195313 blocks.
x ./poplt, 100000000 bytes, 195313 media blocks.
…..
…..
Using tar to copy data to a remote filesystem
You can also use tar to copy data across the network, although scp will do the job. I generally prefer to use tar, for filesystem copies. To tar across the network use ssh as the transport method. You could use rsh, but I recommend not to because of the security flaws it opens.

Assume we wish to copy data from /opt/pluto on the local host to the remote host nordkapp filesystem /opt/pluto, I could use:
# cd /opt/pluto
# tar -cpf - . | ssh nordkapp (cd /opt/pluto; tar -xpf -)
As can be seen from this example, there is not much difference in the tar command between copy/restore locally and copy/restore remotely. The previous assumes that the ssh keys have been exchanged to allow password-less connection/login.
Copying a logical volume within a volume group
Using cplv is quite slower than using cp or tar when dealing with smaller filesystems. Another option to consider is that cplv copies the entire lv across, where tar and cp only need to copy the files across. As a general rule of thumb, I would use cplv if the filesystem is greater than 10 GB.

In the following example, we are going to copy the logical volume that resides under /opt/pluto, which is called fslv00 to the copied filesystem logical volume, fslv01. The cplv command overwrites the current contents of fslv01, which is what we want. Notice in this example, the filesystem /opt/pluto_bak has been created as demonstrated earlier; there is no data in that file system at the moment. This can be seen by the output of the df command:
# df -g
…..
/dev/fslv00   1.00      0.03   97%       22     1% /opt/pluto
/dev/fslv01   1.00      1.00    1%        4     1% /opt/pluto_bak
The first thing to do is unmount both filesystems. Unlike tar and cp, cplv cannot be carried out with the filesystems online:
# umount /opt/pluto
# umount /opt/pluto_bak
If the filesystem reports it cannot unmount, because it is busy, check to ensure that the application is closed. Then determine which processes are keeping the filesystem from un-mouting; use fuser:
# fuser -u <filesystem>
For example:
     # fuser -u /opt/pluto
If you decide you wish to kill all processes on that filesystem, use:
# fuser -k <filesystem>
Next, use the cplv command. In this instance, we are going to copy the logical volume fslv00, which overwrites the existing destination logical volume (fslv01). The basic format for this demonstration is:
cplv -e < dest lv>  -f  <source lv>
Where:
-e	Copies the logical volume contents to an existing logical volume
>dest lv	Specifies the destination logical volume, in this example it will be fslv01
source lv	Specifies the source logical volume, in this example it will be fslv00
As we are overwriting another logical volume, make sure that the destination logical volume has the logical volume type set to copy instead of jfs2 (in the logical volume attributes). If not, the command fails and you are warned that you need to change it. To check the TYPE, run the following lslv command against the destination lv:
# lslv fslv01 |grep TYPE
TYPE:          jfs2                 WRITE VERIFY:   off
From the previous output, we see that the destination logical volume is set to jfs2. Now set it to copy and run the lslv command to ensure that is set:
# chlv -t copy fslv01
# lslv fslv01 |grep TYPE
TYPE:          copy                 WRITE VERIFY:   off
Now that it is set to copy, we can copy the logical volume:
 # cplv -e fslv01 -f fslv00
cplv: Logical volume fslv00 successfully copied to fslv01 .
From this output, we see that the copy was successful, once the cplv command has completed the logical volume type that has been reset back to: jfs2. Let's verify that:
 # lslv fslv01 |grep TYPE
TYPE:            jfs2                WRITE VERIFY:   off
All is good. Now, mount the filesystems:
# mount /opt/pluto
# mount /opt/pluto_bak
# df -g
….
/dev/fslv00    1.00      0.03   97%       22     1% /opt/pluto
/dev/fslv01    1.00      0.03   97%       22     1% /opt/pluto_bak
The filesystem /opt/pluto has now been copied to /opt/pluto_bak using the cplv command. Be sure to compare size and file count on the copied filesystem, as before.

If during an application upgrade events go wrong, the application is unusable, you have no choice but to restore out. However, as in this demonstration, we have made a copy of the filesystem, so all that we need to do is to swap over the bad application filesystem to the good one. Swapping the filesystems over is quicker than restoring from tape, and you also have a copy of the failed upgraded filesystem for further diagnostics.

In the following example, assume we wish to swap (by that I mean change the mount point) from /opt/pluto_bak to /opt/pluto. First, we have to change the mount point of /opt/pluto to /opt/pluto_err. This is done so that there is no naming conflicts when we change /opt/pluto_bak to /opt/pluto. Changing the mount point of a filesystem is accomplished using the chfs command. Be sure to have the filesystems unmounted first. The basic format is:
chfs -m <new mount point> <original mount point>
To confirm, change mount point of /opt/pluto to /opt/pluto_err and change the mount point of /opt/pluto_bak to /opt/pluto:
#  chfs -m /opt/pluto_err /opt/pluto
Now we have changed the mount point of /opt/pluto to /opt/pluto_err we can now change /opt/pluto_bak to /opt/pluto:
# chfs -m /opt/pluto /opt/pluto_bak
Next, mount the filesystems:
# mount /opt/pluto_err
# mount /opt/pluto
The application is now usable. The failed application now resides on /opt/pluto_err, which has also been mounted. This allows further investigation since the application filesystems are now both mounted, and as such, a comparison can now be carried out.
Copying a logical volume to a different volume group
Copying a filesystem data to a different volume group can be done using tar, cp, or cplv. In the this section I am using cplv. The cplv procedure is similar to previous demonstrations. The only difference is, instead of the target filesystem residing in the same volume group, it would be created in a different volume group. When copying to a different volume group the logical volume device (and maybe the log device) attributes in /etc/filesystems have to be changed, so AIX knows where to look for the filesystem when a request to mount it is made.

Let's look at how to copy a logical volume to a different volume group. The steps involved are:
Unmount the /opt/pluto filesystem.
Copy the logical volume that /opt/pluto resides on, (fslv00). With the copy command, parse it to the new logical volume, pluto_lv.
If this is a new volume group, create a new jfs2log and format it. Otherwise, use the existing jfs2log that resides on that volume group.
Edit /etc/filesystems to point /opt/pluto's dev and log device to the correct devices that now reside on that volume group.
Mount the /opt/pluto filesystem on the newly copied logical volume, pluto_lv.
Sanity check the newly mounted filesystem.
Unmount the filesystem and fsck and re-mount it.
Using our /opt/pluto filesystem, assume we wish to copy the logical volume fslv00 from rootvg to a different volume group, apps_vg. And the logical volume should be renamed to pluto_lv.

The basic format of the cplv command for this demonstration is:
cplv -v <dest vg> -y <new lv name> source _lv
Where:
-v <dest vg>	is the destination volume group, in this example it is apps-vg
-y <new lv name>	is the destination logical volume name, in this example is pluto_lv
So the first task is to unmount the filesystem we wish to copy, so that we can access the logical volume.
# umount /opt/pluto
Using the lsvg command, we see that the filesystem is closed:
# lsvg -l rootvg
…
fslv00              jfs2       64      64      1    closed/syncd  /opt/pluto
Now do the copy:
#  cplv -v apps_vg -y pluto_lv fslv00
cplv: Logical volume fslv00 successfully copied to pluto_lv .
Now that it is copied, verify with the lsvg command:
 # lsvg -l apps_vg
apps_vg:
LV NAME     TYPE       LPs     PPs     PVs  LV STATE      MOUNT POINT
pluto_lv    jfs2       128     128     1    closed/syncd  N/A
From the previous output, we see that the logical volume fslv00 has been copied to the volume group apps_vg and the logical volume is renamed to pluto_lv. However, also notice that there is no JFS (journaled file system) jfs2log entry. This occurs if you are copying logical volumes to an empty volume group.
If there is already a jfs2log on the volume group, then your copied filesystem can use that one, there is no need to create a new jfs2log.

To create the jfs2log use the mklv command. The basic format of the mklv command for this demonstration is:
mklv -t <type> -y <new lv_name> vg_name <number of LPs>
Where:
-t <type>	Specifies the logical volume type. in this case, it is jfs2log.
-y <new lv name>	Specifies the destination logical volume name. In this example, it is jfs2log_lv.
vg_name :	Indicates the volume group name where the jfs2log is to reside. In this example, it is apps_vg.
Number of LPs	The number of logical partitions; in this case, one partition is required.
So, to create the jfs2log, which is to be called jfs2log_lv for the volume group apps_vg, use:
# mklv -t jfs2log -y jfslog_lv apps_vg 1
jfslog_lv
You can omit the -y < new lv_name> and let AIX name it for you (by default the first one is called loglv00).

To verify it has been created:
# lsvg -l apps_vg
apps_vg:
LV NAME     TYPE       LPs     PPs     PVs  LV STATE      MOUNT POINT
pluto_lv    jfs2       128     128     1    closed/syncd  N/A
jfslog_lv   jfs2log    1       1       1    closed/syncd  N/A
The next task is to initialize and format the logical volume jfs2log_lv so it can be used as a jfs2 log. This is achieved using the logform command. When prompted to destroy the contents, select Yes. You are not actually destroying anything, rather you are formatting a newly created logical volume.
# logform /dev/jfslog_lv
logform: destroy /dev/rjfslog_lv (y)?y
#
We are now nearly ready to mount the /opt/pluto; however, we must first let AIX know the new device and jfs2log associated with it. If we look at the filesystem entry for /opt/pluto, from the /etc/filesystems file, we have:
# grep -w -p "/opt/pluto" /etc/filesystems
/opt/pluto:
        dev             = /dev/fslv00
        vfs             = jfs2
        log             = /dev/hd8
        mount           = true
        options         = rw
        account         = false
We can see that we need to change the following attributes:
dev
log
These attributes reflect the log and device when the logical volume resided in rootvg. These need to be changed as the logical volume now resides in the volume group apps_vg with different log and dev values. To reflect where the log and logical volume now resides, change the following:
dev  = /dev/fslv00  
to
dev = /dev/pluto_lv
If there is already a jfs2log on the volume group where you copied your logical volume, be sure you use that device for the jfs2log attribute when making your changes in /etc/filesystems.

Change:
log   = /dev/hd8
to
log   = /dev/jfslog_lv
Now edit /etc/filesystems and change those attributes as in the previous example, once this is done verify that the attribute changes have been carried out.
# grep -w -p "/opt/pluto" /etc/filesystems
/opt/pluto:
        dev             = /dev/pluto_lv
        vfs             = jfs2
        log             = /dev/jfslog_lv
        mount           = true
        options         = rw
        account         = false
Now all that is left to do is mount /opt/pluto that now resides in the apps_vg volume group. The logical volume copy is now complete.
# mount /opt/pluto

# lsvg -l apps_vg
apps_vg:
LV NAME    TYPE       LPs     PPs     PVs  LV STATE      MOUNT POINT
pluto_lv   jfs2       128     128     1    open/syncd    /opt/pluto
jfslog_lv  jfs2log    1       1       1    open/syncd    N/A
We still have the original logical volume residing in rootvg, with no mount point associated with it. Once /opt/pluto has been checked out, this can be removed. As part of the checking process, it is a good habit and good practice to run fsck on the newly copied filesystem (be sure to unmount it first though).
# umount /opt/pluto
# fsck -y /dev/pluto_lv
The current volume is: /dev/pluto_lv
Primary superblock is valid.
J2_LOGREDO:log redo processing for /dev/pluto_lv
Primary superblock is valid.
*** Phase 1 - Initial inode scan
*** Phase 2 - Process remaining directories
*** Phase 3 - Process remaining files
*** Phase 4 - Check and repair inode allocation map
*** Phase 5 - Check and repair block allocation map
File system is clean

# mount /opt/pluto
Next, assuming everything has checked out OK, remove the original logical volume from rootvg. Be sure to remove the original logical volume before a reboot (or exportvg), as the ODM will still hold the original logical volume and fielsystem attributes:
# lsvg -l rootvg
…..
fslv00              jfs2       64      64      1    closed/syncd  N/A

# rmlv fslv00
Warning, all data contained on logical volume fslv00 will be destroyed.
rmlv: Do you wish to continue? y(es) n(o)? y
rmlv: Logical volume fslv00 is removed.
Conclusion
Moving or copying data between filesystems is a common task for system administrators, whether within the same volume group or across networks. In this article, I have demonstrated different ways these tasks can be carried out. There are many ways to copy data, I have just highlighted a couple of them with examples.

Source https://developer.ibm.com/components/aix/


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


Migrating to AIX 7.1 with nimadm

Why should I migrate?
Before I discuss how to migrate to a newer version of the IBM AIX® operating system, let's review why you should consider migrating at all. One of the most important reasons to migrate is support. If you are running an older version of AIX, such as 5.3 or earlier, you should already be aware that these versions are no longer supported by IBM. If problems arise on an older version of AIX you are most likely going to be on your own. IBM support will no longer be able to help you.

AIX 5.3 officially went out of support on April 30th 2012. IBM is offering extended support for a limited time for a fee. This will help some customers in the interim while they migrate their systems to AIX 7.1 or 6.1. If you have IBM POWER7® hardware, you might want to consider AIX 5.2 and 5.3 Workload Partitions (WPARs). This will allow you to continue running your legacy applications on AIX 5.2 or 5.3, however they will run within an AIX 7.1 WPAR. These special systems are known as versioned WPARs and are only supported on POWER7 hardware. You can find more information on versioned WPARs.

Of course there are other pressing reasons to migrate as well. Newer releases of AIX include a multitude of new enhancements, improvements, features and performance boosts. I encourage you to read the >AIX 7.1 and 6.1 Differences Guides (IBM Redbooks® publications) to find out more – see the Resources section .
Migrating to AIX 7.1 with nimadm
I've discussed using nimadm to migrate to AIX 6.1 in the past. In this article I'll briefly cover that same process but this time migrating to AIX 7.1. Admittedly the steps are almost identical. So I'll refer you to my 2010 article as a starting point for migrating to 7.1. In this article I'll provide a brief guide to migrating both AIX 5.3 and 6.1 systems to 7.1. I'll also offer some general advice and tips.

The nimadm utility offers several advantages over a conventional migration. For example, a system administrator can use nimadm to create a copy of a NIM client's rootvg (on a spare disk on the client, similar to a standard alternate disk installation alt_disk_install) and migrate the disk to a newer version or release of AIX. All of this can be done without disruption to the client (there is no outage required to perform the migration). After the migration is finished, the only downtime required will be a scheduled reboot of the system.

Another advantage is that the actual migration process occurs on the NIM master, taking the load off the client client logical partition (LPAR). This reduces the processing overhead on the LPAR and minimizes the performance impact to the running applications.

For customers with a large number of AIX systems, it is also important to note that the nimadm tool supports migrating several clients at once.

Just as I did in my previous article I'll assume you already have a NIM master in your environment. And I'm going to assume that your NIM master is already running AIX 7.1 with the latest latest technology level (TL) and and service pack (SP) applied. If not, I recommend you refer to my previous article and the associated Resources section.

My NIM master is running AIX 7.1 TL1 SP4.
# oslevel -s
7100-01-04-1216
# lslpp -l bos.sysmgt.nim.master
  Fileset                      Level  State      Description
  ----------------------------------------------------------------------------
Path: /usr/lib/objrepos
  bos.sysmgt.nim.master     7.1.1.15  APPLIED    Network Install Manager -
                                                 Master Tools
I created new lpp_source and SPOT NIM resources for AIX 7.1 TL1 SP4.
# lsnim -t lpp_source
lpp_sourceaix710104     resources       lpp_source
# lsnim -t  spot
spotaix710104     resources       spot
# lsnim -l lpp_sourceaix710104
lpp_sourceaixaix710104:
   class       = resources
   type        = lpp_source
   arch        = power
   Rstate      = ready for use
   prev_state  = unavailable for use
   location    = /export/lpp_source/lpp_sourceaix710104
   simages     = yes
   alloc_count = 0
   server      = master
# lsnim -l spotaix710104
spotaix7101014:
   class         = resources
   type          = spot
   plat_defined  = chrp
   arch          = power
   Rstate        = ready for use
   prev_state    = verification is being performed
   location      = /export/spot/spotaix7101014/usr
   version       = 7
   release       = 1
   mod           = 1
   oslevel_r     = 7100-01
   alloc_count   = 2
   server        = master
   if_supported  = chrp.64 ent
   Rstate_result = success
To create these resources, I downloaded AIX 7.1 ISO images from the IBM Entitled Software support website. I placed these images into a temporary directory and then used the loopmount command to temporarily mount them.
# ls -ltr
total 11301248
drwxr-xr-x    2 root     system          256 May 14 15:47 lost+found
-rw-r--r--    1 root     system   3361046528 May 14 16:22 NIMAIX71DVD1.iso
-rw-r--r--    1 root     system   2425192448 May 14 16:23 NIMAIX71DVD2.iso
# loopmount -i NIMAIX71DVD1.iso -o "-V cdrfs -o ro" -m /mnt/dvd1
# loopmount -i NIMAIX71DVD2.iso -o "-V cdrfs -o ro" -m /mnt/dvd2
# df | grep loop
/dev/loop0       6563484         0  100%  1640871   100% /mnt/dvd1
/dev/loop1       4735648         0  100%  1183912   100% /mnt/dvd2
# ls -ltr /mnt/dvd1 /mnt/dvd2
/mnt/dvd1:
total 84
drwxr-xr-x    3 4000     4000           2048 Sep 03 2010  ppc
-rw-r--r--    1 4000     4000            819 Sep 03 2010  README.aix
drwxr-xr-x    2 4000     4000           2048 Sep 03 2010  7100-00
drwxr-xr-x    3 4000     4000           2048 Sep 03 2010  root
-rw-r--r--    1 4000     4000          15081 Sep 03 2010  image.data
-rw-r--r--    1 4000     4000           6252 Sep 03 2010  bosinst.data
-rw-r--r--    1 4000     4000             16 Sep 03 2010  OSLEVEL
drwxrwxr-x    4 4000     4000           2048 Sep 03 2010  RPMS
drwxr-xr-x   11 4000     4000           2048 Sep 03 2010  usr
drwxr-xr-x    4 4000     4000           2048 Sep 03 2010  installp
-rw-rw-r--    1 4000     4000             42 Sep 03 2010  .Version
/mnt/dvd2:
total 16
drwxr-xr-x    3 4000     4000           2048 Sep 03 2010  ismp
drwxrwxr-x    3 4000     4000           2048 Sep 03 2010  usr
drwxrwxr-x    4 4000     4000           2048 Sep 03 2010  installp
-rw-rw-r--    1 4000     4000             42 Sep 03 2010  .Version
After they are mounted, I used smitty bffcreate to copy the contents of these images to my new AIX 7.1 lpp_source directory create (/export/lpp_source/lpp_sourceaix710104).

Copy Software to Hard Disk for Future Installation
Type or select values in entry fields.
Press Enter AFTER making all desired changes.
                                                     [Entry Fields]
* INPUT device / directory for software               /mnt/dvd1
* SOFTWARE package to copy                           [all]        +
* DIRECTORY for storing software package      [/export/lpp_source/lpp_sourceaixaix710104]
  DIRECTORY for temporary storage during copying     [/tmp]
  EXTEND file systems if space needed?                yes         +
  Process multiple volumes?                           yes         +
After the base filesets had been copied over, I defined the new lpp_source and SPOT within NIM. Then I downloaded the latest TL and SP for AIX 7.1 and updated the lpp_source and SPOT.

My NIM clients are running AIX 5.3 and AIX 6.1. We will migrate both of these systems to AIX 7.1 using nimadm. We will review the migration process for each system and check that the systems are appropriately tuned after the migration.
root@lparlparaix53[/] > oslevel -s
5300-12-04-1119
root@lparlparaix61[/] > oslevel -s
6100-06-04-1112
I have NIM client definitions for both systems already in place on my NIM master.
# lsnim -t standalone
lparlparaix53     machines       standalone
lparlparaix61     machines       standalone
# lsnim -l lparaix53
lparaix53:
   class          = machines
   type           = standalone
   connect        = nimsh
   platform       = chrp
   netboot_kernel = 64
   if1            = 172_29_154 lparaix53 0
   cable_type1    = N/A
   Cstate         = ready for a NIM operation
   prev_state     = not running
   Mstate         = currently running
   cpuid          = 00CDB5114C00
   Cstate_result  = reset
# lsnim -l lparaix61
lparaix61:
   class          = machines
   type           = standalone
   connect        = nimsh
   platform       = chrp
   netboot_kernel = 64
   if1            = 172_29_154 lparaix61 0
   cable_type1    = N/A
   Cstate         = ready for a NIM operation
   prev_state     = not running
   Mstate         = currently running
   cpuid          = 00C8E4244C00
   Cstate_result  = reset
Each NIM client has a spare disk available that we will use for the alternate disk migration.
root@lparaix53[/] > lspv
hdisk4          00f6050a2cd79ef8                    rootvg          active
hdisk5          00cdb511757d999e                    None
root@lparaix61[/] > lspv
hdisk4          00f6050a2cd79ef8                    rootvg          active
hdisk5          00c8e42485fabfd7                    None
The NIM Master is configured with only three volume groups, rootvg, nimvg and nimadmvg. The nimadmvg volume group will be used as temporary client data cache location for the 7.1 migrations. The volume group is currently empty.
# lsvg
rootvg
nimvg
nimadmvg
# lspv | grep adm
hdisk4          00c342c6395ff736                    nimadmvg        active
# lsvg -l nimadmvg
nimadmvg:
LV NAME             TYPE       LPs     PPs     PVs  LV STATE      MOUNT POINT
Currently, nimadm requires rsh access to the NIM clients in order to function. Therefore we ensure that the NIM Master has rshaccess to each of the clients and that NIM can communicate with each client successfully.
# rsh lparaix53 date
Fri May 18 14:06:07 EETDT 2011
# rsh lparaix61 date
Sat May 18 14:06:40 EETDT 2012
# nim -o lslpp lparaix53 | grep -w "bos.rte "
  bos.rte                   5.3.0.60  COMMITTED  Base Operating System Runtime
  bos.rte                   5.3.0.60  COMMITTED  Base Operating System Runtime
# nim -o lslpp lparaix61 | grep -w "bos.rte "
  bos.rte                    6.1.0.0  COMMITTED  Base Operating System Runtime
  bos.rte                    6.1.0.0  COMMITTED  Base Operating System Runtime
  bos.rte                    6.1.1.0  COMMITTED  Base Operating System Runtime
  bos.rte                    6.1.2.0  COMMITTED  Base Operating System Runtime
  bos.rte                    6.1.3.0  COMMITTED  Base Operating System Runtime
  bos.rte                    6.1.4.0  COMMITTED  Base Operating System Runtime
  bos.rte                    6.1.6.0  COMMITTED  Base Operating System Runtime
  bos.rte                   6.1.6.15  COMMITTED  Base Operating System Runtime
We will now initiate a migration for both systems. Starting with the 5.3 system, we run the following nimadm command on the NIM master to start the alternate disk-migration process.

NIMADM operation for AIX 5.3 system:
# nimadm -j nimvadmg -c lparaix53 -s spotaix710104 –l lpp_sourceaix710104 -d "hdisk5" –Y
Initializing the NIM master.
Initializing NIM client lparaix53.
Verifying alt_disk_migration eligibility.
Initializing log: /var/adm/ras/alt_mig/lparaix53_alt_mig.log
Starting Alternate Disk Migration.
+-----------------------------------------------------------------------------+
Executing nimadm phase 1.
+-----------------------------------------------------------------------------+
Cloning altinst_rootvg on client, Phase 1.
Client alt_disk_install command: alt_disk_copy -j -M 7.1 -P1 -d "hdisk5"
Calling mkszfile to create new /image.data file.
Checking disk sizes.
Creating cloned rootvg volume group and associated logical volumes.
Creating logical volume alt_hd5
Creating logical volume alt_hd6
Creating logical volume alt_hd8
...ETC...
In a new secure shell (SSH) session on the NIM master we initiate a second nimadm operation to migrate our AIX 6.1 NIM client.

NIMADM operation for AIX 6.1 system:
# nimadm -j nimadmvg -c lparaix61 -s spotaix710104 –l lpp_sourceaix710104 -d "hdisk5" –Y
Initializing the NIM master.
Initializing NIM client lparaix61.
Verifying alt_disk_migration eligibility.
Initializing log: /var/adm/ras/alt_mig/lparaix61_alt_mig.log
Starting Alternate Disk Migration.
+-----------------------------------------------------------------------------+
Executing nimadm phase 1.
+-----------------------------------------------------------------------------+
Cloning altinst_rootvg on client, Phase 1.
Client alt_disk_install command: alt_disk_copy -j -M 7.1 -P1 -d "hdisk5"
Calling mkszfile to create new /image.data file.
Checking disk sizes.
LOGICAL_VOLUME= hd11admin
FS_LV= /dev/hd11admin
Creating cloned rootvg volume group and associated logical volumes.
Creating logical volume alt_hd5
Creating logical volume alt_hd6
Creating logical volume alt_hd8
...ETC...
At this point the nimadm process is copying data from the clients, to the cache file systems on the NIM master, and performing the migration on the master itself. After the migration process for a client is complete, the data is copied back to the client's alternate rootvg disk. If you are interested in learning more about each phase of the nimadm process, then again, I refer to my original nimadm article on the IBM developerWorks® website.
We observe that both clients now have a new volume group named altinst_rootvg. This volume group contains a copy of the original rootvg, now migrated to AIX 7.1.
root@lparaix53[/tmp] > lspv
hdisk4          00f6050a2cd79ef8                    rootvg          active
hdisk5          00cdb511757d999e                    altinst_rootvg  active
root@lparaix61[/] > lspv
hdisk4          00f6050a2cd79ef8                    rootvg          active
hdisk5          00c8e42485fabfd7                    altinst_rootvg  active
As the migrated data is being copied from the NIM master to the client, we observe that the alternate rootvg file systems are temporarily mounted on each client to receive the data.
root@lparaix53[/tmp] > df | grep alt
/dev/alt_hd4           262144    261384    1%       10     1% /alt_inst
/dev/alt_hd11admin     262144    261448    1%        4     1% /alt_inst/admin
/dev/alt_hd1           262144    261448    1%        4     1% /alt_inst/home
/dev/alt_hd10opt       1048576   1047760   1%        4     1% /alt_inst/opt
/dev/alt_hd3           262144    247936    6%        5     1% /alt_inst/tmp
/dev/alt_hd2           7077888   7076152   1%        4     1% /alt_inst/usr
/dev/alt_hd9var        524288    523552    1%        4     1% /alt_inst/var
root@lparaix61[/] > df | grep alt
/dev/alt_hd4           1048576   1047696   1%       10     1% /alt_inst
/dev/alt_hd11admin     524288    523552    1%        4     1% /alt_inst/admin
/dev/alt_hd1           524288    523552    1%        4     1% /alt_inst/home
/dev/alt_hd10opt       1572864   1571968   1%        4     1% /alt_inst/opt
/dev/alt_hd3           524288    508256    4%        5     1% /alt_inst/tmp
/dev/alt_hd2           8388608   8386672   1%        4     1% /alt_inst/usr
/dev/alt_hd9var        524288    523552    1%        4     1% /alt_inst/var
On the NIM Master we discover temporary cache file system mounts for each of the NIM clients. These cache file systems are housed in the nimadmvg volume group.
# df -g
Filesystem    GB blocks      Free %Used    Iused %Iused Mounted on
/dev/hd4           0.38      0.16   58%    11761    22% /
/dev/hd2           6.00      1.95   68%    93348    17% /usr
/dev/hd9var        2.38      2.02   15%     7620     2% /var
/dev/hd3           0.50      0.49    3%      187     1% /tmp
/dev/hd1           0.12      0.10   24%       18     1% /home
/dev/hd11admin      0.12      0.12    1%        7     1% /admin
/proc                 -         -    -         -     -  /proc
/dev/hd10opt       2.62      2.01   24%    12726     3% /opt
/dev/livedump      0.25      0.25    1%        4     1% /var/adm/ras/livedump
/dev/cglv         25.00     19.61   22%        6     1% /cg
/dev/lppsrclv     25.00     13.99   45%     7269     1% /lppsrc
/dev/spotlv       25.25     23.96    6%    29122     1% /spot
/dev/loop0         3.13      0.00  100%  1640871   100% /mnt/dvd1
/dev/loop1         2.26      0.00  100%  1183912   100% /mnt/dvd2
/dev/lv00          0.25      0.16   37%     7441    12% /lparaix53_alt/alt_inst
/dev/lv01          0.25      0.24    4%       18     1% /lparaix53_alt/alt_inst/admin
/dev/lv02          0.25      0.24    4%       25     1% /lparaix53_alt/alt_inst/home
/dev/lv03          0.75      0.29   62%     6718     4% /lparaix53_alt/alt_inst/opt
/dev/lv04          0.25      0.20   21%      225     1% /lparaix53_alt/alt_inst/tmp
/dev/lv05          3.50      0.73   80%    80350     9% /lparaix53_alt/alt_inst/usr
/dev/lv06          0.25      0.15   42%     7792    12% /lparaix53_alt/alt_inst/var
/dev/lv07          0.25      0.03   89%    13533    21% /lparaix61_alt/alt_inst
/dev/lv08          0.25      0.24    4%       17     1% /lparaix61_alt/alt_inst/admin
/dev/lv09          0.25      0.24    4%       23     1% /lparaix61_alt/alt_inst/home
/dev/lv10          0.75      0.61   19%     6409     4% /lparaix61_alt/alt_inst/opt
/dev/lv11          0.25      0.24    6%      107     1% /lparaix61_alt/alt_inst/tmp
/dev/lv12          4.25      0.26   94%   104878    10% /lparaix61_alt/alt_inst/usr
/dev/lv13          0.25      0.12   54%     9917    16% /lparaix61_alt/alt_inst/var
/usr/lib           6.00      1.95   68%    93348    17% /lparaix53_alt/alt_inst/usr/
lib/alt_mig/usr/lib
/usr/ccs/lib       6.00      1.95   68%    93348    17% /lparaix53_alt/alt_inst/usr/
lib/alt_mig/usr/ccs/lib
/lparaix53_alt/alt_inst      0.25 0.16 37% 7441    12% /lparaix53_alt/alt_inst/usr/
lpp/bos/inst_root
/lparaix53_alt/alt_inst/var  0.25 0.15 42% 7792    12% /lparaix53_alt/alt_inst/usr/
lpp/bos/inst_root/var
/lparaix53_alt/alt_inst/tmp  0.25 0.20 21% 225     1% /lparaix53_alt/alt_inst/usr/
lpp/bos/inst_root/tmp
/lparaix53_alt/alt_inst/home 0.25 0.24 4%  25     1% /lparaix53_alt/alt_inst/usr/
lpp/bos/inst_root/home
/lparaix53_alt/alt_inst/admin 0.25 0.24 4% 18 1% /lparaix53_alt/alt_inst/usr/
lpp/bos/inst_root/admin
# lsvg -l nimadmvg
nimadmvg:
LV NAME    TYPE       LPs     PPs     PVs  LV STATE      MOUNT POINT
loglv00    jfs2log    1       1       1    open/syncd    N/A
lv00       jfs        1       1       1    open/syncd    /lparaix53_alt/alt_inst
lv01       jfs        1       1       1    open/syncd    /lparaix53_alt/alt_inst/admin
lv02       jfs        1       1       1    open/syncd    /lparaix53_alt/alt_inst/home
lv03       jfs        3       3       1    open/syncd    /lparaix53_alt/alt_inst/opt
lv04       jfs        1       1       1    open/syncd    /lparaix53_alt/alt_inst/tmp
lv05       jfs        14      14      1    open/syncd    /lparaix53_alt/alt_inst/usr
lv06       jfs        1       1       1    open/syncd    /lparaix53_alt/alt_inst/var
lv07       jfs        1       1       1    open/syncd    /lparaix61_alt/alt_inst
lv08       jfs        1       1       1    open/syncd    /lparaix61_alt/alt_inst/admin
lv09       jfs        1       1       1    open/syncd    /lparaix61_alt/alt_inst/home
lv10       jfs        3       3       1    open/syncd    /lparaix61_alt/alt_inst/opt
lv11       jfs        1       1       1    open/syncd    /lparaix61_alt/alt_inst/tmp
lv12       jfs        17      17      1    open/syncd    /lparaix61_alt/alt_inst/usr
lv13       jfs        1       1       1    open/syncd    /lparaix61_alt/alt_inst/var
Each of my migrations took around 60 minutes to complete. By using nimadm, that was an hour of downtime I was able to avoid.

We can review the associated nimadm log files for each client to verify the migration process was successful. You can monitor the migration by tailing each of the log files on the NIM master.
# cd /var/adm/ras/alt_mig
# ls –ltr *.log
total 7136
-rw-r--r--    1 root     system       420858 May 18 14:33 lparaix61_alt_mig.log
-rw-r--r--    1 root     system       429109 May 18 14:33 lparaix53_alt_mig.log
# tail –f lparaix53_alt_mig.log
 All rights reserved.
 US Government Users Restricted Rights - Use, duplication or disclosure
 restricted by GSA ADP Schedule Contract with IBM Corp.
. . . . . << End of copyright notice for bos.help.msg.en_US >>. . . .
Filesets processed:  566 of 2038  (Total time:  14 mins 7 secs).
installp:  APPLYING software for:
        bos.help.msg.en_US.com 7.1.1.0
# tail –f lparaix61_alt_mig.log
 All rights reserved.
 US Government Users Restricted Rights - Use, duplication or disclosure
 restricted by GSA ADP Schedule Contract with IBM Corp.
. . . . . << End of copyright notice for bos.msg.Ja_JP >>. . . .
Filesets processed:  418 of 2059  (Total time:  13 mins 17 secs).
installp:  APPLYING software for:
        bos.msg.JA_JP.rte 7.1.1.0
After the migration process is finished, the NIM master unmounts the cache file systems on the master and clients. We observe that the correct oslevel is returned at the end of the migration that is 7100-01.

lparaix53: 
install_all_updates: Checking for recommended maintenance level 7100-01.
install_all_updates: Executing /usr/bin/oslevel -rf, Result = 7100-01
install_all_updates: Verification completed.
install_all_updates: Log file is /var/adm/ras/install_all_updates.log
install_all_updates: Result = SUCCESS
Known Recommended Maintenance Levels
...
Expanding /alt_inst/usr client filesystem.
Filesystem size changed to 8650752
Adjusting size for /var
Syncing cache data to client ...
+-----------------------------------------------------------------------------+
Executing nimadm phase 10.
+-----------------------------------------------------------------------------+
Unmounting client mounts on the NIM master.
forced unmount of /lparaix53_alt/alt_inst/var
forced unmount of /lparaix53_alt/alt_inst/usr
forced unmount of /lparaix53_alt/alt_inst/tmp
forced unmount of /lparaix53_alt/alt_inst/opt
forced unmount of /lparaix53_alt/alt_inst/home
forced unmount of /lparaix53_alt/alt_inst/admin
forced unmount of /lparaix53_alt/alt_inst
Removing nimadm cache file systems.
Removing cache file system /lparaix53_alt/alt_inst
Removing cache file system /lparaix53_alt/alt_inst/admin
Removing cache file system /lparaix53_alt/alt_inst/home
Removing cache file system /lparaix53_alt/alt_inst/opt
Removing cache file system /lparaix53_alt/alt_inst/tmp
Removing cache file system /lparaix53_alt/alt_inst/usr
Removing cache file system /lparaix53_alt/alt_inst/var
+-----------------------------------------------------------------------------+
Executing nimadm phase 11.
+-----------------------------------------------------------------------------+
Cloning altinst_rootvg on client, Phase 3.
Client alt_disk_install command: alt_disk_copy -j -M 7.1 -P3 -d "hdisk5"
## Phase 3 ###################
Verifying altinst_rootvg...
Modifying ODM on cloned disk.
forced unmount of /alt_inst/var
forced unmount of /alt_inst/usr
forced unmount of /alt_inst/tmp
forced unmount of /alt_inst/opt
forced unmount of /alt_inst/home
forced unmount of /alt_inst/admin
forced unmount of /alt_inst
Changing logical volume names in volume group descriptor area.
Fixing LV control blocks...
Fixing file system superblocks...
Bootlist is set to the boot disk: hdisk5 blv=hd5
+-----------------------------------------------------------------------------+
Executing nimadm phase 12.
+-----------------------------------------------------------------------------+
Cleaning up alt_disk_migration on the NIM master.
Cleaning up alt_disk_migration on client lparaix53.

lparaix61:
install_all_updates: Checking for recommended maintenance level 7100-01.
install_all_updates: Executing /usr/bin/oslevel -rf, Result = 7100-01
install_all_updates: Verification completed.
install_all_updates: Log file is /var/adm/ras/install_all_updates.log
install_all_updates: Result = SUCCESS
Known Recommended Maintenance Levels
...
Expanding /alt_inst/usr client filesystem.
Filesystem size changed to 8650752
Adjusting size for /var
Syncing cache data to client ...
+-----------------------------------------------------------------------------+
Executing nimadm phase 10.
+-----------------------------------------------------------------------------+
Unmounting client mounts on the NIM master.
forced unmount of /lparaix61_alt/alt_inst/var
forced unmount of /lparaix61_alt/alt_inst/usr
forced unmount of /lparaix61_alt/alt_inst/tmp
forced unmount of /lparaix61_alt/alt_inst/opt
forced unmount of /lparaix61_alt/alt_inst/home
forced unmount of /lparaix61_alt/alt_inst/admin
forced unmount of /lparaix61_alt/alt_inst
Removing cache file system /lparaix61_alt/alt_inst/admin
Removing cache file system /lparaix61_alt/alt_inst/home
Removing cache file system /lparaix61_alt/alt_inst/opt
Removing cache file system /lparaix61_alt/alt_inst/tmp
Removing cache file system /lparaix61_alt/alt_inst/usr
Removing cache file system /lparaix61_alt/alt_inst/var
+-----------------------------------------------------------------------------+
Executing nimadm phase 11.
+-----------------------------------------------------------------------------+
Cloning altinst_rootvg on client, Phase 3.
Client alt_disk_install command: alt_disk_copy -j -M 7.1 -P3 -d "hdisk5"
## Phase 3 ###################
Verifying altinst_rootvg...
Modifying ODM on cloned disk.
forced unmount of /alt_inst/var
forced unmount of /alt_inst/var
forced unmount of /alt_inst/usr
forced unmount of /alt_inst/usr
forced unmount of /alt_inst/tmp
forced unmount of /alt_inst/tmp
forced unmount of /alt_inst/opt
forced unmount of /alt_inst/opt
forced unmount of /alt_inst/home
forced unmount of /alt_inst/home
forced unmount of /alt_inst/admin
forced unmount of /alt_inst/admin
forced unmount of /alt_inst
forced unmount of /alt_inst
Changing logical volume names in volume group descriptor area.
Fixing LV control blocks...
Fixing file system superblocks...
Bootlist is set to the boot disk: hdisk5 blv=hd5
+-----------------------------------------------------------------------------+
Executing nimadm phase 12.
+-----------------------------------------------------------------------------+
Cleaning up alt_disk_migration on the NIM master.
Cleaning up alt_disk_migration on client lparaix61.
At this point we restart each of the NIM clients into AIX 7.1. You'll observe that the bootlist for each client was modified bynimadm, so that the alternate rootvg is now the only disk in the boot list. With the clients successfully restarted on 7.1 the migration is now complete.
AIX Tunables post migration
After an AIX migration, I usually like to run the tuncheck command to verify the current tunable parameters are valid. One area that can indicate a tuning problem is the AIX error report. If you see the following messages in the errpt output, you might want to verify the current settings are valid:
IDENTIFIER TIMESTAMP  T C RESOURCE_NAME  DESCRIPTION
D221BD55   0523115112 I O perftune       RESTRICTED TUNABLES MODIFIED AT REBOOT
---------------------------------------------------------------------------
LABEL:          TUNE_RESTRICTED
IDENTIFIER:     D221BD55
Date/Time:       Wed May 23 11:51:16 EET 2012
Sequence Number: 676
Machine Id:      00C342C64C00
Node Id:         lparaix53
Class:           O
Type:            INFO
WPAR:            Global
Resource Name:   perftune
Description
RESTRICTED TUNABLES MODIFIED AT REBOOT
Probable Causes
SYSTEM TUNING
User Causes
TUNABLE PARAMETER OF TYPE RESTRICTED HAS BEEN MODIFIED
        Recommended Actions
        REVIEW TUNABLE LISTS IN DETAILED DATA
Detail Data
LIST OF TUNABLE COMMANDS CONTROLLING MODIFIED RESTRICTED TUNABLES AT REBOOT, 
SEE FILE /etc/tunables/lastboot.log
vmo
In the output above, you'll notice that we are advised to check the /etc/tunables/lastboot.log for a modified restricted vmo tuning parameter. At this point I usually like to run the tuncheck command against the current /etc/tunables/nextboot file and review its output. As you can see, in the example below, we are warned that several restricted tunables are not set to their default values. These values might not be appropriate for your newly migrated AIX 7.1 (or 6.1) system. Settings that worked well with 5.3 are most likely no longer appropriate with 7.1.
# tuncheck -p -f /etc/tunables/nextboot
Warning: restricted tunable lrubucket is not at default value
Warning: restricted tunable strict_maxperm is not at default value
Warning: unknown parameter lru_file_repage in stanza vmo
Warning: restricted tunable maxperm% is not at default value
Warning: restricted tunable maxclient% is not at default value
Checking successful
Based on the output above, the tuning for this newly migrated 7.1 system appears to be inappropriate. Unless we have a valid reason (which has been verified by IBM AIX support) we should set these tunables to their default AIX 7.1 settings.
You can reset individual tunables to their defaults using the –d flag and the corresponding tuning command. For example to set the maxperm% tunable to its default you would run the following vmo command:
# vmo -p -d maxperm%
Modification to restricted tunable maxperm%, confirmation required yes/no yes
Setting maxperm% to 90 in nextboot file
Setting maxperm% to 90
Warning: a restricted tunable has been modified
If you want to set all the vmo tunables back to their defaults you would run the following vmo command with the –D option:
#  vmo -r -D
Setting maxfree to 1088 in nextboot file
Setting minfree to 960 in nextboot file
Setting minperm% to 3 in nextboot file
Modification to restricted tunable maxperm%, confirmation required yes/no yes
Setting maxperm% to 90 in nextboot file
Modification to restricted tunable strict_maxperm, confirmation required yes/no yes
Setting strict_maxperm to 0 in nextboot file
Setting maxpin% to 80 in nextboot file
...etc...
Warning: some changes will take effect only after a bosboot and a reboot
Run bosboot now? yes/no yes
bosboot: Boot image is 47016 512 byte blocks.
Note that setting all parameters to their defaults will require the bosboot command to be run and a reboot of the system for the changes to take effect.

The tundefault command can also reset tuning to default parameters. The command launches all the tuning commands (ioo, vmo, schedo, no, nfso, and raso) with the -D flag. This resets all the AIX tunable parameters to their default values. The –r flag defers the reset to default value to the next reboot. This clears the stanza(s) in the /etc/tunables/nextboot file and if necessary, runs bosboot and warns that a reboot is needed.
# tundefault -r
After the tunables have been reset, re-run the tuncheck command and ensure it runs without errors:
# tuncheck -p -f /etc/tunables/nextboot
Checking successful
You can verify when a systems tunables were lasted checked (with the tuncheck command) by reviewing the info stanza in the /etc/tunables/nextboot file. For example, the nextboot file (below) was last checked on 7th June 2012 and the system was running AIX 7.1.
# IBM_PROLOG_BEGIN_TAG
# This is an automatically generated prolog.
#
# bos520 src/bos/usr/sbin/perf/tune/nextboot 1.1
#
# Licensed Materials - Property of IBM
#
# (C) COPYRIGHT International Business Machines Corp. 2002
# All Rights Reserved
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
# IBM_PROLOG_END_TAG
info:
        AIX_level = "7.1.1.1"
        Kernel_type = "MP64"
        Last_validation = "2012-06-07 12:29:54 EETDT (current, reboot)"
vmo:
nfso:
        portcheck = "1"
        nfs_use_reserved_ports = "1"
Unless you've permanently set restricted tunables in your /etc/tunables/nexboot file, the migration will change the systems default tuning to match the newer version of AIX. For example, we observed the following tuning changes on our AIX 5.3 system after migrating to 7.1.
The maxperm default value changed from 80 to 90:
maxperm%  80 80 80 1 100 % memory  D
maxperm%  90 90 90 1 100  % memory D
The minperm default value changed from 20 to 3:
minperm%  20 20 20 1 100 % memory  D
minperm%  3 3 3 1 100 % memory  D
Note that with AIX 7.1 lru_file_repage is hardcoded to 0 and removed from the list of vmo tunables. Please refer to the following document, for more information.
Oracle Architecture and Tuning on AIX v2.20
As expected, we noted a number of new tunables with AIX 7.1. Some examples are shown below.
vmm_klock_mode 2 2 2 0 3 numeric  B
j2_inodeCacheSize 200 200 200 1 1000  D
To learn more about these new tunables we can run the corresponding tuning utility with the –h flag to obtain usage information.
# vmo -h vmm_klock_mode
Help for tunable vmm_klock_mode:
Purpose:
Kernel locking prevents paging out kernel data. This improves system performance in many cases. If set to 0, kernel locking is disabled. If set to 1, kernel locking is enabled automatically if Active Memory Expansion (AME) feature is also enabled. In this mode, only a subset of kernel memory is locked. If set to 2, kernel locking is enabled regardless of AME and all of kernel data is eligible for locking. If set to 3, only the kernel stacks of processes are locked in memory. Enabling kernel locking has the most positive impact on performance of systems that do paging but not enough to page out kernel data or on systems that do not do paging activity at all. Note that 1, 2, and 3 are only advisory. If a system runs low on free memory and performs extensive paging activity, kernel locking is rendered ineffective by paging out kernel data. Kernel locking only has an impact on pageable page-sizes in the system.
Values:
  Default: 2
  Range: 0 - 3
  Type: Bosboot
  Unit: numeric
Tuning:
If processes are being delayed waiting for compressed memory to become available, increase ame_minfree_mem to improve response time. Note, this must be at least 257kb less than ame_maxfree_mem.
We also noticed a new subsystem, named aso. The Active System Optimizer (ASO) is a new AIX 7.1 (on POWER7 only) feature that autonomously tunes the allocation of system resources to improve performance.
# lsitab -a | grep aso
aso:23456789:once:/usr/bin/startsrc -s aso -e "NORMAL_RESPAWN_NOLOG"
New network (no) tuning options also appeared after the migration. The example below relates to TCP tuning for loopback network access.
# no -a | grep tcp_fast
               tcp_fastlo = 0
     tcp_fastlo_crosswpar = 0
# no -h tcp_fastlo
Help for tunable tcp_fastlo:
Purpose:
Specifies whether TCP fastpath loopback is enabled (1) or disabled (0).
Values:
  Default: 0
  Range: 0 - 1
  Type: Connect
  Unit: boolean
Tuning:
This option allows the TCP loopback traffic to shortcut the entire TCP/IP stack (protocol and interface) in order to achieve better performances.
# no -h tcp_fastlo_crosswpar
Help for tunable tcp_fastlo_crosswpar:
Purpose:
Specifies whether TCP fastpath loopback between WPARs of a system is allowed (1) or forbidden (0).
Values:
  Default: 0
  Range: 0 - 1
  Type: Connect
  Unit: boolean
Tuning:
This option is valid only if TCP fastpath loopback is enabled (with tcp_fastlo option).
I highly recommend that you refer to the IBM AIX Version 7.1 Differences Guide Redbook publication for more information on the new features of the AIX 7.1 OS.
Considerations when migrating to AIX 7.1 (or 6.1)
Do you have JFS file systems in rootvg? If you do, please be aware that nimadm does not convert rootvg file systems from JFS to JFS2. I have requested that IBM include this feature with nimadm in the future. Starting with AIX 6.1 TL4, thealt_disk_copy utility has a new –T flag to convert rootvg file systems to JFS2 during the cloning process. Unfortunately nimadm does not currently call this flag with alt_disk_copy.
If you are already running AIX 6.1 TL4 or higher, then you can use alt_disk_copy –T to convert rootvg file systems to JFS2 first and then use nimadm to migrate to AIX 7.1.
If you are on AIX 5.3, the alt_disk_copy command does not have the –T flag. In this case you might want to migrate to AIX 7.1 (or 6.1) with nimadm first, and then use the alt_disk_copy –T command to convert rootvg file systems to JFS2.
You might need to upgrade your MPIO device driver software. For example, if you are using IBM SDDPCM, then you will need to uninstall the previous version of SDDPCM and then install the correct version of the software for your new version of AIX. You might be able to use pre and post-migration scripts to include this update as part of the overall AIX migration process. Please refer to the following link for an example.
Using a post migration script with nimadm
As discussed in my previous nimadm article, multibos is not supported in nimadm environments. Before you start animadm migration make sure you have removed any old standby BOS instance and that your rootvg logical volumes are not using any bos_ LV names.
During our tests we found that even though we removed the standy instance (multibos –R), the nimadm process failed with the following error:
+-----------------------------------------------------------------------------+
Executing nimadm phase 11.
+-----------------------------------------------------------------------------+
Cloning altinst_rootvg on client, Phase 3.
Client alt_disk_install command:
 alt_disk_copy -j -M 7.1 -P3 -d "hdisk1"
## Phase 3 ###################
Verifying altinst_rootvg...
alt_disk_copy: 0505-218 ATTENTION: init_multibos() 
returned an unexpected result.
Cleaning up.
forced unmount of /alt_inst/var/log
forced unmount of /alt_inst/var/log
forced unmount of /alt_inst/var
forced unmount of /alt_inst/var
forced unmount of /alt_inst/usr/local
forced unmount of /alt_inst/usr/local
forced unmount of /alt_inst/usr
forced unmount of /alt_inst/usr
forced unmount of /alt_inst/tmp
forced unmount of /alt_inst/tmp
forced unmount of /alt_inst/opt
forced unmount of /alt_inst/opt
forced unmount of /alt_inst/home
forced unmount of /alt_inst/home
forced unmount of /alt_inst/admin
forced unmount of /alt_inst/admin
forced unmount of /alt_inst
forced unmount of /alt_inst
0505-187 nimadm: Error cloning altinst_rootvg on client.
Cleaning up alt_disk_migration on the NIM master.
Cleaning up alt_disk_migration on client lpar1.
Client alt_disk_install command: alt_disk_install -M 7.1 -X
Bootlist is set to the boot disk: hdisk0 blv=hd5
We also found the init_multibos error in the /var/adm/ras/alt_disk_inst.log file on the NIM client:
Tue Nov 22 14:48:12 EETDT 2011
cmd: /ALT_MIG_SPOT/sbin/alt_disk_copy -j -M 7.1 -P3 -d hdisk1
Verifying altinst_rootvg...
alt_disk_copy: 0505-218 ATTENTION: init_multibos() returned an unexpected result.
Cleaning up.
Given that the error appeared to be related to init_multibos, we assumed the failure was due to some multibos checks being performed by alt_disk_copy on the client. The client system did not have an existing multibos standby instance. So, we tried two things: First we created a standby instance on the client (multibos –s –X) and re-tried the nimadmoperation. This failed. Next we removed the standby instance (multibos –R) and re-tried the nimadm operation. This worked and the client then migrated to AIX 7.1 successfully. We re-tried the same operations (that is, create standby instance, remove standby instance and nimadm) several times and each worked as expected.

Unfortunately, it appears that 'multibos –R' may not clean up the /bos_inst directory. If this directory exists the nimadm operation will most likely fail. The simple fix was (in our case) to remove the /bos_inst directory before attempting the AIX migration.
# rm –r /bos_inst
If you plan on using your AIX 7.1 NIM master to migrate your AIX 5.3 clients to AIX 6.1, then make sure that you install the AIX 7.1 bos.alt_disk_install.rte fileset into the AIX 6.1 SPOT resource first. Failure to do so will result in your nimadmoperation reporting the following error message:
# nimadm -j nimadmvg -c lparaix53 -s spotaix610605 -l 
lpp_sourceaix610605_NEW -d hdisk2 -Y
Initializing the NIM master.
Initializing NIM client lparaix53.
0042-001 nim: processing error encountered on "master":
   /usr/bin/lslpp: Fileset bos.alt_disk_install.rte not installed.
0505-204 nimadm: SPOT spotaix610605_NEW does not have 
bos.alt_disk_install.rte installed.
0505-205 nimadm: The level of bos.alt_disk_install.rte installed in SPOT
spotaix610605_NEW (0.0.0.0) does not match the NIM master's level (7.1.1.0).
Cleaning up alt_disk_migration on the NIM master.
You must install the AIX 7.1 bos.alt_disk_install.rte fileset into your AIX 6.1 SPOT resource.
# smit nim_res_op
....etc...
> spotaix610605
Customize a SPOT
Type or select values in entry fields.
Press Enter AFTER making all desired changes.
                                                     [Entry Fields]
* Resource Name                                       spotaix610605
* Source of Install Images                           [lpp_sourceaix710104] +
  Fileset Names                                      [bos.alt_disk_install.rte]
You can verify the correct fileset is installed in your 6.1 SPOT using the following nim command:
# nim -o showres spotaix610605 | grep bos.alt_disk_install.rte
  bos.alt_disk_install.rte   7.1.1.15    A     F    Alternate Disk Installation
Some administrators, migrating from AIX 5.3 to 6.1, reported issues with certain device filesets left behind after the migration. They identified there was an issue when the lppchk command returned errors after migration. To resolve the problem, IBM support advised that certain filesets be uninstalled and that several entries be deleted from the ODM. Please refer to the following link for further information.
AIX 5.3 to 6.1 migration
Another 6.1 related issue we discovered was that after migrating, the sys0 maxuproc attribute was returned to its default value. This resulted in performance issues and application crashes. Check your maxuproc value before and after the migration and ensure it has not changed. We did not experience this issue with AIX 7.1 migrations. Please refer to the following blog post for more information.
AIX 6.1 migration: iostat and maxuproc change to their defaults?
Read the latest AIX 7.1 installation tips document when planning your migrations. It can help you resolve and/or avoid issues either before, during or after the upgrade. For example:
7100-01 Installation
When applying the 7100-01 Technology Level with Service Pack 1 included, you will have to run smitty update_all a second time to update bos.aso and mcr.rte. Until this is done, the oslevel command will not indicate the correct level.
I recommend you migrate to the latest TL and SP for AIX 7.1 (or 6.1) to avoid any known issues. For example, SP3 for 7.1 TL1 is vulnerable to an issue where the netstat –f command can crash an LPAR. SP4 for 7.1 TL1 contains APARIV09942 which resolves this problem. We hit this problem during our migrations. One of our system monitoring tools was regularly running the netstat command, which resulted in a number of unwanted system outages on some systems.
Customers using IBM DB2® Versions 8.2, 9.1, 9.5 or 9.7 should apply the following ifixes when applying SP4 for AIX 7.1 TL1 or AIX 6.1 TL7. Use APAR IV22132 for AIX 7.1 TL1 SP4 and APAR IV22062 for AIX 6.1 TL7 SP4. Please refer to the following website for further information:
Known issues for DB2 for Linux, UNIX and Windows on AIX 5.2, 5.3, 6.1, and 7.1
Before applying AIX 7.1 TL1 SP4 to your system, make sure you have removed any legacy tuning from your system. During our tests we discovered that if we left legacy AIX 5.2 or 5.3 tuning in place the LPAR would hang during restart at "Setting tunable parameters". The following entries in our nextboot file were removed and the system started OK. This issue only appeared with systems migrated to SP4. Systems on AIX 7.1 TL1 SP3 did not exhibit this problem however we still removed the legacy tuning as it was inappropriate for 7.1.
info:
        AIX_level = "5.2.0.31"
        Kernel_type = "MP64"
        Last_validation = "2004-12-08 13:48:10 EETDT (current, reboot)"
vmo:
        lrubucket = "262144"
        strict_maxclient = "1"
        strict_maxperm = "1"
        lru_file_repage = "0"
        minperm% = "2"
        maxperm% = "5"
        maxclient% = "5"
        maxfree = "1200"
ioo:
        aio_maxreqs = "12288"
        j2_maxPageReadAhead = "512"
        maxpgahead = "8"
no:
        use_isno = "0"
        udp_sendspace = "65536"
        udp_recvspace = "65536"
        tcp_sendspace = "262144"
        tcp_recvspace = "262144"
        rfc132
You might want to simply move the existing nextboot file "out of the way" prior to migrating. You can then review the file post migration. For example:
# mv /etc/tunables/nextboot /etc/tunables/nextboot.old
For special considerations for SSH host keys and AIX migrations, refer to this blog.
Note: As of AIX Version 7.1, the 32-bit kernel has been deprecated. Therefore, 64-bit hardware is required to run AIX Version 7.1 (IBM POWER4™, POWER5™, POWER6™ or POWER7 systems only).


further more information Source Link :http://www.ibm.com/developerworks/aix/library/au-aix-nimadm/index.html

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Moving FS from one volume group to Volume Group

ATTENTION: Make sure a full backup exists of any data you intend to migrate before using these procedures. In AIX, storage allocation is performed at the volume group level. Storage cannot span volume groups. If space within a volume group becomes constrained, then space that is available in other volume groups cannot be used to resolve storage issues. The solution to this problem is to add more physical volumes to the relevant volume group. This may not be an option in all environments. If other volume groups contain the required free space, the alternative is to move the required logical volumes to the desired volume group and expand them as needed. The source logical volume can be moved to another volume group with the cplv command. The following steps achieve this.

ATTENTION:The logical volume should be inactive during these steps to prevent incomplete or inconsistent data. If the logical volume contains a mounted file system, then that file system should be unmounted first. If this logical volume is being used as a RAW storage device, then the application using this logical volume should close the device or be shut down.

1.Copy the source logical volume to the desired volume group with the cplv command. For example, where myvg is the new volume group and mylv is the name of the user's logical volume, enter:
$cplv -v myvg mylv
This will return the name of the new logical volume, such as lv00. If this logical volume was being used for RAW storage, skip to to step 6. If this is a JFS or JFS2 file system, proceed to step 2. Note that RAW storage devices should NOT use the first 512 bytes of the RAW device. This is reserved for the LVCB or logical volume control block. cplv will not copy the first 512 bytes of the RAW logical volume, but it will update fields in the new logical volume's LVCB.

2.All JFS and JFS2 file systems require a log device. This will be a logical volume with a type of jfslog or jfs2log for JFS2 file systems. Run the lsvg -l command on your destination volume group. If a JFS or JFS2 log DOES NOT already exist on the new volume group, create one by using the mklv and logform commands as detailed below. If a JFS or JFS2 log DOES exist, proceed to
step 3 With a JFS2 filesystem, you also have the option of using an inline log. With inline logs, the jfs2log exists on the filesyster itself. After the cplv command is ran on a JFS2 inline log filesystem, run:
$logform /dev/lvname
You should receive a message about formatting the inline log. If you do not receive a message about an inline log, then this filesystem is not a JFS2 inline log filesystem and you should treat it as a regular JFS2 filesystem. After hitting y on formatting the inline log, continue to step 3. To make a new JFS log, enter the following command, where myvg is the name of the new volume group, enter:
$mklv -t jfslog myvg 1
To make a new JFS2 log, enter: mklv -t jfs2log myvg 1 This will return a new logical volume of either type jfslog or jfs2log, such as loglv00. This new logical volume will need to be formatted with the logform command in order to function properly as either a JFS or JFS2 log. 
For example:
logform /dev/loglv00
Answer yes to destroy.
3.Change the filesystem to reference a log device that exists in the new volume group and the new logical volume with the chfs command. For example, where myfilesystem is the name of the user's filesystem, enter: $chfs -a dev=/dev/lv00 -a log=/dev/loglv00 /myfilesystem With inline logs on JFS2 filesystems this command is also different: $chfs -a dev=/dev/lv00 -a log=INLINE /myfilesystem

4.Run fsck to ensure filesystem integrity. Enter:
fsck -p /dev/lv00
NOTE: It is common to receive errors after running fsck -p /dev/lvname prior to mounting the filesystem. These errors are due to a known bug that development is currently aware of and which will be resolved in a future release of AIX. Once the filesystem is mounted, a future fsck with the filesystem unmounted should no longer produce an error.

5.Mount the file system: For example,where myfilesystem is the name of the user's file system, enter:
$mount /myfilesystem
At this point, the migration is complete, and any applications or users can now access the data in this filesystem. To change the logical volume name, proceed to the following step. NOTE: If you receive errors from the preceding step, do not continue. Contact you AIX support center.

6.Remove the source logical volume with the rmlv command.
For example, where mylv is the name of the user's logical volume, enter:
$rmlv mylv
Rename and reset any needed attributes on the new logical volume with the chlv or chmod commands. In order to rename the logical volume, the filesystem or raw logical volume must be in a closed state. For example, where mylv is the new name you wish to change lv00 to be, enter:
$chlv -n mylv lv00
Logical volumes specific to rootvg
The following logical volumes and file systems are specific to the rootvg volume group and cannot be moved to other volume groups Logical Volume File System or Description 
------------------------------------------------------ 
hd2 /usr 
hd3 /tmp 
hd4 / 
hd5 
hd6 
hd8 
hd9var /v


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

MustGather: WebSphere Performance on AIX

MustGather: 
Performance, hang, or high CPU issues with WebSphere Application Server on AIX
If you are experiencing performance, hang, or high CPU issues with WebSphere Application Server on AIX, this MustGather will assist you in collecting the data necessary to diagnose and resolve the issue.

To improve the accuracy of complete data collection, IBM recommends you use the automated data collectors within IBM Support Assistant. Not only will the automated collector gather the equivalent of the manual process, it will also provide a secure file transfer of the collection to IBM.
Collecting data using the IBM Support Assistant Data Collector
Go to the ISA Data Collector site for WebSphere Application Server. hwrp://public.dhe.ibm.com/software/isa/isadc/?taxonomy=ApplicationServer

Start the ISA Data Collector:
To run online, select the option to collect from this system using the current browser and click Start Collection.
To run locally, select the option to collect from this or another system using a downloadable utility. Download and extract the zip file to your WAS_HOME directory. From a command line, run isadc.[sh|bat] or launch index.html to use the web interface.
Select the JDK > Hang / High CPU / Performance Problem collector and click Start.
Follow the prompts to automatically submit the collected data to IBM Support
Collecting data using the WAIT Data Collector
This data collection method should only be used with WebSphere Application Server 6.1 and later.

If you have not already done so, enable verboseGC (hwrp://www.ibm.com/support/docview.wss?uid=swg21114927)and restart the server.

At the time of the problem, run the script linked below with the following command:
./perfMustGather.sh [PID]

This command will create a file named waitData.tar.gz which will contain all of the diagnostic data needed, server logs and javacores included. This script should be ?executed as the root user?. As with any script, you may need to add execute permissions before executing the script (chmod).?

In the above command, [PID] is the Process ID of the problematic JVM(s). If specifying multiple Process IDs they should each be separated by a space.?

Download link: hwrps://wait.researchlabs.ibm.com/wait/public/perfMustGather.sh

Send the waitData.tar.gz output file to IBM Support: "Exchanging information with IBM Support" hwrp://www.ibm.com/support/docview.wss?uid=swg21153852
Collecting data manually
Complete the following three steps:

(1) Collecting the required data:

If you have not already done so, enable verboseGC (hwrp://www.ibm.com/support/docview.wss?uid=swg21114927) and restart the server.

At the time of the problem, run one of the awrached scripts with the appropriate command:
For WebSphere Application Server 6.1 and later:

./aixperf.sh [PID]
aixperf.shaixperf.sh (hwrp://www-01.ibm.com/support/docview.wss?uid=swg21052641&aid=1)

For WebSphere Application Server 6.0 and earlier:

./aixperf60.sh [PID]

Note: Both aixperf60.sh and dbxtrace_aix.sh should be in the same directory and dbx must be installed (hwrp://www.ibm.com/support/docview.wss?uid=swg21222456) to diagnose high CPU issues.
aixperf60.shaixperf60.sh  (hwrp://www-01.ibm.com/support/docview.wss?uid=swg21052641&aid=3) dbxtrace_aix.sh (hwrp://www-01.ibm.com/support/docview.wss?uid=swg21052641&aid=5) 

These scripts will create a file named aixperf_RESULTS.tar.gz and three javacores. These scripts should be executed as the root user. As with any script, you may need to add execute permissions before executing the script (chmod).

In the above commands, [PID] is the Process ID of the problematic JVM(s). If specifying multiple Process IDs they should each be separated by a space.

(2) Collecting log files:

Collect the server logs (SystemOut.log, native_stderr.log,...) from the problematic server(s):

<profile_root> /logs/ server_name /*

(3) Submiwring required data:

Zip/Tar all the files gathered:
aixperf_RESULTS.tar.gz
three javacores
server logs (SystemOut.log, native_stderr.log,...)

Send the results to IBM Support: "Exchanging information with IBM Support" (hwrp://www.ibm.com/support/docview.wss?uid=swg21153852) 


Frequently Asked Questions:
What is the impact of enabling verboseGC?
VerboseGC data is critical to diagnosing these issues. This can be enabled on production systems because it has a negligible impact on performance (< 2%).

What is the aixperf_RESULTS.tar.gz file and where can I find it?
The aixperf_RESULTS.tar.gz file is created while running the aixperf.sh script and contains output from the commands called by the script. It will be created in the directory from which you execute the script.

What are 'javacores' and where do I find them?
Javacores are snapshots of the JVM activity and are essential to troubleshooting these issues. These files will usually be found in the <profile_root>. If you do not find the files here, you can search your entire system for them using the following command:

find / -name "*javacore*"


If asked to do so:
The preceding data is used to troubleshoot most of these type of issues; however, in certain situations Support may require additional data. Only collect the following data if asked to do so by IBM Support.
System core
You can collect a system core by executing the following command:

gencore [PID] core.[PID]

Process the system core file using the instructions in How to process a core dump using jextract on the IBM SDK on Windows, Linux, and AIX

Monitor process sizes and paging usage
The aixmon.sh script will collect data every 5 minutes until it is stopped manually. Run the following command before the issue occurs to start the script:

./aixmon.sh

This will create two files: ps_mon.out and vmstat_mon.out.
 aixmon.sh	(hwrp://www-01.ibm.com/support/docview.wss?uid=swg21052641&aid=7)
Exchanging data with IBM Support
To diagnose or identify a problem, it is sometimes necessary to provide Technical Support with data and information from your system. In addition, Technical Support might also need to provide you with tools or utilities to be used in problem determination. You can submit files using one of following methods to help speed problem diagnosis:
IBM Support Assistant (ISA)
Service Request (SR)
E-mail
FTP to the Enhanced Customer Data Repository (ECuRep)



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Network File System (NFS) Concepts

This post will discuss about the concepts involved in network file system (NFS) administration.
Prerequisites for NFS:
NFS daemons should be running on both client as well as server machines.
A file system should always be available on the server that has to be exported.
Exported file system must be mounted on the remote client machine.
NFS daemons are not running by default on new OS installation.
To active the NFSD daemons, following command needs to be run:
# startsrc –s nfsd
To start all daemons:
# startsrc –g nfs
Can also be activated from smit by running this command,
# smit mknfs
Exporting a Directory:
There are 2 ways to export a directory:
Using smit
# smit mknfsexp
It will update /etc/exports file. If the file does not exist, it will be created.
Through command line
End user or admin will create (update) /etc/exports file using,
# vi /etc/exports
If it does not exists, end user will create it and then run the export command,
# exportfs –a
This command will send the information available in /etc/exports file to the kernel.
Other Options available are:
# exportfs –u </dir name>
This will remove the information from /etc/exports file
This can also be done through smit using the following command:
# smit rmnfsexp
It will remove the information from /etc/exports file
To change the data through smit, command used is:
# smit chnfsexp
Will change the information in /etc/exports file
Verification:
To verify from the remote server:
# showmount –e <localhost> OR <ip address>
To check/verify from the client side:
Using smit,
# smit mknfsmnt
Using command line,
# mount –t nfs <ip address> </dir name> /mnt
To unmount:
# umount /mnt


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Network Related commands in AIX
By Surya21:23No comments

host 193.9.200.1  Resolves ip to host name (from /etc/hosts file)

host ibm                 Resolve ibm to ip address (from /etc/hosts file)

hostname ibm      To change the host name to ibm

entstat en0         To the status of ethernet device en0

entstat -d en0     To list the detailed status of device en0

no -a                  To list all net configurable attributes and their values

no -d thewall      To change thewall parameter to its default value

no -o ipforwarding=1   To make the machine as router in tcpip networks

traceroute ibm            To trace the route to ibm

ping ibm                     To tcp ping to the machine ibm

ifconfig -a                  To show the status of all network interfaces

ifconfig en0                To show the status of en0

ifconfig en0 up           Turns on network card en0

ifconfig en0 down       Turns off network card en0
ifconfig en0 detach     Removes en0 card from the network interface list

ifconfig en0 inet 194.35.52.1 netmask 255.255.255.0 up     configure en0 and starts immediately

mktcpip -h ibm -a 10.0.2.40 -m 255.255.255.0 -i en0  assign hostname as ibm, IP as 10.0.2.40 subnetmask 255.255.255.0 to en0 interface

ifconfig en0 alias 195.60.60.1   Create alias ip address for en0

route add 0 192.100.13.7          To make 192.100.13.7 as default gateway for entire network

route add 192.100.12.0 192.100.13.7   To make 13.7 as gateway for 12.0 network

route -f                To clear the gateway table

chdev -l inet0 -a hostname=ibm    To change the host name to ibm permanently

netstat -a                To show the state of all sockets

netstat -c                 To show the network buffers cache

netstat -D                To show the net drops of packets

netstat -i               To display interface statistics

netstat -r               To show the routing table

netstat -rn             To show routing table (ip will be given instead of host names)

netstat -s                 To show the statistics of the protocols

netstat -s -p <>      To show the statistics of respective protocols



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Networking [AIX]

To find out the link status, link speed and mac address and statistics of an Ethernet adapter ent0
 # entstat -d ent0  (or entstat -dt en0)
 ETHERNET STATISTICS (ent0) : 
 Device Type: 10/100/1000 Base-TX PCI-X Adapter (14106902)
 Hardware Address: 00:11:25:08:1c:21

 Transmit Statistics:                          Receive Statistics: 
 --------------------                          -------------------
 Packets: 242183399                            Packets: 318139934
 Bytes: 41638159225                            Bytes: 234717791764
 Interrupts: 0                                 Interrupts: 172984103
 Transmit Errors: 0                            Receive Errors: 0
 Packets Dropped: 0                            Packets Dropped: 0
                                              Bad Packets: 0
 Max Packets on S/W Transmit Queue: 21        
 S/W Transmit Queue Overflow: 0
 Current S/W+H/W Transmit Queue Length: 1

 Broadcast Packets: 16676                      Broadcast Packets: 6200001
 Multicast Packets: 0                          Multicast Packets: 0
 No Carrier Sense: 0                           CRC Errors: 0
 DMA Underrun: 0                               DMA Overrun: 0
 Lost CTS Errors: 0                            Alignment Errors: 0
 Max Collision Errors: 0                       No Resource Errors: 0
 Late Collision Errors: 0                      Receive Collision Errors: 0
 Deferred: 0                                   Packet Too Short Errors: 0
 SQE Test: 0                                   Packet Too Long Errors: 0
 Timeout Errors: 0                             Packets Discarded by Adapter: 0
 Single Collision Count: 0                     Receiver Start Count: 0
 Multiple Collision Count: 0
 Current HW Transmit Queue Length: 1

 General Statistics:
 -------------------
 No mbuf Errors: 0
 Adapter Reset Count: 1
 Adapter Data Rate: 2000
 Driver Flags: Up Broadcast Debug 
         Running Simplex 64BitSupport 
         ChecksumOffload PrivateSegment LargeSend 
         DataRateSet 

 10/100/1000 Base-TX PCI-X Adapter (14106902) Specific Statistics:
 -----------------------------------------------------------------
 Link Status : Up
 Media Speed Selected: Auto negotiation
 Media Speed Running: 1000 Mbps Full Duplex
 PCI Mode: PCI-X (100-133)
 PCI Bus Width: 64-bit
 Latency Timer: 144
 Cache Line Size: 128
 Jumbo Frames: Disabled
 TCP Segmentation Offload: Enabled
 TCP Segmentation Offload Packets Transmitted: 681521
 TCP Segmentation Offload Packet Errors: 0
 Transmit and Receive Flow Control Status: Disabled
 Transmit and Receive Flow Control Threshold (High): 49152
 Transmit and Receive Flow Control Threshold (Low): 24576
 Transmit and Receive Storage Allocation (TX/RX): 8/5
To find out the statistics of each adapter in a etherchannel
 # entstat -dt en2 
==> where en2 is a etherchannel device
==> This output give statistics about ent1 and ent2 including the link status and speed.  
To find out the MAC address, Hardware/Physical location of a network card
  # lscfg -vpl ent1 
   ent1             U7879.001.DQDGMBD-P1-T6  2-Port 10/100/1000 Base-TX PCI-X Adapter (14108902)

        2-Port 10/100/1000 Base-TX PCI-X Adapter:
        Network Address.............001125E6ACAA
        ROM Level.(alterable).......DV0210
        Hardware Location Code......U7879.001.DQDGMBD-P1-T6


  PLATFORM SPECIFIC

  Name:  ethernet
    Node:  ethernet@1
    Device Type:  network
    Physical Location: U7879.001.DQDGMBD-P1-T6
Setting multiple IP address for a single network card
 # ifconfig lo0 alias 195.60.60.1 
 # ifconfig en0 alias <IPadress> netmask <net_mask>
To make the alias permaent, either add the above line to /etc/rc.net or /etc/rc.tcpip. You can also make it permanent by running the following command.
 # chdev -l en0 -a alias=<IP_address>,<netmask>
To delete a static route manually
Syntax :-
chdev -l inet0 -a delroute=<net>,<destination_address>,<Gate_way_address>,<Subnet_mask>
 # chdev -l inet0 -a delroute='net','0.0.0.0','172.26.160.2'
To change the IP address of an interface manually
 # chdev -l en0 -a netaddr=192.168.123.1 -a netmask=255.255.255.0 -a state=up
To set the IP address initially
 # mktcpip -h <hostname> -a <ipaddress> -m <subnet_mask> -i <if_name> -n <NameServer_address> 
   -d <domain_name> -g <gateway_address> -A no 
Smit fast paths
 # smit chinet or smit inet
Name resolution order
We can achieve in two ways.
 01. By modifying /etc/netsvc.conf file
 02. By setting NSORDER Variable. (NSORDER Overrides /etc/netsvc.conf.
To change the Network speed
 # ifconfig en0 down detach
 # chdev -l ent0 -a media_speed=......
 # ifconfig en0 up
Network Options:
no
 command is used to change the network tuning parameters.

To list the current network parameters / network options
 # no  -a     
To enable IP forwarding
 # no -o "ipforwarding=1"
To make ipforwarding=1 permanent now and after reboot
 # no -p -o ipforwarding=1
To make the mbuff value to 200000 after the reboot
 # no -r -o ipforwarding=1
To set the ipforwarding to the default level
 # no -d ipforwarding
Network Packet Tracing and analyzing commands
Iptrace, Ipreport and tcpdump commands are used to trace and analyze network packets in AIX.
Using iptrace and ipreport utility:
1. Log in as a root user, then type the following command to start the iptrace utility:
 # startsrc -s iptrace -a -s it-ibm01 \ 
   -d it-ibm100 -p tcp -i en0 /tmp/iptrace.raw 
The utility will capture all packets using TCP protocol through the en0 interface from the source host it-ibm01 to the destination host it-ibm100. Captured packets are logged into the raw file /tmp/iptrace.raw.

2. To stop the iptrace daemon so that it no longer captures packets, type the following command:
 # stopsrc -s iptrace
3. To format the report
 # ipreport -srn /tmp/iptrace.raw > /tmp/iptrace.rpt
Using tcpdump utility:
1. To start tcpdump utility:
 # tcpdump -i en0 -w /tmp/tcpdump.raw host it-ibm01 and it-ibm100 and tcp
2. To read the captured /tmp/tcpdump.raw file
 # tcpdump -v -x -r /tmp/tcpdump.raw > /tmp/tcpdump.rpt
Etherchannel
EtherChannel and IEEE 802.3ad Link Aggregation are network port aggregation technologies that allow several Ethernet adapters to be aggregated together to form a single pseudo Ethernet device. For example, ent0 and ent1 can be aggregated into an EtherChannel adapter called ent3; interface en3 would then be configured with an IP address. The system considers these aggregated adapters as one adapter. In addition, all adapters in the EtherChannel or Link Aggregation are given the same hardware (MAC) address, so they are treated by remote systems as if they were one adapter. Both EtherChannel and IEEE 802.3ad Link Aggregation require support in the switch so it is aware which switch ports should be treated as one.

The adapters that belong to an EtherChannel must be connected to the same EtherChannel-enabled switch. You must manually configure this switch to treat the ports that belong to the EtherChannel as an aggregated link

If an adapter fails, network traffic is automatically sent on the next available adapter without disruption to existing user connections. The adapter is automatically returned to service on the EtherChannel or Link Aggregation when it recovers.

Because the EtherChannel cannot be spread across two switches, the entire EtherChannel is lost if the switch is unplugged or fails. To solve this problem, a new backup option available in AIX 5.2 and later keeps the service running when the main EtherChannel fails. The backup and EtherChannel adapters should be attached to different network switches, which must be inter-connected for this setup to work properly. In the event that all of the adapters in the EtherChannel fail, the backup adapter will be used to send and receive all traffic. When any link in the EtherChannel is restored, the service is moved back to the EtherChannel.
Network Interface Backup
Network Interface Backup protects against a single point of network failure by providing failure detection and failover with no disruption to user connections. When operating in this mode, only one adapter is active at any given time. If the active adapter fails, another adapter in the EtherChannel will be used for all traffic. When operating in Network Interface Backup mode, it is not necessary to connect to EtherChannel-enabled switches.

The Network Interface Backup setup is most effective when the adapters are connected to different network switches, as this provides greater redundancy than connecting all adapters to one switch. When connecting to different switches, make sure there is a connection between the switches. This provides failover capabilities from one adapter to another by ensuring that there is always a route to the currently-active adapter.

To create a etherchannel with Network Backup
 # mkdev -c adapter -s pseudo -t ibm_ech -a adapter_names='ent0' -a backup_adapter='ent2'
 ent3 Available

 # lsattr -El ent3
 adapter_names   ent0           EtherChannel Adapters                       True
 alt_addr        0x000000000000 Alternate EtherChannel Address              True
 auto_recovery   yes            Enable automatic recovery after failover    True
 backup_adapter  ent2           Adapter used when whole channel fails       True
 hash_mode       default        Determines how outgoing adapter is chosen   True
 mode            standard       EtherChannel mode of operation              True
 netaddr         0              Address to ping                             True
 noloss_failover yes            Enable lossless failover after ping failure True
 num_retries     3              Times to retry ping before failing          True
 retry_time      1              Wait time (in seconds) between pings        True
 use_alt_addr    no             Enable Alternate EtherChannel Address       True
 use_jumbo_frame no             Enable Gigabit Ethernet Jumbo Frames        True

Source Link (https://publib.boulder.ibm.com/infocenter/pseries/v5r3/index.jsp?topic=/com.ibm.aix.doc/aixbman/commadmn/tcp_etherchannel.htm)


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

NIM Commands
By Surya21:21No comments
A. INTRODUCTION: OBJECTS AND CLASSES
NIM (the Network Installation Manager) stores all information needed for the installation of servers in objects. Objects are organized in object types and object classes. Here is an overview of the most important object types and classes:

Class	Type	Description
machines	standalone	the client LPAR to be installed via NIM
networks	ent	network definition (network address, gateway)
resources	lpp_source	a set of AIX filesets
resources	mksysb	an mksysb image
resources	spot	a /usr filesystem
resources	fb_script	script, to be executed during the first boot after installation
resources	script	a postinstall script

B. COMMAND OVERVIEW
1. LISTING ALL DEFINED NIM OBJECTS
# lsnim
2. LISTING ALL DEFINED OBJECTS OF A SPECIFIC TYPE
# lsnim -t <type>
3. SHOWING AN OBJECT'S DEFINITION
# lsnim -l <object>
4. DEFINING AN LPP SOURCE
# nim -o define -t lpp_source \
            -a server=master \
            -a location=</path/to/bffs> \
            -a comments=<free text> \
        <lpp source>
5. DEFINING A NETWORK
# nim -o define -t ent \
          -a net_addr=<netaddress>  \
          -a snm=<netmask>  \
          -a routing1="default <gateway>" \
       <network>
6. DEFINING A NIM CLIENT
# nim -o define -t standalone \
           -a platform=chrp \
           -a netboot_kernel=64 \
           -a if1="<network> <ip label> 0 ent" \
           -a cable_type1=tp \
        <client>

You could also use an ip address instead of an ip label here
7. DEFINING AN MKSYSB RESOURCE
# nim -o define -t mksysb \
        -a server=master \
        -a comments="<free text>" \
        -a location=<directory> \
    <mksysb>
8. DEFINING AN IMAGE_DATA RESOURCE
# nim -o define -t image_data \
        -a server=master \
        -a comments="<free text>" \
        -a location=</path/to/image_data> \
    <image_data>
9. CREATING A SPOT FROM AN LPP SOURCE
# nim -o define -t spot \
            -a server=master \
            -a source=<lpp source> \
            -a location=<directory> \
            -a comments="<free text>" \
        <spot>
10. CREATING A SPOT FROM AN MKSYSB
# nim -o define -t spot \
        -a server=master \
        -a source=<mksysb> \
        -a location=<directory> \
        -a comments="<free text>" \
    <spot>

Use the base directory for your spots here rather than a spot specific directory. NIM automatically creates a subdirectory with the name of the spot object: <spot>
11. PREPARE SPOT AND LPP SOURCE FOR AN ALTERNATE DISK MIGRATION
# nimadm -M -s <spot> -l <lpp source> -d <source directory>

In <source directory> NIM searches for the two filesets «bos.alt_disk_install.rte» and «bos.alt_disk_install.boot_images». nimadm then updates spot and LPP source with these two filesets. This way you can migrate a client to a lower AIX level then the level of the NIM server itself. This feature has been added to NIM with AIX 7.1.
12. MODIFYING A CLIENT DEFINITION
# nim -o change -a <attribute>=<value> <client>

You find the exact names of valid attributes in the output of lsnim -l <client>. The option change is used to change the value of an attribute, e.g. if you want to change a client's netboot kernel from 64 to mp you would type:

# nim -o change -a netboot_kernel=mp <client>
13. RE-INITIALIZING A CLIENT
If a client's /etc/niminfo is out of date. It can be rewritten by the below procedure:

client# rm /etc/niminfo
client# niminit -a name=<client> -a master=<nimserver> -a connect=nimsh¹

This procedure is useful if you want to move a client from one NIM server to another. In this case remember to first create the client on the server before running this procedure.
¹ "-a connect=nimsh" is optional and only required if you don't want the NIM server to communicate via rsh with the client.
14. INSTALLING A CLIENT
# nim -o bos_inst \
           -a spot=<spot> \
           -a lpp_source=<lpp source> \
           -a fb_script=<script> \
           -a script=<postinstall script> \
           -a no_client_boot=yes \
           -a accept_licenses=yes \
        <client>

Use the option no_client_boot=yes if you don't want NIM to initiate a reboot of your LPAR over rsh. You have to manually boot the LPAR from the SMS menu then - what is probably what you want.
15. INSTALLING A CLIENT WITH AN MKSYSB IMAGE
# nim -o bos_inst \
           -a source=mksysb \
           -a spot=<spot> \
           -a mksysb=<mksysb> \
           -a lpp_source=<lpp source> \
           -a fb_script=<script> \
           -a script=<postinstall script> \
           -a no_client_boot=yes \
           -a accept_licenses=yes \
        <client>
16. RESET A NIM CLIENT
# nim -F -o reset <client>

resets a NIM client so new operations can be done. Please note that often it's not enough to just reset a NIM object because there are still resources allocated for the client. You find all resources still allocated to the client with lsnim -l <client>. They can be removed with:
# nim -o deallocate -a spot=<spot> -a ...=... <client>

To remove all resources from a client simply run:
# nim -o deallocate -a subclass=all <client>
17. QUERY A CLIENT FOR INSTALLED APARS
# nim -o fix_query <client>

This command is useful to check for your nimserver can reach the client.
18. ENABLING A MAINTENANCE BOOT
# nim -o maint_boot -a spot=<spot> <client>

Now you can boot your client over the network into a maintenance shell.
19. START AN ALTERNATE DISK MIGRATION
# nimadm -c <client> -l <lpp source> -s <spot> -d <hdisk> -Y


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

nmon command
By Surya00:19No comments

Purpose
Displays local system statistics in interactive mode and records system statistics in recording mode.
Syntax
Interactive mode:
nmon [-h ]
nmon [ -s < seconds > ] [ -c < count > ] [ -b ] [ -B ] [ -g < filename > ] [ -k disklist ] [ -C < process1:process2:..:processN > ]
Recording mode:
nmon [ -f | -F filename | -x | -X | -z ] [ -r < runname > ] [ -t | -T | -Y ] [ -s seconds ] [ -c number ] [ -w number ] [ -l dpl ] [ -d ] [-g filename ] [ -k disklist ] [ -C <process1:process2:..:processN > ] [ -G ] [ -K ] [ -o outputpath ] [ -D ] [ -E ] [ -J ] [ -V ] [ -P ] [ -M ] [ -N ] [ -W ] [ -S ] [ -^ ] [ -O ] [ -L ] [ -I percent ] [ -A ] [ -m < dir > ] [ -Z priority ]
Note: In recording mode, specify only one of the -f, -F, -z, -x, or -X flags as the first argument.
Description
The nmon command displays and records local system information. The command can run either in interactive or recording mode. If you specify any of the -F, -f, -X, -x, and -Z flags, the nmon command is in recording mode. Otherwise, the nmon command is in interactive mode.
The nmon command provides the following views in interactive mode:
System resources view(using the r key)
Process view (using the t and u keys)
AIO processes view (using the A key)
Processor usage small view (using the c key)
Processor usage large view (using the C key)
Shared-processor logical partition view (using the p key)
NFS panel (using the N key)
Network interface view (using the n key)
WLM view (using the W key)
Disk busy map (using the o key)
Disk groups (using the g key)
ESS vpath statistics view (using the e key)
JFS view (using the j key)
Kernel statistics (using the k key)
Long term processor averages view (using the l key)
Large page analysis (using the L key)
Paging space (using the P key)
Volume group statistics (using the V key)
Disk statistics (using the D key)
Disk statistics with graph (using the d key)
Memory and paging statistics (using the m key)
Adapter I/O statistics (using the a key)
Shared Ethernet adapter statistics (using the O key)
Verbose checks OK/Warn/Danger view (using the v key)
Detailed Page Statistics (using the M key)
Fibre Channel adapter statistics (using the ^ key)

In the recording mode, the command generates the nmon files. You can view these files directly by opening them or with post processing tools such as nmon analyzer. The nmon tool disconnects from the shell during the recording, ensuring that the command continues running even if you log out.
If you use the same set of keys every time the nmon command is started, you can place the keys in the NMON shell variable. For example, you can run the following command:

export NMON=mcd

Then, run the nmon command.
To stop the nmon command from the command line, use the kill -USR2 with the nmon process ID.
To print the background process IDs of the nmon recording, run the nmon command with the -p flag.
To limit the processes that the nmon command lists (online and to a file), you can utilize the following options:
Set the program names in environment variables from NMONCMD0 to NMONCMD63
Use the -C flag with cmd:cmd:cmd parameter. For example, you can enter the following command:
nmon -C ksh:vi:syncd
To limit the disks that the nmon lists to a maximum of 64 (online only), use the -k flag with the diskname parameter. For example, you can enter the following command:
nmon -k hdisk2,hdisk0,hdisk3
The nmon tool disconnects from the shell during the recording, ensuring that the command continues running even if you log out. This function is not true in the case of recordings triggered using the on-demand recording facility.
Recording or monitoring journaled file system (JFS) statistics in nmon can prevent unloading a file system because the file system is in use while collecting statistics.
Inside workload partitions (WPAR), the nmon command shows global values for processors and memory statistics. The rest of the values are WPAR specific. The following statistics cannot be retrieved inside aWPAR, and the nmon screen does not support them inside aWPAR:
Disks, disk I/O graphs, disk busy map, disk groups
Disk adapters
Paging space
Volume group
ESS/vpaths
Fibre Channel adapters
VIOS Shared Ethernet adapters
Flags in Interactive Mode
You can use the following flags in the interactive mode.
Item	Description
-s < seconds >	Time interval between refreshing the screen. The default value is 2 seconds.
-c < count >	Number of times the screen must be refreshed.
-g < filename >	A file that contains user-defined disk groups that can be specified using the filenameparameter. Each line in the file begins with a group name. The list of hard disks follows the group name and is separated by spaces. The file can contain a maximum of 64 disk groups. A hard disk can belong to various disk groups.
-b	Displays the view in black and white mode.
-B	Does not include boxes in the view. By default, the command displays boxes.
-h	Displays help information.
-k < disklist >	Reports only the disks in the disk list.
Flags in Recording Mode
Item	Description
-A	Includes the Asynchronous I/O section in the view.
-c	Specifies the number snapshots that must be taken by the command. The default value is 10000000.
-d	Includes the Disk Service Time section in the view.
-D	Skips the Disk Configuration section.
-E	Skips the ESS Configuration section.
-f	Specifies that the output is in spreadsheet format. By default, the command takes 288 snapshots of system data with an interval of 300 seconds between each snapshot. The name of the output file is in the format ofhostname_YYMMDD_HHMM.nmon.
-F	Specifies that the output is in spreadsheet format and the name of the output file is filename. The filenameparameter specifies the name of the output file.
-g	Specifies the file that contains the user-defined disk groups, using the filename parameter. Each line in the file begins with a group name. The list of disks follows the group name and is separated with spaces. The file can contain a maximum of 64 disk groups. A disk can belong to various disk groups.
-G	Uses Greenwich mean time (GMT) instead of local time. This method is helpful when you compare nmon files from many LPARs of 1 system for processor view but the LPARs are in different time zones.
-I	Specifies the percentage of process threshold at which the command ignores the TOP processes statistics. The default percentage is zero. The command does not save the TOP processes statistics if the process is using less processor than the specified percentage.
-J	Skips the JFS section.
-k	Specifies a list of disks to be recorded.
-K	Includes the RAW Kernel section and the LPAR section in the recording file. The -K flag dumps the raw numbers of the corresponding data structure. The memory dump is readable and can be used when the command is recording the data.
-l	Specifies the number of disks to be listed on each line. By default, 150 disks are listed per line. For EMC disks, specify a value of 64.
-L	Includes the large page analysis section.
-m	Changes the directory before the command saves the data to a file.
-M	Includes the MEMPAGES section in the recording file. The MEMPAGES section displays detailed memory statistics per page size.
-N	Includes the NFS section in the recording file. To collect the NFSv4 statistics, specify -NN.
-o	Specifies the file name or directory to which the recorded file is to be stored.
-O	Includes the Shared Ethernet adapter (SEA) VIOS sections in the recording file.
-P	Includes the Paging Space section in the recording file.
-r	Specifies the value for the runname field written to the spreadsheet file. By default, the value is the hostname.
-s	Specifies the interval in seconds between 2 consecutive recording snapshots.
-S	Includes WLM sections with subclasses in the recording file.
-t	Includes the top processes in the output. You cannot specify the -t, -T, or -Y flags with each other.
-T	Includes the top processes in the output and saves the command-line arguments into the UARG section. You cannot specify the -t, -T, or -Y flags with each other.
-V	Includes disk volume group section.
-w	Specifies the size of timestamp (Tnnnn) to be recorded. The timestamp is recorded in the .csv file. The value of the number parameter ranges from 4 through 16. For NMON analyzer, use the values 4 or 8.
-W	Includes the WLM sections into the recording file.
-x	Specifies the sensible spreadsheet recording for duration of 1 day for capacity planning. By default, the recording is done every 900 seconds for 96 times. This flag is equivalent to -ft -s 900 -c 96.
-X	Specifies the sensible spreadsheet recording for duration of 1 hour for capacity planning. By default, the recording is done every 30 seconds for 120 times. This flag is equivalent to -ft -s 30 -c 120.
-Y	Includes the top process in the recording with all of the commands of the same name added and recorded. You cannot specify the -t, -T, or -Y flags together.
-z	Specifies the sensible spreadsheet recording for duration of 1day for capacity planning. By default, the recording is done every 900 seconds for 96 times. This flag is equivalent to -f -s 900 -c 96.
-Z	Specifies the priority of the nmon command that is running. A value of -20 means important. A value of 20 means not important. Only root user can specify negative value.
-^	Includes the Fibre Channel (FC) sections.
Parameters
Item	Description
disklist	Specifies a list of disks.
dir	Specifies a directory.
dpl	Specifies the number of disks to list on each line.
filename	Specifies a file that contains the disk group you select.
number	Specifies the number of refreshes.
count	Specified the number of times to record.
percent	Specifies the percentage of processor usage.
priority	Specifies the priority of processes to be run.
runname	Specifies the value for the runname field in the spreadsheet file to be run.
seconds	Specifies the interval, in seconds, of refreshing the snapshot.
outputpath	Specifies the path for the output file.
Subcommands
Item	Description
space	Refreshes the screen immediately.
.	Displays only busy disks and processes.
~	Switches to the topas screen.
^	Displays the Fibre Channel adapter statistics
+	Doubles the screen refresh time.
-	Decreases the screen refresh time by half.
0	Resets the peak values of statistics (displayed on the screen) to zero. Applicable only for panels that display peak values.
a	Displays the I/O statistics of the adapters.
A	Summarizes the Async I/O (AIO server) processes.
b	Displays the view in black and white mode.
c	Displays processor statistics with bar graphs.
C	Displays processor statistics. It is useful for comparison when the number of processors ranges from 15 to 128.
d	Displays the I/O information of disks. To display specific disks only, specify the -k flag.
D	Displays the I/O statistics of disks. To get additional statistics of the disks, press the D key more than once.
e	Displays the I/O statistics of the ESS virtual path logical disks.
g	Displays the I/O statistics of the Disk Group. You must specify the -g flag with this key.
h	Displays the online help information.
j	Displays the JFS statistics.
k	Displays the internal statistics of the kernel.
l	Displays the processor statistics in long format. More than 75 snapshots are displayed with bar graphs.
m	Displays the memory and paging statistics.
M	Displays multiple page size statistics in pages. If you press the M key twice, the statistics are displayed in megabytes.
n	Displays the network statistics.
N	Displays the statistics of the NFS Network file system. If you press the N key twice, you see the NFSv4 statistics.
o	Displays the map of Disk I/O.
O	Displays only the Shared Ethernet adapter VIOS.
p	Displays the statistics of the partitions.
P	Displays the statistics of the paging space.
q	Quits. You can also use the x, or Ctrl+C key sequence.
r	Displays the resource type, system name, cache details, AIX® version, and the LPAR information.
S	Displays the WLM with subclasses.
t	Displays the statistics of top processes. You can press the following keys with this subcommand:
1: Displays basic details.
2: Displays accumulated process information.
3: Sorts the view by processor.
4: Sorts the view by size.
5: Sorts the view by I/O information.
u	Displays the top processes with the command arguments. To refresh the arguments for new processes, press the u key twice.
U	Displays the top processes with the command arguments, and the workload class or workload partitioninformation.
v	Highlights status of pre-defined system resources and categorizes them as either danger, warnings, or normal.
V	Displays the statistics of the Disk Volume Group.
w	Displays the wait processes when used with the top processes.
W	Displays the statistics of the Workload Manager (WLM).
[	Triggers a custom on-demand recording. The recording initiated exits along with the interactive nmon if not stopped earlier.
]	Stops a custom recording triggered by ] .
Output Details
This section provides explanations to the metrics that are displayed on nmon screen.
System resources view




This view provides general information about the system resources. To display this view, press the r key. It contains information about the following resources:
The number of processors in the system.
The number of online processors that are active in the system.
The frequency of the processors.
The version of AIX and its technical level.
The type of the running kernel.
The logical partition.
The power savings mode of the logical partition.
The model of the hardware.
The processor architecture of the system.
The type of the platform bus.
The cache information of processors.
The number of active events.
The old serial number. This number is the system ID of the partition before the dynamic configuration event.
The current serial number. This number is the current system ID or the system ID of the partition after the dynamic configuration event.
The local time of the last dynamic reconfiguration event. This information is labeled with the "When" keyword.
AIO Processes View
The AIO processes view provides information about the asynchronous I/O (AIO) processes. To display this view, press the A key. The following columns are displayed on the screen:
Item	Description
Total AIO Processes	The total number of AIO processes.
Actually in use	The number of AIO processes that uses more than 0.1% of the processor.
CPU Used	The percentage of the processor that is used by all of the kernel processes.
All time peak	The maximum number of kernel processes that are running since the system starts.
Recent peak	The recent maximum number of kernel processes that use more than 0.1% of the processor.
Peak	The maximum percentage of the processor that is used by all of the kernel processes.
Process View
The Process View provides details of the processes in the system. To display this view, press the t key or the v key. It contains the following columns are displayed on the screen:
Item	Description
pid	The ID of the process.
ppid	The ID of the parent process.
User	The user ID of the process.
Proc Group	The ID of the process group.
Nice	The initial priority of a process. This value is set by the nice command.
Priority	The base schedule priority of a process.
Status	The status of a program.
Proc_Flag	The flag of a process.
Thrds	The number of threads.
Files	The maximum file index that is in use.
Foreground	Foreground process or background process.
Command	The name of the command.
Time Start	The time when the command started.
CPU-Total	The total time that the process takes since it starts.
Child Total	The total time that the child process takes since it starts.
Delta-Total	The total time taken by the process in the interval.
%CPU Used	The percentage of the processor that is used in the last interval.
Size KB	The size of the pages in kilobytes.
Res Size	The sum of real-memory data (resident set) and real-memory (resident set) text size of the process.
Res Set	The sum of real-memory data (resident set) and real-memory (resident set) text size of the process.
Res Text	The real-memory text size of the process.
Res Data	The real-memory data size of the process.
Char I/O	The number of I/O characters per second from the last interval.
RAM Use	The percentage of the RAM that is used.
Paging I/O	The I/O page faults per second in the last interval.
Paging Other	The non-I/O page faults per second in the last interval.
Paging Repages	The number of repage faults per second in the last interval.
Class	The Workload Manager class name of the process.
Processor Usage Small View
The Processor Usage Small View provides a brief summary of the user, system, idle, and wait time of logical processors, the corresponding entitlement, and the virtual processor used. You can generate the Processor Usage Small View using the c key.
Processor Usage Large View
The Processor Usage Large View displays the use of logical processor in a graph. To display this view, you can press the C key.
The following labels are used to identify time spent in different modes:
s: Labels the percentage of time spent in system mode
u: Labels the percentage of time spent in user mode
Shared-Processor Logical Partition View
The Shared-Processor Logical Partition View includes flags that indicate the following information of a partition:
Whether the partition is an LPAR or not
Whether the partition can be an LPAR or not
Whether the partition is shared or dedicated
Whether the SMT is turned on or off
Whether the shared-partition is capped or uncapped
To display this view, you can press the p key.
Processors:
The following metrics of the processor status are displayed in this view:
Item	Description
Max Phys in Sys	Maximum number of physical processors in the system
Phys CPU in system	Number of physical processors in the system
Virtual Online	Number of online virtual processors
Logical online	Number of online logical processors
Physical pool	Number of shared physical processors in the shared pool ID that this partition is assigned to
SMT threads/CPU	Number of SMT threads per processor
Capacity:
The following information displays the processor capacity:
Item	Description
Cap. Processor Min	Minimum number of processing units that are defined for this LPAR
Cap. Processor Max	Maximum number of processing units that are defined for this LPAR
Cap. Increment	Granularity at which changes to the entitled capacity can be made
Cap. Unallocated	Sum of the number of processor units that are unallocated from shared LPARs in an LPARgroup
Cap. Entitled	Entitled capacity
MinReqVirtualCPU	Minimum required virtual processors for this LPAR
ID Memory:
The following metrics of the ID memory are displayed:
Item	Description
LPAR ID Group:Pool	ID of an LPAR group and its pool ID
Memory (MB/GB) Min:Max	Minimum and maximum memory that is defined for this LPAR in megabytes or gigabytes
Memory(MB/GB) Online	Online real memory in megabytes or gigabytes
Memory Region LMB	Size in bytes of one logical memory block (LMB)
Time (in seconds):
Item	Description
Time Dispatch Wheel	Interval during which each virtual processor receives its entitlement
MaxDispatch Latency	Maximum latency in seconds between the dispatch of the LPAR on the physical processors
Time Pool Idle	Time in seconds that the shared processor pool is idle
Time Total Dispatch	Total time in seconds that the LPAR dispatches
Minimum and Maximum Values of Processors
The following minimum and maximum values of processors are displayed:
Item	Description
Virtual CPU ( Min - Max )	Minimum number and maximum number of virtual processors in the LPARdefinition
Logical CPU ( Min - Max )	Minimum number and maximum number of logical processors
Weight
The following information about the weight of the processor is displayed:
Item	Description
Weight Variable	Variable weight of the processor capacity
Weight Unallocated	Unallocated variable weight available for this partition
NFS Panel
The NFS Panel provides information about the Network File System (NFS). To display this view, press the N key. The following metrics are included in the view:
Item	Description
Root	NFS V2 server and client root requests
Wrcache	NFS server and client write cache requests
Null	NFS server and client write cache requests
Getattr	NFS server and client get attributes requests
Setattr	NFS server and client set attributes requests
Lookup	NFS server and client filename lookup requests
Readlink	NFS server and client read link requests
Read	NFS server and client read requests
Write	NFS server and client write requests
Create	NFS server and client file creation requests
Mkdir	NFS server and client directory creation requests
Symlink	NFS server and client symbolic link creation requests
Remove	NFS server and client file removal requests
Rmdir	NFS server and client directory removal requests
Rename	NFS server and client file renaming requests
Link	NFS server and client link creation requests
Readdir	NFS server and client read-directory requests
Fsstat	NFS server and client file-status requests
Access	NFS V3 server and client access requests
Mknod	NFS V3 server and client mknod creation requests
readdir+	NFS V3 server and client read-directory plus requests
Fsinfo	NFS V3 server and client file information requests
Pathconf	NFS V3 server and client path configuration requests
Commit	NFS server and client commit requests
Bad calls	NFS server and client failed calls
Calls	NFS server and client requests
The following NFS V4 client/server statistics are printed when you press the N key twice.
Item	Description
Access	NFS V4 server and client access requests
acl_read	NFS V4 client reading access control list (ACL)
acl_stat_l	NFS V4 client retrieving long ACL information
acl_write	NFS V4 client write access control list (ACL)
Clntconfirm	NFS V4 client confirm operations
Close	NFS V4 client closing files
Commit	NFS V4 server and client committed
Compound	NFS V4 server compound calls
Create	NFS V4 server and client creating a non-regular object
Delegpurge	NFS V4 server purge delegations awaiting recovery
Delegreturn	NFS V4 server and client returning delegation
Finfo	NFS V4 client obtaining file information
getattr	NFS V4 server and client retrieving attributes
getfh	NFS V4 server retrieving file handles
Link	NFS V4 server and client linking operations
Lock	NFS V4 server and client locking operations
lockt/test	NFS V4 server testing the specified lock or NFS V4 client lock test
locku/unlock	NFS V4 server or NFS V4 client unlock operations
lookup	NFS V4 server and client looking up filenames
lookupp	NFS V4 server looking up parent directories
mkdir	NFS V4 client creating directories
mknod	NFS V4 client creating special files
Null	NFS V4 server null calls or NFS V4 client null calls
nverify	NFS V4 server verifying difference in attributes
openattr	NFS V4 server opening named attribute directories
openconfirm	NFS V4 server and client confirming the open for usage
opendowngrade	NFS V4 server and client downgrading the access for a specified file
Open	NFS V4 server and client open operations
operations	NFS V4 server and client operations
pcl_read	NFS V4 client extracting numeric data from printer control language (PCL) files
pcl_readstat_l	NFS V4 client pcl_stat long operations
pcl_stat	NFS V4 client pcl_stat operations
pcl_write	NFS V4 client pcl_write operations
putfh	NFS V4 server setting current file handles
putpubfh	NFS V4 server setting public file handles
putrootfh	NFS V4 server setting root file handles
readdir	NFS V4 server and client reading directories
readlink	NFS V4 server and client reading symbolic links
Read	NFS V4 server and client reading data from files
release	NFS V4 server and client release_lock operations
remove	NFS V4 server and client removing file system object
rename	NFS V4 server and client renaming object names
renew	NFS V4 server and client renewing leases
replicate	NFS V4 client replicate operations
restorefh	NFS V4 server restoring file handles
rmdir	NFS V4 client removing directories
savefh	NFS V4 server saving file handles
secinfo	NFS V4 server and client obtaining security information
setattr	NFS V4 server and client setting object attributes
setclient	NFS V4 server and client setclient operations
statfs	NFS V4 client file statistics requests
symlink	NFS V4 client symbolic link operations
verify	NFS V4 client verifying same attributes
write	NFS V4 server and client writing to files
Network Interface View
The Network Interface View shows the statistics errors for the network. You can view this information by pressing the n key.
If the screen is updated 3 times with no network errors, the Network Interface View does not contain the network error statistics.
The following metrics are displayed in this view:
Item	Description
I/F Name	Interface name
Recv-KB/s	Data received in kilobytes per second in the interval
Trans-KB/s	Data transmitted in kilobytes per second in the interval
Packin	Number of packets received in the interval
Packout	Number of packets sent in the interval
Insize	Average size of packet received in the interval
Outsize	Average size of packet sent in last interval
Peak->Recv	Peak value of received data in kilobytes per second
Peak->Trans	Peak value of sent data in kilobytes per second
Total Recv	Total received data in megabytes per second
Total Sent	Total sent data in megabytes per second
MTU	Maximum size of transport unit in bytes
Ierror	Number of input errors
Oerror	Number of output errors
Collision	Number of collision
Mbits/s	Adapter bit rate in megabits per second
Description	Description of the interface
WLM View
The WLM View displays the information about workload management. You can display this view using the W key. To turn on the subclasses section, press the S key from WLM View. To turn off the subclasses section, press the S key again.
The following metrics are displayed in this view:
Item	Description
CPU	Percentage of processor use of the class.
MEM	Percentage of physical memory use of the class.
BIO	Percentage of disk I/O bandwidth use for the class.
Process (Procs)	Number of processes in the class.
Tier (T)	Tier number. The value ranges from zero through nine.
Inheritance (I)	Values of the inheritance attribute. A value of zero means no. A value of one means yes.
Location	Values of location. A value of one means avoiding transfer of segments to shared classes. Otherwise, a value of zero is displayed.
Disk Busy Map
The Disk Busy Map shows the use statistics of disks. To display this map, press the o key. A maximum of 100 disks is shown per screen. Only the disks with the names ranging from hdisk0 through hdisk100 are displayed. The following table shows the symbols for the ranges of names.
Symbols	Names
_	Less than 5
.	Less than 10
-	Less than 20
+	Less than 30
o	Less than 40
0	Less than 50
O	Less than 60
8	Less than 70
X	Less than 80
#	Less than 90
@	Less than 100 and equal to 100
Disk Groups
Multiple disks can be monitored by placing them in groups. To display this view, press the g key.
You need to create a group configuration file containing the lines as shown in the following example:
<Group_name1> <disk_name1> <disk_name2> ....
<Group_name2> <disk_nameA> <disk_nameB> ... 
In the example, <Group_name1> is the name of the first disk in the group; <disk_name1> and <disk_name2> are the first and second disks in the group.
To see the Disk Group I/O, run the nmon command with the -g flag and a group file, and then press the g key. The following metrics are shown in this view:
Item	Description
Name	Disk Group name. You can specify a maximum of 64 groups. A disk can be in multiple groups.
Disks	Number of disks in the group.
Read/Write-KB/s	Data transfer rate of read and written data in kilobytes per second in the interval.
TotalMB/s	Sum of read and written data in megabytes per second in the interval.
Xfers/s	Number of read and written data transfers per second in the interval.
BlockSizeKB	Block size in kilobytes read or written per transfer operation.
ESS Vpath Statistics View
This view provides the ESS Vpath Statistics. To display this view, press the e key. The following metrics are included in this view:
Item	Description
Name	Name of the virtual path.
Size	Size of the ESS path.
AvgBusy	Average busy use of the disk.
Write-KB/s	Transfer rate of written data in kilobytes per second in the interval.
Read-KB/s	Transfer rate of read data in kilobytes per second in the interval.
Xfers/s	Number of read and write transfers per second.
Total vpaths	Number of virtual paths.
JFS View
This view provides the Journaled File System (JFS) statistics. To display this view, press the j key. The following statistics are recorded in this view:
Item	Description
FileSystem	Name of the file system.
Size (MB)	Size in megabytes for the file system.
Free (MB)	Available free space in megabytes in the file system.
%Used	Percent of file system used.
%Inodes	Percent of file system used by i-nodes.
Mount point	Local mount point.
Kernel Statistics
This view contains the statistics of the kernel. To display this view, press the k key. The following statistics are displayed in this view:
Item	Description
runqueue	Average number of threads that are ready to run but are waiting for an available processor.
pswitch	Number of processor switches per second in the interval.
fork	Number of forks per second in the interval.
exec	Number of execs per second in the interval.
msg	Number of interprocess communication (IPC) messages sent and received per second in the interval.
sem	Number of semaphore operation system calls per second in the interval.
hw intrp	Number of device interrupts per second in the interval.
sw intrp	Number of off-level handlers called per second in the interval.
Swapin	Number of processes in swap queue per second in the interval.
Syscall	Number of system calls per second in the interval.
read	Number of read calls per second in the interval.
write	Number of write calls per second in the interval.
readch	Number of characters transferred through read system call per second in the interval.
Writech	Number of characters transferred through write system call per second in the interval.
R + W (MB/s)	Number of read and write characters in megabytes per second in the interval.
Uptime	Time duration for which the system is up.
iget	Number of inode lookups per second in the interval.
dirblk	Number of 512-byte block reads by the directory search routine to locate an entry for a file per second in the interval.
namei	Number of vnode lookup from a path name per second in the interval.
ksched	Number of kernel processes created per second in the interval.
koverf	Number of kernel process creation attempts where the user forked to the maximum limit or the configuration limit of processes reached per second in the interval.
kexit	Number of kernel processes that become zombies per second in the interval.
Long Term Processor Averages View
This view provides information about the instantaneous system. To display this view, press the l key. You can use the following labels to identify the time spent in different modes:
s: Labels the percentage of the time spent in system mode.
u: Labels the percentage of the time spent in user mode.
w: Labels the percentage of the time spent in wait mode.
The following metrics are displayed on this view:
Item	Description
EntitledCPU	Entitled capacity of the partition.
UsedCPU	Number of physical processors used by the partition.
Large Page Analysis
This view provides analysis of the large page. To display this view, press the L key. The following information is displayed:
Item	Description
Count	Number of large pages and their total size.
Free	Percentage of free large pages and their size.
In Use	Percentage of large pages in use and their size.
Size	Size of a large page.
High water mark	Large page high watermark.
Paging Space
This view prints the paging-space statistics. To display this view, press the p key. The following metrics are displayed in the view:
Item	Description
PagingSpace	Number of paging space.
Volume-Group	Number of volume groups.
Type	Type of logical volumes. The types can be NFS or LV.
LPs	Size of logical partitions.
MB	Size in megabytes.
Used	Percentage of use for volume groups.
IOpending	Number of pending I/O in the paging space.
Active/Inactive	Active or inactive paging space.
Auto/NotAuto	Indicates whether the paging space is auto loaded or not.
Volume Group Statistics
This view provides statistics for the volume group. To display this view, press the V key. The following information is displayed in the view:
Item	Description
Name	Volume group name.
Disks	Number of disks in the group.
AvgBusy	Average busy of the disks in the volume group.
Read/Write-KB/s	Data transfer rate of read and written data in kilobytes per second in the interval.
TotalMB/s	Sum of read and written data in megabytes per second in the interval.
Xfers/s	Number of read and written transfers per second in the interval.
BlockSizeKB	Block size read or written per transfer in kilobytes per second in the interval.
Disk Statistics
This view provides statistics for disks. To display this view, press the D key. You can press the D key for the following times to view various metrics:
Once (https://pic.dhe.ibm.com/infocenter/aix/v6r1/topic/com.ibm.aix.cmds/doc/aixcmds4/nmon.htm#nmon__once): Shows disk numbers
Twice (https://pic.dhe.ibm.com/infocenter/aix/v6r1/topic/com.ibm.aix.cmds/doc/aixcmds4/nmon.htm#nmon__twice): Shows disk descriptions
Three times (https://pic.dhe.ibm.com/infocenter/aix/v6r1/topic/com.ibm.aix.cmds/doc/aixcmds4/nmon.htm#nmon__three): Shows service times
Four times (https://pic.dhe.ibm.com/infocenter/aix/v6r1/topic/com.ibm.aix.cmds/doc/aixcmds4/nmon.htm#nmon__four): Shows disk statistics with graphs similar to the graph shown on pressing the d key
Disk Numbers (Pressing the D key once)
The following metrics are shown in this view:
Item	Description
Name	Name of the disks.
Busy	Average busy of the disks.
Read-KB/s	Data transfer rate of read data in kilobytes per second in the interval.
Write-KB/s	Data transfer rate of written data in kilobytes per second in the interval.
Transfers/sec	Number of read and written transfer per second in the interval.
SizeKB	Block size read or written per transfer in kilobytes per second in the interval.
Peak	Peak percentage of average busy.
Peak KB/s	Peak read and written data in kilobytes per second.
qDepth	Number of requests sent to disk and are not completed.
Totals Size (GB)	Total size of disks in gigabytes.
Totals Free (GB)	Total free space left in disks in gigabytes.
Totals Read (MB/s)	Total data transfer rate of read data from all disks in megabytes per second.
Totals Write (MB/s)	Total data transfer rate of written data to all disks in megabytes per second.
Disk Descriptions (Pressing the D key twice)
The following metrics are shown in this view:
Item	Description
Name	Disk names.
Size (GB)	Size of disks in gigabytes.
Free (GB)	Free space left in disk in gigabytes.
Disk Paths	Number of paths defined to the disk.
Disk Adapter	Name of disk adapters.
Volume Group	Volume group that the disk belongs to.
Disk Description	Description of the disk.
Totals Size (GB)	Total size of disks in gigabytes.
Totals Free (GB)	Total free space left in disks in gigabytes.
Totals Read (MB/s)	Total data transfer rate of read data from all disks in megabytes per second.
Totals Write (MB/s)	Total data transfer rate of written data to all disks in megabytes per second.
Service Times (Pressing the D key three times)
The following metrics are displayed in the view:
Item	Description
Disk	Name of the disk.
Service (in msecs)	Average service time per request in milliseconds.
Wait (in msecs)	Average waiting time per request in milliseconds.
ServQ size	Average number of requests in service queue.
WaitQ size	Average number of requests waiting to be accomplished.
ServQ Full	Number of times the disk is not accepting any coming requests.
Totals Size (GB)	Total size of disks in gigabytes.
Totals Free (GB)	Total free space left in disks in gigabytes.
Totals Read (MB/s)	Total data transfer rate of read data from all disks in megabytes per second.
Totals Write (MB/s)	Total data transfer rate of written data to all disks in megabytes per second.
Disk Statistics With Graphs (Pressing the D key four times)
This view displays disk statistics with graphs. To display this view, press the d key. The following metrics are displayed in this view:
Item	Description
Name	Name of the disk.
Busy	Average percentage of busy for the disk.
Read-KB/s	Data transfer rate of read data in kilobytes per second.
Write-KB/s	Data transfer rate of written data in kilobytes per second.
Memory and Paging Statistics
The view provides information about the memory and paging statistics. To display this view, press the m key. The following metrics are included in this view:
Item	Description
%Used	Percentage of used space in physical memory and paging space.
%Free	Percentage of free space in physical memory and paging space.
MB Used	Physical memory and paging space that are used in megabytes.
MB Free	Physical memory and paging space that are free in megabytes.
Pages/sec to Paging Space	Number of I/O pages transferred to or from the paging space per second.
Pages/sec to file system	Number of I/O pages transferred to or from the file system per second.
Page Scans	Number of page scans by clock.
Page Faults	Number of page faults.
Page Cycles	Number of page replacement cycles.
Page Steals	Number of page steals.
Numperm	Number of frames used for files (in 4-KB pages).
Process	Percentage of real memory used by process segments.
System	Percentage of real memory used by system segments.
Free	Percentage of real memory that is free.
Total	Percentage of total real memory used.
Min/Maxperm	The minperm and maxperm values for page steals.
Min/Maxfree	The minfree and maxfree pages free list.
Min/Maxpgahead	Minimum and maximum number of page ahead pages.
Total Virtual	Total virtual memory.
Accessed Virtual	Active virtual memory.
Numclient	Number of client frames.
Maxclient	Maximum number of client frames.
User	Real memory used by non-system segments.
Pinned	Real memory that is pinned.
The AMS statistics are displayed in the topas_nmon memory panel. To display this view, press the m key. The following metrics are included in this view:
Item	Description
Pool	AMS pool ID of the pool that the logical partition (LPAR) belongs to.
Weight	Weight of the variable memory.
pMem	Physical memory currently backing up the logical memory partition (in MB).
hpi	Number of hypervisor page-ins.
hpit	Time spent in hypervisor page-ins (in seconds).
Storage Pool Statistics for Next Gen VIOS
This view provides the logical organization of one or more physical volumes in a Next Gen VIOS environment that blocks the storage. The block storage capacity of the storage pool is the summation of the capacity for all physical volumes in the pool.
start of changeThe topas_nmon recording includes the following storage pool metrics:end of change
List of cluster configuration for all nodes:
Item	Description
start of changeCluster Configurationend of change	Records the cluster configuration by using the topas_nmon recording for both AIX and VIOS.
CLUSTER NAME	Unique name that is used to identify a specific Next Gen VIOS cluster.
Type	Type of the cluster.
SHID	Unique identifier to specify size of the cluster.
UUID	Unique cluster identifier.
Note: start of change The topas_nmon records cluster configuration for both AIX and VIOS while the remaining mapping information is specific to VIOS.end of change
List of available storage pools:
Item	Description
Pool	Storage pool name.
Size (mb)	Total size in MB.
Free (mb)	Free space in MB.
LUs	Number of logical units.
Type	Type of pool.
PoolID	Pool identifier.
Logical unit information:
Item	Description
Lu(Disk) Name	Logical unit name.
Size (MB)	Total size allocated for the logical unit.
Lu Udid	Logical unit identifier.
Adapter I/O Statistics View
This view provides the adapter I/O statistics. To display this view, press the a key. The following metrics are displayed in this view:
Item	Description
Adapter	Name of the adapter.
Busy%	Bandwidth use of the adapter.
Read-KB/s	Data transfer rate of read data in kilobytes per second.
Write-KB/s	Data transfer rate of written data in kilobytes per second.
Transfers	Number of read and write transfers.
Disks	Number of disks.
Adapter-Type	Type of the adapter.
Shared Ethernet adapter
This view provides shared Ethernet adapter statistics in a Virtual I/O Server (VIOS). To display this view, press the O key. The following metrics are displayed in this view:
Item	Description
Number	Serial number.
Name	Name of the shared Ethernet adapter.
Recv-KB/s	Data transfer rate of received data in kilobytes per second.
Trans-KB/s	Data transfer rate of sent data in kilobytes per second.
Packin	Number of packets received per second in the interval.
Packout	Number of packets sent per second in the interval.
Insize	Average size per second for received packet in the interval.
Outsize	Average size per second for outgoing packet in the interval.
Verbose Checks OK/Warn/Danger
This view prints the statistics for processor, memory, and disks. It also prints the status message, such as OK, Warn, or Danger, based on the system metrics exceeding pre-defined threshold values. To display this view, press the v key.
Detailed Page Statistics
This view provides page statistics. To display this view, press the M key.
If you press the M key once, the view contains the statistics in pages. If you press the M key twice, the page statistics are shown in megabytes.
The following metrics are shown in this view:
Item	Description
Numframes	Number of real memory frames of this page size.
Numfrb	Number of pages on free list.
Numclient	Number of client frames.
Numcompress	Number of frames in compressed segments.
Numperm	Number of frames in non-working segments.
Numvpages	Number of accessed virtual pages.
Minfree	Minimum free list.
Maxfree	Maximum free list.
Numpout	Number of page-outs.
Numremote	Number of remote page-outs.
Numwseguse	Number of pages in use for working segments.
Numpseguse	Number of pages in use for persistent segments.
Numclseguse	Number of pages in use for client segments.
Numwsegpin	Number of pages pinned for working segments.
Numpsegpin	Number of pages pinned for persistent segments.
Numclsegpin	Number of pages pinned for client segments.
numpgsp_pgs	Number of allocated page space.
numralloc	Number of remote allocations.
pfrsvdblks	Number of system reserved blocks.
Pfavail	Number of pages available for pinning.
Pfpinavail	Application level number pages available for pinning.
system_pgs	Number of pages on segment control blocks (SCB) that are marked withV_SYSTEM.
nonsys_pgs	Number of pages on SCBs not marked with V_SYSTEM.
Numpermio	Number of pageouts in non-working storage.
Pgexct	Number of page faults.
Pgrclm	Number of page reclaims.
Pageins	Number of paged-in pages.
Pageouts	Number of paged-out pages.
Pgspgins	Number of paged-in pages from page space.
Pgspgouts	Number of paged-out pages from page space.
Numsios	Number of I/O started.
Numiodone	Number of I/O completed.
Zerofills	Number of zero-filled pages.
Exfills	Number of exec-filled pages.
Scans	Number of page scans by clock.
Cycles	Number of clock hand cycles.
pgsteals	Number of page steals.
Fibre Channel Adapter Statistics
This view contains information about the Fibre Channel adapter. You can see this view by pressing the caret (-^) key. The following metrics are included in this view:
Item	Description
Number	Serial number.
Name	Name of the Fibre Channel adapter.
Receive-KB/s	Data transfer rate of received data in kilobytes per second.
Transmit-KB/s	Data transfer rate of sent data in kilobytes per second.
Requests In	Number of requests received per second in the interval.
Requests Out	Number of requests sent per second in the interval.
Outsize	Average outgoing packet size per second in the interval.
start of change
Mapping information
The mapping information about shared storage pools that are captured in nmon recording are as follows:
Physical location to client ID
Client ID to virtual target device
Virtual target device to backing device
Cluster to disks
Note: The recording on mapping information is specific to Virtual I/O Server (VIOS) .
end of change
Environment Variables
Environment variables NMON_START, NMON_END, NMON_SNAP, and NMON_ONE_IN are used for collecting external data while recording in nmon format.
Item	Description
NMONCMD0, NMONCMD1, ..., NMONCMD63	You can monitor only the processes that are set in these variables when these environment variables are set. Alternatively, you can use the -C flag to restrict the commands in the process listing of the nmon command. For example, you can run the nmon -C db2:websm:nmon:topas command.
NMON	Contains the set of key strokes corresponding to the initial set of panels to be displayed when the nmon command is started.
TIMESTAMP	You can specify the TIMESTAMP variable to the following values:
TIMESTAMP = 0
The recorded lines contain the nmon Tnnnn timestamps at the beginning of the line and work with the nmon data file.
TIMESTAMP = 1
The lines contains timestamps that have the hours, minute, seconds, day, month, and year. This value can be used if you do not want to merge the data with the nmon file for analysis.
NMON_START	External command to be started when the nmon recording begins.
NMON_END	External command to be started when the nmon recording ends.
NMON_SNAP	External command to be started periodically to record metrics.
NMON_ONE_IN	You can specify the NMON_ONE_IN variable to the following values:
NMON_ONE_IN=1
Runs the snap command every time the recording is done.
NMON_ONE_IN=n
Runs the snap command after the number of recordings specified by the n parameter is done.
Examples
To generate the nmon recording in the current directory for two hours, capturing data every 30 seconds, enter the following command:
nmon -f -s 30 -c 240
To display the memory and processor statistics immediately after the nmon command is started, do the following steps:
Enter the following command:
export NMON=mc
Run the nmon command.
To run the nmon command for 20 seconds with the screen refreshing at 10 seconds, enter the following command:
nmon -c 10 -s 2
To run nmon in black and white mode, enter the following command:
nmon -b
To view the process information, do the following steps:
Run the nmon command.
Press the t key.
To view the list of views that nmon command provides, press the key h.
The following sample explains the steps to collect external data. In the sample, the mystart file, the mysnap file, and the myend file are executable and are in the path that the $PATH defines.
Set the environment variables as indicated in the following example:
$export TIMESTAMP=0
$export NMON_START="mystart"
$export NMON_SNAP="mysnap"
$export NMON_END="myend"
$export NMON_ONE_IN=1
In the previous example, the value of one is the default value for the NMON_ONE_IN environment variable. It generates one set of external recorded data for every snapshot of nmon recording.
Modify the content of the mystart file as the following:
ps -ef >start_ps.xt
echo "PROCCOUNT,Process Count, Procs" >ps.csv
Modify the content of the mysnap file as the following:
echo PROCCOUNT,$1,`ps -ef | wc -l` >>ps.csv
Modify the content of the myend file as the following:
echo PROCCOUNT,$1,`ps -ef | wc -l` >>ps.csv
Run the nmon command as follows:
nmon -f -s 2 -c 10
The recording finishes in 20 seconds.
The output of the ps.csv file is similar to the following sample:
PROCCOUNT,Process Count, Procs
PROCCOUNT,T0001, 43
PROCCOUNT,T0002, 43
PROCCOUNT,T0003, 43
PROCCOUNT,T0004, 43
PROCCOUNT,T0005, 43
PROCCOUNT,T0006, 43
PROCCOUNT,T0007, 43
PROCCOUNT,T0008, 43
PROCCOUNT,T0009, 44
PROCCOUNT,T0010, 44
PROCCOUNT,T0010, 44
To concatenate the generated nmon file with the ps.csv file that is generated by external recording, enter the following command:
cat  filename.nmon ps.csv > c.csv
To get the graph, open the c.csv file in nmon analyzer.
start of changeTo view the hdisk details, enter the nmon command with -k flag :
nmon -k hdisk1,hdisk2
The previous command shows the disk details for hdisk1 and hdisk2. For hdiskpower devices, enter the following command:
nmon -k hdiskpower or
nmon -k power
Note: The nmon -k hdisk matches all the hdisk devices on the LPAR and does not the match the hdiskpower devices.
All hdiskpower devices display as power in interactive and recording modes. For example, nmon -k hdiskpower1 matches the device hdiskpower1 and nmon -k hdiskpower matches all hdiskpower devices on the LPAR.
Note: The output of the lsconf and lspv commands in the nmon recording file is not affected by the changes to the nmon-kcommand


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Object Data Manager (ODM)
By Surya12:53No comments
What is ODM?
Location of ODM Repositories
Some ODM Database files
Some Useful ODM commands
ODM commands - examples
What is ODM?
ODM
Maintains system config, device and vital product data
Provide a more robust, secure and sharable resource
Provide a reliable object oriented database facility
Data Managed By ODM

Device Configuration Information
Software Vital Product Data
SRC information
Communications configuration data
Menus and commands for SMIT
ODM has three components

Object class - These are datafiles.
Objects - Records within Datafiles
Descriptors - Field within a record
Where ODM Object Class files are stored?
This can be defined in /etc/environment file. The ODM object clases are held in three repositories

/etc/objrepos
/usr/lib/objrepos
/usr/share/lib/objrepos
Some important ODM Database files
Supported devices and attributes and connection information are stored in
PdDv, PdAt, PdCn, etc..
Records or customizrd Devices and attributes, VPD are stored in
CuDv, CuAt, CuDep, Config_Rules, CuVPD, etc ...
Have software information
lpp, history, product, inventory, etc..
SMIT menus, commands, options
sm_cmd_hdr, sm_cmd_opt, sm_menu_opt 
NIM Resource and configuraion informations
nim_object, nim_pdattr, nim_altr
Errorlog, alog and dump file info
SWservAt
Useful ODM Commands
odmget     - To retrieves objects from an Object Class in stanza format
odmdelete  - To delete objects what meet a specific criteria. 
             If no criteria specified, all objects are deleted
odmadd     - To add a new object to an object class
odmchange  - To change all objects with in an Object Class that meet a specific criteria
odmshow    - To display object class definition
odmcreate  - To create Object Class for application that will use ODM DB
odmdrop    - To remove an Object Class
Some ODM Command examples
To list all records with an Object Class CuDv
# odmget CuDv
To find out an object within CuAt with condition name=sys0 and attibute=maxuproc
# odmget -q "name=sys0 and attribute=maxuproc" CuAt
    CuAt:
          name = "sys0"
          attribute = "maxuproc"
          value = "2000"
          type = "R"
          generic = "DU"
          rep = "nr"
          nls_index = 20
To delete the above object
# odmget -q "name=sys0 and attribute=maxuproc" CuAt > file.1
 # odmdelete -q "name=sys0 and attribute=maxuproc" -o CuAt 
To add the deleted object again to the above object class
# odmadd file.1   # add the file content to appropriate Object class
Fix ODM related errors for devices (CuDv Object Class)
$ cfgmgr
cfgmgr: 0514-604 Cannot access the CuDv object class in the
device configuration database.
The Fix:
 01. cd /etc/oberepos 
 02. cp Config_Rules Config_Rules.backup 
 03. odmget -q rule="/etc/methods/darcfgrule" Config_Rules 
 04. odmdelete -q rule="/etc/methods/darcfgrule" -o Config_Rules
 05. savebase -v
 06. cfgmgr



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Online migration of a file system to a smaller physical volume
By Surya19:26No comments
Tip: Online migration of a file system to a smaller physical volume
Use Logical Volume Manager (LVM) to reclaim disk space without an outage
The problem: Downsizing a physical volume
The IBM AIX LVM has several features that allow you to reclaim unused disk space without downtime. You can reduce a file system using chfs, and you can remove unused physical volumes (PVs) from volume groups (VGs) so that you can allocate the storage somewhere else.
However, if you want to reduce the size of an AIX PV to reclaim unused disk space, you will damage the data on the PV. If you have a large SAN LUN that has a significant amount of unused physical partitions (PPs), you could back up the data, reduce the LUN size, and restore the data to the new, smaller PV. But that could involve unacceptable downtime. If, after a data cleanup, a large LUN needs to have some of its space reclaimed, it should be as seamless a procedure as possible.
The solution: Migrate to a new, smaller physical volume
It may not be possible to downsize a PV that is in use, but you can create a new, smaller SAN LUN, add it to the existing VG, and then migrate data from the larger PV to the smaller one. When that is done, the original oversized PV can be removed from the VG. The hdisk can then be taken out of the Object Data Manager (ODM) using rmdev. Then, you can recycle the SAN storage for some other use.
This procedure requires the new PV to have a suitable size and characteristics for adding to the existing VG. It must be large enough to hold all the data that is on the original PV (the used PPs). The procedure also assumes that there is no logical volume (LV) striping that would restrict the ability to run a mirror of a logical volume using mklvcopy.
For this exercise, there is a VG called datavg with a 50 GB PV. The lspv command shows the total size of the PV as well as the free and used PPs (see Listing 1).

Listing 1. Displaying physical volume characteristics
 
# lspv hdisk1
PHYSICAL VOLUME:    hdisk1                   VOLUME GROUP:     datavg
PV IDENTIFIER:      00cb07a45a12b4ca VG IDENTIFIER     00cb07a400004c00000001345a26db3e
PV STATE:           active
STALE PARTITIONS:   0                        ALLOCATABLE:      yes
PP SIZE:            512 megabyte(s)          LOGICAL VOLUMES:  1
TOTAL PPs:       99 (50688 megabytes)     VG DESCRIPTORS:   2
FREE PPs:         0 (0 megabytes)          HOT SPARE:        no
USED PPs:        99 (50688 megabytes)     MAX REQUEST:      256 kilobytes
FREE DISTRIBUTION:  00..00..00..00..00
USED DISTRIBUTION:  20..20..19..20..20
MIRROR POOL:        None
There is a single enhanced journaled file system (JFS2) called /scratch that has more than 35 GB free of its 49.50 GB allocation. This file system was created with an INLINE JFS2 log:
# df -gI /scratch
Filesystem    GB blocks      Used      Free %Used Mounted on
/dev/scratchlv     49.50     14.20     35.30   29% /scratch

The fine print
This solution applies to LVs that are not striped at the LVM level. LVM striping introduces its own restrictions that are beyond the scope of this article. The file system in this example uses an INLINE JFS2 log.
The solution here also assumes that there is sufficient storage to create a new SAN LUN of similar performance and redundancy to the original so that the end result will not affect system response times. The new LUN should have sufficient space to fit the used PPs from the original, larger LUN.
Reduce the file system
Because the file system is using less than one third of its allocation, its total disk allocation can be reduced. You can reduce the file system size using chfs. The following command reduces it by 30 GB:
# chfs -a size=-30G /scratch
Filesystem size changed to 40894464
Inlinelog size changed to 78 MB.
The total disk allocation for the file system has been reduced to 19.50 GB:
# df -gI /scratch
Filesystem    GB blocks      Used      Free %Used Mounted on
/dev/scratchlv     19.50     14.08      5.42   73% /scratch
This process has freed up some PPs on the PV, as the lspv command in Listing 2 shows.

Listing 2. lspv showing free physical partitions
 
# lspv hdisk1
PHYSICAL VOLUME:    hdisk1                   VOLUME GROUP:     datavg
PV IDENTIFIER:      00cb07a45a12b4ca VG IDENTIFIER     00cb07a400004c00000001345a26db3e
PV STATE:           active
STALE PARTITIONS:   0                        ALLOCATABLE:      yes
PP SIZE:            512 megabyte(s)          LOGICAL VOLUMES:  1
TOTAL PPs:          99 (50688 megabytes)     VG DESCRIPTORS:   2
FREE PPs:        60 (30720 megabytes)     HOT SPARE:        no
USED PPs:           39 (19968 megabytes)     MAX REQUEST:      256 kilobytes
FREE DISTRIBUTION:  00..01..19..20..20
USED DISTRIBUTION:  20..19..00..00..00
MIRROR POOL:        None
Add a smaller physical volume to the volume group
The next step is to add a new, smaller PV to the existing VG. This PV should have at least the same redundancy and input/output (I/O) performance as the original, larger PV. For example, it should be of an equivalent Redundant Array of Independent Disks (RAID) array. Any other tuning characteristics—such as queue depth— should be set to ensure that the system performance is comparable to the original, larger PV.
Create a new LUN, and allocate it to the AIX logical partition (LPAR). In this example, the new LUN is 20 GB:
# cfgmgr
The output of the lspv command shows that the new disk is called hdisk2 (see Listing 3) and it does not yet belong to a VG.

Listing 3. Listing the new disk
 
# lspv
hdisk0          00c5a47e3f356f3c                    rootvg          active
hdisk1          00cb07a45a12b4ca                    datavg          active
hdisk2          none                                None
You can view the size of the disk even before it is added to a VG using the getconf command. This reports the size in MB:
# getconf DISK_SIZE /dev/hdisk2
20480
Add the disk to the existing VG using the extendvg command:
# extendvg datavg hdisk2
0516-1254 extendvg: Changing the PVID in the ODM.
Mirror or migrate the logical partitions to a new physical volume
You can mirror the LV to the new PV, and then remove the copy from the original PV after all the PPs have been synchronised between the two PVs.
mklvcopy -k scratchlv 2

Migrate instead of mirror
Instead of mirroring, you can migrate the LV usingmigratepv. Refer to Resources for a link to more information.
There are other options for mklvcopy. For example, you can postpone the synchronization until a quieter time. You can also specify the disk allocation policy. The official documentation formklvcopy has the necessary details (refer to Resources).
Remove the copy from the original physical volume
When the synchronization is complete, you can remove the copy from the original PV using rmlvcopy. Be sure to specify the PV that has the copy you want to remove.
rmlvcopy scratchlv 1 hdisk1
You can use the lspv command to confirm that there are no more used PPs on the original PV. If there are still some PPs in use, you can list the LVs on the PV using lspv -l PVNAME. When you are sure that all the PPs have been moved to other PVs, the original PV can be removed from the VG using reducevg:
reducevg datavg hdisk1
You should be able to remove the original larger PV from the ODM using rmdev:
rmdev -d -l hdisk1
Finally, you can remove the LUN or allocate it for some other use.

Cutting out outages
As you can see, the LVM features allow you to move data around—even to smaller disks—without unnecessary user impact. By taking advantage of the LVM mirroring and migration capabilities, you can keep your system up and still recover the much-needed storage space if it has been over-allocated.
Original Source (https://www.ibm.com/developerworks/aix/library/au-aix-online-migration/index.html) 



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

OpenSource Tools for AIX
By Surya18:16No comments
Here are several websites that has OpenSource Tools for AIX. The "IBM AIX Toolbox" has the most tools, but not necessarily the most current versions. The other links are also good to note.
IBM AIX Toolbox for Linux Applications – http://www.ibm.com/servers/aix/products/aixos/linux/download.html
AIX Open Source – http://www.perzl.org/aix/
Hudson Valley CC - http://pware.hvcc.edu
Bull Open Software archive for AIX - http://www.bullfreeware.com
IBM Developerworks in general - http://www.ibm.com/developerworks/downloads/




------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Optimizing AIX 7 network performance: Part 1
By Surya20:09No comments
 Optimizing AIX 7 network performance: Part 1, Network overview - Monitoring the hardware
About this series
Part 1 of this three-part series on AIX networking provides a networking overview and discusses the tools that help you monitor your hardware. Part 2 covers tuning the Network File System (NFS) with monitoring utilities, such as nfsstat and nmon, and it also goes over how to tune with nfso. Part 3 shows you how to monitor network packets and how to use netstat for this purpose. You'll learn how to tune your network subsystem using the no utility. This series also expounds on various best practices of network I/O performance tuning.
Introduction
The first thing that usually comes to mind when a system administrator hears that there might be some network contention issues is to run netstat. netstat, the equivalent of using vmstat or iostat for your memory reports, is a quick way to get an overview of how your network is configured. Unlike vmstat or iostat, the defaults usually do not give you as much information as you probably would like. You need to understand the correct usage of netstat and how best to utilize it when monitoring your system.

netstat is really not a monitoring tool in the sense of vmstat and iostat. You can use other tools more suitable (discussed later in the article) to help monitor your network subsystem. At the same time, you can't really start to monitor unless you have a thorough understanding of the various components related to network performance. These components include your network adapters, your switches and routers, and how you are using virtualization on your host logical partitions. If you determine you are indeed having a network bottleneck, fixing the problem might actually lay outside of your immediate host machine. There is little you can do if the network switch is improperly configured on the other end. Of course, you might be able to point the network team in the right direction. You should also spend time gathering overall information about your network. How are you going to be able to understand how to troubleshoot your network devices unless you really understand your network? In this article, you'll look at specific AIX network tracing tools, such as netpmon, and how they can help you isolate your bottlenecks.

Finally, no matter which subsystem you are looking to tune, you must think of systems tuning as an ongoing process. As stated before, the best time to start monitoring your systems is at the beginning, before you have any problems and users aren't screaming. You must have a baseline of network performance so that you know what the system looks like when it is behaving normally. Finally, when making changes, be careful to make changes only one at a time so that you can really assess the impact of your change.

Network I/O overview

This section provides an overview of the network as it relates to AIX 7 and covers the physical aspects of the network (device drives and adapters), the AIX networking stack, and how to make some changes to your adapter.

Understanding the network subsystem, as it relates to AIX, is not an easy undertaking. When examining the CPU and memory bottlenecks, there are far fewer areas that you need to examine from a hardware and software aspect. Disk I/O tuning is more complex, as there are many more issues that impact performance, particularly during the architectural and build-out of your systems. In this respect, tuning your network is probably most like tuning your disk I/O, which is actually not too surprising, as they both relate to I/O. Let's start.

Figure 1 illustrates the AIX Transmission Control Protocol/Internet Protocol (TCP/IP) layers.

Figure 1. The AIX TCP/IP layers
Screen shot of the AIX TCP/IP layers
Figure 1 illustrates that there is more to network monitoring than running netstat and looking for collisions. From the application layer through the media layer, there are areas that need to be configured, monitored, and tuned. At this point, you should notice some similarities between this illustration and the Open Systems Interconnection Basic Reference Model (OSI Model). The OSI Model has seven layers (bottom to top):
Physical
Data-link
Network
Transport
Session
Presentation
Application
Perhaps the most important concept to understand is that on the host machine each layer communicates with its corresponding layer on the remote machine. The actual application programs transmit data using either User Datagram Protocol (UDP) or Transmission Control Protocol (TCP) transport layer protocols. They receive the data from whatever application you are using and divide them into packets. The packets themselves differ, depending on whether it is a UDP or TCP packet. Generally speaking, UDP is faster, while TCP is more secure. There are many tunable parameters to look at—you'll get to these parameters during subsequent phases of the series. You might want to start to familiarize yourself with the no command, which is the utility designed to make the majority of your network changes. From a hardware perspective, it is critical that you understand the components that need to be configured appropriately to optimize performance. Though you might work together with the network teams that manage your switches and routers, it is unlikely that you will be configuring them (unless you are a small shop or a one-person IT department). The most important component you will be working with is your network adapter. Gigabit Ethernet is now the standard network interface, although 10Gbit network cards and infrastructure is becoming more accessible.
Maximum Transfer Unit
Maximum Transfer Unit (MTU) is defined as the largest packet that can be sent over a network. The size depends on the type of network. For example, 16-bit token ring has a default MTU size of 17914, while Fiber Distributed Data Interface (FDDI) has a default size of 4352. Ethernet has a default size of 1500 (9000 with jumbo frames enabled). Larger packets require less packet transfers, which result in higher bandwidth utilization on your system. In particular, using jumbo frames allows for an entire 8KB NFS block to be exchanged in a single packet, which can significantly improve performance. An exception to this is if your application prefers smaller packets, and this includes web applications on the Internet, since most Internet connections do not support jumbo frames. If you are using a Gigabit Ethernet, you can use a jumbo frames option. To support the use of jumbo frames, it's important to note that your switch must also be configured, accordingly.

To change to jumbo frames, use this fastpath: # smit devices.

Then go to Communication>Ethernet>Adapter>Change/show characteristics of an Ethernet adapter. Try to change the transmit jumbo frames option from "No" to "Yes" (see Listing 1).

Listing 1. Characteristics of an Ethernet adapter screen
             
              Change / show characteristics of an Ethernet adapter
                        Change / Show Characteristics of an Ethernet Adapter
Type or select values in entry fields.
Press Enter AFTER making all desired changes.
  
                                                     [Entry Fields]
  Ethernet Adapter                                 ent0
  Description                                      Virtual I/O Ethernet Adapter (l-lan)
  Status                                           Available
  Location
  Enable ALTERNATE ETHERNET address                no                                +
  ALTERNATE ETHERNET address                      [0x000000000000]                   +
  Minimum Tiny Buffers                            [512]                              +#
  Maximum Tiny Buffers                            [2048]                             +#
  Minimum Small Buffers                           [512]                              +#
  Maximum Small Buffers                           [2048]                             +#
  Maximum Medium Buffers                          [128]                              +#
  Maximum Medium Buffers                          [256]                              +#
  Minimum Large Buffers                           [24]                               +#
  Maximum Large Buffers                           [64]                               +#
  Minimum Huge Buffers                            [24]                               +#
  Maximum Huge Buffers                            [64]                               +#
  Transmit Copy Buffers                           [32]                               +#
  Transmit Copy Buffer Size                       [65536]                            +#
  Trace Debug Enable                               no                                +
  Checksum Offload Enable                          yes                               +
  I/O memory entitlement reserved for device       0
  Apply change to DATABASE only                    no                                +
Where is the jumbo frames option? In this case, you cannot make the change. The reason for this is because you are only using the Virtual I/O Ethernet on this system—this topic is discussed in more detail later.

On a system where you have direct access to the network hardware, check the system using Listing 2.

Listing 2. Checking the system
             
              Change / show characteristics of an Ethernet adapter

Type or select values in entry fields.
Press Enter AFTER making all desired changes.

                                                        [Entry Fields]
  Ethernet Adapter                                    ent1
  Description                                         10/100/1000 Base-TX P>
  Status                                              Available
  Location                                            1j-08
  RX descriptor queue size                           [1024]                  +#
  TX descriptor queue size                           [1024]                  +#
  Software transmit queue size                       [8192]                  +#
  Transmit jumbo frames                               yes                    +
  Enable hardware TX TCP resegmentation               yes                    +
  Enable hardware transmit and receive checksum       yes                    +
  Media speed                                         Auto_Negotiation       +
  Enable ALTERNATE ETHERNET address                   no                     +
  ALTERNATE ETHERNET address                         [0x000000000000]        +
  Apply change to DATABASE only                       no                     +

F1=Help             F2=Refresh          F3=Cancel           F4=List
F5=Reset            F6=Command          F7=Edit             F8=Image
F9=Shell            F10=Exit            Enter=Do
You have now changed the field to support jumbo frames.

Media speed

Most modern network switches and environments can take advantage of auto-negotiation to provide the best speed, especially as full-duplex network switches have become the standard. However, you force a particular configuration if the auto-negotiation fails to configure a speed that you know your network switch is capable of supporting.

The lsattr command gives you the information that you need. The en prefix displays your driver parameters, while the ent prefix displays your hardware parameters. Let's display your hardware parameters (see Listing 3).

Listing 3. Displaying the hardware parameters
             
testsys:/home/test>lsattr -El ent0
alt_addr       0x000000000000 Alternate Ethernet Address                 
Truechksum_offload yes        Checksum Offload Enable                    True
copy_buffs     32             Transmit Copy Buffers                      True
copy_bytes     65536          Transmit Copy Buffer Size                  True
desired_mapmem 0              I/O memory entitlement reserved for device False
max_buf_huge   64             Maximum Huge Buffers                       True
max_buf_large  64             Maximum Large Buffers                      True
max_buf_medium 256            Maximum Medium Buffers                     True
max_buf_small  2048           Maximum Small Buffers                      True
max_buf_tiny   2048           Maximum Tiny Buffers                       True
min_buf_huge   24             Minimum Huge Buffers                       True
min_buf_large  24             Minimum Large Buffers                      True
min_buf_medium 128            Minimum Medium Buffers                     True
min_buf_small  512            Minimum Small Buffers                      True
min_buf_tiny   512            Minimum Tiny Buffers                       True
trace_debug    no             Trace Debug Enable                         True
use_alt_addr   no             Enable Alternate Ethernet Address          True
In this case, your interface is set as auto-negotiate.

You should also check your firmware levels to make sure they are up to date. We've seen many network problems fixed when updating to the latest levels of firmware. The lscfg command gives you the firmware information (see Listing 4).

Listing 4. Using the lscfg command for firmware information
             
testsys:/home/test >lscfg -vp | grep -p ETHERNET
      4 X 1GB ETHERNET:        Record Name.................VINI
        Flag Field..................XXET
        Hardware Location Code......U78C0.001.DBJ3229-P2-C8
        Customer Card ID Number.....2BC4
        Serial Number...............YL10D9360034
        CCIN Extender...............1
        Product Specific.(VZ).......04
        FRU Number..................46K5965
        Part Number.................46K6484
        Product Specific.(HE).......0001
        Product Specific.(CT).......30910008
        Product Specific.(HW).......0001
        Product Specific.(B3).......000000000001
        Product Specific.(B4).......00
        Product Specific.(B7).......000000000000000000000000
        Product Specific.(B1).......00215EEB40C0002000215EEB40E00020
        Version.....................ipzSeries
      Physical Location: U78C0.001.DBJ3229-P2-C8

      4 X 1GB ETHERNET:
        Record Name.................VINI
        Flag Field..................XXET
        Hardware Location Code......U78C0.001.DBJ3226-P2-C8
        Customer Card ID Number.....2BC4
        Serial Number...............YL10D9360085
        CCIN Extender...............1
        Product Specific.(VZ).......04
        FRU Number..................46K5965
        Part Number.................46K6484
        Product Specific.(HE).......0001
        Product Specific.(CT).......30910008
        Product Specific.(HW).......0001
        Product Specific.(B3).......000000000001
        Product Specific.(B4).......00
        Product Specific.(B7).......000000000000000000000000
        Product Specific.(B1).......00215EEB4680002000215EEB46A00020
        Version.....................ipzSeries
      Physical Location: U78C0.001.DBJ3226-P2-C8

      4 X 1GB ETHERNET:
        Record Name.................VINI
        Flag Field..................XXET
        Hardware Location Code......U78C0.001.DBJ3227-P2-C8
        Customer Card ID Number.....2BC4
        Serial Number...............YL10D9360028
        CCIN Extender...............1
        Product Specific.(VZ).......04
        FRU Number..................46K5965
        Part Number.................46K6484
        Product Specific.(HE).......0001
        Product Specific.(CT).......30910008
        Product Specific.(HW).......0001
        Product Specific.(B3).......000000000001
        Product Specific.(B4).......00
        Product Specific.(B7).......000000000000000000000000
        Product Specific.(B1).......00215EEB4140002000215EEB41600020
        Version.....................ipzSeries
      Physical Location: U78C0.001.DBJ3227-P2-C8
See the Resources section at the end of the article for a link to the most current release information for your adapter.

Though the series focuses on tuning in subsequent parts, you might want to start to familiarize yourself with the memory management facility of network subsystems. What you need to know at this point is that it relates to data structures called mbufs. These are used to store kernel data for incoming and outbound traffic. The buffer sizes themselves can range from 32 to 16384 bytes. They are created by making allocation requests to the Virtual Memory Manager (VMM). In an SMP box, each memory pool is split evenly for every processor. The monitoring section below shows you how to view mbufs. An important concept to note is that processors cannot borrow from the memory pool outside of its own processor.

Two other concepts you should be familiar with are virtual Ethernet and shared Ethernet.
Virtual Ethernet: Virtual Ethernet allows for inter-partition- and IP-based communications between logical partitions on the same frame. This is done by the use of a virtual I/O switch. The Ethernet adapters themselves are created and configured using the HMC. If you recall, you tried to change an adapter earlier that was configured with virtual Ethernet.
Shared Ethernet: Shared Ethernet allows for the use of Virtual I/O servers (VIOs), where several host machines can actually share one physical network adapter. Typically, this is used in environments that do not require substantial network bandwidth.
While the scope of this series is not on virtualization, you should understand that if you are using virtualization, there might be other reasons for your bottleneck outside of what you are doing on your host machine. While virtualization is a wonderful thing, be careful not to share too many adapters from your VIO server, or you might pay a large network I/O penalty. Keep in mind as well that with workload partitions (WPAR), the network configuration of the host environment is used and shared by each partition; you cannot configure WPAR network performance individually. Using appropriate monitoring tools should inform you if you have a problem.

In addition, application performance can be affected fundamental services, such as domain name service (DNS) used to resolve hostnames and Internet addresses.

Monitoring

This section provides an overview of general network monitoring commands and specific AIX 7 tools available to you. Some of the tools allow you to troubleshoot a performance problem quickly while others capture data for historical trending and analysis.

Let's get back to the old standby, netstat, which displays overall network statistics. Probably one of the most common commands you type in is netstat -in (see Listing 5).

Listing 5. Using netstat with the -in option
             
l488pp065_pub[/tmp] > netstat -in
Name  Mtu   Network     Address            Ipkts Ierrs    Opkts Oerrs  Coll
en1   1500  link#2      66.da.93.d1.6b.18 70136750     0   336237     0     0
en1   1500  10.153      10.153.20.65      70136750     0   336237     0     0
en0   1500  link#3      66.da.93.d1.6b.17 202571785    0   79277      0     0
en0   1500  172.29.128  172.29.148.225    202571785    0   79277      0     0
lo0   16896 link#1                         778719      0   778718     0     0
lo0   16896 127         127.0.0.1          778719      0   778718     0     0
lo0   16896 ::1%1                          778719      0   778718     0     0
Here is what it means:
Name: Interface name.
MTU: Interface Maximum Transfer Unit size.
Network: The actual network address that the interface connects to.
Address: Mac and IP address.
Ipkts: The total amount of packets received by the interface.
Ierrs: The amount of errors reported back from the interface.
Opkts: The amount of packets transmitted from the interface.
Oerrs: The amount of error packets transmitted from the interface.
Coll: The amount of collisions on the adapter. If you are using Ethernet, you won't see anything here.
Another handy netstat flag is the -m option. This flag allows you to view the Kernel malloc statistics; the mbuf memory requests, including the size of the buffers, the amount in use and the failures by CPU (see Listing 6).

Listing 6. netstat with -m option
             
l488pp065_pub[/tmp] > netstat -m
Kernel malloc statistics:

******* CPU 0 *******
By size           inuse     calls failed   delayed    free   hiwat   freed
64                  566   2015884      0         7     266    5240       0
128                5890   1830085      0       175     158    2620       0
256                5781    651987      0       295    2875    5240     500
512                8000 181192188      0       972      56    6550       0
1024               3165   1889042      0       792      35    2620       0
2048               1071   3387085      0       520      23    3930       0
4096               2056      2775      0        83       5    1310       0
8192                  6       260      0         3     163     327       0
16384               256       413      0        62       0     163       0
32768                55       274      0        23       4      81       0
65536               117       175      0        76       0      81       0
131072                4         5      0         0     102     204       0


******* CPU 1 *******
By size           inuse     calls failed   delayed    free   hiwat   freed
64                   46    226765      0         0     146    5240       0
128                  58    152657      0         2     134    2620       0
256                  51     70035      0         2     301    5240       0
512                  78  46458768      0         4      66    6550       0
1024                 62    171426      0        12      30    2620       0
2048                 23   3669503      0         5      25    3930       0
4096                  1       891      0         4       9    1310       0
8192                  1       567      0         3     306     327       0
16384                 0        12      0         5       2     163       0
32768                 2        17      0         3       7      81       0
65536                 0        11      0         6       0      81       0
131072                0         1      0         0      20      40       0


******* CPU 2 *******
By size           inuse     calls failed   delayed    free   hiwat   freed
64                   21      1295      0         1      43    5240       0
128                   9       781      0         0      23    2620       0
256                   9      1226      0         0      39    5240       0
512                  81  36991563      0        10      55    6550       0
1024                 27      1241      0        15      33    2620       0
2048                  5      3286      0         0      23    3930       0
4096                  0        52      0         1       5    1310       0
8192                  0         1      0         1       0     327       0
32768                 0         1      0         1       1      81       0
131072                0         0      0         0      16      32       0


******* CPU 3 *******
By size           inuse     calls failed   delayed    free   hiwat   freed
64                   42      1224      0         2      86    5240       0
128                  15      1195      0        13     401    2620       0
256                  12      2607      0        82    1316    5240       0
512                  83  36405229      0       222    1733    6550       0
1024                 32      1220      0        14      32    2620       0
2048                 23      4549      0       260     507    3930       0
4096                  1        42      0         3       3    1310       0
8192                  0        58      0         7      21     327       0
16384                 0       128      0        19     121     163       0
32768                 2        29      0         7      22      81       0
65536                 0        47      0        24      47      81       0
131072                0         0      0         0     102     204       0
The -m option is particularly useful because it shows the network performance statistics in relation to individual CPUs. When monitoring and managing the performance with LPAR and WPAR environments, the ability to correlate your CPU resources and the network resources can give you valuable information about the correct allocation and distribution of network resources.

For Ethernet, you can use the entstat command to display device-driver statistics. This provides a plethora of information (seeListing 7).

Listing 7. Using the entstat command to display device driver statistics
             
l488pp065_pub[/tmp] > entstat -d ent0
-------------------------------------------------------------
ETHERNET STATISTICS (ent0) :
Device Type: Virtual I/O Ethernet Adapter (l-lan)
Hardware Address: 66:da:93:d1:6b:17
Elapsed Time: 16 days 1 hours 48 minutes 7 seconds

Transmit Statistics:                          Receive Statistics:
--------------------                          -------------------
Packets: 79636                                Packets: 203054741
Bytes: 15868037                               Bytes: 30905882351
Interrupts: 0                                 Interrupts: 201058047
Transmit Errors: 0                            Receive Errors: 0
Packets Dropped: 0                            Packets Dropped: 0
                                              Bad Packets: 0
Max Packets on S/W Transmit Queue: 0         
S/W Transmit Queue Overflow: 0
Current S/W+H/W Transmit Queue Length: 0

Broadcast Packets: 5                          Broadcast Packets: 203036730
Multicast Packets: 6171                       Multicast Packets: 215
No Carrier Sense: 0                           CRC Errors: 0
DMA Underrun: 0                               DMA Overrun: 0
Lost CTS Errors: 0                            Alignment Errors: 0
Max Collision Errors: 0                       No Resource Errors: 0
Late Collision Errors: 0                      Receive Collision Errors: 0
Deferred: 0                                   Packet Too Short Errors: 0
SQE Test: 0                                   Packet Too Long Errors: 0
Timeout Errors: 0                             Packets Discarded by Adapter: 0
Single Collision Count: 0                     Receiver Start Count: 0
Multiple Collision Count: 0
Current HW Transmit Queue Length: 0

General Statistics:
-------------------
No mbuf Errors: 0
Adapter Reset Count: 0
Adapter Data Rate: 20000
Driver Flags: Up Broadcast Running 
        Simplex 64BitSupport ChecksumOffload 
        DataRateSet 

Virtual I/O Ethernet Adapter (l-lan) Specific Statistics:
---------------------------------------------------------
RQ Length: 4481
Trunk Adapter: False
Filter MCast Mode: False
Filters: 255
  Enabled: 1  Queued: 0  Overflow: 0
LAN State: Operational

Hypervisor Send Failures: 0
  Receiver Failures: 0
  Send Errors: 0
Hypervisor Receive Failures: 0

Invalid VLAN ID Packets: 0

ILLAN Attributes: 0000000000003002 [0000000000003002]

Port VLAN ID:     2
VLAN Tag IDs:  None


Switch ID: ETHERNET0

Hypervisor Information  
  Virtual Memory        
    Total (KB)                 79
  I/O Memory            
    VRM Minimum (KB)          100
    VRM Desired (KB)          100
    DMA Max Min (KB)          128

Transmit Information    
  Transmit Buffers       
    Buffer Size             65536
    Buffers                    32
    History             
      No Buffers                0
  Virtual Memory        
Collisions are largely a thing of the past with modern network switches, but look for transmit errors and make sure they are not increasing too fast. You need to learn to troubleshoot collision and error problems before you even begin to think about tuning. Alternatively, you can use netstat -v, which provides similar information.

Let's look at netpmon. netpmon provides information on CPU usage as it relates to the network, and it also includes data about the network device driver I/O, Internet socket calls, and other various statistics. Similar to its other trace brethren, tprof andfilemon, it starts a trace and runs in the background until you stop it with the trcstop command. We like netpmon because it really gives you a detailed overview of network activity and also captures data for trending and analysis (though it is not as useful as nmon for this purpose). Here you'll use a trace buffer size of two million bytes (see Listing 8).

Listing 8. netpmom with -T option
             
l488pp065_pub[/tmp] > netpmon -T 2000000 -o /tmp/net.out
Run trcstop command to signal end of trace.
Sun Aug 15 04:58:06 2010
System: AIX 7.1 Node: l488pp065_pub Machine: 00F604884C00
Now you'll stop it (see Listing 9).

Listing 9. Stopping netpmom
             
l488pp065_pub[/tmp] > trcstop[netpmon: Reporting started]
23675650 Missed Entries found

[netpmon: Reporting completed]
[               4 traced cpus               ]
[         0.091 secs total preempt time   ]

[netpmon: 43.388 secs in measured interval]
Let's look at the data. Here is just a small sampling of the output (see Listing 10).

Listing 10. Sample output
             
Sun Aug 15 04:58:06 2010System: AIX 7.1 Node: l488pp065_pub Machine: 00F604884C00


========================================================================

Process CPU Usage Statistics:
-----------------------------
                                                   Network
Process (top 20)             PID  CPU Time   CPU %   CPU %
----------------------------------------------------------
netpmon                 12976354   41.7559  24.072   0.000
netpmon                 14155800   32.1352  18.526   0.000
inetd                   14155804   29.3093  16.897   0.000
xmtopas                 14155834   29.2385  16.856   0.000
xmtopas                 14155830   29.2381  16.856   0.000
xmtopas                 14155822   28.9899  16.713   0.000
xmtopas                 14155816   28.9433  16.686   0.000
xmtopas                 14155826   28.9390  16.683   0.000
xmtopas                 14155828   28.9308  16.679   0.000
inetd                   14155824   28.9287  16.677   0.000
xmtopas                 14155820   28.9227  16.674   0.000
xmtopas                 14155814   28.9158  16.670   0.000
inetd                   14155866   23.7606  13.698   0.000
inetd                   14155864   23.7131  13.671   0.000
xmtopas                 14155846   19.0223  10.966   0.000
inetd                   14155848   19.0083  10.958   0.000
inetd                    9371742   18.8547  10.870   0.000
inetd                    9371658   16.5665   9.551   0.000
inetd                    9371886   16.4571   9.488   0.000
xmtopas                  9371888   16.4094   9.460   0.000
----------------------------------------------------------
Total (all processes)             838.3315 483.300   0.000
Idle time                          78.8376  45.450

========================================================================

First Level Interrupt Handler CPU Usage Statistics:
---------------------------------------------------
                                                   Network
FLIH                              CPU Time   CPU %   CPU %
----------------------------------------------------------
data page fault                   255.0988 147.065   0.000
UNKNOWN                            17.9673  10.358   0.000
PPC decrementer                     2.7282   1.573   0.000
external device                     0.0081   0.005   0.000
instruction page fault              0.0002   0.000   0.000
queued interrupt                    0.0000   0.000   0.000
----------------------------------------------------------
Total (all FLIHs)                 275.8026 159.001   0.000

========================================================================

TCP Socket Call Statistics (by Process):
----------------------------------------
                                   ------ Read -----   ----- Write -----
Process (top 20)             PID   Calls/s   Bytes/s   Calls/s   Bytes/s
------------------------------------------------------------------------
sshd:                    5636334      0.12      1888      0.53        37
nonstop_aix              3539136      0.05         9      0.05         0
java                     4260046      0.05         9      0.05         0
------------------------------------------------------------------------
Total (all processes)                 0.21      1907      0.62        37

========================================================================

Detailed TCP Socket Call Statistics (by Process):
-------------------------------------------------

PROCESS: sshd:   PID: 5636334
reads:                  5
As you can see, there is little overall network I/O activity going on during this time. The top section is most important, as it really helps you get an understanding of what processes are consuming network I/O time, and you can use the more detailed per-process output to obtain more specific information. lsattr (used earlier to view the hardware parameters) is another command you will be using frequently to display statistics on your interfaces. The attributes that you see here are configured using either the chdev or no commands. Let's display your driver parameters (see Listing 11).

Listing 11. Displaying the driver parameters using lsattr 
             
l488pp065_pub[/tmp] > lsattr -El en0alias4                       
IPv4                         Alias including Subnet Mask                True
alias6                       IPv6 Alias including Prefix Length         True
arp           on             Address Resolution Protocol (ARP)          True
authority                    Authorized Users                           True
broadcast                    Broadcast Address                          True
mtu           1500           Maximum IP Packet Size for This Device     True
netaddr       172.29.148.225 Internet Address                           True
netaddr6                     IPv6 Internet Address                      True
netmask       255.255.192.0  Subnet Mask                                True
prefixlen                    Prefix Length for IPv6 Internet Address    True
remmtu        576            Maximum IP Packet Size for REMOTE Networks True
rfc1323                      Enable/Disable TCP RFC 1323 Window Scaling True
security      none           Security Level                             True
state         up             Current Interface Status                   True
tcp_mssdflt                  Set TCP Maximum Segment Size               True
tcp_nodelay                  Enable/Disable TCP_NODELAY Option          True
tcp_recvspace                Set Socket Buffer Space for Receiving      True
tcp_sendspace                Set Socket Buffer Space for Sending        True
Finally, let's look at Figure 2.

Figure 2. nmon statistics
Screen shot of nmon statistics
If you've been following the other series on AIX 7 (see Resources), you know we love nmon and you should also, once you start using it. With nmon (type in n after startup), you have a quick snapshot of everything going on in your network, including adapter details, MTU, error counters and collisions, and megabit rating.

Further, you also have the ability to capture data with nmon. Using the nmon analyzer, you can print out graphical reports directly from Microsoft® Excel spreadsheets. See Resources for a link to an IBM Wiki for the nmon manual or for downloads.

Summary

This article covered the relative importance of the network I/O subsystem, and defined the AIX 7 network I/O layers and how it relates to the OSI Model. You learned some best practices for network configuration, changed your Ethernet settings to support jumbo frame, and viewed interface hardware and driver data. You even examined the monitoring tools available to you and captured data using netpmon and nmon. In the next part of the series, you'll tune NFS, find out more about monitoring utilities, such as nfsstat and nmon, and discover how to tune with nfso.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Optimizing AIX 7 network performance: Part 2
By Surya20:102 comments
Optimizing AIX 7 network performance: Part 2, NFS monitoring and tuning
Introduction
Often performance tuning is the last thing on your mind when you consider Network File Systems (NFS). You're so preoccupied with configuring your file systems properly and ensuring the security of your systems that you might routinely forget that the N in NFS stands for network. Unfortunately, if you don't pay attention to NFS tuning, you might have a poorly performing NFS. Fortunately, IBM has integrated several tools to help monitor and tune NFS on AIX, including nfsstat and nfsmo. This article describes that monitoring and tuning.
As in previous versions of AIX, AIX 7 supports NFS v2, v3, and v4 (with NFS v4 as the default). In general, NFS v4 should be used in preference to previous versions, since it is more efficient and generally handles the performance of large loads and busy network environments. Most modern client operating systems support NFS v4 so there should be no need to support the older versions.
You'll have to tune both the client and the server. This article explains how you can use netpmon to monitor read subroutines and write subroutines for NFS clients, as well as NFS servers. You can also use nmon for a quick snapshot of NFS activity, and you can describe how to use nmon to analyze historically based data. Using netstat, you can validate that your network is healthy, because poor network utilization (or a poorly designed configuration) can result in poor NFS performance. This article also examines utilities such as nfs4cl that can be used for a specific version of NFS. And you'll learn some best practices, including spreading I/O across as many spindles as possible. In this case, you want the CPU load to be the bottleneck, not your I/O system.
Unlike other tuning examples in this series, for NFS you must monitor (and possibly tune) all subsystems including CPU, memory, I/O, and the network. From a client perspective, NFS file systems use disks that are remotely attached. Anything that affects the performance of that mounted disk will affect the performance of the NFS clients. The article also discusses important daemons, such as nfsd and biod, and how they actually tune themselves. You can see the basic interactions between the client and server to help you understand what's going on behind the scenes. Finally, the article emphasizes that, regardless of which subsystem you are tuning, systems tuning is an on-going process. Of course, the best time to start monitoring your systems is from the beginning, before you run into problems and users scream. Because there are so many factors that can influence NFS performance, make changes only one at a time so that you can accurately assess the impact of your change.
Reviewing NFS
This section offers an overview of the NFS as it relates to AIX 7. You can learn how the client and server relate to one another and the various factors that influence NFS performance.
You can choose the version type during the actual mounting of the file system, and you can have different versions of NFS running on the server. NFS now supports both TCP and UDP. Because UDP is faster (it does less), some environments that demand optimum performance (on a LAN) over reliability might perform better with UDP. TCP is more reliable (by establishing connections), and it also provides better performance over a WAN, because its flow control helps minimize network latency.
A benefit of NFS is that it acts independently of machine types and operating systems. It does this through its use of Remote Procedure Calls (RPCs), as shown below in Figure 1.

Figure 1. Interaction between client and server
Illustration of interaction between client and server
Figure 1 shows how NFS clients A and B access the data off NFS server Z. The client computers first request access to the exported data by mounting the file system. Then, when the client thread tries to process data within the NFS mounted file system, the data is redirected to biod, which takes the data through the LAN to the NFS server and its nfsd daemon. The server usesnfds to export the directories that are available to its clients.
As you can tell, you'll need to tune the network and I/O parameters. If Server Z is performing poorly, that obviously affects all of its NFS clients. If possible, tune the server specifically to function as an NFS server (more about that later).
What about the biod daemon? This daemon is required to perform both read-ahead and write-behind requests. The bioddaemon improves overall NFS performance as it either empties or fills up the buffer cache, acting as a liaison of the client applications. As shown in Figure 1, the biod daemon sends the requests to the server. On the other hand, nfsd is the liaison that provides NFS services to clients. When the server receives biod communication from the client, the server uses the nfsddaemon until the request is completed.
How is it that NFS was not stateful until Version 4, even though it could use TCP as early as Version 2? Figure 2 shows where NFS resides in relation to the TCP/IP stack and the OSI model.

Figure 2. OSI - TCP/IP - NFS
Illustration of OSI model, TCP/IP model, and NFS
NFS does not reside on the transport stack, because NFS uses Remote Procedure Calls (RPCs). RPCs are a library of procedures that allow the client and server processes to execute system calls as if they were executed in their own address spaces. In a typical UDP NFS Version 2 or 3 implementation, the NFS server sends its client a type of cookie after the clients are authorized to share the volume. This helps minimize network traffic. The problem is that if the server goes down, clients will continue to inundate the network with requests. That is why there is a preference for using TCP. Only Version 4 can use stateful connections, and only Version 4 uses TCP as its transport protocol.
NFS Version 4 has no interaction with portmapper or other daemons, such as lockd and statd, because they are rolled into the kernel. In versions other than Version 4, portmapper is used to register RPC services and to provide the port numbers for the communication between clients and servers. External Data Representation (XDR) provides the mechanism that RPC and NFS use to ensure reliable data exchange between the client and the server. It does so in a way that is platform independent for the exchange of binary data. This addresses the possibility of systems representing data in different ways. Using XDR, data can be interpreted correctly, even on platforms that are not alike.
Monitoring
This section provides an overview of the tools available to you to monitor your NFS systems. These tools enable you to troubleshoot a performance problem quickly and capture data for historical trending and analysis. Some tools are used more often for the server, while other tools are used more for the client. This section covers nmon, topas, nfsstat, nfs, nfs4cl, andnetpmon.
nmon and topas
For NFS tuning, you could use a tool like topas or nmon initially, because they provide a nice dashboard view of what is happening in your system. Remember that NFS performance problems might not be related to your NFS subsystem at all. Your bottleneck might be on the network or, from a server perspective, on your CPU or Disk I/O. Running a tool like topas or nmon can quickly enable you to get a sense of what the real issues are. The example system in this article has two CPUs, and it is running AIX 5.3 TL6.
Figure 3 shows nmon output from an NFS perspective.

Figure 3. nmon output
Screen shot of nmon output from an NFS perspective
Using nmon, there is a lot of information that is available to you from an NFS (client and server) perspective. There are no current bottlenecks at all on this system. Though topas has improved recently with its ability to capture data, nmon might still be a better choice. While nmon provides a front-end similar to topas, nmon is more useful in terms of long-term trending and analyses. Further, nmon provides the system administrator the capability to output data to a Microsoft® Excel spreadsheet that yields good looking charts (tailored for senior management and functional teams) that clearly illustrate your bottlenecks. This is done through a tool called nmon analyzer, which provides the hooks into nmon. The nmon analyzer is available as a free download (see Resources).
How can you use nmon to capture data and import it into the analyzer? Using sudo, first run nmon for 3 hours, taking a snapshot every 60 seconds: # sudo nmon -f -t -r test1 -s 60 -c 180. Then sort the output file that gets created: # sort -A systemnfs_yymmdd.nmon > systemnfs_yymmdd.csv.
Next, ftp the .csv file to your computer, start the nmon analyzer (enable macros), and click analyze nmon data.
nfsstat
The nfsstat tool is arguably the most important tool you'll use. This command displays all types of information about NFS and RPC calls. nfsstat is used as a monitoring tool to troubleshoot problems and for performance tuning. Depending on the flags you use, you can use nfsstat to display NFS client or server information. It can also show the actual usage count of file system operation. This helps you understand exactly how each file system is utilized, so that you can understand how to best tune your system.
Look at the client flag (c) first. The r flag gives the RPC information (see Listing 1).

Listing 1. Running nfsstat with the c flag

                
root@lpar24ml162f_pub[/] > nfsstat -cr
l488pp065_pub[/tmp] > nfsstat -cr
Client rpc:
Connection oriented
calls      badcalls   badxids    timeouts   newcreds   badverfs   timers     
279        0          0          0          0          0          0          
nomem      cantconn   interrupts 
0          0          0          
Connectionless
calls      badcalls   retrans    badxids    timeouts   newcreds   badverfs   
24         0          0          0          0          0          0          
timers     nomem      cantsend   
0          0          0   

What does this mean? Here are some of the connection-oriented parameters:
calls —Number of received RPC calls
badcalls —Number of calls rejected by the RPC layers
badxids —Number of times a server reply was received that did not correspond to any outstanding call
timeouts —Number of times calls timed-out while waiting for replies from the server
newcreds —Number of times authentication information was refreshed
badverfs —Number of times the call failed due to a bad verifier in the response
If you notice a large number of timeouts or badxids, you could benefit by increasing the timeo parameter with the mount command (details to come).
nfs
Now look at the nfs information (the n flag) in Listing 2.

Listing 2. nfs n flag information

                
l488pp065_pub[/tmp] > nfsstat -cn
Client nfs:
calls      badcalls   clgets     cltoomany  
279        0          0          0          
Version 2: (0 calls)
null       getattr    setattr    root       lookup     readlink   read       
0 0%       0 0%       0 0%       0 0%       0 0%       0 0%       0 0%       
wrcache    write      create     remove     rename     link       symlink    
0 0%       0 0%       0 0%       0 0%       0 0%       0 0%       0 0%       
mkdir      rmdir      readdir    statfs     
0 0%       0 0%       0 0%       0 0%       
Version 3: (279 calls)
null       getattr    setattr    lookup     access     readlink   read       
0 0%       126 45%    14 5%      9 3%       17 6%      0 0%       1 0%       
write      create     mkdir      symlink    mknod      remove     rmdir      
51 18%     6 2%       0 0%       0 0%       0 0%       0 0%       0 0%       
rename     link       readdir    readdir+   fsstat     fsinfo     pathconf   
0 0%       0 0%       1 0%       1 0%       1 0%       1 0%       0 0%       
commit     
51 18%  

What does this mean? Version 3 parameters include:
calls —Number of received NFS calls
badcalls —Number of calls rejected by the NFS layers
clgets —Number of times a client handle was received
cltoomany —Number of times the client handle had no unused entries
You should check that the badcalls number is not too high (you can calculate a simple percentage against the calls statistic). Unfortunately, the cltoomany statistic provides evidence of a problem, but there is no way to address the problem.
For the remainder of the statistics, you get a count of the individual operations. This is useful only to determine if you are handling high numbers of reads or writes, in which case you may want to reorganize your disk and NFS sharing allocations.
nfs4cl
If you're running NFS Version 4, you might be using nfs4cl more often. This command displays NFS Version 4 statistics and properties (see Listing 3).

Listing 3. Using nfs4cl

                
l488pp065_pub[/tmp] > nfs4cl showfs
Server      Remote Path          fsid                 Local Path         
--------    ---------------      ---------------      --------------- 

After running this command, you see that there is no output. Run the mount command to see more detail (see Listing 4).

Listing 4. Running the mount command

                
l488pp065_pub[/tmp] > mount   

node       mounted        mounted over    vfs       date        options      
-------- ---------------  ---------------  ------ ------------ --------------- 
         /dev/hd4         /                jfs2   Jul 30 03:16 rw,log=/dev/hd8 
         /dev/hd2         /usr             jfs2   Jul 30 03:16 rw,log=/dev/hd8 
         /dev/hd9var      /var             jfs2   Jul 30 03:16 rw,log=/dev/hd8 
         /dev/hd3         /tmp             jfs2   Jul 30 03:16 rw,log=/dev/hd8 
         /dev/hd1         /home            jfs2   Jul 30 03:16 rw,log=/dev/hd8 
         /dev/hd11admin   /admin           jfs2   Jul 30 03:16 rw,log=/dev/hd8 
         /proc            /proc            procfs Jul 30 03:16 rw              
         /dev/hd10opt     /opt             jfs2   Jul 30 03:16 rw,log=/dev/hd8 
         /dev/livedump    /var/adm/ras/livedump jfs2   Jul 30 03:16 rw,log=/dev/hd8 
192.168.1.11 /userdata/20009539 /home/u0009539   nfs3   Jul 30 03:22 bg,hard,intr,rw 
         /dev/fslv00      /wpars/webserver1 jfs2   Aug 13 09:42 rw,log=INLINE   
         /dev/fslv01      /wpars/webserver1/home jfs2   Aug 13 09:42 rw,log=INLINE   
         /opt             /wpars/webserver1/opt namefs Aug 13 09:42 ro              
         /proc            /wpars/webserver1/proc namefs Aug 13 09:42 rw              
         /dev/fslv02      /wpars/webserver1/tmp jfs2   Aug 13 09:42 rw,log=INLINE   
         /usr             /wpars/webserver1/usr namefs Aug 13 09:42 ro              
         /dev/fslv03      /wpars/webserver1/var jfs2   Aug 13 09:42 rw,log=INLINE 

As you can see, there are no file systems mounted using NFS Version 4. The nfs4cl command can also be used to set tunable parameters for NFS v4 filesystems, only NFS Version 3. You do this by using the setfsoptions subcommand to tune NFS Version 4.
Some of the key parameters you can configure include:
acdirmax and acdirmin—Specifies the upper and lower limit for the directory attribute cache time out value. You can tune these values to set the timeout in seconds that directory entries are retained in the cache after files have been changed. Setting too high a value can lead to file information being stale.
acregmax and acregmin—Specifies the upper and lower limit for the file attribute cache time out value. You can tune these values to set the timeout in seconds that file cache information is kept.
cio—Specifies that the filesystem should be mounted with support for concurrent readers and writers.
dio—Specifies that I/O on the filesystem behaves as if all of the files were opened using the direct I/O method, which can provide much faster performance with certain workloads.
rbr—Enables the release-behind-when-reading capability. This frees up NFS cache pages used to hold file data as soon as they have been copied to internal buffers. It can be useful to set this option if you are using NFS as temporary or transient storage for development servers. When the contents of the files are regularly changing, or you are regularly reading a wide variety of files, caching the file information may not achieve any performance benefits.
Listing 5 below shows you how to do it.

Listing 5. Tuning timeo with nfs4cl

                
root@lpar24ml162f_pub[/] > nfs4cl setfsoptions mnt rbr=7

Remember that you can also use the mount command to tune timeo.
netpmon
The netpmon command can be used to help troubleshoot NFS bottlenecks. In addition to monitoring many other types of network statistics, netpmon also monitors for clients: both read and write subroutines and NFS RPC requests. For servers,netpmon monitors read and write requests. netpmon starts a trace and runs in the background until you stop it (see Listing 6).

Listing 6. Using netpmon

                
l488pp065_pub[/tmp] > netpmon -T 2000000 -o /tmp/net.out
Run trcstop command to signal end of trace.
Sun Aug 15 04:58:06 2010
System: AIX 7.1 Node: l488pp065_pub Machine: 00F604884C00

Listing 7 below shows you how to stop the trace.

Listing 7. Stopping a trace

                
l488pp065_pub[/tmp] > trcstop[netpmon: Reporting started]
23675650 Missed Entries found

[netpmon: Reporting completed]
[               4 traced cpus               ]
[         0.091 secs total preempt time   ]

The output file
Now look at the NFS-specific information provided for in the output file (see Listing 8).

Listing 8. NFS-specific information in the output file

                
NFSv3 Client RPC Statistics (by Server):
----------------------------------------

Server                     Calls/s
----------------------------------
p650                        126.68
------------------------------------------------------------------------
Total (all servers)         126.68


Detailed NFSv3 Client RPC Statistics (by Server):
-------------------------------------------------

SERVER: p650
calls:                  5602
  call times (msec):    avg 1.408   min 0.274   max 979.611 sdev 21.310

COMBINED (All Servers)
calls:                  5602
  call times (msec):    avg 1.408   min 0.274   max 979.611 sdev 21.310

Using netpmon, you can see the NFS Version 3 Client statistics by Server. Note that while netpmon is a useful trace utility, the performance overhead can sometimes outweigh its benefits; particularly when there are other ways to get similar information, so be aware of that when using this utility.
Tuning with nfsmo and mount
This section describes specific nfs tuning commands. Use nfsmo to set and display your nfsstat tuning parameters. Use mount to tune NFS server-based resources, which take effect only after mounting the NFS file system.
Client
The biod daemon plays an important role in connectivity. While biod self-tunes the number of threads (the daemon process creates and kills threads as needed), the maximum number of biod threads can be tuned, depending on the overall load. An important concept to understand here is that only increasing the number of threads will not alleviate performance problems caused by CPU, I/O, or memory bottlenecks. For example, if your CPU is near 100% utilization, increasing the amount of threads does not help you at all. Increasing the number of threads can help when multiple application threads access the same files, and you do not find any other types of bottlenecks. Using lsof can help you further determine which threads are accessing which files.
In earlier tuning sections, you might remember the Virtual Memory Manager (VMM) parameters minperm and maxperm. Unlike when you tune database servers, with NFS you want to allow the VMM to use as much RAM as possible for NFS data caching. Most NFS clients have little need for working segment pages. To ensure that all memory is used for file caching, set the maxpermand maxclient both to 100%. In AIX 7 (and AIX 6), both parameters are restricted tunables, which means their limits are tightly controlled and limited (see Listing 9).

Listing 9. Setting maxperm and maxclient to 100 percent

                
l488pp065_pub[/tmp] > vmo -o maxperm%=100Setting maxperm% to 100
Warning: a restricted tunable has been modified
l488pp065_pub[/tmp] > vmo -o maxclient%=100Setting maxclient% to 100
Warning: a restricted tunable has been modified

Note that in the event that your application uses databases, and it could benefit from the application performing its own file data cache, you should not set maxperm and maxclient to 100%. In this instance, set these numbers low, and mount your file systems using Concurrent I/O over NFS. Note also that NFS maintains caches on each client system that contain attributes of the most recently accessed files and directories. The mount command controls the length of time that the entries are kept in cache. The mount parameters you can change are similar to those supported by nfs4cl.
Mount parameters rsize and wsize define the maximum sizes of RPC packets for read and write directories. The default value is 32768 bytes. With NFS Versions 3 and 4, if your NFS volumes are mounted on high-speed networks, you should increase this value to 65536. On the other hand, if your network is extremely slow, you might think about decreasing your default to reduce the amount of packet fragmentation by sending shorter packets. However, if you decrease the default, more packets will need to be sent, which could increase overall network utilization. Understand your network and tune it accordingly!
Server
Before looking at specific NFS parameters, always try to decrease the load on the network, while also looking at CPU and I/O subsystems. Bottlenecks often contribute to what appears to be an NFS-specific problem. For example, NFS can use either TCP or UDP, depending on the version and your preference. Make sure that your tcp_sendspace and tcp_recvspace are set to values higher than the defaults, because this can have an impact on your server by increasing network performance. These are not tuned with nfso, but with no (see Listing 10).

Listing 10. Setting tcp_sendspace and tcp_recvspace to values higher than the defaults

                
l488pp065_pub[/tmp] > no -a|grep send 
          ipsendredirects = 1
           ipsrcroutesend = 1
       send_file_duration = 300
            tcp_sendspace = 16384
            udp_sendspace = 9216

l488pp065_pub[/tmp] > no -o tcp_sendspace=524288Setting tcp_sendspace to 524288
Change to tunable tcp_sendspace, will only be effective for future connections

If you are running Version 4 of NFS, make sure you turn on nfs_rfc1323 (see Listing 11). This allows for TCP window sizes greater than 64KB. Set this on the client, as well.

Listing 11. Turning on nfs_rfc1323

                
l488pp065_pub[/tmp] >  no -o rfc1323=1Setting rfc1323 to 1
Change to tunable rfc1323, will only be effective for future connections

Setting the rfc1323 with nfso sets the TCP window to affect only NFS (as opposed to no, which sets this across the board). If you already set this with no, you don't need to change this, though you might want to, in case some other UNIX® administrator decides to play around with the no commands.
Similar to the client, if the server is a dedicated NFS server, make sure that you tune your VMM parameters accordingly. Modify themaxperm and maxclient parameters to 100% to make sure that the VMM controls the caching of the page files using as much memory as possible in the process. On the server, tune nfsd, which is multithreaded, like you tuned biod (other daemons you can tune include rpc.mountd and rpc.lockd). Like biod, nfsd self-tunes, depending on the load. Increase the number of threads with the nfso command. One such parameter is nfs_max_read_size, which sets the maximum size of RPCs for read replies.
Look at what nfs_max_read_size is set to in Listing 12.

Listing 12. Setting the nfs_max_read_size parameter

                
l488pp065_pub[/tmp] > nfso -L nfs_max_read_size
NAME                      CUR    DEF    BOOT   MIN    MAX    UNIT           TYPE
     DEPENDENCIES
--------------------------------------------------------------------------------
nfs_max_read_size         64K    64K    64K    512    64K    Bytes             D
-------------------------------------------------------------------------------

There are more parameters you can modify. To list all the parameters, use the -a or -L flag. -L provides more information in a nicer format (see Listing 13).

Listing 13. Using the -L flag with the nfso command

                
l488pp065_pub[/tmp] > nfso -L
NAME                      CUR    DEF    BOOT   MIN    MAX    UNIT           TYPE
     DEPENDENCIES
--------------------------------------------------------------------------------
client_delegation         1      1      1      0      1      On/Off            D
--------------------------------------------------------------------------------
nfs_max_read_size         64K    64K    64K    512    64K    Bytes             D
--------------------------------------------------------------------------------
nfs_max_write_size        64K    64K    64K    512    64K    Bytes             D
--------------------------------------------------------------------------------
nfs_rfc1323               1      1      1      0      1      On/Off            D
--------------------------------------------------------------------------------
nfs_securenfs_authtimeout 0      0      0      0      60     Seconds           D
--------------------------------------------------------------------------------
nfs_server_base_priority  0      0      0      31     125    Pri               D
--------------------------------------------------------------------------------
nfs_server_clread         1      1      1      0      1      On/Off            D
--------------------------------------------------------------------------------
nfs_use_reserved_ports    0      0      0      0      1      On/Off            D
--------------------------------------------------------------------------------
nfs_v3_server_readdirplus 1      1      1      0      1      On/Off            D
--------------------------------------------------------------------------------
nfs_v4_fail_over_timeout  0      0      0      0      3600   Seconds           D
--------------------------------------------------------------------------------
portcheck                 0      0      0      0      1      On/Off            D
--------------------------------------------------------------------------------
server_delegation         1      1      1      0      1      On/Off            D
--------------------------------------------------------------------------------
utf8_validation           1      1      1      0      1      On/Off            D
--------------------------------------------------------------------------------

Now you have a nice list of parameters you can modify!
Summary
This article discussed the Network File System (NFS), including its history and versions. It defined and discussed the NFS I/O stack and how the stack relates to both the OSI model and the TCP/IP stack. The article discussed best practices for disk configuration and VMM tuning in an NFS environment.
You examined the differences between tuning your clients and servers. You monitored your overall network and drilled down to the NFS layer during the monitoring. Further, you tuned your systems using nfso and mount.
In the next part of the series, you'll drill down to the actual networking packets. This will include a more detailed discussion ofnetstat. You'll also learn how to tune your network subsystem using the no utility.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Optimizing AIX 7 network performance: Part 3
By Surya20:11No comments
Optimizing AIX 7 network performance: Part 3, Monitoring your network packets and tuning the network
Introduction
While running commands (such as netstat) can provide useful information, sometimes you need to drill down more to the packet level. This is where tracing tools come in handy, such as iptrace, ipreport, and tcpdump. You'll also learn how you can tune a network using tools such as no. The no command is similar to vmo and ioo, but no is the network flavor. This article focuses on tcp workload tuning, udp workload tuning, and some other noteworthy parameters with the no utility. The article also addresses ARP cache tuning and how to monitor and tune ARP statistics. You will also look at name resolution and how you can easily increase performance by making small adjustments to resolve hostnames.
Monitoring network packets
In this section, you'll see an overview of tools available to help you monitor your network packets. These tools allow you to troubleshoot a performance problem quickly and capture data for historical trending and analysis.
Part 1 of this series addressed some of the very basic flags, such as -in, that you typically use with netstat. Using netstat, you can also monitor more detailed information about the packets themselves. For example, the -D option shows the overall number of packets received, transmitted, and dropped in your communication subsystem. The results are sorted by device, driver, and protocol (see Listing 1).

Listing 1. netstat with the -D option

                
l488pp065_pub[/tmp] > netstat -D
Source                         Ipkts                Opkts     Idrops     Odrops
-------------------------------------------------------------------------------
ent_dev1                    71306227               337207          0          0
ent_dev0                   203313084                82292          0          0
                ---------------------------------------------------------------
Devices Total              274619311               419499          0          0
-------------------------------------------------------------------------------
ent_dd1                     71306227               337207          0          0
ent_dd0                    203313084                82292          0          0
                ---------------------------------------------------------------
Drivers Total              274619311               419499          0          0
-------------------------------------------------------------------------------
ent_dmx1                    70327758                  N/A     978469        N/A
ent_dmx0                   202846759                  N/A     466325        N/A
                ---------------------------------------------------------------
Demuxer Total              273174517                  N/A    1444794        N/A
-------------------------------------------------------------------------------
IP                         204276236              1063977     899839     828213
IPv6                           70588                70588          0       6208
TCP                           714368               785630         72          0
UDP                        202697468               319900  202172157          0
                ---------------------------------------------------------------
Protocols Total            407688072              2169507  203072068     828213
-------------------------------------------------------------------------------
en_if1                      70327759               337207          0          0
en_if0                     202846780                82315          0          0
lo_if0                        780891               780890         12          0
                ---------------------------------------------------------------
Net IF Total               273955430              1200412         12          0
-------------------------------------------------------------------------------
NFS/RPC Client                    24                  N/A          0        N/A
NFS/RPC Server                     0                  N/A          0        N/A
NFS Client                       279                  N/A          0        N/A
NFS Server                         0                  N/A          0        N/A
                ---------------------------------------------------------------
NFS/RPC Total                    N/A                  303          0          0
-------------------------------------------------------------------------------
(Note:  N/A -> Not Applicable)

Another useful flag is the -s, which shows detailed statistics for all protocols used, including packets sent, received and dropped. If you only want to view tcp, you can also use the -p flag (see Listing 2).

Listing 2. netstat with the -p option

                
l488pp065_pub[/tmp] > netstat -p tcptcp:
        785684 packets sent
                227657 data packets (13800898 bytes)
                0 data packets (0 bytes) retransmitted
                279285 ack-only packets (509 delayed)
                0 URG only packets
                0 window probe packets
                69732 window update packets
                418020 control packets
                0 large sends
                0 bytes sent using largesend
                0 bytes is the biggest largesend
        714418 packets received
                360033 acks (for 14009902 bytes)
                69728 duplicate acks
                0 acks for unsent data
                217241 packets (1660096 bytes) received in-sequence
                72 completely duplicate packets (72 bytes)
                0 old duplicate packets
                0 packets with some dup. data (0 bytes duped)
                69632 out-of-order packets (0 bytes)
                0 packets (0 bytes) of data after window
                0 window probes
                69733 window update packets
                0 packets received after close
                0 packets with bad hardware assisted checksum
                0 discarded for bad checksums
                0 discarded for bad header offset fields
                0 discarded because packet too short
                0 discarded by listeners
                0 discarded due to listener's queue full
                5241 ack packet headers correctly predicted
                75327 data packet headers correctly predicted
        69655 connection requests
        69712 connection accepts
        139364 connections established (including accepts)
        139417 connections closed (including 12 drops)
        0 connections with ECN capability
        0 times responded to ECN
        2 embryonic connections dropped
        429685 segments updated rtt (of 429463 attempts)
        0 segments with congestion window reduced bit set
        0 segments with congestion experienced bit set
        0 resends due to path MTU discovery
        1 path MTU discovery termination due to retransmits
        3 retransmit timeouts
                0 connections dropped by rexmit timeout
        0 fast retransmits
                0 when congestion window less than 4 segments
        0 newreno retransmits
        0 times avoided false fast retransmits
        0 persist timeouts
                0 connections dropped due to persist timeout
        0 keepalive timeouts
                0 keepalive probes sent
                0 connections dropped by keepalive
        0 times SACK blocks array is extended
        0 times SACK holes array is extended
        0 packets dropped due to memory allocation failure
        0 connections in timewait reused
        0 delayed ACKs for SYN
        0 delayed ACKs for FIN
        0 send_and_disconnects
        0 spliced connections
        0 spliced connections closed
        0 spliced connections reset
        0 spliced connections timeout
        0 spliced connections persist timeout
        0 spliced connections keepalive timeout
        0 TCP checksum offload disabled during retransmit
        0 Connections dropped due to bad ACKs

There are actually so many different ways of using netstat that the best place to start is by looking at the man page and go from there. Don't be afraid to run these commands, because they won't eat up disk space or affect performance. The tracing tools that are provided within AIX 7 are used to record detailed information about the packets. Use them with more caution. These tools are extremely helpful when trying to determine the root cause of network performance problems.
First, look at iptrace and ipreport. The iptrace command records all the packets received from the network interfaces. Theipreport command formats the data that is generated from iptrace into a readable trace report. Further, you can also useipfilter to sort the output file created from ipreport. Try starting the trace and keep it going for one minute (see Listing 3).

Listing 3. Starting the trace

                
l488pp065_pub[/tmp] > /usr/sbin/iptrace -a -i en0 iptrace.out &
[1]     12845206
l488pp065_pub[/tmp] > [8126632]

[1] +  Done              /usr/sbin/iptrace -a -i en0 iptrace.out &
l488pp065_pub[/tmp] > ps -ef | grep iptrace    
    root  8126632        1  15 05:54:55      -  0:00 /usr/sbin/iptrace 
                                             -a -i en0 iptrace.out 
    root 14221424  7012524   7 05:55:17  pts/1  0:00 grep iptrace 
 

When you are done with the trace, you need to kill the process (see Listing 4).

Listing 4. Killing the process

l488pp065_pub[/tmp] > kill -1 8126632l488pp065_pub[/tmp] 
                              > iptrace: unload success!
l488pp065_pub[/tmp] > ipreport -r -s iptrace.out >/ipreport.network

Now, examine the output (see Listing 5):

Listing 5. Examining the output

l488pp065_pub[/tmp] > more /ipreport.network
IPTRACE version: 2.0

ETH: ====( 114 bytes transmitted on interface en0 )==== 05:54:55.151599119
ETH:    [ 66:da:93:d1:6b:17 -> 6e:87:70:00:40:03 ]  type 800  (IP)
IP:     < SRC =  172.29.148.225 >  (l488pp065_pub)
IP:     < DST =   172.29.131.16 >  
IP:     ip_v=4, ip_hl=20, ip_tos=16, ip_len=100, ip_id=49399, ip_off=0 DF
IP:     ip_ttl=60, ip_sum=d60, ip_p = 6 (TCP)
TCP:    <source port=22(ssh), destination port=54678 >
TCP:    th_seq=47587592, th_ack=3002348404
TCP:    th_off=8, flags<PUSH | ACK>
TCP:    th_win=65522, th_sum=0, th_urp=0
TCP:            nop
TCP:            nop
TCP:            timestamps TSVal: 0x4f486827  TSEcho: 0x4c8da569
TCP: 00000000     9fec0a46 c8dd1c9b 98ff0213 87c714c0     |...F............|
TCP: 00000010     0ec081aa 7c76335f 0bfd0d8f 63d0bf1a     |....|v3_....c...|
TCP: 00000020     808359b4 13e1a29d 4dacdd51 dad01053     |..Y.....M..Q...S|

Listing 5 shows the captured information about each packet, including packet size and IP address information. As you can imagine, the trace file can get very large quickly. The example file grew to 40MB in less than one minute! Be very careful when running these traces, because you will run out of disk space really fast if you don't have the disk bandwidth for these files.
You can also start the trace using the System Resource Controller (SRC). See Listing 6.

Listing 6. Starting the trace using SRC

                
l488pp065_pub[/tmp] > startsrc -s iptrace -a "-i 
en1 /home/testing/iptrace/iptracelog"0513-059 The iptrace Subsystem 
has been started. Subsystem PID is 12845270.

l488pp065_pub[/tmp] > stopsrc -s iptrace
0513-004 The Subsystem or Group, iptrace, is currently inoperative.

What about tcpdump? tcpdump prints out headers of the packets, which are captured for each NIC. One important difference with tcpdump is that, unlike iptrace, it can look at only one network interface at a time. And, because iptrace examines the entire packet from the kernel space, the results can offer lots of dropped packets. With tcpdump, you can also limit the amount of data to be traced. Also, you do not need to use an ipreport type of command to format binary data, because tcpdump does the trace and the output. See Listing 7 for an example.

Listing 7. Using tcpdump

                
l488pp065_pub[/tmp] > tcpdump > tcp.outtcpdump: listening on 
en0, link-type 1, capture size 96 bytes

tcpdump continues to capture packets until you hit Ctrl+C. If any packets were dropped due to a lack of buffer space, it reports that, too.
Listing 8 shows what you see when you end the example trace and view the file.

Listing 8. End of the trace

                                
28 packets received by filter0 packets dropped by kernel
l488pp065_pub[/tmp] > cat tcp.out

06:00:21.003328 IP l488pp065_pub.ssh > 172.29.131.16.54678: 
P 47609416:47609464(48) ack 3002357700 win 65522 <nop,nop,timestamp 133014597
1 1284351989>
06:00:21.003387 IP l488pp065_pub.ssh > 172.29.131.16.54678: P 48:208(160) 
ack 1 win 65522 <nop,nop,timestamp 1330145971 1284351989>
06:00:21.028081 IP 172.29.131.16.54678 > l488pp065_pub.ssh: . ack 208 win 
32761 <nop,nop,timestamp 1284351989 1330145971>
06:00:21.238937 ARP, Request who-has 172.29.173.186 tell 172.29.133.221, length 46
06:00:21.239110 ARP, Request who-has 172.29.173.236 tell 172.29.129.59, length 46
06:00:21.325060 ARP, Request who-has 172.29.175.252 tell 172.29.129.58, length 46
06:00:21.464383 IP6 fe80::4464:ceff:fe65:4f0c > ff02::1:ff41:34d0: ICMP6, 
neighbor solicitation, who has fe80::221:5eff:fe41:34d0, length
 32
06:00:21.505281 ARP, Request who-has 172.29.175.60 tell 172.29.133.223, length 46
06:00:22.013530 ARP, Request who-has 172.29.174.66 tell 172.29.133.222, length 46
06:00:22.054164 ARP, Request who-has 172.29.173.237 tell 172.29.129.59, length 46
06:00:22.076819 ARP, Request who-has 172.29.122.25 tell 172.29.122.2, length 46
06:00:22.393898 IP 172.29.148.116.32852 > 239.255.255.253.svrloc: UDP, length 56
06:00:22.464355 IP6 fe80::4464:ceff:fe65:4f0c > ff02::1:ff41:34d0: ICMP6, neighbor 
solicitation, who has fe80::221:5eff:fe41:34d0, length
 32
06:00:22.935140 802.1d config 8000.00:16:60:f9:a8:00.8011 root 8000.00:16:60:f9:a8:00 
pathcost 0 age 0 max 20 hello 2 fdelay 15 
06:00:23.186380 ARP, Request who-has 172.29.122.26 tell 172.29.122.2, length 46
06:00:24.520770 ARP, Request who-has 172.29.175.60 tell 172.29.133.223, length 46
06:00:24.558139 ARP, Request who-has 172.29.175.252 tell 172.29.129.58, length 46
06:00:24.573524 ARP, Request who-has 172.29.175.5 tell 172.29.129.57, length 46
06:00:24.736838 IP 172.29.148.116.32853 > 239.255.255.253.svrloc: UDP, length 56
06:00:24.931436 802.1d config 8000.00:16:60:f9:a8:00.8011 root 8000.00:16:60:f9:a8:00 
pathcost 0 age 0 max 20 hello 2 fdelay 15 
06:00:25.029112 IP 172.29.133.222.netbios-dgm > 
           172.29.191.255.netbios-dgm: UDP, length 201
06:00:25.029965 IP 172.29.133.222.netbios-dgm > 
           172.29.191.255.netbios-dgm: UDP, length 201
06:00:25.030751 IP 172.29.133.222.netbios-dgm > 
           172.29.191.255.netbios-dgm: UDP, length 201
06:00:25.031674 IP 172.29.133.222.netbios-dgm > 
            172.29.191.255.netbios-dgm: UDP, length 201
06:00:25.032636 IP 172.29.133.222.netbios-dgm > 
            172.29.191.255.netbios-dgm: UDP, length 201
06:00:25.033647 IP 172.29.133.222.netbios-dgm > 
            172.29.191.255.netbios-dgm: UDP, length 201
06:00:25.033732 CDP v2, ttl: 180s, Device-ID 'Switch'[|cdp]
06:00:25.034738 IP 172.29.133.222.netbios-dgm > 
            172.29.191.255.netbios-dgm: UDP, length 201
06:00:25.035741 IP 172.29.133.222.netbios-dgm > 
            172.29.191.255.netbios-dgm: UDP, length 201

The main benefit of tcpdump is that you can specify filters so that you can select only particular protocols, sources, destinations, ports and other combinations. This is useful if you want diagnose or determine the NFS traffic, for example, between two hosts.
Tuning network performance
In this section, you will learn how to use the no command to tune your network subsystem. You'll also look at other areas that can impact network performance, and you'll learn about recommended tuning methodologies where appropriate.
The most important command for tuning network parameters is the no command. First, take a look at all the parameters, using the -a flag (see Listing 9). Be warned, though, that the list is quite extensive.

Listing 9. Viewing the parameters

                
l488pp065_pub[/tmp] > no -a                 
                 arpqsize = 12
               arpt_killc = 20
              arptab_bsiz = 7
                arptab_nb = 149
                bcastping = 0
      clean_partial_conns = 0
                 delayack = 0
            delayackports = {}
         dgd_packets_lost = 3
            dgd_ping_time = 5
           dgd_retry_time = 5
       directed_broadcast = 0
                 fasttimo = 200
        icmp6_errmsg_rate = 10
          icmpaddressmask = 0
ie5_old_multicast_mapping = 0
                   ifsize = 256
               ip6_defttl = 64
                ip6_prune = 1
            ip6forwarding = 0
       ip6srcrouteforward = 1
       ip_ifdelete_notify = 0
                 ip_nfrag = 200
             ipforwarding = 0
                ipfragttl = 2
        ipignoreredirects = 0
                ipqmaxlen = 100
          ipsendredirects = 1
        ipsrcrouteforward = 1
           ipsrcrouterecv = 0
           ipsrcroutesend = 1
          llsleep_timeout = 3
                  lo_perf = 1
                lowthresh = 90
                 main_if6 = 0
               main_site6 = 0
                 maxnip6q = 20
                   maxttl = 255
                medthresh = 95
               mpr_policy = 1
              multi_homed = 1
                nbc_limit = 262144
            nbc_max_cache = 131072
            nbc_min_cache = 1
         nbc_ofile_hashsz = 12841
                 nbc_pseg = 0
           nbc_pseg_limit = 524288
           ndd_event_name = {all}
        ndd_event_tracing = 0
            ndp_mmaxtries = 3
            ndp_umaxtries = 3
                 ndpqsize = 50
                ndpt_down = 3
                ndpt_keep = 120
               ndpt_probe = 5
           ndpt_reachable = 30
             ndpt_retrans = 1
             net_buf_size = {all}
             net_buf_type = {all}
     net_malloc_frag_mask = {0}
        netm_page_promote = 1
           nonlocsrcroute = 0
                 nstrpush = 8
              passive_dgd = 0
         pmtu_default_age = 10
              pmtu_expire = 10
 pmtu_rediscover_interval = 30
              poolbuckets = 4
              psebufcalls = 20

Alternatively, you can also use the -L flag. It provides much more detailed information, including current, default, boot, and range of settings. This can make it much easier to determine whether a given value is working at its optimum value and whether a specific item could be improved beyond it's current value. Listing 10 shows you only the first few lines.

Listing 10. Using the -L flag

                
l488pp065_pub[/tmp] > no -L
General Network Parameters
--------------------------------------------------------------------------------
NAME                      CUR    DEF    BOOT   MIN    MAX    UNIT           TYPE
     DEPENDENCIES
--------------------------------------------------------------------------------
fasttimo                  200    200    200    50     200    millisecond       D
--------------------------------------------------------------------------------
nbc_limit                 256K   256K   256K   0      8E-1   kbyte             D
     thewall
--------------------------------------------------------------------------------
nbc_max_cache             128K   128K   128K   1      256M   byte              D
     nbc_min_cache
     nbc_limit
--------------------------------------------------------------------------------
nbc_min_cache             1      1      1      1      128K   byte              D
     nbc_max_cache
--------------------------------------------------------------------------------
nbc_ofile_hashsz          12841  12841  12841  1      999999 segment           D
--------------------------------------------------------------------------------
nbc_pseg                  0      0      0      0      2G-1   segment           D
--------------------------------------------------------------------------------
nbc_pseg_limit            512K   512K   512K   0      1M     kbyte             D
--------------------------------------------------------------------------------
ndd_event_name            {all}  {all}  {all}  0      128    string            D
... trimmed for clarity

There are many parameters here. The thewall defines the upper limit for network kernel buffers. Today, its size is defined at installation time, depending on the amount of RAM and the kernel type. For example, if you are running AIX 5.3 on a 64-bit kernel, the parameter is set at half the size of real memory.

Listing 11. Setting the size of the thewall parameter 

                
l488pp065_pub[/tmp] > no -a|grep thewall
thewall = 1048576

Part 1 discussed mbufs, but it's worth another mention here, because it relates to thewall. Remember that mbufs are used to store data in the kernel for both incoming and outgoing traffic. This is why determining the right amount of mbufs is extremely important. The value of the maxmbuf tunable limits the amount of memory that the communication systems use. If the value is 0,thewall tunable is used, and it cannot be modified from its default. Changing this tunable is a way to lower the thewall limit. As the default, if maxmbuf is 0, this value is used regardless of what thewall uses. netstat -m is used to detect shortages of failures of network memory requests (see Listing 12).

Listing 12. netstat with the -m option

                
l488pp065_pub[/tmp] > netstat -m
Kernel malloc statistics:

******* CPU 0 *******
By size           inuse     calls failed   delayed    free   hiwat   freed
64                  558   2087455      0         7     274    5240       0
128                5884   1901723      0       175     164    2620       0
256                5780    653578      0       295    2876    5240     500
512                7970 182051630      0       972     102    6550       0
1024               3159   1960612      0       794      49    2620       0
2048               1069   3462138      0       520      25    3930       0
4096               2056      2794      0        83       3    1310       0
8192                  5       260      0         3     163     327       0
16384               256       413      0        62       0     163       0
32768                55       274      0        23       4      81       0
65536               117       175      0        76       0      81       0
131072                4         5      0         0     102     204       0
... other CPU stats trimmed

Streams mblk statistic failures:
0 high priority mblk failures
0 medium priority mblk failures
0 low priority mblk failures

In the example, there are no shortages (failures).
Although there are many parameters you can change with the no utility, most of them are better left alone. The most important parameters are ones that refer to TCP streaming workload tuning.
tcp_sendspace —This controls how much buffer space in the kernel is used to buffer application data. You really want to bump this up from the default, because if its limit is reached, the sending application suspends data transfer until TCP sends the data to the buffer.
tcp_receivespace —In addition to controlling the amount of buffer space to be consumed by receive buffers, AIX 7 also uses this value to determine the size to make its transmit window.
udp_sendspace —With UDP, you can set this to no more than 65536, because IP has an upper limit of 65536 bytes per packet.
udp_resvspace —This value should be greater than udp_sendpsace, because it needs to handle as many simultaneous UDP packets per socket as it can. This parameter can easily be set to 10 times the value ofudp_sendspace.
Now, let's make some changes. First, increase the size of udp_sendspace (see Listing 13).

Listing 13. Increasing the size of udp_sendspace

                
l488pp065_pub[/tmp] > no -p -o udp_sendspace=65536Setting udp_sendspace to 65536
Setting udp_sendspace to 65536 in nextboot file
Change to tunable udp_sendspace, will only be effective for future connections

Next, change udp_recsvspace to the recommended configuration of 10 times udp_sendspace). See Listing 14.

Listing 14. Changing udp_recsvspace

                
l488pp065_pub[/tmp] > no -p -o udp_recvspace=655360Setting udp_recvspace to 655360
Setting udp_recvspace to 655360 in nextboot file
Change to tunable udp_recvspace, will only be effective for future connections

Note that the -p flag keeps the entries, even after a reboot. It appends the /etc/tunables/nextboot stanza file, as shown in Listing 15.

Listing 15. Looking at the /etc/tunables/nextbook file

                
no:
        udp_recvspace = "655360"
        udp_sendspace = "65536"

Regarding the tcp parameters for higher speed adapters, there is no problem setting tcp_sendspace to twice the value oftcp_recvspace. For example, you can use the settings in Listing 16.

Listing 16. Examples settings for tcp_sendspace 

                
tcp_receivespace = 262144
tcp_sendspace= 524288

Other important workload parameters include rfc1323 and sb_max.
The rfc1323 tunable enables the TCP window scaling option, which allows TCP to use a larger window size. Turning it on enables the best TCP performance. The sb_max tunable sets an upper limit on the number of socket buffers queued to an individual socket, which controls the amount of buffer space consumed by buffers (queued to either a sender or received socket). This amount should usually be less than the wall and approximately 4 times the size of the largest value of the tcp or udp send and receive settings. For example, if your udp_recvspace is 655360, you can't go wrong if you double it to 1310720.
Now look at tcp_nodelayack. This tunable prompts TCP to send an immediate acknowledgement, rather than a delayed acknowledgement. While this can add more overhead in some environments, it can greatly improve network performance in others. If you change this parameter, but it does not improve performance, you can quickly change it back.
Next look at ipqmalen. This tunable controls the length of the IP input queue. If you see an overflow counter (through the use ofnetstat -s), setting a maximum length of this queue can help fix the overflow.
What about ARP? When many clients are connected to the system, you might want to tune the ARP cache. You can look at the statistics using netstat (see Listing 17).

Listing 17. Using netstat with -p arp 

                
l488pp065_pub[/tmp] > netstat -p arparp:
        12 packets sent
        0 packets purged

If you see a high purge count, increase the size of the ARP table. For the example table, this isn't needed.
Here are the no parameters that relate to ARP (see Listing 18).

Listing 18. Using the no parameters

                
l488pp065_pub[/tmp] > no -a | grep arp                 
                 arpqsize = 12
               arpt_killc = 20
              arptab_bsiz = 7
                arptab_nb = 149

You can view the specific interface settings using either ifconfig or lsattr. In the example in Listing 19, look at the settings using ifconfig (look at the last line which references some of the tunables mentioned earlier).

Listing 19. Viewing specific interface settings using ifconfig

                
l488pp065_pub[/tmp] > ifconfig en0en0: flags=1e080863,480<P,BROADCAST,NOTRAILERS,
RUNNING,SIMPLEX,MULTICAST,GROUPRT,64BIT,CHECKSUM_OFFLOAD(ACTIVE),CHAIN>
        inet 172.29.148.225 netmask 0xffffc000 broadcast 172.29.191.255
         tcp_sendspace 262144 tcp_recvspace 262144 rfc1323 1

You can change these options (by interface) by using SMIT, chdev, or ifconfig. Note that ifconfig will not update the Object Data Manager (ODM). Therefore, on a reboot, it will revert to the previous value. Because of that, you should use SMIT: the fastpath of smit tcpip>further configuration>Network interfaces>Change/Show characteristics of an interface (see Figure 1).

Figure 1. Using SMIT to change interface settings
Using SMIT to change interface settings
You might wonder why the no parameters don't apply to some interfaces. Name resolution is another area that can impact performance. If you know how you want to resolve (using DNS or the hosts file), make sure name resolution is set up correctly in the /etc/netsvc.conf file. Look at a piece of the file in Listing 20.

Listing 20. Piece of /etc/netsvc.conf file

                
# Example:
# aliases = nis, files
#
hosts=local,bind4

If you're using DNS, take out the local if you are not using a host's file at all, or you can leave it in if you are using it as a backup to DNS (but make it the second entry). Alternatively, take out the bind if you're not using DNS at all, because it will only slow down your performance by first attempting (if it is the first entry in the record) to resolve using a Name Server that doesn't exist.
Summary
This article discussed how to monitor network packets on the network. You used netstat and drilled down to the packet level using tracing tools, such as iptrace and tcpdump. Further, you learned how to tune your network using the no utility. Using this utility, you explored tcp and udp workload tuning while also learning some other noteworthy parameters. You made tuning changes and read about how you might want to tune certain settings. You also examined ARP cache tuning and saw how you could monitor and tune ARP statistics. You looked at ISNO and learned how you could tune specific no tunables by interface. You also looked at name resolution and how you could easily increase performance by making small adjustments in how to resolve hostnames.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------


Optimizing AIX 7 performance: Part 1
By Surya20:15No comments
Part 1, Disk I/O overview and long-term monitoring tools (sar, nmon, and topas)
Introduction
A critical component of disk I/O tuning involves implementing best practices prior to building your system. Because it is much more difficult to move things around when you are already up and running, it is extremely important that you do things right the first time when planning your disk and I/O subsystem environment. This includes the physical architecture, logical disk geometry, and logical volume and file system configuration.

When a system administrator hears that there might be a disk contention issue, the first thing he or she turns to is iostat. iostat, the equivalent of using vmstat for your memory reports, is a quick and dirty way of getting an overview of what is currently happening on your I/O subsystem. While running iostat is not an inappropriate reaction at all, the time to start thinking about disk I/O is long before tuning becomes necessary. All the tuning in the world will not help if your disks are not configured appropriately for your environment from the beginning. Furthermore, it is extremely important to understand the specifics of disk I/O and how it relates to AIX® and your System p™ hardware.

When it comes to disk I/O tuning, generic UNIX® commands and tools help you much less than specific AIX tools and utilities that have been developed to help you optimize your native AIX disk I/O subsystem. In this article, we will define and discuss the AIX I/O stack and correlate it to both the physical and logical aspects of disk performance. We will discuss direct, concurrent, and asynchronous I/O: what they are, how to turn them on, and how to monitor and tune them. We will also introduce some of the long-term monitoring tools that you should use to help tune your system. You might be surprised to hear that iostat is not one of the tools recommended to help you with long-term gathering of statistical data.

This article looks at the support and changes present in a beta release of AIX 7, including the ways in which the configuration of the different subsystems has changed. The main changes in AIX 7 further simplify the operation and configuration of many of the I/O subsystems, work that had originally been started in AIX 6. The result is that many of the different I/O subsystems no longer need to be enabled and configured. Instead, they are supplied in a pre-configured state and are automatically enabled and started when an application requests that functionality.

The article also concentrates on changes that will help identify and improve the subsystem you are looking to tune. The best time to start monitoring your systems is when you first put your system in production, and it is running well (rather than waiting until your users are screaming about slow performance). You really need to have a baseline of what the system looked like when it was behaving normally to analyze data when it is presumably not performing adequately. When making changes to your I/O subsystem, make these changes one at a time so that you will be able to assess fully the impact of your change. To assess that impact, you'll be capturing data using one of the long-term monitoring tools recommended in this article.
Disk I/O overview
It shouldn't surprise you that the slowest operation for running any program is the time actually spent on retrieving the data from disk. This all comes back to the physical component of I/O. The actual disk arms must find the correct cylinder, the control needs to access the correct blocks, and the disk heads have to wait while the blocks rotate to them. The physical architecture of your I/O system should be understood prior to any work on tuning activities for systems, since all the tuning in the world won't help a poorly architected I/O subsystem that consists of a slow disk or inefficient use of adapters.

Figure 1 illustrates how tightly integrated the physical I/O components relate to the logical disk and its application I/O. This is what is commonly referred to as the AIX I/O stack.

Figure 1. The AIX I/O stack
Illustration of the AIX I/O stack
You need to be cognizant of all the layers when tuning, as each impacts performance in a different way. When first setting up your systems, start from the bottom (the physical layer) as you configure your disk, the device layer, its logical volumes, file systems, and the files and application. We can't emphasize enough the importance in planning your physical storage environment. This involves determining the amount of disk, type (speed), size, and throughput. One important challenge with storage technology to note is that while storage capabilities of disk are increasing dramatically, the rotational speed of the disk increases at a much slower pace. You must never lose sight of the fact that while RAM access takes about 540 CPU cycles, disk access can take 20 million CPU cycles. Clearly, the weakest link on a system is the disk I/O storage system, and it's your job as the system administrator to make sure it doesn't become even more of a bottleneck. As alluded to earlier, poor layout of data affects I/O performance much more than any tunable I/O parameter. Looking at the I/O stack helps you to understand this, as Logical Volume Manager (LVM) and disk placement are closer to the bottom than the tuning parameters (ioo and vmo).

Now let's discuss some best practices of data layout. One important concept is making sure that your data is evenly spread across your entire physical disk. If your data resides on only a few spindles, what is the purpose of having multiple logical unit numbers (LUNs) or physical disks? If you have a SAN or another type of storage array, you should try to create your arrays of equal size and type. You should also create them with one LUN for each array and then spread all your logical volumes across all the physical volumes in your Volume Group.

As stated previously, the time to do this is when you first configure your system, as it is much more cumbersome to fix I/O problems than memory or CPU problems, particularly if it involves moving data around in a production environment. You also want to make certain that your mirrors are on separate disks and adapters. Databases pose separate, unique challenges; so, if possible, your indexes and redo logs should also reside on separate physical disks. The same is true for temporary tablespaces often used for performing sort operations.

Using high-speed adapters to connect the disk drives are extremely important, but you must make certain that the bus itself does not become a bottleneck. To prevent this from happening, make sure to spread the adapters across multiple buses. At the same time, do not attach too many physical disks or LUNs to any one adapter, as this also significantly impacts performance. The more adapters that you configure, the better, particularly if there are large amounts of heavily utilized disk. You should also make sure that the device drivers support multi-path I/O (MPIO), which allows for load balancing and availability of your I/O subsystem.
Direct I/O
Let's return to some of the concepts mentioned earlier, such as direct I/O. What is direct I/O? First introduced in AIX Version 4.3, this method of I/O bypasses the Virtual Memory Manager (VMM) and transfers data directly to disk from the user's buffer. Depending on your type of application, it is possible to have improved performance when implementing this technique. For example, files that have poor cache utilization are great candidates for using direct I/O. Direct I/O also benefits applications that use synchronous writes, as these writes have to go to disk. CPU usage is reduced because the dual data copy piece is eliminated. This copy occurs when the disk is copied to the buffer cache and then again from the file. One of the major performance costs of direct I/O is that while it can reduce CPU usage, it can also result in processes taking longer to complete for smaller requests. Note that this applies to persistent segments files that have a permanent location on disk. When the file is not accessed through direct I/O with the IBM Enhanced Journaled File System for AIX 5L™ (JFS2), the file is cached as local pages and the data copied into RAM. Direct I/O, in many ways, gives you the similar performance of using raw logical volumes, while still keeping the benefits of having a JFS filesystem (for example, ease of administration). When mounting a file system using direct I/O, you should avoid large, file-enabled JFS filesystems.
Concurrent I/O
First introduced in AIX Version 5.2, this feature invokes direct I/O, so it has all the other performance considerations associated with direct I/O. With standard direct I/O, inodes (data structures associated with a file) are locked to prevent a condition where multiple threads might try to change the consults of a file simultaneously. Concurrent I/O bypasses the inode lock, which allows multiple threads to read and write data concurrently to the same file. This is due to the way JFS2 is implemented with a write-exclusive inode lock, allowing multiple users to read the same file simultaneously. As you can imagine, direct I/O can cause major problems with databases that continuously read from the same file. Concurrent I/O solves this problem, which is why it's known as a feature that is used primarily for relational databases. Similar to direct I/O, you can implement this either through an open system call or by mounting the file system, as follows:

 # mount -o cio /u.

When you mount the file system with this command, all its files use concurrent I/O. Even more so than using direct I/O, concurrent I/O provides almost all the advantages of using raw logical volumes, while still keeping the ease of administration available with file systems. Note that you cannot use concurrent I/O with JFS (only JFS2). Further, applications that might benefit from having a file system read ahead or high buffer cache hit rates might actually see performance degradation.
Asynchronous I/O
What about asynchronous I/O? Synchronous and asynchronous I/O refers to whether or not an application is waiting for the I/O to complete to begin processing. Appropriate usage of asynchronous I/O can significantly improve the performance of writes on the I/O subsystem. The way it works is that it essentially allows an application to continue processing while its I/O completes in the background. This improves performance because it allows I/O and application processing to run at the same time. Turning on asynchronous I/O really helps in database environments. How can you monitor asynchronous I/O server utilization? Both iostat and nmon can monitor asynchronous I/O server utilization. Monitoring asynchronous I/O and changing the parameters is only possible if you have executed an application that requires asynchronous I/O. The AIX kernel enables the asynchronous I/O components. This can lead to confusion when trying to alter parameters as the ability to change them is unavailable until the module has been loaded.

To determine whether asynchronous I/O has been enabled, you can check the output of the ioo command, as shown in Listing 1.

Listing 1. Checking the output of the ioo command
# ioo -a
                    aio_active = 0
                   aio_maxreqs = 65536
                aio_maxservers = 30
                aio_minservers = 3
         aio_server_inactivity = 300
         j2_atimeUpdateSymlink = 0
 j2_dynamicBufferPreallocation = 16
             j2_inodeCacheSize = 200
           j2_maxPageReadAhead = 128
             j2_maxRandomWrite = 0
          j2_metadataCacheSize = 200
           j2_minPageReadAhead = 2
j2_nPagesPerWriteBehindCluster = 32
             j2_nRandomCluster = 0
              j2_syncPageCount = 0
              j2_syncPageLimit = 16
                    lvm_bufcnt = 9
                    maxpgahead = 8
                    maxrandwrt = 0
                      numclust = 1
                     numfsbufs = 196
                     pd_npages = 65536
              posix_aio_active = 0
             posix_aio_maxreqs = 65536
          posix_aio_maxservers = 30
          posix_aio_minservers = 3
   posix_aio_server_inactivity = 300


You can see from this listing that both the aio_active and posix_aio_active values are set to zero. The other parameters are configurable and will become enabled when the corresponding subsystem has been used.

The aio kernel processes are now available as aioLpool and aioPpool (see Listing 2).

Listing 2. aio kernel processes are available as aioPpool and aioLpool.
 
l488pp065_pub[/] > pstat -a|grep aio
37 a  250068      1 250068     0     0     1  aioPpool  
38 a  260052      1 260052     0     0     1  aioLpool 


The result is that the aio system takes up less memory and process space. The tunable parameters, for exampleaio_maxservers, are now configured per CPU tunable and specify the maximum number of servers that can be created. Note that changing these values will not change the immediate number of servers available, only the maximum created by the kernel when there is existing outstanding I/O.

Additional parameters you may want to change are the maximum number of asynchronous I/O requests (aio_maxreqs) which alter the request queue size, and the aio_server_inactivity which controls when asynchronous services are killed when no more requests exist.

To change the parameters, you can use either ioo or smit. You can find the asynchronous parameters within Performance & Resource Scheduling, Tuning Kernel & Network Parameters, and Tuning IO Parameters. Within smit, you can get good idea of both the current and the maximum possible values.

The iostat -A command reports back asynchronous I/O statistics if the kernel modules are loaded (see Listing 3).

Listing 3. iostat -A command
                
# iostat -A

System configuration: lcpu=2 drives=3 ent=0.60 paths=4 vdisks=4                 
                                                                                
aio: avgc avfc maxgc maxfc maxreqs avg-cpu: % user % sys % idle % iowait physc % entc
       0   0    32    0      4096            6.4    8.0    85.4    0.2    0.1    16.0
                                                                                
Disks:         % tm_    act      Kbps      tps     Kb_read   Kb_wrtn                   
hdisk0           0.5    2.0       0.5       0         4                   
hdisk1           1.0    5.9       1.5       8         4                   
hdisk2           0.0    0.0       0.0       0         0
What does this all mean?
avgc: This reports back the average global asynchronous I/O request per second of the interval you specified.
avfc: This reports back the average fastpath request count per second for your interval.
maxgc: This reports back the max global asynchronous I/O request since the last time this value was fetched.
maxfc: This reports back the maximum fastpath request count since the last time this value was fetched.
maxreqs: This is the maximum asynchronous I/O requests allowed.
The major difference between aio and posixaio is that the two involve different parameter passing, so you really need to configure both.

In AIX 7, as in AIX 6, the fsfastpath and fastpath tunables are no longer modifiable. They are now classed as restricted tunables and are set to 1 (enabled) by default. As such, they both enable asynchronous I/O requests to be sent directly to underlying disk (instead of through the corresponding subsystem and filesystem support), thus producing better performance.

One last concept is I/O pacing. This is an AIX feature that prevents disk I/O-intensive applications from flooding the CPU and disks. Appropriate usage of disk I/O pacing helps prevent programs that generate very large amounts of output from saturating the system's I/O and causing system degradation. Tuning the maxpout and minpout helps prevent threads performing sequential writes to files from dominating system resources.

You can also limit the effect of setting global parameters by mounting file systems using an explicit 0 for minput and maxpout: # mount -o minpout=0,maxpout=0 /u.

Since AIX 6, the I/O pacing is enabled by default on the sys0 device, but you can also control the pacing on your other drives.

Note that you can also remount existing filesystems and set the I/O pacing, which can be helpful if you want to alter the performance of a disk that is already actively providing service.
Monitoring
AIX-specific tools (sar, topas, and nmon) are available to monitor disk I/O activity. These tools allow you to troubleshoot quickly a performance problem and capture data for historical trending and analysis.

Don't expect to see iostat in this section, as iostat is a UNIX utility that allows you to determine quickly if there is an imbalanced I/O load between your physical disks and adapters. Unless you decide to write your own scripting tools using iostat, it will not help you with long-term trending and capturing data.

sar is one of those older generic UNIX tools that have been improved over the years. While I generally prefer the use of more specific AIX tools, such as topas or nmon, sar provides strong information with respect to disk I/O. Let's run a typical sarcommand to examine I/O activity (see Listing 4).

Listing 4. Using sar
                
# sar -d 1 2
AIX l488pp065_pub 1 7 00F604884C00    08/11/10

System configuration: lcpu=4 drives=1 ent=0.25 mode=Uncapped 

11:38:44     device    %busy    avque    r+w/s    Kbs/s   avwait   avserv

11:38:45     hdisk0      1      0.0        6       24      0.0      1.9

11:38:46     hdisk0      0      0.0        3       15      0.0      2.3

Average      hdisk0      0      0.0        4       19      0.0      2.1


Let's break down the column headings from Listing 4.
%busy: This command reports back the portion of time that the device was busy servicing transfer requests.
avque: In AIX Version 5.3, this command reports back the number of requests waiting to be sent to disk.
r+w/s: This command reports back the number of read or write transfers to or from a device (512 byte units).
avwait: This command reports the average wait time per request (milliseconds).
avserv: This command reports the average service time per request (milliseconds).
You want to be wary of any disk that approaches 100 percent utilization or a large amount of queue requests waiting for disk. While there is some activity on the sar output, there really are no I/O problems because there is no waiting for I/O. You need to continue to monitor the system to make sure that other disks are also being used besides hdisk0. Where sar is different than iostat is that it has the ability to capture data for long-term analysis and trending through its system activity data collector (sadc) utility. Usually turned off in cron, this utility allows you to capture data for historic trending and analysis.

Here's how this works. As delivered on AIX systems by default, there are two shell scripts that are normally commented out (/usr/lib/sa/sa1 and /usr/lib/sa/sa2) that provide daily reports on the activity of the system. The sar command actually calls the sadc routine to access system data (see Listing 5).

Listing 5. Example cronjob
                
# crontab -l | grep sa1

0 8-17 * * 1-5 /usr/lib/sa/sa1 1200 3 &
0 * * * 0,6 /usr/lib/sa/sa1 &
0 18-7 * * 1-5 /usr/lib/sa/sa1 &


What about something a little more user-friendly? Did you say topas? topas is a nice performance monitoring tool that you can use for a number of purposes, including, but not limited to, your disk I/O subsystem (see Figure 2).

Figure 2. topas
topas
Take a look at the topas output from a disk perspective. There is no I/O activity going on here at all. Besides the physical disk, pay close attention to "Wait" (in the CPU section up top), which also helps determine if the system is I/O bound. If you see high numbers here, you can then use other tools (such as filemon, fileplace, lsof, or lslv) to help you figure out which processes, adapters, or file systems are causing your bottlenecks. topas is good for quickly troubleshooting an issue when you want a little more than iostat. In a sense, topas is a graphical mix of iostat and vmstat, though with recent improvements, it now allows the ability to capture data for historical analysis.

Also useful is the topas physical hard disk output (-D). It shows disk statistics and can show you if a single hardware disk is being hammered and would benefit from having filesystems or information spread and moved over other disks. You can see a sample of the output in Figure 3.

Figure 3. Sample output for disk statistics
Sample output for disk statistics
In particular, you should check the ART/AWT and MRT/MWT which show the average and maximum wait times for reads and writes to the disk. High values indicate a very busy disk. The AQW shows the average number of queues waiting per request to the I/O device. Again, high values may indicate a disk that is unable to keep up with the demands being requested of it.

This is nmon (my favorite AIX performance tool). While nmon provides a front-end similar to topas, it is much more useful in terms of long-term trending and analyses. Further, it gives the system administrator the ability to output data to an Excel spreadsheet that comes back in charts (tailor-made for senior management and functional teams) that clearly illustrate your bottlenecks. This is done through a tool called nmon analyzer, which provides the hooks into nmon. With respect to disk I/O, nmon reports back the following data: disk I/O rates, data transfers, read/write ratios, and disk adapter statistics.

Here is one small example of where nmon really shines. Say you want to know which processes are taking most of the disk I/O and you want to be able to correlate it with the actual disk to clearly illustrate I/O per process. nmon usage helps you more than any other tool. To do this with nmon, use the -t option; set your timing and then sort by I/O channel.

How do you use nmon to capture data and import it into the analyzer? Use the sudo command and run nmon for three hours, taking a snapshot every 30 seconds: # sudo nmon -f -t -r test1 -s 30 -c 180. Then sort the output file that gets created: # sort -A testsystem_yymmdd.nmon > testsystem_yymmdd.csv.

When this is completed, ftp the .csv file to your PC, start the nmon analyzer spreadsheet (enable macros), and click on analyze nmon data. You can download the nmon analyzer from here.

Figure 4 provides a disk summary for each disk in kilobytes per second for reads and writes.

Figure 4. Disk summary for each disk in kilobytes per second for reads and writes
Disk summary for each disk in kilobytes per second for reads and writes
Conclusion
This article addressed the relative importance of the disk I/O subsystem. It defined and discussed the AIX I/O stack and how it related to both physical and logical disk I/O. It also covered some best practices for disk configuration in a database environment, looked at the differences between direct and concurrent I/O, and also discussed asynchronous I/O and I/O pacing. You tuned your asynchronous I/O servers and configured I/O pacing. You started up file systems in concurrent I/O mode and studied when to best implement concurrent I/O. Further, you learned all about iostat and captured data using sar, topas, and nmon. You also examined different types of output and defined many of the flags used in sar and iostat. Part 2 of this series will drill down to the logical volume manager layer of the AIX I/O stack and looks at some of the snapshot-type tools, which help you quickly access the state of your disk I/O subsystem. Part 3 will focus primarily on tracing I/O usage using tools, such as filemon and fileplace, and how to improve file system performance overall.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Optimizing AIX 7 performance: Part 2
By Surya20:16No comments
Part 2, Monitoring logical volumes and analyzing the results
Summary:  Discover how to use appropriate disk placement prior to creating your logical volumes to improve disk performance. These investigations are based on AIX 7 beta and updating information from the original AIX 5L version of this article. Part 2 of this series focuses on monitoring your logical volumes and the commands and utilities (iostat,lvmstat, lslv, lspv, and lsvg) used to analyze results.
About this series
This three-part series (see Resources) on the AIX® disk and I/O subsystem focuses on the challenges of optimizing disk I/O performance. While disk tuning is arguably less exciting than CPU or memory tuning, it is a crucial component in optimizing server performance. In fact, partly because disk I/O is your weakest subsystem link, there is more you can do to improve disk I/O performance than any other subsystem.
Introduction
Unlike the tuning of other subsystems, tuning disk I/O should actually be started during the architectural phase of building your systems. While there are virtual memory equivalents of I/O tuning parameters (ioo and lvmo), the best way to increase disk I/O performance is by properly configuring your systems and not tuning parameters. Unlike virtual memory tuning, it is much more complex to change the way you structure your logical volumes after they have been created and are running, so you usually get only one chance to do this right. In this article, we will discuss ways that you can configure your logical volumes and where to actually place them with respect to the physical disk. We'll also address the tools used to monitor your logical volumes. Most of these tools are not meant to be used for long-term trending and are specific AIX tools that provide information on how the logical volumes are configured and if they have been optimized for your environment.

There are few changes to the main toolset and tunable parameters available in AIX 7, but it is worth re-examining the functionality to ensure that you are getting the best information and performance out of your system.

Part 1 (see Resources) of this series introduced iostat, but it did not address using the tool outside of viewing asynchronous I/O servers. Part 2 uses iostat to monitor your disks and shows you what it can do to help quickly determine your I/O bottleneck. While iostat is a generic UNIX® utility that was not developed specifically for AIX, it is very useful for quickly determining what is going on in your system. The more specific AIX logical volume commands help drill down deeper into your logical volumes to help you really analyze what your problems are, if any. It's important that you clearly understand what you're looking for before using these tools. This article describes the tools and also shows you how to analyze their output, which helps in analyzing your disk I/O subsystem.
Logical volume and disk placement overview
This section defines the Logical Volume Manager (LVM) and introduces some of its features. Let's drill down into logical volume concepts, examine how they relate to improving disk I/O utilization, and talk about logical volume placement as it relates to the physical disk, by defining and discussing both intra-policy and inter-policy disk practices.

Conceptually, the logical volume layer sits between the application and physical layers. In the context of disk I/O, the application layers are the file system or raw logical volumes. The physical layer consists of the actual disk. LVM is an AIX disk management system that maps the data between logical and physical storage. This allows data to reside on multiple physical platters and to be managed and analyzed using specialized LVM commands. LVM actually controls all the physical disk resources on your system and helps provide a logical view of your storage subsystem. Understanding that it sits between the application layer and the physical layer should help you understand why it is arguably the most important of all the layers. Even your physical volumes themselves are part of the logical layer, as the physical layer only encompasses the actual disks, device drivers, and any arrays that you might have already configured. Figure 1 illustrates the concepts and shows how tightly integrated the logical I/O components relate to the physical disk and its application layer.

Figure 1. Logical volume diagram
Logical volume diagram
Let's now quickly introduce the elements that are part of LVM, from the bottom up. Each of the drives is named as a physical volume. Multiple physical volumes make up a volume group. Within the volume groups, logical volumes are defined. The LVM enables the data to be on multiple physical drives, though they might be configured to be on a single volume group. These logical volumes can be either one or multiple logical partitions. Each of the logical partitions has a physical partition that correlates to it. Here is where you can have multiple copies of the physical portions for purposes such as disk mirroring.

Let's take a quick look at how logical volume creation correlates with physical volumes. Figure 2 illustrates the actual storage position on the physical disk platter.

Figure 2. Actual storage position on the physical disk platter
Example of an actual storage position on the physical disk platter
As a general rule, data that is written toward its center has faster seek times than data written on the outer edge. This has to do with the density of data. Because it is more dense as it moves toward its center, there is actually less movement of the head. The inner edge usually has the slowest seek times. As a best practice, the more intensive I/O applications should be brought closer to the center of the physical volumes. Note that there are exceptions to this. Disks hold more data per track on the edges of the disk, not on the center. That being said, logical volumes being accessed sequentially should actually be placed on the edge for better performance. The same holds true for logical volumes that have Mirror Write Consistency Check (MWCC) turned on. This is because the MWCC sector is on the edge of the disk and not at the center of it, which relates to the intra-disk policy of logical volumes.

Let's discuss another important concept referred to as the inter-disk policy of logical volumes. The inter-disk policy defines the number of disks on which the physical partitions of a logical volume actually resides. The general rule is that the minimum policy provides the greatest reliably and availability, and the maximum policy improves performance. Simply put, the more drives that data is spread on, the better the performance. Some other best practices include allocating intensive logical volumes to separate physical volumes, defining the logical volumes to the maximum size you need, and placing logical volumes that are frequently used close together. This is why it is so important to know your data prior to configuring your systems so that you can create policies that make sense from the start.

You can define your polices when creating the logical volumes themselves using the following command or smit fastpath: # mklv or # smitty mklv.
Monitoring logical volumes and analyzing results
This section provides instructions on how to monitor your logical volumes and analyze the results. Various commands are introduced along with the purposes for which they are used, and we will examine the output.

A ticket has just been opened up with the service desk that relates to slow performance on some database server. You suspect that there might be an I/O issue, so you start with iostat. If you recall, this command was introduced in the first installment of the series (see Resources), though only for the purposes of viewing asynchronous I/O servers. Now, let's look at iostat in more detail. iostat, the equivalent of using vmstat for virtual memory, is arguably the most effective way to get a first glance of what is happening with your I/O subsystem.

Listing 1. Using iostat
             
# iostat 1

System configuration: lcpu=4 disk=4

tty:      tin         tout   avg-cpu:  % user    % sys     % idle    % iowait
          0.0        392.0               5.2      5.5       88.3       1.1

Disks:        % tm_act     Kbps      tps    Kb_read   Kb_wrtn
hdisk1           0.5      19.5       1.4   53437739  21482563
hdisk0           0.7      29.7       3.0   93086751  21482563
hdisk4           1.7     278.2       6.2   238584732  832883320
hdisk3           2.1     294.3       8.0   300653060  832883320
What are you seeing here and what does this all mean?
% tm_act: Reports back the percentage of time that the physical disk was active or the total time of disk requests.
Kbps: Reports back the amount of data transferred to the drive in kilobytes.
tps: Reports back the number of transfers per second issued to the physical disk.
Kb_read: Reports back the total data (kilobytes) from your measured interval that is read from the physical volumes.
Kb_wrtn: Reports back the amount of data (kilobytes) from your measured interval that is written to the physical volumes.
You need to watch % tm_act very carefully, because when its utilization exceeds roughly 60 to 70 percent, it usually is indicative that processes are starting to wait for I/O. This might be your first clue of impending I/O problems. Moving data to less busy drives can obviously help ease this burden. Generally speaking, the more drives that your data hits, the better. Just like anything else, too much of a good thing can also be bad, as you have to make sure you don't have too many drives hitting any one adapter. One way to determine if an adapter is saturated is to sum the Kbps amounts for all disks attached to one adapter. The total should be below the disk adapter throughput rating, usually less than 70 percent.

Using the -a flag (see Listing 2) helps you drill down further to examine adapter utilization.

Listing 2. Using iostat with the -a flag
             
# iostat -a

Adapter:                   Kbps      tps    Kb_read   Kb_wrtn
scsi0                      0.0       0.0          0         0

Paths/Disk:       % tm_act     Kbps      tps     Kb_read   Kb_wrtn
hdisk1_Path0           37.0       89.0     0.0          0         0
hdisk0_Path0           67.0       47.0     0.0          0         0
hdisk4_Path0           0.0        0.0      0.0          0         0
hdisk3_Path0           0.0        0.0      0.0          0         0

Adapter:                   Kbps      tps    Kb_read   Kb_wrtn
ide0                       0.0       0.0          0         0

Paths/Disk:       % tm_act     Kbps      tps    Kb_read   Kb_wrtn
cd0                    0.0       0.0       0.0          0         0
Clearly, there are no bottlenecks here. Using the -d flag allows you to drill down to one specific disk (see Listing 3).

Listing 3. Using iostat with the -d flag
             
# iostat -d hdisk1 1

System configuration: lcpu=4 disk=5

Disks:        % tm_act     Kbps      tps    Kb_read   Kb_wrtn
hdisk1           0.5      19.4       1.4   53437743  21490480
hdisk1           5.0      78.0       23.6         3633      3564
hdisk1           0.0       0.0       0.0          0         0
hdisk1           0.0       0.0       0.0          0         0
hdisk1           0.0       0.0       0.0          0         0
hdisk1           0.0       0.0       0.0          0         0
Let's look at some specific AIX LVM commands. You examined disk placement earlier and the importance of architecting your systems correctly from the beginning. Unfortunately, you don't always have that option. As system administrators, you sometimes inherit systems that must be fixed. Let's look at the layout of the logical volumes on disks to determine if you need to change definitions or re-arrange your data.

Let's look first at a volume group and find the logical volumes that are a part of it. lsvg is the command that provides volume group information (see Listing 4).

Listing 4. Using lsvg
             
# lsvg -l data2vg

rootvg:LV NAME      TYPE       LPs     PPs     PVs  LV STATE      MOUNT POINT
hd5                 boot       1       1       1    closed/syncd  N/A
hd6                 paging     24      24      1    open/syncd    N/A
hd8                 jfs2log    1       1       1    open/syncd    N/A
hd4                 jfs2       7       7       1    open/syncd    /
hd2                 jfs2       76      76      1    open/syncd    /usr
hd9var              jfs2       12      12      1    open/syncd    /var
hd3                 jfs2       4       4       1    open/syncd    /tmp
hd1                 jfs2       1       1       1    open/syncd    /home
hd10opt             jfs2       12      12      1    open/syncd    /opt
hd11admin           jfs2       4       4       1    open/syncd    /admin
livedump            jfs2       8       8       1    open/syncd    /var/adm/ras/livedump
Now, let's use lslv, which provides for specific data on logical volumes (see Listing 5).

Listing 5. Using lslv
              
# lslv data2lv

LOGICAL VOLUME:     hd4                    VOLUME GROUP:   rootvg
LV IDENTIFIER:      00f6048800004c         PERMISSION:     read/write
                    000000012a2263d526.4
VG STATE:           active/complete        LV STATE:       opened/syncd
TYPE:               jfs2                   WRITE VERIFY:   off
MAX LPs:            512                    PP SIZE:        32 megabyte(s)
COPIES:             1                      SCHED POLICY:   parallel
LPs:                7                      PPs:            7
STALE PPs:          0                      BB POLICY:      relocatable
INTER-POLICY:       minimum                RELOCATABLE:    yes
INTRA-POLICY:       center                 UPPER BOUND:    32
MOUNT POINT:        /                      LABEL:          /
MIRROR WRITE CONSISTENCY: on/ACTIVE                              
EACH LP COPY ON A SEPARATE PV ?: yes                                    
Serialize IO ?:     NO 
This view provides a detailed description of your logical volume attributes. What do you have here? The intra-policy is at the center, which is normally the best policy to have for I/O-intensive logical volumes. As you recall from an earlier discussion, there are exceptions to this rule. Unfortunately, you've just hit one of them. Because Mirror Write Consistency (MWC) is on, the volume would have been better served if it were placed on the edge.

Let's look at its inter-policy. The inter-policy is minimum, which is usually the best policy to have if availability is more important then performance. Further, there are double the number of physical partitions than logical partitions, which signify that you are mirroring your systems. In this case, you were told that raw performance was the most important objective, so the logical volume was not configured in such a way as to the reality of how the volume is being utilized. Further, if you are mirroring your system and using an external storage array, this would even be worse, as you're already providing mirroring at the hardware layer, which is actually more effective then using AIX mirroring.

Let's drill down even further in Listing 6.

Listing 6. lslv with the -l flag
             
lslv -l hd4hd4:/
PV                COPIES        IN BAND       DISTRIBUTION  
hdisk0            007:000:000   100%          000:000:007:000:000 

The -l flag of lslv lists all the physical volumes associated with the logical volumes and distribution for each logical volume. You can then determine that 100 percent of the physical partitions on the disk are allocated to this logical volume. The distribution sections show the actual number of physical partitions within each physical volume. From here, you can detail its intra-disk policy. The order of these fields are as follows:
Edge
Middle
Center
Inner-middle
Inner-edge
The reports show that most of the data is in the middle and some at the center.

Let's keep going and find out which logical volumes are associated with the one physical volume. This is done with the lspvcommand (see Listing 7).

Listing 7. Using the lspv command
             
# lspv -l hdisk0hdisk0:
LV NAME               LPs     PPs     DISTRIBUTION          MOUNT POINT
hd8                   1       1       00..00..01..00..00    N/A
hd4                   7       7       00..00..07..00..00    /
hd5                   1       1       01..00..00..00..00    N/A
hd6                   24      24      00..24..00..00..00    N/A
hd11admin             4       4       00..00..04..00..00    /admin
livedump              8       8       00..08..00..00..00    /var/adm/ras/livedump
hd10opt               12      12      00..00..12..00..00    /opt
hd3                   4       4       00..00..04..00..00    /tmp
hd1                   1       1       00..00..01..00..00    /home
hd2                   76      76      00..00..76..00..00    /usr
hd9var                12      12      00..00..12..00..00    /var
Now you can actually identify which of the logical volumes on this disk are geared up for maximum performance.

You can drill down even further to get more specific (see Listing 8).

Listing 8. lspv with the -p flag
             
# lspv -p hdisk0hdisk0:
PP RANGE  STATE   REGION        LV NAME             TYPE       MOUNT POINT
  1-1     used    outer edge    hd5                 boot       N/A
  2-128   free    outer edge                                   
129-144   used    outer middle  hd6                 paging     N/A
145-152   used    outer middle  livedump            jfs2       /var/adm/ras/livedump
153-160   used    outer middle  hd6                 paging     N/A
161-256   free    outer middle                                 
257-257   used    center        hd8                 jfs2log    N/A
258-264   used    center        hd4                 jfs2       /
265-340   used    center        hd2                 jfs2       /usr
341-352   used    center        hd9var              jfs2       /var
353-356   used    center        hd3                 jfs2       /tmp
357-357   used    center        hd1                 jfs2       /home
358-369   used    center        hd10opt             jfs2       /opt
370-373   used    center        hd11admin           jfs2       /admin
374-383   free    center                                       
384-511   free    inner middle                                 
512-639   free    inner edge  
This view tells you what is free on the physical volume, what has been used, and which partitions are used where. This is a nice view.

One of the best tools to look at LVM usage is with lvmstat (see Listing 9).

Listing 9. Using lvmstat
             
# lvmstat -v rootvg
0516-1309 lvmstat: Statistics collection is not enabled for this logical device.
        Use -e option to enable.
As you can see by the output here, it is not enabled (by default), so you need to enable it prior to running the tool using # lvmstat -v data2vg -e. The command shown in Listing 10 takes a snapshot of LVM information every second for 10 intervals.

Listing 10. lvmstat with the -v flag
# lvmstat -v rootvg 1 10

Logical Volume       iocnt   Kb_read   Kb_wrtn      Kbps
  hd8                   54         0       216      0.00
  hd9var                15         0        64      0.00
  hd2                   11         0        44      0.00
  hd4                    5         0        20      0.00
  hd3                    2         0         8      0.00
  livedump               0         0         0      0.00
  hd11admin              0         0         0      0.00
  hd10opt                0         0         0      0.00
  hd1                    0         0         0      0.00
  hd6                    0         0         0      0.00
  hd5                    0         0         0      0.00
.
Logical Volume       iocnt   Kb_read   Kb_wrtn      Kbps
  hd2                    3        40         0     40.00
......
Logical Volume       iocnt   Kb_read   Kb_wrtn      Kbps
  hd4                   11         0        44     44.00
  hd8                    8         0        32     32.00
  hd9var                 8         0        36     36.00
  hd3                    6         0        24     24.00
  hd2                    2         0         8      8.00
   
What is particularly useful about this view is that it only shows the logical volumes where there has been activity. This can make it very convenient when monitoring specific applications and correlating that with the specific logical volume usage.

This view shows the most utilized logical volumes on your system since you started the data collection tool. This is very helpful when drilling down to the logical volume layer when tuning your systems.

What are you looking at here?
% iocnt: Reports back the number of read and write requests.
Kb_read: Reports back the total data (kilobytes) from your measured interval that is read.
Kb_wrtn: Reports back the amount of data (kilobytes) from your measured interval that is written.
Kbps: Reports back the amount of data transferred in kilobytes.
Look at the man pages for all the commands discussed before you start to add them to your repertoire.

Tuning with lvmo

This section goes over using a specific logical volume tuning command. The lvmo is used to set and display your pbuf tuning parameters. It is also used to display blocked I/O statistics.

lvmo allows you to change the pbuf, or pinned memory buffers, used for each volume group, and therefore shows and allows control over the memory used to cache volume group data.

Let's display your lvmo tunables for the data2vg volume group (see Listing 11).

Listing 11. Displaying lvmo tunables
             
# lvmo -v data2vg -a

vgname = data2vg
pv_pbuf_count  = 1024
total_vg_pbubs = 1024
mag_vg_pbuf_count = 8192
perv_blocked_io_count = 7455
global_pbuf_count = 1024
global_blocked_io_count = 7455
What are the tunables here?
pv_pbuf_count: Reports back the number of pbufs added when a physical volume is added to the volume group.
max_vg_pbuf_count: Reports back the max amount of pbufs that can be allocated for a volume group.
global_pbuf_count: Reports back the number of pbufs that are added when a physical volume is added to any volume group.
Let's increase the pbuf count for this volume group:
# lvmo -v redvg -o pv_pbuf_count=2048
Quite honestly, we usually stay away from lvmo and use ioo. We are more accustomed to tuning the global parameters. It's important to note that if you increase the pbuf value too much, you can actually see a degradation in performance.
Conclusion
This article focused on logical volumes and how they relate to the disk I/O subsystem. It defined logical volumes at a high level and illustrated how it relates to the application and physical layers. It also defined and discussed some best practices for inter-disk and intra-disk polices as they relate to creating and maintaining logical volumes. You looked at ways to monitor I/O usage for your logical volumes, and you analyzed the data that was captured from the commands that were used to help determine what your problems were. Finally, you actually tuned your logical volumes by determining and increasing the amount of pbufs used in a specific volume group. Part 3 of this series will focus on the application layer as you move on to file systems, using various commands to monitor and tune your file systems and disk I/O subsystems.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Optimizing AIX 7 performance: Part 3
By Surya20:17No comments
 Optimizing AIX 7 performance: Part 3, Tune with ioo, filemon, fileplace, JFS and JFS2
Summary:  Part 3 of the AIX 7 performance series covers how to improve overall file system performance, how to tune your systems with the ioo command, and how to use the filemon and fileplace utilities. You will also learn about JFS and JFS2 that is available in AIX7.
About this series
This three-part series (see Resources) on the AIX® disk and I/O subsystem focuses on the challenges of optimizing disk I/O performance. While disk tuning is arguably less exciting than CPU or memory tuning, it is a crucial component in optimizing server performance. In fact, partly because disk I/O is your weakest subsystem link, there is more you can do to improve disk I/O performance than on any other subsystem.
Introduction
The first and second installments of this series discussed the importance of architecting your systems, the impact it can have on overall system performance, and a new I/O tuning tool, lvmo, which you can use to tune logical volumes. In this installment, you will examine how to tune your systems using theioocommand, which configures the majority of all I/O tuning parameters and displays the current or next boot values for all I/O tuning parameters. You will also learn how and when to use the filemon and fileplace tools. With enhanced journaled file system, the default file system within AIX, improving your overall file system performance, tuning your file systems, and getting the best out of the JFS2 are all important parts of your tuning toolkit. You'll even examine some file system attributes, such as sequential and random access, which can affect performance.
File system overview
This section discusses JFS2, file system performance, and specific performance improvements over JFS. As you know, there are two types of kernels in AIX. There is a 32-bit kernel and a 64-bit kernel. While they both share some common libraries and most commands and utilities, it is important to understand their differences and how the kernels relate to overall performance tuning. JFS2 has been optimized for the 64-bit kernel, while JFS is optimized for the 32-bit kernel. Journaling file systems, while much more secure, historically have been associated with performance overheads. In a Performance Rules shop (at the expense of availability), you would disable metadata logging to increase performance with JFS. With JFS2, you can also disable logging (in AIX 6.1 and higher) to help increase performance. You can disable logging at the point of mounting the filesystem, which means that you don't need to worry about changing or reconfiguring the filesystem. You can instead just modify your mount options. For example, to disable logging on filesystem you would use the following:mount -i log=NULL /database.

Although JFS2 was optimized to improve the performance of metadata operations, that is, those normally handled by the logging framework, switching logging off can have a significant performance benefit for filesystems where there is a high proportion of file changes and newly created/deleted files. For example, filesystems on development filesystems may see an increase in performance. For databases where the files used are static, the performance improvement may be less significant.

However, you should be careful making use of compression. Although compression can save disk space (and disk reads and writes, since less data is physically read from or written to the disk), the overhead on systems with a heavy CPU loads can actually slow performance down.

Enhanced JFS2 uses a binary tree representation while performing inode searches, which is a much better method than the linear method used by JFS. Furthermore, you do not need to assign inodes anymore when creating file systems, as they are now dynamically allocated by JFS2 (meaning you won't be running out of them).

While concurrent I/O was covered in the first installment of the series, it's worth another mention here. Implementation of concurrent I/O allows multiple threads to read and write data concurrently to the same file. This is due to the way in which JFS2 is implemented with write-exclusive inode locks. This allows multiple users to read the same file simultaneously, which increases performance dramatically when multiple users read from the same data file. To turn concurrent I/O on, you just need to mount the f/s with the appropriate flags (see Listing 1). We recommend that you look at using concurrent I/O when using databases such as Oracle.

Listing 1. Turning on concurrent I/O
                
root@lpar29p682e_pub[/] mount -o cio /test
root@lpar29p682e_pub[/] > df -k /test
Filesystem    1024-blocks      Free %Used    Iused %Iused Mounted on
/dev/fslv00        131072    130724    1%        4     1% /test
Table 1 illustrates the various enhancements of JFS2 and how they relate to systems performance. It's also important to understand that when tuning your I/O systems, many of the tunables themselves (you'll get into that later) differ, depending on whether you are using JFS or JFS2.

Table 1. Enhancements of JFS2
Function	JFS	JFS2
Compression	Yes	No
Quotas	Yes	Yes
Deferred update	Yes	No
Direct I/O support	Yes	Yes
Optimization	32-bit	64-bit
Max file system size	1 terabyte	4 petabytes
Max file size	64 gigabyes	4 petabytes
Number of inodes	Fixed when creating f/s	Dynamic
Large file support	As mount option	Default
On-line defragmentation	Yes	Yes
Namefs	Yes	Yes
DMAPI	No	Yes
Filemon and fileplace
This section introduces two important I/O tools, filemon and fileplace, and discusses how you can use them during systems administration each day.

Filemon uses a trace facility to report on the I/O activity of physical and logical storage, including your actual files. The I/O activity monitored is based on the time interval that is specified when running the trace. It reports on all layers of file system utilization, including the Logical Volume Manager (LVM), virtual memory, and physical disk layers. Without any flags, it runs in the background while application programs or system commands are being run and monitored. The trace starts automatically until it is stopped. At that time, the command generates an I/O activity report and exits. It can also process a trace file that has been recorded by the trace facility. Reports can then be generated from this file. Because reports generated to standard output usually scroll past your screen, it's recommended that you use the-ooption to write the output to a file (see Listing 2).

Listing 2. Using filemon with the-ooption
                  
l488pp065_pub[/] > filemon -o dbmon.out -O all

Run trcstop command to signal end of trace.
Thu Aug 12 09:07:06 2010
System: AIX 7.1 Node: l488pp065_pub Machine: 00F604884C00
l488pp065_pub[/] > trcstop

l488pp065_pub[/] > cat dbmon.out
Thu Aug 12 09:10:09 2010
System: AIX 7.1 Node: l488pp065_pub Machine: 00F604884C00
Cpu utilization:  72.8%
Cpu allocation:  100.0%

21947755 events were lost.  Reported data may have inconsistencies or errors.

Most Active Files
------------------------------------------------------------------------
  #MBs  #opns   #rds   #wrs  file                     volume:inode
------------------------------------------------------------------------
   0.4      1    101      0  unix                     /dev/hd2:82241
   0.0      9     10      0  vfs                      /dev/hd4:9641
   0.0      4      6      1  db.sql                 
   0.0      3      6      2  ksh.cat                  /dev/hd2:111192
   0.0      1      2      0  cmdtrace.cat             /dev/hd2:110757
   0.0     45      1      0  null                   
   0.0      1      1      0  dd.cat                   /dev/hd2:110827
   0.0      9      2      0  SWservAt                 /dev/hd4:9156
   0.0      1      0      3  db2.sql                
   0.0      9      2      0  SWservAt.vc              /dev/hd4:9157

Most Active Segments
------------------------------------------------------------------------
  #MBs  #rpgs  #wpgs  segid  segtype                  volume:inode
------------------------------------------------------------------------
   0.1      2     13   8359ba  client                 

Most Active Logical Volumes
------------------------------------------------------------------------
  util  #rblk  #wblk   KB/s  volume                   description
------------------------------------------------------------------------
  0.04      0     32    0.3  /dev/hd9var              /var
  0.00      0     48    0.5  /dev/hd8                 jfs2log
  0.00      0      8    0.1  /dev/hd4                 /

Most Active Physical Volumes
------------------------------------------------------------------------
  util  #rblk  #wblk   KB/s  volume                   description
------------------------------------------------------------------------
  0.00      0     72    0.7  /dev/hdisk0              N/A

Most Active Files Process-Wise
------------------------------------------------------------------------
  #MBs  #opns   #rds   #wrs  file                     PID(Process:TID)
------------------------------------------------------------------------
   0.0      3      6      0  db.sql                  7667828(ksh:9437345)
   0.0      1      2      0  ksh.cat                 7667828(ksh:9437345)
   0.0      1      0      3  db2.sql                 7667828(ksh:9437345)
   0.0      1      0      1  db.sql                  7733344(ksh:7405633)
   0.4      1    101      0  unix                    7667830(ksh:9437347)
   0.0      1      2      0  cmdtrace.cat            7667830(ksh:9437347)
   0.0      1      2      0  ksh.cat                 7667830(ksh:9437347)
   0.0      9      2      0  SWservAt                7667830(ksh:9437347)
   0.0      9      2      0  SWservAt.vc             7667830(ksh:9437347)
   0.0      1      0      0  systrctl                7667830(ksh:9437347)
   0.0     44      0     44  null                    4325546(slp_srvreg:8585241)
   0.0      1      2      2  ksh.cat                 7667826(ksh:23527615)
   0.0      1      1      0  dd.cat                  7667826(ksh:23527615)
   0.0      1      1      0  null                    7667826(ksh:23527615)
   0.0      1      0      0  test                    7667826(ksh:23527615)
   0.0      8      8      0  vfs                     3473482(topasrec:13566119)
   0.0      1      0      0  CuAt.vc                 3473482(topasrec:13566119)
   0.0      1      0      0  CuAt                    3473482(topasrec:13566119)
   0.0      1      2      0  vfs                     2097252(syncd:2490503)
   0.0      1      0      0  installable             4260046(java:15073489)

Most Active Files Thread-Wise
------------------------------------------------------------------------
  #MBs  #opns   #rds   #wrs  file                     TID(Process:PID)
------------------------------------------------------------------------
   0.0      3      6      0  db.sql                  9437345(ksh:7667828)
   0.0      1      2      0  ksh.cat                 9437345(ksh:7667828)
   0.0      1      0      3  db2.sql                 9437345(ksh:7667828)
   0.0      1      0      1  db.sql                  7405633(ksh:7733344)
   0.4      1    101      0  unix                    9437347(ksh:7667830)
   0.0      1      2      0  cmdtrace.cat            9437347(ksh:7667830)
   0.0      1      2      0  ksh.cat                 9437347(ksh:7667830)
   0.0      9      2      0  SWservAt                9437347(ksh:7667830)
   0.0      9      2      0  SWservAt.vc             9437347(ksh:7667830)
   0.0      1      0      0  systrctl                9437347(ksh:7667830)
   0.0     44      0     44  null                    8585241(slp_srvreg:4325546)
   0.0      1      2      2  ksh.cat                 23527615(ksh:7667826)
   0.0      1      1      0  dd.cat                  23527615(ksh:7667826)
   0.0      1      1      0  null                    23527615(ksh:7667826)
   0.0      1      0      0  test                    23527615(ksh:7667826)
   0.0      8      8      0  vfs                     13566119(topasrec:3473482)
   0.0      1      0      0  CuAt.vc                 13566119(topasrec:3473482)
   0.0      1      0      0  CuAt                    13566119(topasrec:3473482)
   0.0      1      2      0  vfs                     2490503(syncd:2097252)
   0.0      1      0      0  installable             15073489(java:4260046)
dbmon.out: END
Look for long seek times, as they can result in decreased application performance. By looking at the read and write sequence counts in detail, you can further determine if the access is sequential or random. This helps you when it is time to do your I/O tuning. This output clearly illustrates that there is no I/O bottleneck visible. Filemon provides a tremendous amount of information and, truthfully, we've found there is too much information at times. Further, there can be a performance hit using filemon, depending on how much general file activity there is while filemon is running. Let's look at the topas results while running filemon (see Figure 1).

Figure 1. topas results while running filemon
topaz results while running filemon 

In the figure above, filemon is taking up almost 60 percent of the CPU! This is actually less than in previous AIX versions but still a significant impact on your overall system performance. We don't typically like to recommend performance tools that have such a substantial overhead, so we'll reiterate that while filemon certainly has a purpose, you need to be very careful when using it.

What about fileplace? Fileplace reports the placement of a file's blocks within a file system. It is commonly used to examine and assess the efficiency of a file's placement on disk. For what purposes do you use it? One reason would be to help determine if some of the heavily utilized files are substantially fragmented. It can also help you determine the physical volume with the highest utilization and whether or not the drive or I/O adapter is causing the bottleneck.

Let's look at an example of a frequently accessed file in Listing 3.

Listing 3. Frequently accessed file
                
fileplace -pv /tmp/logfile
File: /tmp/logfile  Size: 63801540 bytes  Vol: /dev/hd3
Blk Size: 4096  Frag Size: 4096  Nfrags: 15604 
Inode: 7  Mode: -rw-rw-rw-  Owner: root  Group: system  

  Physical Addresses (mirror copy 1)                                    Logical Extent
  ----------------------------------                                  ----------------
  02884352-02884511  hdisk0        160 frags    655360 Bytes,   1.0%  00000224-00000383
  02884544-02899987  hdisk0      15444 frags  63258624 Bytes,  99.0%  00000416-00015859
        unallocated           -27 frags      -110592 Bytes      0.0%

  15604 frags over space of 15636 frags:   space efficiency = 99.8%
  2 extents out of 15604 possible:   sequentiality = 100.0%
  
You should be interested in space efficiency and sequentiality here. Higher space efficiency means files are less fragmented and provide better sequential file access. A higher sequentiality tells you that the files are more contiguously allocated, which will also be better for sequential file access. In the case here, space efficiency could be better while sequentiality is quite high. If the space and sequentiality are too low, you might want to consider file system reorganization. You would do this with thereorgvgcommand, which can improve logical volume utilization and efficiency. You may also want to consider using thedegrafscommand which can help ensure that the free space on your filesystem is contiguous, which will help with future writes and file creates. Defragmentation can occur in the background while you are using your system.
Tuning with ioo
This section discusses the use of theioocommand, which is used for virtually all I/O-related tuning parameters.

Likevmo, you need to be extremely careful when changingiooparameters, as changing parameters on the fly can cause severe performance degradation. Table 2 details specific tuning parameters that you use often for JFS file systems. As you can see, the majority of the tuning commands for I/O utilize theiooutility.

Table 2. Specific tuning parameters

Function	JFS tuning parameter	Enhanced JFS tuning parameter
Sets max amount of memory for caching files	vmo -o maxperm=value	vmo -o maxclient=value(< or = maxperm)
Sets min amount of memory for caching	vmo -o minperm=value	n/a
Sets a limit (hard) on memory for caching	vmo -o strict_maxperm	vmo -o maxclient(hard limit)
Sets max pages used for sequential read ahead	ioo -o maxpgahead=value	ioo -o j2_maxPageReadAhead=value
Sets min pages used for sequential read ahead	ioo -o minpgahead	ioo -o j2_minPageReadAhead=value
Sets max number of pending write I/O to a file	chhdev -l sys0 -a maxpout maxpout	chdev -l sys0 -a maxpout maxpout
Sets min number of pending write I/Os to a file at which programs blocked by maxpout might proceed	chdev -l sys0 -a minpout minpout	chdev -l sys0 -a minpout minpout
Sets the amount of modified data cache for a file with random writes	ioo -o maxrandwrt=value	ioo -o j2_maxRandomWrite ioo -o j2_nRandomCluster
Controls gathering of I/Os for sequential write behind	ioo -o numclust=value	ioo -o j2_nPagesPerWriteBehindCluster=value
Sets the number of f/s bufstructs	ioo -o numfsbufs=value	ioo -o j2_nBufferPerPagerDevice=value
Let's further discuss some of the more important parameters below, as we've already discussed all thevmotuning parameters in the memory tuning series (see Resources).

There are several ways you can determine the existingioovalues on your system. The long display listing foriooclearly gives you the most information (see Listing 4). It lists the values for current, reboot value, range, unit, type, and dependencies of all tunables parameters managed byioo.

Listing 4. Display for ioo
                
root@lpar29p682e_pub[/] > ioo -L
NAME                      CUR    DEF    BOOT   MIN    MAX    UNIT           TYPE
     DEPENDENCIES

j2_atimeUpdateSymlink     0      0      0      0      1      boolean           D
j2_dynamicBufferPreallo   16     16     16     0      256    16K slabs         D
j2_inodeCacheSize         400    400    400    1      1000                     D
j2_maxPageReadAhead       128    128    128    0      64K    4KB pages         D
j2_maxRandomWrite         0      0      0      0      64K    4KB pages         D
j2_maxUsableMaxTransfer   512    512    512    1      4K     pages             M
j2_metadataCacheSize      400    400    400    1      1000                     D
j2_minPageReadAhead       2      2      2      0      64K    4KB pages         D
j2_nBufferPerPagerDevice  512    512    512    512    256K                     M
j2_nPagesPerWriteBehindC  32     32     32     0      64K                      D
j2_nRandomCluster         0      0      0      0      64K    16KB clusters     D
j2_nonFatalCrashesSystem  0      0      0      0      1      boolean           D
j2_syncModifiedMapped     1      1      1      0      1      boolean           D
j2_syncdLogSyncInterval   1      1      1      0      4K     iterations        D
jfs_clread_enabled        0      0      0      0      1      boolean           D
jfs_use_read_lock         1      1      1      0      1      boolean           D
lvm_bufcnt                9      9      9      1      64     128KB/buffer      D
maxpgahead minpgahead     8      8      8      0      4K     4KB pages         D
maxrandwrt                0      0      0      0      512K   4KB pages         D
memory_frames             512K          512K                 4KB pages         S
Minpgahead maxpgahead     2      2      2      0      4K     4KB pages         D
numclust                  1      1      1      0      2G-1   16KB/cluster      D
numfsbufs                 196    196    196    1      2G-1                     M
pd_npages                 64K    64K    64K    1      512K   4KB pages         D
pgahd_scale_thresh        0      0      0      0      419430 4KB pages         D
pv_min_pbuf               512    512    512    512    2G-1                     D
sync_release_ilock        0      0      0      0      1      boolean           D

n/a means parameter not supported by the current platform or kernel

Parameter types:
    S = Static: cannot be changed
    D = Dynamic: can be freely changed
    B = Bosboot: can only be changed using bosboot and reboot
    R = Reboot: can only be changed during reboot
    C = Connect: changes are only effective for future socket connections
    M = Mount: changes are only effective for future mountings
    I = Incremental: can only be incremented
    d = deprecated: deprecated and cannot be changed
Listing 5 below shows you how to change a tunable.

Listing 5. Changing a tunable
                
root@lpar29p682e_pub[/] > ioo -o maxpgahead=32
Setting maxpgahead to 32
root@lpar29p682e_pub[/] >
This parameter is used for JFS only. For JSF2, there are additional file system performance enhancements including sequential page read ahead and sequential and random write behind. The Virtual Memory Manager (VMM) of AIX anticipates page requirements for observing the patterns of files that are accessed. When a program accesses two pages of a file, VMM assumes that the program keeps trying to access the file in a sequential method. The number of pages to be read ahead can be configured using VMM thresholds. With JFS2, make note of these two important parameters:

J2_minPageReadAhead: Determines the number of pages ahead when VMM initially detects a sequential pattern.
J2_maxPageReadAhead: Determines the maximum amount of pages that VMM can read in a sequential file.
Sequential and random write behind relates to writing modified pages in memory to disk after a certain threshold is reached. In this way, it does not wait forsyncdto flush out pages to disk. The reason for this is to limit the amount of dirty pages in memory, which further reduces I/O overhead and disk fragmentation. The two types of write behind are sequential and random. With sequential write behind, pages do not stay in memory until thesyncddaemon runs, which can cause real bottlenecks. With random write behind, the number of pages in memory exceeds a specified amount and all subsequent pages are written to disk.

For the sequential write behind, you should specify the number of pages to be scheduled to be written; thej2_nPagesPerWriterBehindClusterparameter specifies this parameter. By default the value is 32 (that is, 128KB), for modern disks and high write environments, such as databases, you may want to increase this parameter so that more data is written in a single block when the data needs to be synced to disk.

The random write behind can be configured by changing the values ofj2_nRandomClusterandj2_maxRandomWrite. Thej2_maxRandomWriteparameter specifies the number of pages of a file that are allowed to stay in memory. The default is 0 (meaning that information is written out as quickly as possible), and this is used to ensure data integrity. If you are willing to sacrifice some integrity in the event of a system failure, for better write performance you can increase these values. This keeps them in cache, so a system failure may not have written the data to disk properly. Thej2_nRandomClusterdefines the number of clusters apart two writes must be to be considered random. Increasing this value can lower the write frequency if you have a high number of files being modified at the same time.

Another important area worth mentioning is large sequential I/O processing. When there is too much simultaneous I/O to your file systems, the I/O can bottleneck at the f/s level. In this case, you should increase thej2_nBufferPerPagerDeviceparameter (numfsbus with JFS). If you use raw I/O as opposed to file systems, this same type of bottleneck can occur through LVM. Here is where you might want to tune thelvm_bufcntparameter.

Summary

This article focused on file system performance. You examined the enhancements in JFS2 and why it would be the preferred file system. Further, you used tools, such as filemon and fileplace, to gather more detailed information about the actual file structures and how they relate to I/O performance. Finally, you tuned your I/O subsystem by using theioocommand. You learned about theJ2_minPageReadAheadandJ2_maxPageReadAheadparameters in an effort to increase performance when encountering sequential I/O.

During this three-part series on I/O you learned that, perhaps more so than any other subsystem, your tuning must start prior to stress testing your systems. Architecting the systems properly can do more to increase performance than anything you can do with tuning I/O parameters. This includes strategic disk placement and making sure you have enough adapters to handle the throughput of your disks. Further, while this series focused on I/O, understand that the VMM is also very tightly linked with I/O performance and must also be tuned to receive optimum I/O performance.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Paging [AIX]
By Surya13:09No comments
Swap space related commands and files in AIX
 swapon
 swapoff
 lsps
 chps
 mkps
 rmps
 /etc/swapspaces
swapon: Used to activate a paging space.
   swapon -a --> activates all paging devices specified on /etc/swapspaces
   swapon < Device Name > --> Activates the specified paging space
mkps: This command is used to add an additional paging space.
Syntax:
       mkps [ -a ] [ -n ] [ -s Number of LPs ] VG_Name
          -a activates the paging space during next reboot
          -n activates the paging space immediately
chps: This command is used to change the attributes of a paging space
Syntax:
       chps [ -a LPs | -d LPs ] [ -a { y | n } ] paging_space_name
          -s Specifies the number of logical partitions to add 
          -d specifies the number of logical partitions to subtract
          -a To specify to use the Paging Space at the next reboot
Cookbook to add / remove paging space dynamically
To add a paging space "paging0"
01. Create a new LV for paging space
      mklv -t paging -y paging0 rootvg 10
02. Add the entry in /etc/swapspaces to activate the paging space during next reboot
      chps -a y paging0
03. Activate the paging space
      swapon /dev/paging0
To remove an active paging space "paging00"
1. Deactivate the paging space using swapoff commnad
   # swapoff /dev/paging00
2. remove the paging space using rmps command
   # rmps paging00
03. Remove the entry from /etc/swapspaces so that it is not activated during next reboot
   # chps -a n paging00


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Paging Space Administration -AIX
By Surya12:13No comments

1) What is Paging Space?
2) What is Page-in & Page-out?
3) What is thrashing?
All these questions about paging space will be answered in this very particular post.
1) What is Paging Space?
In a system, there are multiple processes running. For a new process to be actively running, the process should be loaded into the OS memory. Once the process is loaded, it is then assigned number of 4 KB units called page frames.
Keeping this in view, more number of additional processes is loaded into the memory with each process assigned 4 KB areas. But when the processes are overloaded and the memory is full, OS scans memory to trace frames that are least recently used. When such a frame is discovered, 4 KB block or page of disk space is allocated and the data from least active frame is moved to area on the disk. This area on disk is called Paging Space.
2) What is Page-in & Page-out?
If the paged out information for the least active process is needed back into the memory, the page is retrieved from the disk and brought back into the memory. This is called page-in.
Similarly, when the least active frame is moved out from the memory on to the disk, the process is called page-out.
3) What is thrashing?
If the OS is loaded with many active processes and there is no further real memory available to load additional active processes, the OS goes into the constant state of paging called thrashing as no additional real memory is available to load a new process into the memory.
Increasing the amount of paging Space will be of no benefit because the processes involved are all active and thrashing is the result of not enough real memory.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Paging space best practices
By Surya21:45No comments
Here are a couple of rules that your paging spaces should adhere to, for best performance:

The size of paging space should match the size of the memory possible double of memory.
Use more than one paging space, on different disks to each other.
All paging spaces should have the same size.
All paging spaces should be mirrored.
Paging spaces should not be put on "hot" disks.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Performance Monitoring and Tuning
By Surya13:18No comments
Monitoring Commands
nmon
 vmstat
 iostat
 sar
 topas
 nmon
 svmon
 filemon
 mpstat
 rmss
 netpmon
vmstat
The vmstat command is useful for obtaining an overall picture of CPU, paging, and memory usage. The following is a sample report produced by the vmstat command:
# vmstat 5 2
 kthr      memory             page              faults     cpu
 ----- -----------   ------------------------ ------------ ----------- 
 r b     avm   fre    re pi po fr sr cy        in  sy  cs   us sy id wa 
 1 1  197167 477552   0  0  0  7  21 0        106 1114 451   0  0 99 0 
 0 0  197178 477541   0  0  0  0  0  0        443 1123 442   0  0 99 0 
Remember that the first report from the vmstat command displays cumulative activity since the last system boot. The second report shows activity for the first 5-second interval.
iostat
The iostat command is the fastest way to get a first impression, whether or not the system has a disk I/O-bound performance problem. This tool also reports CPU statistics.
 Flags
 -a  Specifies adapter throughput report.
 -d  Specifies drive report only.
 -m  Specifies statistics for paths.
 -t  Specifies tty/cpu report only.
 -z  Resets the disk input/output statistics

 # iostat  2 2
 tty:      tin         tout   avg-cpu:  % user    % sys     % idle    % iowait
           0.0          0.8               8.4      2.6       88.5       0.5
           0.0         80.2               4.5      3.0       92.1       0.5

 Disks:     % tm_act    Kbps    tps        Kb_read      Kb_wrtn
 hdisk3       0.0        0.3    0.0        258032       224266
 hdisk2       0.1        1.1    0.0        258088       1658678
To display the adapter information
 # iostat -t -a -D
 System configuration: lcpu=120 drives=27 paths=252 vdisks=0 tapes=0

 Adapter:           
 fcs0                 xfer:      bps      tps    bread      bwrtn
                               1.1M    47.7    468.3K     668.8K
 Adapter:           
 fcs1                 xfer:      bps      tps    bread      bwrtn
                             800.2K    34.7    330.9K     469.3K
To display disk statistics including queue info in long list format
# iostat -lD  
System configuration: lcpu=120 drives=27 paths=252 vdisks=0

Disks:                     xfers                                read                                write                                  queue                  
-------------- -------------------------------- ------------------------------------ ------------------------------------ -------------------------------------- 
                 %tm    bps   tps  bread  bwrtn   rps    avg    min    max time fail   wps    avg    min    max time fail    avg    min    max   avg   avg  serv
                 act                                    serv   serv   serv outs              serv   serv   serv outs        time   time   time  wqsz  sqsz qfull
hdisk1           0.6  58.6K  12.3   1.8K  56.8K   0.1   3.8    0.0    0.0     0    0  12.2   5.4    0.8   92.3     0    0   0.5    0.0   47.0    0.0   0.0   0.2
hdisk0           0.5  63.6K  12.5   6.9K  56.7K   0.3   2.5    2.6    7.1     0    0  12.2   5.0    0.3  100.0     0    0   0.4    0.0   50.3    0.0   0.0   0.2
hdisk8           5.0 908.7K  81.5 203.2K 705.5K  17.1  17.6    0.2  284.0     0    0  64.5 540.5    0.3   40.7     0    0   2.3S   0.0   26.6  215.0  36.0  21.3
hdisk2           1.8  55.4K   3.4  45.9K   9.6K   2.8  12.4    0.2   11.8     0    0   0.6 156.5    0.3   11.6     0    0   4.5    0.0    0.0    0.0   0.0   0.0
hdisk6           5.3 931.6K  85.3 254.3K 677.3K  22.5  13.9    0.2  420.5     0    0  62.8 563.9    0.2   38.0     0    0   1.2S   0.0   10.4  107.0  36.0  18.7
hdisk7           5.0 944.0K  85.5 208.7K 735.3K  17.3  17.5    0.2  313.6     0    0  68.2 497.0    0.3   43.7     0    0   2.2S   0.0   27.2  215.0  35.0  22.0
svmon
The svmon command provides a more in-depth analysis of memory usage. It is more informative, but also more intrusive, than the vmstat and ps commands. The svmon command captures a snapshot of the current state of memory.

The memory consumption is reported using the inuse, free, pin, virtual and paging space counters.

The inuse counter represents the number of used frames.
The free counter represents the number of free frames from all memory pools.
The pin counter represents the number of pinned frames, that is, frames that cannot be swapped.
The virtual counter represents the number of pages allocated in the system virtual space.
The paging space counter represents the number of pages reserved or used on paging spaces.
Flags
 -G   Global report
 -U   User report
 -P   Process report
 -i   To define intervel and number of intervels. eg. -i 1 5
To find out the total memory/swap and free memory/swap available in an AIX system
# svmon -G
               size      inuse       free        pin    virtual
memory      3932160    3914793      17367     444363    1609451
pg space    1048576       6622

               work       pers       clnt
pin          444363          0          0
in use      1609451          0    2305342

PageSize   PoolSize      inuse       pgsp        pin    virtual
s   4 KB          -    3787625       6622     370027    1482283
m  64 KB          -       7948          0       4646       7948

# pagesize
4096
So, the above system have almost 16GB physical Memory and 4 GB swap

A memory leak can be detected with the svmon command, by looking for processes whose working segment continually grows. A leak in a kernel segment can be caused by an mbuf leak or by a device driver, kernel extension, or even the kernel. To determine if a segment is growing, use the svmon command with the -i option to look at a process or a group of processes and see if any segment continues to grow.
 # svmon -P 13548 -i 1 2

 Pid                         Command        Inuse        Pin      Pgsp  Virtual 64-bit Mthrd LPage
 13548                       pacman         8535        2178      847     8533      N     N     N

 Vsid     Esid Type  Description          LPage  Inuse    Pin  Pgsp  Virtual
     0       0 work  kernel seg               -   4375   2176   847     4375
 48412       2 work  process private          -   2357     2    0    2357
 6c01b       d work  shared library text      -   1790      0     0     1790
 4c413       f work  shared library data      -     11     0    0      11
 3040c       1 pers  code,/dev/prodlv:4097    -      2      0     -        -
 ginger :svmon -P 13548 -i 1 3

 Pid                         Command        Inuse        Pin      Pgsp  Virtual 64-bit Mthrd LPage
 13548                       pacman         8589         2178       847  8587      N     N     N

 Vsid     Esid Type  Description          LPage  Inuse    Pin  Pgsp  Virtual
    0        0 work  kernel seg               -   4375   2176   847     4375
 48412       2 work  process private          -   2411     2    0    2411
 6c01b       d work  shared library text      -   1790      0     0     1790
 4c413       f work  shared library data      -     11     0    0      11
 3040c       1 pers  code,/dev/prodlv:4097    -      2      0     -        - 
filemon
The filemon command monitor a trace for file system and IO system events and reports performance statistics for files, virtual memory segments, logical volumes and physical volumes. filemon is useful to those whose applications are believed to be disk-bound and want to know where and why.

filemon command shows the load on different disks, logical volumes and files in a great detail.
trcstop command is used to stop the filemon monitoring.

The syntax of filemon command is
 filemon [-o output_file] [-O levels] [-u] [-v] 

  -O [lv | pv | vm | If | all ]    
     (If - Logical file level, vm - Virtual memory level, lv - lv level)  
  -u Reports on files that were opened prior to the start of the trace daemon
If the output file is not specified, the output is sent to standard output.

To start the filemon monitoring for 1 min.
 # filemon -uo filemon.out -O all ; sleep 60; trcstop
To find out the most active Logical Volumes
 # awk '/Most Active Logical Volumes/,/^$/' filemon.out
 Most Active Logical Volumes
 ------------------------------------------------------------------------
   util  #rblk  #wblk   KB/s  volume                   description
 ------------------------------------------------------------------------
   0.04   4208      0   34.9  /dev/paging00            paging
   0.04   4000      0   33.2  /dev/hd6                 paging
   0.01   1680  11408  108.6  /dev/oralvr32            /oracle/R32
   0.00      0    264    2.2  /dev/hd8                 jfs2log
To find out most active Files
 # awk '/Most Active Files/,/^$/' filemon.out
To find out most active physical Volumes
 # awk '/Most Active Physical Volumes/,/^$/' filemon.out
rmss
The rmss command provides you with a means to simulate different sizes of real memory that are smaller than your actual machine, without having to extract and replace memory boards or reconfigure memory using logical partitions.

To change the memory size to 500 MB,
 # rmss -c 500
 Simulated memory size changed to 500 Mb.
To reset the memory size to the real memory size of the machine, enter:
 # rmss -r
Tuning Commands
 vmo
 ioo
 no
 nice and renice
 vmtune
 defragfs
The /etc/tunables commands
To manage its files in the /etc/tunables directory, new commands have been added to AIX. They are as follows:

tuncheck: This command validates a file either to be applied immediately or at reboot time (-r flag). It checks the ranges, dependencies, and prompts to run bosboot if required. Run this command if you copy a file to a new system, or edit it with an editor such as vi.

tunsave: This command saves all current values to a file, including optionally the
nextboot file.

tunrestore: This command applies values from a file, either immediately, or at the next reboot (-r flag). With the -r flag, it validates and copies the file over the current nextboot file.

tundefault: This command resets all parameters to their default value. It can be applied at the next reboot with the -r flag.
ioo, vmo and no commands:
These commands are used to set or display current or next boot values of different tuning parameters.
ioo for IO tuning parameters
vmo for Virtual Memory Manager parameters
no for network tuning parameters
These commands can also make permanent changes or defer changes until the next reboot. When a permanent change or nextboot value is changed using these commands, the/etc/tunables/nextboot file is updated automatically with the new values (if the new value is different from the default value).

The following flags are common for ioo, vmo and no commands.
 -L [tunable] List the characteristics of one or all tunables
 -d tunable - Resets 'tunable' to default value
 -o [tunable] - Display the current value of 'tunable'
 -o tunable=<value> - Set the 'tuneble' to new value
 -D - Resets all tunables to their default value  
 -p - Changes apply to both current and reboot values (/etc/tunables/nextboot file updated)
 -r - Changes apply to only reboot values (/etc/tunables/nextboot file updated)
Examples:
 # vmo -p -o minfree=1200 -o maxfree=1280 
 # ioo -r -o maxpgahead=64 -o j2_minPageReadAhead=8
 # no -r -o rfc1323=1 -o tcp_recvspace=262144 -o tcp_sendspace=262144
A sample /etc/tunables/nextboot file.
cat /etc/tunables/nextboot

vmo:
        minfree = "1200"
        maxfree = "1280"
        minperm% = "10"
        maxperm% = "40"
        maxclient% = "40"

ioo:
        j2_nBufferPerPagerDevice = "1024"

no:
        tcp_recvspace = "65536"
        tcp_sendspace = "65536"
        tcp_pmtu_discover = "0"
        udp_pmtu_discover = "0
minfree Minimum acceptable number of real-memory page frames in the free list. When the size of the free list falls below this number, the VMM begins stealing pages. It continues stealing pages until the size of the free list reaches maxfree.

maxfree Maximum size to which the free list will grow by VMM page-stealing. The size of the free list may exceed this number as a result of processes terminating and freeing their working-segment pages or the deletion of files that have pages in memory.

minperm If the percentage of real memory occupied by file pages falls below this level, the page-replacement algorithm steals both file and computational pages, regardless of repage rates.
maxperm' If the percentage of real memory occupied by file pages rises above this level, the page-replacement algorithm steals only file pages.

maxclient If the percentage of real memory occupied by file pages is above this level, the page-replacement algorithm steals only client pages.
aio (Asynchronous IO)
AIO is an AIX software subsystem that allows processes to issue I/O operations without waiting for I/O to finish. Because both I/O operations and applications processing run concurrently, they essentially run in the background and improve performance. This is particularly important in a database environment.

Prior to AIX 6.1, AIO is a device whose details are stored in the ODM and managed using the ‘chdev’ command.
From AIX 6.1 and above, AIO is no longer a device, and is managed using the ‘ioo’ command.
AIO is a prerequisite of Oracle, and must be ‘enabled’ prior to installing Oracle.
Prior to AIX 6.1, AIO is enabled as follows:
 smit aio  
   or 
 chdev –l aio0 –aautoconfig=available -a minservers=100 -a maxservers=100 -a maxreqs=9152 
 mkdev aio0
 chdev –l posix_aio0 –aautoconfig=available
 mkdev posix_aio0
 aioo  ### To manage aio parameters
minserver: Minimum number of kernel processes dedicated to asynchronous I/O processing
masservers: Maxiimum number of kernel processes dedicated to AIO processing

maxreqs: maximum number of asynchronous I/O requests that can be outstanding at one time
autoconfig: The state to which AIO is to be configured during system initialization. The possible values are "defined", which means that AIO cannot be used, and "available"

From AIX 6.1 and above, AIO is activated ‘dynamically’ as and when a program makes a call to AIO, so it is no longer necessary to manually enable AIO. The ‘ioo’ command is used change the properties of AIO only.

 # ioo -a 
                    aio_active = 0
                   aio_maxreqs = 65536
                aio_maxservers = 30
                aio_minservers = 3
         aio_server_inactivity = 300
         j2_atimeUpdateSymlink = 0
  j2_dynamicBufferPreallocation = 16
             j2_inodeCacheSize = 400
           j2_maxPageReadAhead = 128
             j2_maxRandomWrite = 0
          j2_metadataCacheSize = 400
           j2_minPageReadAhead = 2
 j2_nPagesPerWriteBehindCluster = 32
             j2_nRandomCluster = 0
              j2_syncPageCount = 0
              j2_syncPageLimit = 16
                    lvm_bufcnt = 9
                    maxpgahead = 8
                    maxrandwrt = 0
                      numclust = 1
                     numfsbufs = 196
                     pd_npages = 65536
              posix_aio_active = 0
             posix_aio_maxreqs = 65536
          posix_aio_maxservers = 30
          posix_aio_minservers = 3
   posix_aio_server_inactivity = 300
Disk IO pacing (High water-mark and Low Water-mark)
AIX 6.1 enables I/O pacing by default. In AIX 5.3, you needed to explicitly enable this feature.
The way it does this is by setting the sys0 settings of minpout and maxput parameters to 4096 and 8193, respectively:

Disk-I/O pacing is intended to prevent programs that generate very large amounts of output from saturating the systems I/O facilities and causing the response times of less-demanding programs to deteriorate.

When a process tries to write to a file that already has high-water mark pending writes, the process is put to sleep until enough I/Os have completed to make the number of pending writes less than or equal to the low-water mark. The logic of I/O-request handling does not change. The output from high-volume processes is slowed down somewhat.

The maxpout parameter specifies the number of pages that can be scheduled in the I/O state to a file before the threads are suspended. The minpout parameter specifies the minimum number of scheduled pages at which the threads are woken up from the suspended state. The default value for both the maxpout and minpout parameters is 0, which means that the I/O pacing feature is disabled. Changes to the system-wide values of the maxpout and minpout parameters take effect immediately without rebooting the system.
Changing the values for the maxpout and minpout parameters overwrites the system-wide settings. You can exclude a file system from system-wide I/O pacing by mounting the file system and setting the values for the maxpout and minpout parameters explicitly to 0. The following command is an example: mount -o minpout=0,maxpout=0 /<file system>

To change the high water-mark level

 # chdev -a maxpout=20 -l sys0
Network Monitoring
netpmon Monitors activity and reports statistics on network I/O and network-related CPU usage. The netpmon command monitors a trace of system events, and reports on network activity and performance during the monitored interval. By default, the netpmon command runs in the background while one or more application programs or system commands are being executed and monitored. The netpmon command automatically starts and monitors a trace of network-related system events in real time. By default, the trace is started immediately; optionally, tracing may be deferred until the user issues a trcon command. When tracing is stopped by a trcstop command, the netpmon command generates all specified reports and exits.
# netpmon 
Run trcstop command to signal end of trace.
Fri Mar 23 10:08:43 2012
System: AIX 6.1 Node: nbmedia200 Machine: 00C7C24E4C00

# trcstop
[netpmon: Reporting started]

========================================================================

Process CPU Usage Statistics:
-----------------------------
                                                   Network
Process (top 20)             PID  CPU Time   CPU %   CPU %
----------------------------------------------------------
netpmon                  2294244    6.8347    9.820   0.000
ps                           3080288     0.0156    0.022   0.000
ps                           983804       0.0146    0.021   0.000
ps                           3145998     0.0143    0.021   0.000
ps                           3015104     0.0129    0.019   0.000
trcstop                    3080290     0.0053    0.008   0.000
ksh                         1835464     0.0051     0.007   0.000
topasrec                 2228292     0.0051     0.007   0.000
----------------------------------------------------------
Total (all processes)                   6.9672    10.011  0.003
Idle time                                 59.3796     85.319

========================================================================

First Level Interrupt Handler CPU Usage Statistics:
---------------------------------------------------
                                                   Network
FLIH                              CPU Time   CPU %   CPU %
----------------------------------------------------------
data page fault               0.0495   0.071   0.000
UNKNOWN                      0.0170   0.024   0.000
PPC decrementer            0.0024   0.003   0.000
external device               0.0000   0.000   0.000
queued interrupt             0.0000   0.000   0.000
----------------------------------------------------------
Total (all FLIHs)               0.0689   0.099   0.000

========================================================================
Network Device-Driver Statistics (by Device):
---------------------------------------------
                        ----------- Xmit -----------   -------- Recv ---------
Device                   Pkts/s  Bytes/s  Util  QLen   Pkts/s  Bytes/s   Demux
------------------------------------------------------------------------------
ethernet 0                 0.69       74  0.1%  0.00     1.61      243  0.0000
ethernet 1                 0.00        0  0.0%  0.00     0.23      136  0.0000

======================================================================== 



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Practical AIX troubleshooting
By Ramesh Peram01:16No comments
any of you probably remember the commercials from IBM that aired during Monday Night Football in the 1980s called, "You Make The Call." The spots would show an interesting play that had happened on the field. The narrator would explain what the players did, highlighting the questionable nature of the event, and then query the viewing audience as to what they would have ruled, saying, "You make the call." After a brief ad for IBM products or services, the narrator would come back and summarize the decision the referee made and what guidelines he used. It was good way to learn about American football and have some conversations around the dinner table.

Frequently used acronyms
LPAR: Logical partition
SAN: Storage area network
Just like that ad, in this article, you have a chance to make the call in the realm of troubleshooting practical problems in IBM AIX®. You get the tools and knowledge to triage, test, and temper your skills to solve some of those particularly vexing problems you might encounter. The article provides a couple of real-world, interesting situations that I have come across, gives you the steps to detect the anomalies, and pauses to give you a moment to deduce what was wrong before giving the answer.
Sample problems
Let's set the groundwork with a couple of problems I have run into as a systems administrator.
Problem 1: Bigger server, less power
I needed to migrate an AIX 5.3 LPAR from an older IBM pSeries® p670 server on POWER4™ to a brand new pSeries p570 server on POWER6®. The older server was short on resources, using Workload Manager to manage resources for the main applications on the server, thus the new dynamic processor resources available on the new hardware would work perfectly in giving me the power I needed. I took a mksysb of the LPAR, restored it to the new hardware by using Network Installation Manager, and mapped over the SAN disks.
I booted up the LPAR, and all appeared well, until the applications were started. Immediately, users started calling in. They couldn't access their products at all. When I logged in, I found that the server was completely idle. None of the processes were taxing the server at all. Why were the users having problems?
Problem 2: Dying hard disk that won't give up the ghost
I had a server with mirrored root disks. One day, the error report started logging problems about a bad block being unable to relocate itself on one of the disks. Knowing that this was symptomatic of an impending hardware failure, I began breaking the mirror. But the server said that it could not completely break the mirror, because the only good copy of one of the logical volumes was on the dying disk. How could I overcome this problem and replace the hardware?

The troubleshooting process
With these two sample problems in mind, let's dive into the process for troubleshooting them.
Step 1: Freeze
At the first sign of trouble, the smartest thing to do is freeze. Much like Indiana Jones in "Raiders of The Lost Ark," if you get the idea that the floor might cause blow darts to come shooting in your direction, stop where you are, and don't continue merrily sprinting across the ground. Additional changes may only compound the problem and potentially worsen the situation. There is no sense in having to address multiple problems when one good one can affect uptime as is.
For the first sample problem, I had the users log off immediately, and I halted the applications. Knowing that it was possible that the users' data could be compromised when poor performance halted their queries and inputs, I didn't want their environment altered any further without first taking a look at the situation. Although the users weren't happy to hear that they couldn't use their new, beefier server at that moment, they were grateful that I was exercising all due caution. Plus, this gave me time to start working my way down the rest of the troubleshooting steps.
Step 2: Start with basic commands, then add complexity
When I studied kung fu, I heard a story of a second-degree black belt who had disabled someone trying to steal her purse at a bus stop. The class was curious what technique she had used to take down her attacker. Was it the golden tiger style? Did she use the circular motions of pa kua? Or maybe, we wondered, she got really exotic and used the eight drunken immortals to bring him down. It turned out to be none of the above: She used one of the very first techniques a white belt learns in class—a firm elbow to the chest followed by a punch to the nose.
AIX provides a plethora of commands for examining the most granular facets of servers—both hardware and software. Even the most basic of commands provides a great basis for analyzing problems. And when there isn't enough information or things still don't behave properly, you can work your way into more complex and powerful options. But start with the simplest of commands and ideas before breaking out the big guns.
For example, the AIX errpt is one of the greatest basic tools found in any flavor of UNIX®. It is a one-stop shop for getting all sorts of information about hardware and software problems. By tossing on the –a flag or the –j option with an identifier code, more detailed output will describe the type of problem, which components were affected, and how the system reacted to it based on the type of error. And if that doesn't provide enough information, then you can interrogate the system further with the diagcommand, running specific tests on various pieces of hardware and the operating system.
In the case of the second sample problem, after I detected the hardware problem by looking at the errpt, I used theunmirrorvg command—a simple, powerful utility to try to break the mirror—instead of running an rmlvcopy for every single logical volume on the disk. And when I found that I couldn't remove the one remaining logical volume, I went to other basic commands like lspv, lsvg, and migratepv to gain information. I tried extendvg and mirrorvg to create another copy of the volume group on another disk. That still left some stale partitions out there, so I went deeper with syncvg and synclvdom to reconcile the Object Data Manager with the server. Eventually, I went to migratelp to try to move the individual logical partitions off of the disk. Unfortunately, none of these tools worked, but they did give me tons of information.
Step 3: Replicate the problem
In the scientific method, one critical point of any hypothesis and testing is the ability to re-create and reproduce the process with the same outcome. Failure to do so makes for inconclusive results at best. At worst, it can ruin ideas and tarnish reputations, like the physicists who claimed to have made room-temperature cold fusion in the 1990s.
Or, as I jest: If at first you don't succeed, see if you can break it somewhere else.
When working on AIX servers, if something goes wrong along the way and you have the resources to duplicate the problem, try to see whether the same actions yield the same results on another, similar type of LPAR. If changing the same attributes on another server causes the same effect, it is reasonable to deduce that action was the source of the problem. But if a totally opposite effect is produced, then examine the subtle differences between the servers and try to deduce what could have contributed to the problem.
For the LPAR I had in the first sample problem, I saw that when I swung the SAN disks back to the old p670 server and booted it up, the problem was not present. Users were able to access their application, and the CPU incurred a decent load, going above 80% CPU utilization (10% kernel + 70% user). So, I was able to determine that there was something unique to running things on the p570 machine that was causing the problem rather than something introduced in the migration process.
Step 4: Research the problem
In the Information Age, a wealth of knowledge is accessible with just a few keystrokes and mouse clicks. Fortunately for systems administrators, we tend to be a part of a greater community that has documented centuries of experience and libraries of syntax online.
One good first place to start is with the manufacturers and vendors themselves. Companies like IBM have put all of their manuals, Redbooks, technical papers, and even their man pages on the web for research purposes. Just putting a simple keyword into the main site's search bar can provide thousands of possible suggestions for information that might help.
Other places I recommend are the various newsgroups, forums, and sites that other systems administrators frequent. People who work all day on servers tend to keep up with reading tech sites and commenting on things they see in the course of their work. Most systems administrators are happy to lend some pointers or shoot a few e-mails back and forth in response to a public cry for help. And you can often find information going back decades that pertains to other versions of operating systems and software, which can serve as jumping-off platforms for more information.
The main trick to use in any of these circumstances is the right set of keywords. If I use a general web site like Google to get started on an AIX problem, I make sure I start the search string explicitly with AIX to avoid any other flavors of UNIX. Then, I might include something like the output from the command or the label from the errpt. I also make sure to use double quotation marks ("") around specific phrases to limit the search to those specific issues and not bring in extraneous information, especially for common words like Logical Volume Manager.
For my problem with the disk that would not work around the bad block relocation, using the phrase AIX "bad block relocation" failure got me a few hundred results on Google, but no one seemed to have come across the exact same circumstance that fell in my lap.
Step 5: Back out any changes
Sometimes, the wisest thing you can do in working on a problem is undo anything you've put in place and go back to where you were originally. This step isn't always available in all circumstances. Sometimes, it's forced upon you by overzealous C-level executives who need their servers back up. Or, it might be necessitated by getting crunched for time. But the option of rolling back is one of the best tactics to keep in a hip pocket.
I included this option at the midpoint in my list of troubleshooting steps, because sometimes it has to be done earlier and sometimes falls later in your triage. But in my experience, I have found it wisest to do the previous four steps before considering backing out any changes, because if the changes get rolled back immediately in the process, it is possible that the problem won't be resolved, and you will merely set yourself up for the same headache the next time you attempt the same work. If the changes get rolled back too late in the process, you could affect uptime or complicate the problem to the point where no back-out is possible.
I actually did have to roll back the server migration from my first example because of time. The users and company would have lost money if this production server were down any longer. The week it took to reschedule the work afforded me the ability to do some more research, but when I attempted the migration again, the beast reared its ugly head. In the second example, there was no rolling back from a hardware problem. There was no way to tell the server, "Take back that bad block relocation error!" I had to continue to try to overcome the disk's reticence.
Step 6: The one-delta rule
If all the steps above haven't worked and you decide that it is time to start altering major components or getting more intrusive with the server, there is one important rule to remember above all else: Change things one piece at a time.
Multiple alterations will do one of two things. First, if the problem is resolved along the way, you won't know which change was the effective action. If you don't care what fixed the issue, it may not be a big deal, but good systems administrators like expanding their knowledge base, because they know that problems tend to strike the same place twice or more. Second, if the problem doesn't get fixed, it is possible to introduce more complications. Then, you won't know which one to back out. Go far enough, and the next thing you know, you'll be confused while your system sits in shambles. (Refer to xkcd for a funny joke about this.)
If the problem doesn't get resolved after one delta, you'll generally want to put it back and try something else. This was the case in my first example: When I compared the two servers’ Hardware Management Console profiles, I looked at how they were different. I noticed that the older POWER4 hardware used dedicated CPUs, while the newer POWER6 hardware had shared CPU pools with no caps. Curious about how this difference could affect CPU performance, I changed the profile on the POWER6 machine to use dedicated CPUs. Strangely, the server then performed "correctly" according to the users, and I saw a load on the processors. So, I knew that the problem had to be related to CPU resources but needed to find out why it would do this.
Step 7: Engage IBM Support
When you've exhausted all reasonable steps and need to bring in a second opinion, it's usually time to contact IBM Support. They have advanced troubleshooting tools, various specialists who cover every facet of the operating system and related products (such as VIO and PowerHA) and can pull up related case numbers to corroborate and collaborate with similar problems. But if you've never called             800-IBM-SERV      , here are the things you will need to know.
First, you should have a contract number with IBM. There are various levels of support, from the highest levels of 24x7x365 coverage with dedicated personnel down to casual 8:00 am to 5:00 pm support for non-critical servers. These support packages can be purchased directly from IBM or by contacting a value-added reseller.
You will also need to provide some information so that IBM Support can pull up your accounts—typically, a phone number where the machine is located, a serial number, a contract number, or a physical location. This information largely depends on whether you are opening a hardware or a software case.
You must also let the Support person know the severity or priority of the case. Priorities vary from 1—which typically relates to systems being down or production impact, resulting with a live call transfer to a tech—down to a 4, which means a longer turnaround time, usually used for more general administration questions.
After you provide a description of the problem and the case is opened, you will be issued a tracking number—typically called aPMR. This number identifies the case to any other Support people with whom you work. Hardware and software PMRs are unique, and if your problem crosses boundaries, you will need to be issued a new number.
I had to contact IBM for both of my sample problems. For the first problem, IBM engaged everyone—from VIO support to the kernel team—to try to get resolution. For the second problem, I remained on the hardware side of their house, providing information from the snap command for analysis.
Step 8: Go to the extremes
Occasionally, there is no other choice to fix a problem but to try something so unorthodox and outlandish that most people would call it crazy. This typically happens at a point of desperation, where a job or life might even be on the line. It's usually when even IBM would say, "If you do this, you will be in an unsupported state and will have to start over before we will support it." But the trade-off is that if your solution works, you might be able to save the day.
For my second example, after I had called IBM Support, they said that my only option was to go to a mksysb image to restore the server. With nothing else to lose, after speaking with my team of administrators, we made a plan to try to physically yank the disk from the server after triple-mirroring the root disk. The known risk was that the removal of the disk could cause the server to be unable to boot. But the latent risk was that the physical removal could panic the larger server and crash all of the LPARs on it. Did we decide to dare it?

You make the call
Now that I've provided the background on these tickets, it's time for you to make the call. To summarize:
Why would moving a Workload Manager-enabled server to faster hardware only work correctly if the LPAR profile was set to dedicated CPUs instead of dynamic CPUs?
How could I recover a server from a disk that could not be deconfigured or have the data from a failed physical partition moved off of it?
When you think you have an idea, move ahead.
What really happened
The culprit of the first example was the Workload Manager. The applications that used it had been throttled back to use 50% of the CPU. So, when the hypervisor polling cycle probed the LPAR, it asked, "How much CPU did you need?" The server replied, "I'm only using half of what I have assigned." So, the hypervisor would dynamically reduce the CPU entitlement by half. After this cycle was repeated a few times, the CPU horsepower would effectively halve itself to zero. To fix the problem, the Workload Manager pool was adjusted to use up to 100% of the CPU, and then the dynamic CPU entitlement would throttle itself appropriately.
For the second example, ultimately, we had to go to backup and restore. There was no way around the failed block relocation that the business was willing to take. According to IBM Support, this is an infrequently encountered problem but one where there is no other choice but to lay a mksysb onto a good disk and recover the box that way. And after I recovered the operating system, I could then hot-swap the bad disk out in a safe manner and get it replaced without compromising the other LPARs on the hardware.

Conclusion
Hopefully, you've gained some practical insight into how systems administrators troubleshoot AIX servers, what strategies you can use, some cautionary areas to avoid, and where you can look for advice on fixing your problems. These steps don't cover every situation perfectly, and there are other choices you can make, but these steps can point you down the right road.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Printer AIX
By Surya12:36No comments

Commands to give print to a job:
# lp
# lpr: for eg: # lpr –p <printername> <filename> : will print the file to a specific printer.
# qprt
# enq
Each job sent for print has a print job number associated with it.
Commands to check the status of print jobs:
# lpq
# lpstat
# qchk
# enq –A
Commands to cancel the print jobs:
# cancel
# lprm
# qcan
#enq –X
Summary:
PRINT	STATUS	CANCEL
Lp	lpq	cancel
Lpr	lpstat	lprm
Qprt	qchk	qcan
Enq	enq -A	enq -X
Advanced Concepts:
Print Subsystem:
There are 5 different types of print subsystem available:
1.       AIX Print Subsystem
2.       Print directly to local printer
3.       System V Print Subsystem
4.       Print directly to remote printer
5.       Info print manager
To show current print subsystem:
# switch.prt –d
To change current print subsystem:
# switch.prt –s AIX
# switch.prt –d AIX
# switch.prt –s System V
# switch.prt –d System V
Printer Workflow:
End user sends a request to print a file using any of the print commands (lp,lpr,qprt,enq) to the print queue.
The request goes to /var/spool/lpd/qdir
A copy of the request goes to the spool directory /var/spool/qdaemon
/qdaemon gets notified of the request in /qdir
/qdaemon checks for availability of the queue in /etc/qconfig
Once queue is ready, /qdaemon updates /var/spool/lpd/stat to start processing the request in the queue
Printer Interface:
There are 3 types of printer interface available:
Parallel
RS232
RS422
To enable a queue whose status is Down (only user with admin privileges can run this command):
# enable queuename
To disable a queue whose status is Ready (only user with admin privileges can run this command):
# disable queuename
To move jobs between queues in AIX:
# qmov –m <queuename> -# <jobnumber>


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Quickly and Easily Convert Between Storage Size Units
By surya aix10:431 comment
Quickly and Easily Convert Between Storage Size Units-KB,MB,GB,TB& 512 byte blocks
A very common task in the IT industry is needing to convert between storage size units - bytes, kilobytes, megabytes, gigabytes, terabytes, etc.

To make things even more complicated, the POSIX standard also specifies that the default output for commands like "df" and "du" must be in 512 byte block sizes.

This posting will cover a very simple and easy way to quickly convert between any of these units.
A kilobyte/megabyte/gigabyte versus a kibibyte/mebibyte/gibibyte
Historically there has been a discrepancy/dispute on how much space a kilobyte, megabyte, and gigabyte represented.

If you ask a hard drive manufacturer, they would say a gigabyte is 1,000,000,000 bytes.However, most Operating Systems calculated a gigabyte as 1,073,741,824 (which is 1024*1024*1024).

This is about a 7% discrepancy, and as sizes increase the discrepancy gets larger (for example a terabyte has about a 9% discrepancy.)

The solution to all this was that the official definition of a "Gigabyte" is now 1,000,000,000 bytes, and a "Gibibyte" is 1,073,741,824.

I don't know about you, but I have never actually heard another person say the word "Gibibyte".   Throughout the rest of this post I will refer to a gigabyte as 1,073,741,824 bytes as this is the common use among people even if it is incorrect per the textbook definition.
The wrong way to convert between size units
Many people will look at a filesize such as 54,183,672,092 bytes and say it is "54 Gigabytes"  based on the first 2 digits of the number. In fact, it is really 50.5 Gigabytes (54,183,672,092 divided by 1,073,741,824 (size of 1 GB) equals ~ 50.5 GB).

The larger the file size, the bigger the discrepancy will be between the size it appears to be at first glance and the actual size.
The quick and easy method to convert between size units
There is an extremely fast and easy way to do any of these conversions.With this method the only number you need to memorize is 1024.   The only other thing you need to know is the name/order of the sizes (kilobyte, megabyte, gigabyte, terabyte).

To convert smaller units to larger units (i.e. take bytes and convert to kilobytes, megabytes, gigabytes, or terabytes) you simply divide the original number by 1,024 for each unit size along the way to the final desired unit.

For example, if you wanted to convert 110,214,321,212 bytes to megabytes, you would divide by 1,024 (to first covert to KB), and then divide by 1,024 again (to end up in MB).   If you wanted to convert to gigabytes, you would divide by 1,024 three times (once to get to KB, once to get to MB, and then once to end up in GB).

To convert larger units to smaller units (i.e. take a number of gigabytes and convert it down in to megabytes, kilobytes, or bytes) you simply multiply the original number by 1,024 for each unit size along the way to the final desired unit.

For example, if you want to convert 384 megabytes to bytes, you would simply multiply it by 1,024 two times (first time to convert to KB, and the second time to end up in bytes).

If you wanted to convert 14 terabytes to the number of bytes, you would multiply 14 by 1,024 four times (first to convert to GB, then to MB, then to KB, and then to bytes).
Here is a diagram that summarizes this:
Here are some examples:

Convert 67,003,324,746 bytes to Gigabytes:   67,003,324,746 / 1024 / 1024 / 1024 = 62.40 GB  (Divide by 1024 three times because we are moving across 3 units, smaller to larger unit)

Convert 67,003,324,746 bytes to Megabytes:  67,003,324,746 / 1024 / 1024 = 63,899 MB (Divide by 1024 two times because we are moving across 2 units, smaller to larger unit)

Convert 8,846,679 Megabytes to Terabytes:  8,846,679 / 1024 / 1024 = 8.44 TB (Divide by 1024 two times because we are moving across 2 units, smaller to larger unit)

Convert 78 Gigabytes to Bytes:  78 * 1024 * 1024 * 1024 = 83,751,862,272 (Multiple by 1024 three times because we are moving across 3 units, larger to smaller unit)

Convert 52 Terabytes to Gigabytes:  52 * 1024 = 53,248 Gigabytes (Multiply by 1024 one time because we are moving across 1 unit, larger to smaller)
The final piece of the puzzle:  512 byte blocks
The POSIX standards require that the default output of commands like "df" and "du" be in 512 byte block units, so this is a unit you will run in to from time to time.   A 512 byte block is exactly what it sounds like:  512 bytes of data.

There are a couple of methods to convert 512 byte blocks in to something more meaningful:

1) You can convert 512 byte blocks to kilobytes by dividing them by
    For example, six 512-byte-blocks divided by two equals 3 KB.
2) You can convert 512 byte blocks to blocks by multiplying them by 512.
    For example, six 512-byte-blocks multiplied by 512 equals 3,072 bytes

Once you have converted the 512-byte-blocks in to either kilobytes or bytes, you can then easily convert them to whatever other unit you need.
Conclusion
Converting between size units is much easier then most people think.   All you need to do is memorize the number 1,024 and a couple of other rules and you will be on your way to being able to quickly and easily convert between any size units. 


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Quickly estimating mksysb size on AIX
By Surya00:57No comments
I'm not a fan of large mksysb's. They cause slow backups, slow restores, and if you ever need to make a NIM SPOT from a mksysb I've found that it takes exponentially longer for larger size mksysbs.

And a lot of times mksysbs are unnecessarily large just due to junk being left in the rootvg that isn't needed any more like old versions of AIX upgrades. The size of the mksysb is basically the size of the used space of the mounted filesystems in AIX. To quickly estimate how large the mksysb will be you can use this one-liner:
df -tk `lsvgfs rootvg` | awk '{total+=$3}\
 END {printf "Estimated mksysb size: %d bytes, %.2f GB\n", total*1024, total/1024/1024}'
The output looks something like this:
Estimated mksysb size: 8540651520 bytes, 7.95 GB
This is just a quick estimate. It doesn't take in to account if you have an mksysb exclude list file or if you are using mksysb compression (which I have found generally causes problems anyway, just specify the "-p" option on the mksysb command to disable it)


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Read password without showing / displaying on the screen
By Surya13:55No comments
Q) My requirement is to write a bash script which prompts for the username, Password and then do some operations. When the password is entered on the unix terminal / screen, the password should not be displayed on the terminal. How to do this?

Solution:

The following unix or linux shell script reads the username, password from the terminal and then prints the values on the output screen:
$ cat pass_script.sh

#!/bin/bash
echo -n "Enter username: "
read username
echo -n "Enter password: "
read -s passwd
echo
echo "$username, the password entered is $passwd"
#Statements to connect to remote box
#using the entered username and password.

The -s option to the read command makes the value to be not printed on the screen.
# bash pass_script.sh
Enter username: root
Enter password: 
root, the password entered is hidden passwd


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Recovery from an LED 553 in AIX
By Surya01:40No comments
Question
Recovery from an LED 553 in AIX
Answer
This document describes a procedure to attempt to recover from an IPL hang at LED 553.

About LED 553
Recovery procedure
Sample /etc/inittab file for AIX Versions 5 and 6
Sample /etc/environment file for AIX.
1) About LED 553:
An LED value of 553 is a checkpoint code displayed to indicate the system transition to phase 3 of IPL. A halt or hang at LED 553 is often the result of a corrupted or missing /etc/inittab file. It can also be caused by full / (root) or /tmp file systems, inconsistencies in either startup configuration files, Object Data Manager (ODM) object class databases, or system library files. Additionally, a number of other issues involving file permissions, invalid hard links in the root file system, etc. have been observed to cause a hang at LED 553.
Summary of the recovery procedure:
To attempt to isolate the cause for an LED 553 hang, start by checking the root file systems with the fsck command. Then check /dev/hd3 and /dev/hd4 for space problems, and erase files if necessary. Check the /etc/inittab file for corruption, and fix it if necessary. If the inittab file was not corrupted, you will need to check the shell profile and environment files, the /bin/bsh file, as well as other system configuration files. A check of the consistency of all installed files within the installed fileset base and an update of the boot image should be done. To conclude, run the configuration manager to find out if there is a hang during device configuration.
2) Recovery procedure:
Boot your system into a limited function maintenance shell (Service or Maintenance mode) from AIX bootable media.
Please refer to your system user's or installation and service guide for specific IPL procedures related to your type and model of hardware. You can also refer to the document titled "Booting in Service Mode", available at http://techsupport.services.ibm.com/server/aix.srchBroker for more information.
With bootable media of the same version and level as the system, boot the system. The bootable media can be any ONE of the following:
Bootable CD-ROM
mksysb
Bootable Install Tape
Follow the screen prompts to the Welcome to Base OS menu.
Choose Start Maintenance Mode for System Recovery (Option 3). The next screen contains prompts for the Maintenance menu.
Choose Access a Root Volume Group (Option 1).
The next screen displays a warning that indicates you will not be able to return to Base OS menu without rebooting.
Choose 0 continue.
The next screen displays information about all volume groups on the system.
Select the root volume group by number. The logical volumes in rootvg will be displayed with two options below.
Choose Access this volume group and start a shell before mounting file systems (Option 2).
If you get errors from the preceding option, do not continue with the rest of this procedure. Correct the problem causing the error. If you need assistance correcting the problem causing the error, contact one of the following:
local branch office
your point of sale
your AIX support center
If no errors occur, proceed with the following steps.
Run the following series of commands to check and repair file systems.
 fsck -p /dev/hd4
 fsck -p /dev/hd2
 fsck -p /dev/hd3
 fsck -p /dev/hd9var
 fsck -p /dev/hd1
NOTE: The -y option gives the fsck command permission to repair file system corruption when necessary. This flag can be used to avoid having to manually answer multiple confirmation prompts, however, use of this flag can cause permanent data loss in some situations.
To format the default jfslog for the rootvg Journaled File Systems (JFS), run the following command:
 /usr/sbin/logform /dev/hd8
Answer yes when asked if you want to destroy the log.
Type exit to exit from the shell. The file systems should automatically mount after you type exit. If you receive error messages at this point, reboot into a limited function maintenance shell again to attempt to address the failure causes.
Use the df command to check for free space in /dev/hd3 and /dev/hd4.
   df  /dev/hd3
   df  /dev/hd4
If the output from the df command shows that either file system is out of space, erase some files from that file system. Three files you may want to erase are/smit.log, /smit.script and /.sh_history.
Next, check the /etc/inittab file for corruption. It may be empty or missing, or it may have an incorrect entry. For comparison, see the section "Sample /etc/inittab file" at the end of this document.
If the inittab file is corrupt, set your terminal type in preparation for editing the file. (xxx stands for a terminal type, such as lft, ibm3151, or vt100.)
   TERM=xxx
   export TERM
Now use an editor to create the /etc/inittab file. For an example, see the section "Sample /etc/inittab file" in this document. If your /etc/inittab file was corrupt and you recreated it, the following steps may not be necessary.
There are only three entries which must be in the /etc/inittab file to successfully boot the system. If your /etc/inittab file is missing or corrupted AND you are unable to use an editor while in Service mode, do the following to create a minimal inittab file to boot the machine into run level 2 (Normal mode).
  mv /etc/inittab /etc/inittab.MMYYDD
  touch /etc/inittab
  chmod 544 /etc/inittab
  chown root:system /etc/inittab
  echo 'init:2:initdefault:' >> /etc/inittab
  echo 'brc::sysinit:/sbin/rc.boot 3 >/dev/console 2>&1' >> /etc/inittab
  echo 'cons:0123456789:respawn:/usr/sbin/getty /dev/console' >> /etc/inittab
MMDDYY represents the current two-digit representation of the Month, Day and Year respectively.
Use the following command to check for any modifications or problems with permissions on shell startup files.
NOTE: The /.kshrc and /.profile files are not necessary for the system to boot into run level 2 (Normal mode) and, in fact, may not exist on your system.
   ls -al /.kshrc /.profile /etc/environment /etc/profile
Sample output:
-rw-r--r--  1 root  system   71 Dec 14 1993  /.kshrc
-rw-r--r--  1 root  system  158 Dec 14 1993  /.profile
-rw-rw-r--  1 root  system 1389 Oct 26 1993  /etc/environment
-rw-r-xr-x  1 bin   bin    1214 Jan 22 1993  /etc/profile
etc/profile or .profile may contain a command that is valid only in the Korn shell. Change the command to something that is also valid in the Bourne shell. For example, change the following:
   export PATH=/bin:/usr/bin/:/etc:/usr/ucb:.
to the following:
   PATH=/bin:/usr/bin/:/etc:/usr/ucb:.
   export PATH
/etc/environment is a special case. The only commands it may contain are simple variable assignments, such as statements of the form (varname)=(value). Check this file with an editor to verify the format. See the section "Sample /etc/environment file" at the end of this document.
Check for missing or moved files, or changed ownership/permissions with the following command:
   ls -al /bin /bin/bsh /bin/sh /lib /unix /u
Sample output:
lrwxrwxrwx 1 bin  bin       8 Aug 5 1994 /bin -> /usr/bin
-r-xr-xr-x 3 bin  bin 25622 4 Jun 4 1993 /bin/bsh
-r-xr-xr-x 3 bin  bin 25622 4 Jun 4 1993 /bin/sh
lrwxrwxrwx 1 bin  bin       8 Aug 5 1994 /lib -> /usr/lib
lrwxrwxrwx 1 bin  bin       5 Aug 5 1994 /u -> /home 
lrwxrwxrwx 1 root system    18 Aug 5 1994 /unix -> /usr/lib/boot/unix
If any of these files are missing, the problem may be a missing symbolic link. Use the commands from the following list that correspond to the missing links.
   ln -s /usr/bin /bin
   ln -s /usr/lib/boot/unix /unix
   ln -s /usr/lib /lib
   ln -s /home /u
Use the following command to make sure that rc.boot is not missing or corrupt.
   ls -l /sbin/rc.boot
Sample output:
-rwxrwxr-- 1 root system 33760 Aug 30 1993 /sbin/rc.boot
Make sure the /etc/inittab file is for AIX Version 5 or 6. For these versions, the line that begins with brc is
   brc::sysinit:/sbin/rc.boot 3 >/dev/console 2>&1
See the section "Sample /etc/inittab file" in this document for an example.
If you have not found any obvious problems, try substituting ksh for bsh with the following series of commands. (The first command saves your bsh before you copy over it.)
   cp /bin/bsh /bin/bsh.orig
   cp /bin/ksh /bin/bsh
If you can then reboot successfully, this indicates that one of the profiles was causing problems for bsh. Check the profiles again by running the following:
   /bin/bsh.orig /.profile
   /bin/bsh.orig /etc/profile
   /bin/bsh.orig /etc/environment
If you receive errors with any of the preceding commands, this indicates that there is a command in that profile that bsh cannot handle.
To run a checksum validation of all files in the installed fileset base and a consistency check of the fileset installation, run the following commands:
 lppchk -c
 lppchk -v
        lppchk -l
NOTE: These commands should not produce output. If they do, then the messages should be examined to assess whether it is a potential cause of the hang.
Detemine the boot drive and update the boot image with the following command:
 lslv -m hd5
Sample output:
   hd5:N/A
   LP    PP1  PV1               PP2  PV2               PP3  PV3
   0001  0001 hdisk0
The disk number under the PV1 column is the disk name you should use to run the following two commands:
 bosboot -ad /dev/hdisk0
 bootlist -m normal hdisk0
To check the device configuration routines, the following command should identify any problems associated with configuration routines:
 cfgmgr -vp 2
If the cfgmgr command hangs, this is likely the cause of the system hang. You may be able to stop the command by pressing Ctrl-C, however, a reboot is often required to get back into Service mode and continue troubleshooting the problem.
If your model has a mode select key, turn it to the Normal position.
Attempt to reboot the system into Normal mode by running the following command:
 sync;sync;sync;reboot
If you followed all of the preceding steps and the system still stops at an LED 553 during a reboot in Normal mode, you may want to consider reinstalling your system from a recent backup. Isolating the cause of the hang could be excessively time-consuming and may not be cost-effective in your operating environment. To isolate the possible cause of the hang, would require a debug boot of the system. Instructions for doing this are included in the document, "Capturing Boot Debug", available at http://techsupport.services.ibm.com/server/aix.srchBroker. It is still possible, in the end, that isolation of the problem may indicate a restore or reinstall of AIX is necessary to correct it.
If you wish, you may pursue further system recovery assistance from one of the following:
local branch office
your point of sale
your AIX support center
Sample /etc/inittab file for AIX Versions 5 and 6
:  US Government Users Restricted Rights - Use, duplication or
:  disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
:
: Note - initdefault and sysinit should be the first and second entry.
:
init:2:initdefault:
brc::sysinit:/sbin/rc.boot 3 >/dev/console 2>&1 # Phase 3 of system boot
powerfail::powerfail:/etc/rc.powerfail 2>&1 | alog -tboot > /dev/console # Power  Failure Detection
load64bit:2:once:/etc/methods/cfg64 >/dev/console 2>&1 # Enable 64-bit execs
rc:2:wait:/etc/rc 2>&1 | alog -tboot > /dev/console # Multi-User checks
fbcheck:2:wait:/usr/sbin/fbcheck 2>&1 | alog -tboot > /dev/console # run /etc/firstboot
srcmstr:2:respawn:/usr/sbin/srcmstr # System Resource Controller
rctcpip:2:wait:/etc/rc.tcpip > /dev/console 2>&1 # Start TCP/IP daemons
rcnfs:2:wait:/etc/rc.nfs > /dev/console 2>&1 # Start NFS Daemons
cron:2:respawn:/usr/sbin/cron
piobe:2:wait:/usr/lib/lpd/pio/etc/pioinit >/dev/null 2>&1  # pb cleanup
uprintfd:2:respawn:/usr/sbin/uprintfd
logsymp:2:once:/usr/lib/ras/logsymptom # for system dumps
pmd:2:wait:/usr/bin/pmd > /dev/console 2>&1 # Start PM daemon
diagd:2:once:/usr/lpp/diagnostics/bin/diagd >/dev/console 2>&1
dt:2:wait:/etc/rc.dt
cons:0123456789:respawn:/usr/sbin/getty /dev/console
Sample /etc/environment file for AIX Versions 5 and 6
# @(#)18        1.21  src/bos/etc/environment/environment, cmdsh, bos430, ...
PATH=/usr/bin:/etc:/usr/sbin:/usr/ucb:/usr/bin/X11:/sbin:/local/netscape:/usr/local/bin
TZ=CST6CDT
LANG=en_US
LOCPATH=/usr/lib/nls/loc
MOZILLA_HOME=/local/netscape
export MOZILLA_HOME
NLSPATH=/usr/lib/nls/msg/%L/%N:/usr/lib/nls/msg/%L/%N.cat
LC__FASTMSG=true
PS1='MYSYSTEM $PWD=>'
set -o vi
# ODM routines use ODMDIR to determine which objects to operate on
# the default is /etc/objrepos - this is where the device objects
# reside, which are required for hardware configuration
ODMDIR=/etc/objrepos 

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Recovery from LED 552, 554, or 556 in AIX
By Surya01:21No comments
Question
Recovery from LED 552, 554, or 556 system hang conditions in AIX.
Answer
This document discusses the known causes of LED 552, 554, and 556. Included is a procedure for recovery from these errors. This document was originally written for AIX Versions 4 and 5 but applies to all versions.
Causes of an LED 552, 554, or 556
Recovery procedure
Recommended fixes
Causes of an LED 552, 554, or 556
An LED code of 552, 554, or 556 during a standard disk based boot indicates a failure occurred during the varyon of the rootvg volume group.
Some known causes of an LED 552, 554, or 556 are:
a corrupted file system
a corrupted Journaled File System (JFS) log device
a bad IPL-device record or bad IPL-device magic number; the magic number indicates the device type
a corrupted copy of the Object Data Manager (ODM) database on the boot logical volume
a fixed disk (hard disk) in the inactive state in the root volume group
Recovery procedure
To diagnose and fix the problem, boot to a Service mode shell and run the fsck command (file system check) on each file system. If the file system check fails, you may need to perform other steps.
WARNING: Do not use this document if the system is a /usr client, diskless client, or dataless client.
Boot your system into a limited function maintenance shell (Service or Maintenance mode) from bootable AIX media to use this recovery procedure.
Refer to your system user's or installation and service guide for specific IPL procedures related to your type and model of hardware. You can also refer to the document titled "Booting in Service Mode", available at http://techsupport.services.ibm.com/server/aix.srchBroker for more information.
With bootable media of the same version and level as the system, boot the system into Service mode. The bootable media can be any ONE of the following:
Bootable CD-ROM
mksysb
Bootable Install Tape
Follow the screen prompts to the Welcome to Base OS menu.
Choose Start Maintenance Mode for System Recovery (Option 3). The next screen displays prompts for the Maintenance menu.
Choose Access a Root Volume Group (Option 1).
The next screen displays a warning that indicates you will not be able to return to the Base OS menu without rebooting.
Choose 0 continue.
The next screen displays information about all volume groups on the system.
Select the root volume group by number. The logical volumes in rootvg will be displayed with two options below.
Choose Access this volume group and start a shell before mounting the file systems (Option 2).
If you receive errors from the preceding option, do not continue with the rest of this procedure. Correct the problem causing the error. If you need assistance correcting the problem causing the error, contact one of the following:
local branch office
your point of sale
your AIX support center
Run the following commands to check and repair file systems.
 fsck -p /dev/hd4 
   fsck -p /dev/hd2 
   fsck -p /dev/hd9var 
   fsck -p /dev/hd3
   fsck -p /dev/hd1 
NOTE: The -y option gives the fsck command permission to repair file system corruption when necessary. This flag can be used to avoid having to manually answer multiple confirmation prompts, however, use of this flag can cause permanent data loss in some situations.
If any of the following conditions occur, proceed accordingly.
If fsck indicates that block 8 could not be read, the file system is probably unrecoverable. See step 5 for information 
on unrecoverable file systems.
If fsck indicates that a file system has an unknown log record type, or if fsck fails in the logredo process, then go to step 6.

If the file system checks were successful, skip to step 8.
The easiest way to fix an unrecoverable file system is to recreate it. This involves deleting it from the system and restoring it from a very current system backup. Note that hd9var and hd3 can be recreated, but hd4 and hd2 cannot be recreated. If hd4 and/or hd2 is unrecoverable, AIX must be reinstalled or restored from system backup. For assistance with unrecoverable file systems, contact your local branch office, point of sale, or AIX support center. Do not follow the rest of the steps in this document.
A corruption of the JFS log logical volume has been detected. Use the logform command to reformat it.
 /usr/sbin/logform /dev/hd8
Answer yes when asked if you want to destroy the log.
Repeat step 4 for all file systems that did not successfully complete fsck the first time. If step 4 fails a second time, the file system is almost always unrecoverable. See step 5 for an explanation of the options at this point. In most cases, step 4 will be successful. If step 4 is successful, continue to step 8.
With the key in Normal position (for microchannel machines), run the following commands to reboot the system:
  exit
   sync;sync;sync;reboot
As you reboot in Normal mode, notice how many times LED 551 appears. If LED 551 appears twice, fsck is probably failing because of a bad fshelperfile. If this is the case and you are running AFS, see step 11.
The majority of instances of LED 552, 554, and 556 will be resolved at this point. If you still have an LED 552, 554, or 556, you may try the following steps.
ATTENTION: The following steps will overwrite your Object Data Manager (ODM) database files with a very primitive, minimal ODM database. Due to the potential loss of user configuration data caused by this procedure, it should only be used as a last resort effort to gain access to your system to attempt to back up any data that you can. It is NOT recommended to use the following procedure in lieu of restoring from a system backup.
Repeat step 1 through step 3.
Run the following commands, which remove much of the system's configuration and save it to a backup directory.
 mount /dev/hd4 /mnt
   mount /dev/hd2 /mnt/usr
   mkdir /mnt/etc/objrepos/bak
   cp /mnt/etc/objrepos/Cu* /mnt/etc/objrepos/bak
   cp /etc/objrepos/Cu* /mnt/etc/objrepos
   umount /dev/hd2
   umount /dev/hd4
   exit
Determine which disk is the boot disk with the lslv command. The boot disk will be shown in the PV1 column of the lslv output.
 lslv -m hd5
Save the clean ODM database to the boot logical volume. (# is the number of the fixed disk, determined with the previous command.)
 savebase -d /dev/hdisk# 
If you are running AFS, go to step 11; otherwise, go to step 12.
If you are running the Andrew File System (AFS), use the following commands to find out whether you have more than one version of the v3fshelper file.
 cd /sbin/helpers
   ls -l v3fshelper*
If you have only one version of the v3fshelper file (for example, v3fshelper), proceed to step 12.
If there is a version of v3fshelper marked as original (for example, v3fshelper.orig), run the following commands:
 cp v3fshelper v3fshelper.afs
   cp v3fshelper.orig v3fshelper
WARNING: Do not proceed further if the system is a /usr client, diskless client, or dataless client.
Make sure that hd5 is on the edge of the drive and if it is more than 1 partition that the partitions are contiguous. For systems of 5.1 and above, make sure that hd5 is greater than 12 MB:
   lslv hd5 (Check to see what the PP Size: is equal to)
     lslv -m hd5
LP    PP1  PV1           PP2   PV2                    PP3   PV3
0001   0001 hdisk2
0002   0002 hdisk2
Recreate the boot image (hdisk# is the fixed disk determined in step 11):
 bosboot -a -d /dev/hdisk# 
Make sure the bootlist is set correctly:
   bootlist -m normal -o
Make changes, if necessary:
   bootlist -m normal hdiskX cdX
(This can be edited to whatever you wish it to be.)
NOTE: If you suspect an inactive or damaged disk device is causing the boot problem and the boot logical device, hd5, is mirrored onto another device, you may wish to list this other boot device first in the bootlist.
Make sure that the disk drive that you have chosen as your bootable device has a yes next to it:
   ipl_varyon -i
Example:
PVNAME                     BOOT DEVICE       
PVID                                 VOLUME GROUP ID
hdisk1                     NO                
0007b53cbfd04a9000000000000000000007b53c00004c00
hdisk4                     NO                
0007b53c1244625d00000000000000000007b53c00004c00
hdisk2                     YES               
0007b53c8ffd631200000000000000000007b53c00004c00
From the above example, hdisk2 would be a bootable disk drive while hdisk1 and hdisk4 would not be.
If you copied files in step 11, copy the AFS file system helper back to v3fshelper:
 cp v3fshelper.afs v3fshelper
Turn the key to the Normal position if dealing with microchannel machine and run
 sync;sync;sync;reboot
If you followed all of the preceding steps and the system still stops at an LED 552, 554, or 556 during a reboot in Normal mode, you may want to consider reinstalling your system from a recent backup. Isolating the cause of the hang could be excessively time-consuming and may not be cost-effective in your operating environment. To isolate the possible cause of the hang, would require a debug boot of the system. Instructions for doing this are included in the document "Capturing Boot Debug", available at http://techsupport.services. ibm.com/server/aix.srchBroker . It is still possible, in the end, that isolation of the problem may indicate a restore or reinstall of AIX is necessary to correct it.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Remote X11 Windows to AIX
By Surya21:29No comments
Author:Urban Biel

I love command line. It's numerous advantages over GUI is hard to list, but there are situations, where you need a remote X Windows connection. I've been asked many times by my colleagues, how to set up remote X Windows (X11, as the most recent version of X Windows is 11) on AIX, why it doesn't work, etc.
Basic overview of X11 Windows architecture
X11 is a client / server architecture. You need to know two things:
an application e.g. xclock is an X11 client
the application's content is displayed by an X11 server
Anyway, some people are confused here: I'm connecting to an AIX server using ssh/telnet, thus my workstation is an ssh/telnet client. What do I have to run on my local machine: an X11 client or an X11 server? You obviously need to install and run an X11 server on your local workstation. If you run e.g. xclock on a remote machine (AIX), that's an X11 client.

Let's have a quick look at a connection between an X11 client and an X11 server. The connection can be a unix socket or TCP/IP. The socket is used, when the client and the server run on the same machine, which is not our case. Remote X Windows connection is using the TCP/IP. To tell the client, where the X11 server runs, you need to set up a DISPLAY environment variable. By default an X11 server listens on port 6000. You can have more X server instances, but that's out of the topic.
Your workstation
If you want to display a program on your local workstation, that is running on a remote AIX, you need to install and run an X server locally. If you run Linux on your workstation and you're reading this in a browser, you're done. On Windows there is a few X servers; some are commercial, some are free. Very popular is Xming, I use Cygwin.
https://www.cygwin.org/
A quick Cygwin howto:
Install Cygwin from www.cygwin.org
select at least the following extra packages: xorg-server xinit xauth xclock xterm xhost
Make an entry in your Startup folder: C:\cygwin\bin\run.exe /usr/bin/bash.exe -l -c /usr/bin/startxwin.exe
Start the X11 server from the Startup folder and from a Windows command line check, if it's listening for TCP/IP connection on port 6000:
C:\Users\IBM_ADMIN>netstat -atn | findstr 6000
  TCP    0.0.0.0:6000           0.0.0.0:0              LISTENING       InHost
  TCP    [::]:6000              [::]:0                 LISTENING       InHost

if you see the output like this, you're done with your workstation.
Remote AIX server
An X Windows minimum installation includes filesets: X11.base.lib X11.base.rte X11.apps.config. I suggest to install X11.apps.clients too, that contains xclock program. By running this program I check the time, and of course the X11 setup. For an X11 client to run, it needs to establish TCP/IP connection to your X11 server. You can do this directly or you can tunnel the connection.
Direct X11 TCP/IP connection
The simplest scenario. It works, if there is no firewall blocking port 6000 to your workstation and there is no NAT. Try to ping your workstation from the AIX server, and if it works, try telnet to port 6000 to your workstation. If everything is fine, set the DISPLAY variable to an IP address of your workstation, for example export DISPLAY=192.168.0.100:0. On your workstation, allow the IP address of the AIX server to open an X11 session using xhost + <ip_address_of_the_aix_server>. Run xclock on AIX and enjoy.

SSH X11 port forwarding
This is the way professionals do it, as ssh is installed by default on AIX now. Advantages:
you do not care about network infrastructure, VPNs, NATs and firewalls between you and the target server. All you need is a working ssh connection
you do not care about DISPLAY anymore
X11 session is automatically authenticated
X11 session is automatically encrypted
On the AIX check, that ssh X11 forwarding requests are allowed:
# grep X11Forwarding /etc/ssh/sshd_config
X11Forwarding yes

If it's necessary, change the value and restart the ssh service. You can do it while you're logged in, your current ssh session will not be dropped. Keep in mind, that the ssh X11 forwarding will apply only to new ssh sessions, that are opened with X forwarding.
stopsrc –s sshd; sleep 2; startsrc –s sshd

Now set the X11 forwarding on your workstation. If you have an command line ssh client e.g. as part of Cygwin, run ssh -X <server_ip> to log in. If you use Putty, check that X11 forwarding is set for your session and don't forget to save the change. For other ssh clients check a documentation (or browse through all the session settings, as pros do....)


After you log in, check the DISPLAY and authentification value. If it is as on an example below, run xclock and enjoy.
# echo $DISPLAY
DISPLAY=localhost:10
# xauth list
server/unix:10 MIT-MAGIC-COOKIE-1 6299564796e4cf089e38619a354cfdcc
Note: If you open more ssh sessions to one host, with the X11 forwarding turned on, every session will have different offset number in the DISPLAY variable. The offset number is the one after a colon, e.g. 10 in the example above.
Issues
A few FAQ's I'm being asked
I run xclock, but it hangs out and does not display anything
Realy? An X11 windows can open underneath other windows. Check again.
A DISPLAY variable is not set or is set incorrectly. In this case it takes few minutes for an application to terminate.
An X11 server is not running on your local machine.
I use ssh the X11 forwarding, but the DISPLAY variable is not set
Check X11Forwarding directive in sshd_config
Check that ssh client has X11 forwarding option set
The AIX machine is missing xauth programm. Install X11.apps.config fileset.
There are some older OpenSSH or OpenSSL versions that are buggy. I have had issues with OpenSSH versions 4.6.X, OpenSSH_4.3p2, OpenSSL 0.9.7l 28


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Removing ODM information of a logical volume
By Surya18:14No comments

Sometimes situations occur where a logical volume is deleted, but the ODM is not up to date. E.g. when "lsvg -l" doesn't show you the logical volume, but the lslv command can still show information about the logical volume. Not good.

To resolve this issue, first try:
# synclvodm -v [volume group name]
If that doesn't work, try this: (in the example below logical volume hd7 is used). Save the ODM information of the logical volume:
# odmget -q name=hd7 CuDv | tee -a /tmp/CuDv.hd7.out
# odmget -q name=hd7 CuAt | tee -a /tmp/CuAt.hd7.out

If you mess things up, you can allways use the following command to restore the ODM information:
# odmadd /tmp/[filename]

Delete the ODM information of the logical volume:
# odmdelete -o CuDv -q name=hd7
# odmdelete -o CuAt -q name=hd7

Then, remove the device entry of the logical volume in the /dev directory (if present at all). 


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Repairing File Systems with fsck in AIX V5 (LED 517 or 518)
By Surya01:45No comments
Technote (FAQ)
Repairing File Systems with fsck in AIX V5 or V6 (LED 517 or 518)
Answer
This document covers the use of the fsck (file system check) command in Maintenance mode to repair inconsistencies in file systems. The procedure described is useful when file system corruption in the primary root file systems is suspected or, in many cases, to correct an IPL hang at LED value 517, 518, or LED value 555.
This document applies to AIX version 5.x, 6.x, and VIOS LPAR.
Recovery procedure
Boot your system into a limited function maintenance shell (Service, or Maintenance mode) from AIX bootable media to perform file system checks on your root file systems.
 
Please refer to your system user's or installation and service guide for specific IPL procedures related to your type and model of hardware. You can also refer to the document titled "Booting in Service Mode," available at http://techsupport.services.ibm.com/server/aix.srchBroker.
With bootable media of the same version and level as the system, boot the system. If this is a VIOS LPAR, use the correct VIOS media. The bootable media can be any ONE of the following:
Bootable CD-ROM
NON_AUTOINSTALL mksysb
Bootable Install Tape
Follow the screen prompts to the following menu:
   Welcome to Base Operating System 
   Installation and Maintenance 
Choose Start Maintenance Mode for System Recovery (Option 3).
The next screen displays the Maintenance menu.
Choose Access a Root Volume Group (Option 1).
The next screen displays a warning that indicates you will not be able to return to the Base OS menu without rebooting.
Choose 0 continue.
The next screen displays information about all volume groups on the system.
Select the root volume group by number.
Choose Access this volume group and start a shell before mounting file systems (Option 2).
If you get errors from the preceding option, do not continue with the rest of this procedure. Correct the problem causing the error. If you need assistance correcting the problem causing the error, contact one of the following:
local branch office
your point of sale
your AIX support center
If no errors occur, proceed with the following steps.
Run the following commands to check and repair file systems.
NOTE: The -y option gives fsck permission to repair file system corruption when necessary. This flag can be used to avoid having to manually answer multiple confirmation prompts, however, use of this flag can cause permanent, unnecessary data loss in some situations.
 fsck /dev/hd4 
 fsck /dev/hd2 
 fsck /dev/hd3 
 fsck /dev/hd9var 
 fsck /dev/hd1 
To format the default jfslog for the rootvg Journaled File System (JFS) file systems, run the following command:
 /usr/sbin/logform /dev/hd8 
Answer yes when asked if you want to destroy the log.
If your system is hanging at LED 517 or 518 during a Normal mode boot, it is possible the /etc/filesystems file is corrupt or missing. To temporarily replace the disk-based /etc/filesystems file, run the following commands:
 mount /dev/hd4 /mnt
 mv /mnt/etc/filesystems /mnt/etc/filesystems.[MMDDYY]
 cp /etc/filesystems /mnt/etc/filesystems
 umount /mnt
MMDDYY represents the current two-digit representation of the Month, Day and Year, respectively.
Type exit to exit from the shell. The file systems should automatically mount after you type exit. If you receive error messages, reboot into a limited function maintenance shell again to attempt to address the failure causes.
If you have user-created file systems in the rootvg volume group, run fsck on them now. Enter:
 fsck /dev/[LVname] 
LVname is the name of your user-defined logical volume.
If you used the preceding procedure to temporarily replace the /etc/filesystems file, and you have user-created file systems in the rootvg volume group, you must also run the following command:
 imfs -l /dev/[LVname]
If you used the preceding procedure to temporarily replace the /etc/filesystems file, also run the following command:
 imfs [VGname]
The preceding commands can be repeated for each user-defined volume group on the system.
If your system was hanging at LED 517 or 518 and you are unable to activate non-rootvg volume groups in Service mode, you can manually edit the/etc/filesystems file and add the appropriate entries.
The file /etc/filesystems.MMDDYY saved in the preceding steps may be used as a reference if it is readable. However, the imfs method is preferred since it uses information stored in the logical volume control block to re-populate the /etc/filesystems file.
If your system has a mode select key, turn it to the Normal position.
Reboot the system into Normal mode using the following command:
 sync;sync;sync;reboot 
If you followed all of the preceding steps and the system still stops at an LED 517 or 518 during a reboot in Normal mode, you may want to consider re-installing your system from a recent backup. Isolating the cause of the hang could be excessively time-consuming and may not be cost-effective in your operating environment. To isolate the possible cause of the hang, would require a debug boot of the system. Instructions for doing this are included in the document "Capturing Boot Debug", available at IBM Technical Help Database for AIX. It is still possible, in the end, that isolation of the problem may indicate a restore or reinstall of AIX is necessary to correct it.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Replace a “Hot Swap” mirrored rootvg disk (hdisk1)
By Surya12:292 comments
In the following example, AIX system has 2 disks in the rootvg with mirrored lv except ibmDIRlv . The boolist contains both hdisk0 and hdisk1. There are no other logical volumes in rootvg other than the AIX systemlogical volumes. hdisk1 has failed and need replacing, both hdisk0 and hdisk1 are in “Hot Swap” carriers and therefore the machine does not need shutting down.  In the below procedure from steps 9 to step 15 are  only applicable to Internal disk and are not applicable to SAN LUNs.
Pre Requisite:   Make a note of the slot disk number for replacing disk using lscfg -vl hdisk1
                          hdisk1           U787B.001.DNW8950-P1-T14-L3-L0  16 Bit LVD SCSI Disk Drive (146800 MB)
Step1:- if hdisk0 and hdisk1 are not similar migrate lv’s those are not in hdisk0. Here hdisk0 containing all hdisk1 LVs except ibmDIRlv. To move physical partitions in logical volume ibmDIRlv from hdisk1 to hdisk0, enter
#migratepv –l ibmDIRlv hdisk1 hdsik0
Step2:- unmirror hdisk1 from rootvg
#unmirrorvg rootvg hdisk1                       (Breaks the mirroring).
Step3:- Clear’s the boot record of hdisk1.
#chpv –c hdisk1                                         (Clears the bootrecords of hdisk1).
Step4:- Reduce the rootvg by eliminating hdisk1.
#reducevg rootvg hdisk1
Step5:- Set the bootlist to hdisk0.
#bootlist –m normal hdisk0     (-m refers mode.Here it will boot normal mode from hdisk0).
Step6:- Removed hdisk1 from rootvg so we have problem with quorum so need to varryoff quorum automatically).
#chvg –Qn rootvg   (here we have two disks each having 50-50% and quoram must be >51 so it is not possible with one disk for that it need to disable).
Step7:- sync the odm for lv special file ownerships and permissions.
#synclvodm –Pv rootvg  
Ste      Step8 :Remove the hdisk1 definition from the server. rmdev –dl /dev/hdisk1
Step9:  Select the Identifier of the hdisk1 as show below. It will help the onsite person to identify the disk as Indicator will be lit on the hdisk1 slot.
daig —>task selection —> Identify and Attention Indicators
Step10 :  Now do the following step and asked on site engineer to remove the device physically from the server and add a new disk.
diag —-> enter —> task selection—->hot plug task —–> scsi&scsi     RAID plug master—> select replace/ remove –> select hdisk1 —-> select device has been removed/replace
Step11:  Press Enter. The disk drive slot exits the Remove state and enters the Normal state.

Step12: Scan the new device by running the cfgmgr
Step13: Update the system log by using daig.
daig —>task selection —> Log Repair Action —>hdisk1 —-> F3
Step14: Check the errpt status by errpt | more
Step15: certify the device by daig .
daig —–>task selection —-> certify the device —>hdisk1.
Step16: Add hdisk1 to rootvg
#extendvg rootvg hdisk1
Step17: Mirror and Sync rootvg with disk hdisk1
#mirrorvg –S rootvg
Step18:  Create boot image on hdisk1
#bosboot –ad /dev/hdisk1
www.unixmantra.com

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Resolving LED code 555-AIX
By Surya09:15No comments

If your system hangs with LED code 555, it will most likely mean that one of your rootvg file systems is corrupt. The following link will provide information on how to resolve it:

http://www-304.ibm.com/support/docview.wss?uid=isg3T1000217

After completing the procedure, the system may still hang with LED code 555. If that happens, boot the system from media and enter service mode again, and access the volume group. Then check what the boot disk is according to:

# lslv -m hd5

Then also check your bootlist:

# bootlist -m normal -o

If these 2 don't match, set the boot list to the correct disk, as indicated by the lslv command above. For example, to set it to hdisk1, run:

# bootlist -m normal hdisk1

And then, make sure you can run the bosboot commands:

# bosboot -ad /dev/hdisk1
# bosboot -ad /dev/ipldevice

Note: exchange hdisk1 in the example above with the disk that was indicated by the lslv command.

If the bosboot on the ipldevice fails, you have 2 options: Recover the system from a mksysb image, or recreate hd5. First, create a copy of your ODM:

# mount /dev/hd4 /mnt
# mount /dev/hd2 /mnt/usr
# mkdir /mnt/etc/objrepos/bak
# cp /mnt/etc/objrepos/Cu* /mnt/etc/objrepos/bak
# cp /etc/objrepos/Cu* /mnt/etc/objrepos
# umount /dev/hd2
# umount /dev/hd4
# exit

Then, recreate hd5, for example, for hdisk1:

# rmlv hd5
# cd /dev
# rm ipldevice
# rm ipl_blv
# mklv -y hd5 -t boot -ae rootvg 1 hdisk1
# ln /dev/rhd5 /dev/ipl_blv
# ln /dev/rhdisk1 /dev/ipldevice
# bosboot -ad /dev/hdisk1

If things still won't boot at this time, the only option you have left is to recover the system from a mksysb image.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Restoring individual files from a mksysb image
By Surya08:52No comments
First of all, go to the directory that contains the mksysb image file:
# cd /sysadm/iosbackup
In this example, were using the mksysb image of a Virtual I/O server, created using iosbackup. This is basically the same as a mksysb image from a regular AIX system. The image file for this mksysb backup is called vio1.mksysb

First, try to locate the file you're looking for; For example, if you're looking for file nimbck.ksh:
# restore -T -q -l -f vio1.mksysb | grep nimbck.ksh
New volume on vio1.mksysb:
Cluster size is 51200 bytes (100 blocks).
The volume number is 1.
The backup date is: Thu Jun  9 23:00:28 MST 2011
Files are backed up by name.
The user is padmin.
-rwxr-xr-x- 10   staff  May 23  08:37  1801 ./home/padmin/nimbck.ksh
Here you can see the original file was located in /home/padmin.
Now recover that one single file:
# restore -x -q -f vio1.mksysb ./home/padmin/nimbck.ksh
x ./home/padmin/nimbck.ksh
Note that it is important to add the dot before the filename that needs to be recovered. Otherwise it won't work. Your file is now restore to ./home/padmin/nimbck.ksh, which is a relative folder from the current directory you're in right now:
# cd ./home/padmin
# ls -als nimbck.ksh
4 -rwxr-xr-x    1 10  staff  1801 May 23 08:37 nimbck.ksh


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

rpc.mountd Will Not Start

Technote (FAQ)
rpc.mountd Will Not Start
Answer
Environment
AIX 4.3 and higher
Problem
rpc.mountdwill not start. The following error is found in theerrptoutput:
Solution
Fix loopback/localhost name resolution as follows:
Edit the/etc/hostsfile:
     127.0.0.1 loopback localhost
->Save the file.
Edit the/etc/netsvc.conffile:
     hosts=local,bind4
->Save the file.
Test as follows, enter:
     host localhost
->Your output should be similar to the following:
     loopback is 127.0.0.1, aliases: localhost
Enter the following commands:
     startsrc -s rpc.mountd
     lssrc -s rpc.mountd
->rpc.mountdshould now be listed as active.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Running with Tripwire
Using Tripwire to monitor file changes
Introduction
The open source Tripwire® is a file integrity checker package that has been around for years and, though I have used it many times on Linux® distributions, I have only recently got around to using it on AIX®. This is mainly due to the following:

It is troublesome to compile using the gcc AIX version.
I prefer using the AIX built-in audit service.
However, as there is now a Tripwire rpm for AIX, I use it for some of our AIX boxes. Tripwire does not provide a complete solution to intruder detection based on file changes, but coupled with running an AIX audit, it provides a firm security policy. Tripwire monitors for changes to files and directories on your system via the objects that you provide in the main policy file. These changes may be but are not restricted to:

inode
timestamps
file size
file permissions and ownership attributes
hash values
file types
It reports on changes from the previous run of Tripwire, where you can compare previous ran reports. If files have been altered, removed, or added, then this requires further investigation by the system administrator to determine if it is a valid change or a forced change by some application or user.

Tripwire does have its short comings, when compared to other intruder detection systems (IDS). However, as it is open source, these shortcomings are soon forgotten. There is a commercial Tripwire product, but for this demonstration, I will only focus on the open source version. I am also using AIX 7.1 with Tripwire version 2.4.1. See the Resources section on where to download the Tripwire rpm. Once downloaded, be sure to have the following prerequisite rpms installed:

libgcc-4.6.1-1.aix7.1.ppc.rpm  
libstdc++-4.6.1-1.aix7.1.ppc.rpm
(openssl-1.0.0d-1.aix5.1.ppc.rpm)
Tripwire also requires openssl; most AIX boxes should already have this installed. If you are using SSH, be sure you have at least version 0.9.8. Check your version with:

# openssl
OpenSSL> version
OpenSSL 0.9.8m 25 Feb 2010
OpenSSL> quit
Next, install Tripwire:

#  rpm -ivh tripwire-2.4.2-1-1.aix5.1.ppc.rpm
tripwire                    ##################################################
Once installed, the Tripwire binary files are located in /opt/freeware/sbin.
tripwire-check           
atcadmin
tripwire                 
tripwire-setup-keyfiles  
reprint
The policy files are located at /etc/tripwire. The twcfg.txt file defines variables used by Tripwire (for example, location of tripwire report files, mailing, reporting level). The twpol.txt policy file tells Tripwire what files to monitor.

The first step is to tailor the policy file on what files gets monitored. The twpol.txt files that ships with Tripwire is geared for a Linux distribution, and you want to ensure that it covers the files you want to monitor. If you forget to tailor this policy file, an error for non-existent files are reported. It can be quicker to generate your own policy file, specific to your own security standard policy. This article demonstrates how an initial baseline policy is generated. I do not discuss all the features of Tripwire, such as severity levels and email conditions, but rather how to get up and running with Tripwire using a self-generated policy file to suit your needs and reports on file violations.
Configuring Tripwire
The contents of twcfg.txt are shown below. As Tripwire complains about directory permissions that may not be correct for your AIX box, the documentation suggests, and I agree, to change:
LOOSEDIRECTORYCHECKING = false
to
LOOSEDIRECTORYCHECKING = true
You may also want to change the locations of DBFILE and REPORTFILE to suite your location standards:

ROOT                   =/opt/freeware/sbin
POLFILE                =/etc/tripwire/tw.pol
DBFILE                 =/var/lib/tripwire/$(HOSTNAME).twd
REPORTFILE             =/var/lib/tripwire/report/$(HOSTNAME)-$(DATE).twr
SITEKEYFILE            =/etc/tripwire/site.key
LOCALKEYFILE           =/etc/tripwire/$(HOSTNAME)-local.key
EDITOR                 =/usr/bin/vi
LATEPROMPTING          =false
LOOSEDIRECTORYCHECKING =false
MAILNOVIOLATIONS       =true
EMAILREPORTLEVEL       =3
REPORTLEVEL            =3
MAILMETHOD             =SENDMAIL
SYSLOGREPORTING        =false
MAILPROGRAM            =/usr/sbin/sendmail -oi -t  
If your hostname is not resolvable, you have to inform Tripwire of your local hostname. Edit the twpol.txt file; around line 64 there is an entry for:

HOSTNAME=;
Append your hostname after the '='. For example, the host name of my AIX box is rs6000, so the change would be:

HOSTNAME=rs6000;
Save and exit the file.
Generating the keys
The next task is to generate a site and local key for Tripwire using a passphrase. This helps safeguard Tripwire from unauthorized access. The local key is for the database file, and the site key is for the configuration and policy files. You need to remember the passphrases you give, as you will be prompted for these when you update the policy file or database. The following command generates both keys. For this demonstration, I will show the passphrases I used through out this article:

# /opt/freeware/sbin/tripwire-setup-keyfiles

----------------------------------------------

Creating key files...
Enter the site keyfile passphrase:rs6000
Verify the site keyfile passphrase:rs6000
Generating key (this may take several minutes)...Key generation complete.

(When selecting a passphrase, keep in mind that good passphrases typically
have upper and lower case letters, digits and punctuation marks, and are
at least 8 characters in length.)

Enter the local keyfile passphrase:master
Verify the local keyfile passphrase:master
Generating key (this may take several minutes)...Key generation complete.

----------------------------------------------
Signing configuration file...
Please enter your site passphrase:
Wrote configuration file: /etc/tripwire/tw.cfg

A clear-text version of the Tripwire configuration file:
/etc/tripwire/twcfg.txt
has been preserved for your inspection.  It  is  recommended  that  you
move this file to a secure location and/or encrypt it in place (using a
tool such as GPG, for example) after you have examined it.
Signing policy file...
Please enter your site passphrase:rs6000
Wrote policy file: /etc/tripwire/tw.pol.
When the key generation completes, the following files exist in /etc/tripwire:
rs6000-local.key  tw.cfg            twcfg.txt
site.key          tw.pol            twpol.txt
Looking at the above listing, we now have the additional files:

rs6000-local.key (your encrypted local key file);
site.key (your encrypted site key file);
tw.cfg (your encrypted configuration variables file); and
tw.pol (your encrypted policy file).
At this point, there is no need to keep the twcfg.txt and twpol.txt files in its current location. You can access the encrypted version of the files via a Tripwire utility by providing your passphrase to decrypt it. This is demonstrated in this article.
The initial scan
Now that we have generated the keys and supplied our passphrases, we can do an initial scan. Use the policy in the encrypted tw.pol policy file. As mentioned earlier, the policy file that ships with Tripwire is geared towards a Linux system in what files to check. The policy file needs to be tailored to your AIX system; you'll see how to do that shortly. However, for now, run the scan where Tripwire generates the checksums and records the file's scanned attributes. The database is also created and updated. Expect a lot of errors on this run, but this exercise gives you a feel on what to expect using Tripwire.

When running the initialization, you are prompted for your passphrase (I have also heavily truncated the output due to the amount of errors reported):
# /opt/freeware/sbin/tripwire --init
Please enter your local passphrase:master
Parsing policy file: /etc/tripwire/tw.pol
Generating the database...
*** Processing Unix File System ***
### Warning: File system error.
### Filename: /proc/ksyms
### A file or directory in the path name does not exist.
### Continuing...
### Warning: File system error.
### Filename: /dev/initctl
### A file or directory in the path name does not exist.
### Continuing...
…
...
Wrote database file: /var/lib/tripwire/rs6000.twd
The database was successfully generated.
#
To function correctly, the Tripwire database must always be present; make sure it is backed up regularly. It is easy to re-initialize the database.

Once the initialization has completed, Tripwire reports that the database has been created (note that the current hostname is part of the database file-name located in/var/lib/tripwire/rs6000.twd).
The policy file
To customize the policy file to your needs, use the Tripwire check mode to check the integrity of the system. This also prints errors out where files are not present in the system but are present in the policy file. Expect the listing to be long; it maybe advantageous to redirect the output to a log file for further review:
 # /opt/freeware/sbin/tripwire --check | grep -w "Filename:"
A partial typical output from the above command could be:

     Filename: /bin/ypdomainname
     A file or directory in the path name does not exist.
     Filename: /bin/tcsh
     A file or directory in the path name does not exist.
     Filename: /usr/sbin/fixrmtab
     A file or directory in the path name does not exist.
     …
     …
To tailor the Tripwire policy on what files to monitor, you have two choices:
Go through the policy file and remove the file names that were printed for the non-existing files.
Start from scratch and add your own entries.
I prefer the last choice. That way, I only monitor what I want. Before we create those entries, the basic format of the policy file needs to be explained.

The policy file is very rich in command directives and objects, so be sure to read the man page on twpolicy. In this demonstration, I cover and implement only some of those command objects. Tripwire has the ability to monitor for the file attributes contained below in Listing 1.

Listing 1. File attributes
a     Access timestamp
b     Number of blocks allocated
c     Inode timestamp (create/modify)
d     ID of device on which inode resides
g     File owner's group ID
i     Inode number
l     File is increasing in size (a "growing file")
m     Modification timestamp
n     Number of links (inode reference count)
p     Permissions and file mode bits
r     ID of device pointed to by inode
      (valid only for device objects)
s     File size
t     File type
u     File owner's user ID
C     CRC-32 hash value
H     Haval hash value
M     MD5 hash value
S     SHA hash value
Additional masks can also be added to the attributes:

+ do compare attribute
-ignore  attribute
Built-in objects
If you have looked through the shipped twpol file, you would have noticed that the objects are already defined. These are shown below in Listing 2. Use the attributes as described in Listing 1 to create the property masks.

Listing 2. Masks
Variable       Mask
Device =      +pugsdr-intlbamcCMSH ; # devices file 
Dynamic =     +pinugtd-srlbamcCMSH ; # directories that change
Growing =     +pinugtdl-srbamcCMSH ; # file that grow in size
IgnoreAll =   -pinugtsdrlbamcCMSH ;  # check nothing
IgnoreNone =  +pinugtsdrbamcCMSH-l ; # check everything except growing attribute 
ReadOnly =    +pinugtsdbmCM-rlacSH ; # read only
Temporary =   +pugt                  # temp files that might be removed
Looking at the property mask Temporary, contained in Listing 2, we can see that temporary monitor:
permissions (and compare permissions)
file ownership
file group ownership
file type
Tripwire uses these property masks, that contain variables, to make it easier to specify what attributes to monitor on any given file. However, you can define your own objects, and in this demonstration, that is what I discuss. To aid in cross platform sharing, an object can be created to match certain criteria. In a nutshell, this means that you can specify what file attributes to monitor for different types of files.
The format of an object is:

object_name  = [ mask ];
Where object_name is a meaningful name of the type of files to monitor and mask represents the attributes shown in Listing 1.
Defining objects

If I wish to monitor system binary files, such as reducevg or chfs, I need to know about changes relating to these files on the following:

permissions
symbolic links
group owner
file owner
file size
modification stamp
MD5 hash signature
So using the above changes, I can generate a object called SYSBIN (for system binaries), using the attribute information contained in Listing 1.

SYSBIN =  +pngu+sm;
Note in this mask, I have stated with the plus (+) sign that the file permissions and file size should be compared from a previous Tripwire run or snapshot.

The format of each file or directory to monitor is:
<directory/file-name> - > $(object_name)
An entry in the policy file to monitor for the binary /usr/local/bin/pwgen, using the object SYSBIN, could be:
/usr/local/bin/pwgen  -> $(SYSBIN);
If I wanted to monitor the /usr/bin directory using the object SYSBIN, I could have:
/usr/bin -> $(SYSBIN);
Any modifications in the above directory, like additional new files, removed files created in that directory and are flagged as a violation.

For dynamic files, typically these are logs, we do not have to be so restrictive, as the files sizes are always changing. I could, for example, use the following object:
 SYSLOGS +p-lum
In this object, I specified to monitor only the following:

permissions
ignore file size growth ( -l)
file owner
MD5 hash signature
For an entry in the policy file for the /var/adm/messages log file, I could have:
/var/adm/messages - > $(SYSLOGS)
For certain application configuration scripts, I would want to monitor at least the following attributes:

access timestamp
permissions
modification timestamp
filesize
fileowner
MD5 hash signature
I could use the following object, calling it APPCONF:
APPCONF a+pm+suM;
The entry for an application config file /opt/dstage/Server/DSEngine/dsenv could be:
/opt/dstage/Server/DSEngine/dsenv - > $(APPCONF);
You cannot scan a file system, that already has another file system mounted from the base mount point, (non NFS cross mounts) unless it is specially put in the policy file.

For example, suppose you wanted to monitor /opt, but that file system also has another file system mounted called/opt/myapp and is mounted like:
/opt
/opt/myapp
Tripwire would complain and report:
The object: "/opt/myapp" is on a different file system...ignoring.
So make sure you have all the entries for file systems that you want to scan.
Using non-variable objects
You do not always have to use object variables, though it is easier when doing repetitive commands in the policy file. You can specify the attributes in place of the object, typically called property masks. For example, to monitor the /etc/security directory, plus scan recursively from within that directory, look for changes in:

permission
file owner
group owner
You could use:
/etc/security   -> +pug  (recurse=-1);
Where -1 means to do a recursive scan; 0 means to just scan the inode of the directories.

When specifying directories to scan and a new file is added, removed or, changed to that directory, Tripwire flags it as a violation.
Getting Tripwire to ignore files
To ignore directory or files (by that I mean for Tripwire not to scan them), the format is:
! <object_name>; 
Where object_name could be a predefined variable, or a file-name, or a directory. For example, to inform Tripwire not to scan/opt/dump and the file /opt/freeware/goodies/myjob, you could have:
!/opt/dump;
!/opt/freeware/goodies/myjob;
Previously, there was an example of scanning /etc/security. However, in that directory the lastlog file holds the last login times. If you do not want that scanned, you could put the following entry in !/etc/security/lastlog; .

Now Tripwire scans /etc/security but will ignore the lastlog file.
Decrypting policy file
When you need to edit the policy file, do not get in the habit of copying back existing policy backup files to work with. Always use the current one. That means you need to decrypt it from Tripwire first.

To generate a text version of the current encrypted policy file, created previously, use:
 # /opt/freeware/sbin/twadmin --print-polfile > /etc/tripwire/twpol.txt
The de-decrypted policy file is now called twpol.txt.
Create new policy file
In this demonstration, I have decided to create a new twpol file, so just create a new file called /etc/tripwire/twpol.txt.
Put the following content in that file:
# this is a comment
# aix twpol.txt file

# system binaries
SYSBIN =  +pngu+sm;

/usr/local/bin/pwgen  -> $(SYSBIN);
/usr/bin -> $(SYSBIN);
/usr/sbin -> $(SYSBIN);

/etc/security   -> +pug  (recurse=-1);

# ignore last log
!/etc/security/lastlog;

# logs
SYSLOGS = +p-lum;

/var/adm/messages -> $(SYSLOGS);
/opt -> $(SYSBIN);
# ignore these do not scan
!/opt/dump;
!/opt/freeware;
Encrypt policy file
To get Tripwire to generate the new policy file (or update an exiting policy), use the twadmin command; you will be prompted for your site passphrase:
# /opt/freeware/sbin/twadmin --create-polfile -S site.key /etc/tripwire/twpol.txt
Please enter your site passphrase:rs6000
Wrote policy file: /etc/tripwire/tw.pol
Display encrypted policy file
To confirm Tripwire has pulled in the newly updated policy file, use the following atcadmin command to display the contents of the policy:
# /opt/freeware/sbin/twadmin --print-polfile
# this is a comment
# aix twpol.txt file

# system binaries
SYSBIN =  +pngu+sm;

/usr/local/bin/pwgen  -> $(SYSBIN);
/usr/bin -> $(SYSBIN);
/usr/sbin -> $(SYSBIN);

/etc/security   -> +pug  (recurse=-1);

# ignore last log
!/etc/security/lastlog;

# logs
SYSLOGS = +p-lum;

/var/adm/messages -> $(SYSLOGS);
/opt -> $(SYSBIN);
# ignore these do not scan
!/opt/dump;
!/opt/freeware;
If the Tripwire database exits, prior to running a tripwire --init, it is good practice to delete the original database first. This ensures you get a clean database build. In this demonstration, my database is located in /var/lib/tripwire/rs6000.twd.
Scan it to build the database
Next, get Tripwire to do an initial integrity scan and generate the new database:
# /opt/freeware/sbin/tripwire --init
Please enter your local passphrase:master
Parsing policy file: /etc/tripwire/tw.pol
Generating the database...
*** Processing Unix File System ***
Wrote database file: /var/lib/tripwire/rs6000.twd
The database was successfully generated.
Now run a Tripwire integrity check on the system (by that I mean a Tripwire scan). The output is contained below in Listing 3. Tripwire integrity check shows the output of the report with the new policy being used:

Listing 3. Tripwire integrity check
# /opt/freeware/sbin/tripwire –check

Parsing policy file: /etc/tripwire/tw.pol
*** Processing Unix File System ***
Performing integrity check...
Wrote report file: /var/lib/tripwire/report/rs6000-20110817-173602.twr


Open Source Tripwire(R) 2.4.1 Integrity Check Report

Report generated by:          root
Report created on:            Wed Aug 17 17:36:02 BST 2011
Database last updated on:     Never

===============================================================================
Report Summary:
===============================================================================

Host name:                    rs6000
Host IP address:              192.168.4.8
Host ID:                      None
Policy file used:             /etc/tripwire/tw.pol
Configuration file used:      /etc/tripwire/tw.cfg
Database file used:           /var/lib/tripwire/rs6000.twd
Command line used:            /opt/freeware/sbin/tripwire –check
Rule Summary:
===============================================================================

-------------------------------------------------------------------------------
  Section: Unix File System
-------------------------------------------------------------------------------

  Rule Name                       Severity Level    Added    Removed  Modified
  ---------                       --------------    -----    -------  --------
  pwgen                           0                 0        0        0
  (/usr/local/bin/pwgen)
  bin                             0                 0        0        0
  (/usr/bin)
  sbin                            0                 0        0        0
  (/usr/sbin)
  security                        0                 0        0        0
  (/etc/security)
  messages                        0                 0        0        0
  (/var/adm/messages)
  opt                             0                 0        0        0
  (/opt)

Total objects scanned:  3739
Total violations found:  0
# Section: Unix File System
-------------------------------------------------------------------------------

No violations.

===============================================================================
Error Report:
===============================================================================

No Errors

-------------------------------------------------------------------------------
*** End of report ***
Checking and fixing violations
Using our rather sparse policy file, all looks OK on the system. Now I will change a file permission attribute of one of the files being scanned ( /usr/local/bin/pwgen).
# cd /usr/local/bin
# ls -l pwgen
-rwxrwxr-x    1 root     system       198697 Mar 26 15:15 pwgen
# chmod 755 pwgen
# ls -l pwgen
-rwxr-xr-x    1 root     system       198697 Mar 26 15:15 pwgen
Now run Tripwire to scan again; it picks up the change to the file pwgen. The truncated output of the scan is shown below in Listing 4.

Listing 4. Violation check
# /opt/freeware/sbin/tripwire --check
Parsing policy file: /etc/tripwire/tw.pol
*** Processing Unix File System ***
Performing integrity check...
Wrote report file: /var/lib/tripwire/report/rs6000-20110817-173839.twr


Open Source Tripwire(R) 2.4.1 Integrity Check Report

Report generated by:          root
Report created on:            Wed Aug 17 17:38:39 BST 2011
Database last updated on:     Never

===============================================================================
Report Summary:
===============================================================================

Host name:                    rs6000
Host IP address:              192.168.4.8
Host ID:                      None
Policy file used:             /etc/tripwire/tw.pol
Configuration file used:      /etc/tripwire/tw.cfg
Database file used:           /var/lib/tripwire/rs6000.twd
===============================================================================
Rule Summary:
===============================================================================

-------------------------------------------------------------------------------
  Section: Unix File System
-------------------------------------------------------------------------------

  Rule Name                       Severity Level    Added    Removed  Modified
  ---------                       --------------    -----    -------  --------
* pwgen                           0                 0        0        1
  (/usr/local/bin/pwgen)
  bin                             0                 0        0        0
  (/usr/bin)
  sbin                            0                 0        0        0
# Section: Unix File System
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------
Rule Name: pwgen (/usr/local/bin/pwgen)
Severity Level: 0
-------------------------------------------------------------------------------

Modified:
"/usr/local/bin/pwgen"
…
…
*** End of report ***
To re-init or update the policy
From Listing 4, you can see that Tripwire has correctly detected the change. If this change of the file pwgen is a valid change, we really do not want Tripwire to keep reporting it. So here we have two choices on how to remove Tripwire from reporting this violation.

We can either run Tripwire with the init option again to get a base level scan on what to compare, on the next run, like so:
# /opt/freeware/sbin/tripwire --init
Or update the Tripwire database and inform it to disregard, or rather accept, this change.
In the /var/lib/tripwire/report directory, all report files that Tripwire generates resides here in the form hostname<date_stamp>.twr. Simply select the report that was generated with this Tripwire scan by listing the files in date order. Once you have the correct file, the following command allows you to update the database:
tripwire - - update - - twrfile </var/lib/tripwire/report/<hostname_date_stamp>.twr
After executing the command, you are placed into an editor. Search for the file-names that were reported. All violations or updates have a [x] preceding the file-name. The pattern to look for in this demonstration is:
[x] "/usr/local/bin/pwgen"
Like so:
Rule Name: pwgen (/usr/local/bin/pwgen)
Severity Level: 0
-------------------------------------------------------------------------------

Remove the "x" from the adjacent box to prevent updating the database
with the new values for this object.

Modified:
[x] "/usr/local/bin/pwgen"
If you wish to accept that these changes were valid, just save and exit the file. Tripwire no longer reports on that file. If you want this file to be excluded from being added to the database, remove the 'x'.

When you save and exit from the editor, and updates to the database are to take place, you will be prompted for your passphrase to complete the process. If no update is to take place, then Tripwire informs you of this and no passphrase is required. In this demonstration the following is prompted, as the database will be updated:
Please enter your local passphrase: master
Wrote database file: /var/lib/tripwire/rs6000.twd
Initial population of the policy file
To populate a new policy file with files you want monitored can be time consuming. One alternative in achieving a quick population of the policy file is to just specify the directories/file systems, as demonstrated earlier. However, another alternative is to run a find command on your system binary directories, like /usr/bin, then redirect the output to the policy file. Listing 5 below contains a simple script that finds files of normal type and prints the object name (like SYSBIN, as described earlier). This can then be redirected to the policy file.

Listing 5. pop_twpol
#!/bin/sh
# pop_twpol
dir_list="/usr/bin /usr/sbin /usr/local/bin"

for loop in $dir_list
do
list=$(find ${loop} -type f -exec ls {} \;)

 for loop2 in $list
  do
   echo "${loop2} -> \$(SYSBIN);"
  done

done
A sample output from the above script could be:
/usr/bin/xmtopasagg -> $(SYSBIN);
/usr/bin/xmtrend -> $(SYSBIN);
/usr/bin/xmwlm -> $(SYSBIN);
/usr/bin/xpstat -> $(SYSBIN);
/usr/bin/xsend -> $(SYSBIN);
/usr/bin/yes -> $(SYSBIN);
/usr/bin/ypcat -> $(SYSBIN);
/usr/bin/ypmatch -> $(SYSBIN);
/usr/bin/yppasswd -> $(SYSBIN);
/usr/bin/ypservers -> $(SYSBIN);
/usr/bin/ypwhich -> $(SYSBIN);
First though, get the plain text version of the policy file from Tripwire as we did earlier:
# /opt/freeware/sbin/twadmin --print-polfile > /etc/tripwire/twpol.txt
Next, run the script contained in Listing 5, amend the directory list to suit your needs, and redirect to the twpol.txt file, like so:
#./pop_twpoll >> /etc/tripwire/twpol.txt
Remember to remove any duplicate entries you may have previously inserted earlier in the policy file, or just start afresh with a new policy file.

Next, pull the new policy file into Tripwire:
# /opt/freeware/sbin/twadmin --create-polfile -S site.key /etc/tripwire/twpol.txt
For other ad hoc files and log files, these could be added manually or similar processes to the above could be carried out.
Confirm the policy file now containing our individual files is encrypted and ready for use by printing the policy file contents:
# /opt/freeware/sbin/twadmin –print-polfile
# this is a comment
# aix twpol.txt file

# system binaries
SYSBIN =  +pngu+sm;

# logs
SYSLOGS = +p-lum;

/var/adm/messages -> $(SYSLOGS);

/etc/security   -> +pug  (recurse=-1);
# ignore last log
!/etc/security/lastlog;

/opt -> $(SYSBIN);
# ignore these do not scan
!/opt/dump;
!/opt/freeware/goodies/myjob;

/usr/bin/Mail -> $(SYSBIN);
/usr/bin/ManGetURL.class -> $(SYSBIN);
/usr/bin/Rsh -> $(SYSBIN);
/usr/bin/SpmiArmd -> $(SYSBIN);
…
…
Next, run a Tripwire initial scan to re-regenerate the database:
 # /opt/freeware/sbin/tripwire --init
Next, run a Tripwire check using your newly created policy file:
 # /opt/freeware/sbin/tripwire –-check
Monitoring and reporting on a large quantity of files can sometimes really be too much. So choose carefully what files you want monitored. This process is an iterative one and can take a few weeks till you are satisfied on what actually requires monitoring by Tripwire.

For system binaries, I prefer to just scan by directory name. For all other files, like configuration scripts and security files, I typically enter these in manually.
Reporting
As mentioned earlier, every time Tripwire runs a check, it generates a report. These reports go to standard output and are also saved as a report file. The reports are located in /var/lib/tripwire/report.
Like so:
# pwd
/var/lib/tripwire/report
bash-3.2# ls
rs6000-20110811-174421.twr  rs6000-20110812-092023.twr
rs6000-20110811-175332.twr  rs6000-20110812-093053.twr
rs6000-20110811-192716.twr  rs6000-20110812-093410.twr
To view the a report, use the reprint command. The format is:
pwprint -m r –twrfile <reportfile.twr>
To view the report file rs6000-20110812-093643.twr, you could use:
# /opt/freeware/sbin/twprint \
-m r --twrfile /var/lib/tripwire/report/rs6000-20110812-093643.twr

 Report is not encrypted.
Open Source Tripwire(R) 2.4.1 Integrity Check Report
Report generated by:          root
Report created on:            Fri Aug 12 09:36:43 BST 2011
Database last updated on:     Never
===============================================================================
Report Summary:
===============================================================================
Host name:                    rs6000
Host IP address:              192.168.4.8
Host ID:                      None
Policy file used:             /etc/tripwire/tw.pol
Configuration file used:      /etc/tripwire/tw.cfg
….
….
You can also print information about a particular file that is held in the database. To extract the file information on/usr/local/bin/pwgen, you could use:
# /opt/freeware/sbin/twprint -m d --print-dbfile /usr/local/bin/pwgen
Object name:  /usr/local/bin/pwgen

Property:               Value:
-------------           -----------
Object Type             Regular File
Mode                    -rwxr-xr-x
Num Links               1
UID                     root (0)
GID                     system (0)
Size                    198697
Modify Time             Sat Mar 26 15:15:25 GMT 2011
To extract all the information from the Tripwire database, use the following:
# /opt/freeware/sbin/twprint -m d –print-dbfile |more
Running Tripwire
For Tripwire to be effective, it should be run regularly. This is accomplished by running Tripwire through your favorite scheduler. The following cron entry runs Tripwire every day at 06:30 in the morning, redirecting the report to/opt/dump/logs/triplog<date_stamp>, like so:
30 06 * * *  /opt/freeware/sbin/tripwire \
- - check > /opt/dump/logs/triplog'date +"%d-%m-%y"'
Of course, do not forget you still have the report files in /var/lib/tripwire/report to review if necessary. Alternatively, you could have the report emailed to you. The following cron entry emails the syadmin email group the Tripwire report:
30 06 * * *  /opt/freeware/sbin/tripwire - - check | mail sysadmin -s "tripwire report for
'hostname'"
Conclusion
Be advised, if you are using a backup application to backup your AIX box, some of these applications may change the last accessed attribute of the file it has backed up as part of its backup process.

If you are monitoring this attribute via Tripwire, it flags the attribute as a violation. So you may need to either adjust your policy setting or run a Tripwire initialization after the backup to get a fresh snapshot. One way to check the last accessed time is to use the istat utility. 

For example:
istat <filename>
Tripwire is very feature rich; I have only covered some of the more common features in this article. Be sure to view the twpol manpage on the other feature not covered in the article. Do not hold back in tailoring the policy file to your particular requirements on your system. Tripwire is a good tool to have when used in conjunction with other auditing tools.
Resources
Get products and technologies
Download Tripwire and other rpm packages.(https://www.perzl.org/aix/index.php?n=Main.HomePage)
Download the AIX rpm packages.(https://www.ibm.com/systems/power/software/aix/linux/toolbox/download.html)
Try out IBM software for free. Download a trial version, log into an online trial, work with a product in a sandbox environment, or access it through the cloud. 
Choose from over 100 IBM product trials. (https://www.ibm.com/developerworks/downloads/product.html)
More info read

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

SCP command examples - linux / unix
By Surya13:491 comment
SCP stands for secure copy is used to copy data (files or directories) from one unix or linux system to another unix or linux server. SCP uses secured shell (ssh) to transfer the data between the remote hosts. 
The features of SCP are:
Copies files within in the same machine
Copies files from local machine to remote machine
Copies files from remote machine to local machine
Copies files between two different remote servers
SCP Command Syntax:
The syntax of SCP command is>
scp [Options] [[User@]From_Host:]Source_File [[User@]To_Host:][Destination_File]
Each element of the scp command is explained in detail below:
User is the one who have the permissions to access the files and directories. User should have read permissions if it is a source and write permissions if it is the destination.
From_Host: hostname or Ip address where the source file or directory resides. This is optional if the from host is the host where you are running the scp command.
Source_File: Files or directories to be copied to the destination.
To_Host: Destination host where you want to copy the files. You can omit this when you want to copy the files to the host where you are issuing the scp command.
Destination_File: Name of the file or directory in the target host.
SCP Command Options:
The important SCP command options are listed below:
-r : Recursively copies the contents of source files or directories.
-p : Preserves the access time, modification time, permissions of the source files in the destination.
-q : Progress bar in not displayed
-v : verbose mode. Displays debugging messages.
-P : copy files using the specified port number.
SCP Command Examples:
Let see the examples of scp command in unix or linux system.
1. Copying with in the same system
You can use the scp command just like the cp command to copy files from one directory to another directory.
scp Unix-storage.dat /var/tmp/
This command copies the file unix-storage.dat from current directory to the /var/tmp directory.
2. Copy file from local host to remote server
This is most frequently used operation to transfer files in unix system.
scp filename user@remotehost:/remote/directory/
This command connects to the remote host and copies the specified file to the /remote/directory/.
3. Copy files from remote host to local server
This operation is used when taking backup of the files in remote server.
scp user@remotehost:/usr/backup/oracle_backup.dat .
This command copies the oracle backup file in the remote host to the current directory.
4. Copying files between two remote servers
The scp command can also be used to copy files between two remote hosts.
scp source_user@source_remote_host:/usr/bin/mysql_backup.sh target_user@target_remote_host:/var/tmp/
The above command copies the mysql bakup shell script from the source remote host the /var/tmp directory of target remote host.
5. Copying a directory
To copy all the files in a directory, use the -r option with the scp command. This makes the scp command to copy the directory recursively.
scp -r directory user@remotehost:/var/tmp/
The above command copies the directory from local server to the remote host.
6. Improving performance of scp command
By default the scp command uses the Triple-DES cipher/AES-128 to encrypt the data. Using the blowfish or arcfour encryption will improve the performance of the scp command.
scp -c blowfish filename  user@remoteserver:/var/
scp -c arcfour  localfile user@remoteserver:/var/
7. Limit bandwidth
You can limit the bandwidth used by the scp command using the -l option.
scp -l bandwidth_limit filename user@hostname:/usr/backup/
Here bandwidth_limit is numeric to be specified in kilobits per second.
8. Specifying the port number
We can make the scp command to copy the files over a specified port number using the -P option.
scp -P 6001 storage_backup.bat username@hostname:/tmp/

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Simulating dropped TCP/IP packets on IBM AIX
By Surya11:141 comment
Introduction
This article presents:

An AIX kernel extension to permit a specified percentage of TCP/IP packets to and from a designated host to be dropped randomly so as to simulate adverse network conditions.
A utility to load, activate, and unload the kernel extension.
C and Java™ utilities to monitor total packet throughput to the target host and actual packets dropped.
Full source for the kernel extension with C and Java utilities so that the software can be built, customized, and developed according to local requirements.
All the components needed to build and run this packet dropping simulator are provided with this article as a downloadable compressed file. The (https://www.ibm.com/developerworks/aix/library/au-aix-packet-dropping/index.html#6.Howtobuildandusethekernelextensionassupplied|outline) How to build and use the kernel extension as supplied section enables you to get started and use it as soon as possible.

The kernel extension is designed to be activated on a single source node from which it will selectively drop packets either outbound to a target node or received from it. It is not necessary to install the packet drop simulator on the target node. The target node itself does not even need to be AIX-based but just needs to support the TCP/IP protocol.

The article first presents some background to TCP/IP performance and why dropped packets can have a serious impact on application performance. You will then see how to build and use the kernel extension as provided. This enables you to get up and running quickly with it.

The supplied functionality is deliberately very simple. It allows you to set a given percentage of TCP/IP packets to be dropped randomly to and from a specified host, with all other hosts and protocols unaffected and no retained history. Because in practice, you might need to add further functionality into the kernel extension according to your own requirements, you will also be shown details as to how the extension works and how it can be customised. You can then decide to do this if you need to:

Permit packet dropping to and from multiple hosts.
Support different packet drop rates for each of those hosts.
Create historic logs of total packets received, transmitted, and dropped in both directions.
Implement the packet drop simulator on different versions of AIX or C compilers to those used when the software was written.
The kernel extension could be readily developed further to simulate other network issues that could give rise to performance problems, such as packet corruption, packets arriving out of order, and jitter.

It is recommended the kernel extension is only used on non-production systems.
Background
First let's review some basic terms that are important when considering network performance, bandwidth, latency, and congestion.

Bandwidth is the capacity of the network, that is the rate at which data can be pushed across it. This is usually measured in Megabits per second (Mbps), where one Megabit is 10^6 bits. It can be thought of as the width of the network pipeline.

Latency is the time it takes for one piece of data to traverse the network. This is usually measured in milliseconds. It can be thought of as the length of the network pipeline.

The difference between bandwidth and latency is illustrated in Figure 1.

Figure 1. Latency and bandwidth and the network pipeline
 

Congestion is the effect of heavy usage of the network. It can result in delays in propagating data, loss of packets resulting in packet retransmission, and an inability to make connections to the network. Packet loss is usually measured as a percentage. TCP can normally handle losses up to 0.1% with little direct impact. If the losses increase above this, the effect can be more severe.

Network latency, bandwidth, and congestion can have a serious impact on application performance. Consider, for example, the situation where a front-end application on one system makes frequent calls across the network to another system which hosts a database used by the application. The traffic across the network to the database might consist of many bursts of small data, or might consist of fewer sets of relatively large data transfers. Either way, the ability of the network to transfer this data reliably and speedily can be a significant factor in the application's perceived end-to-end performance by a customer.

Application development teams often have access to isolated, high-speed networks that can be much more lightly used than the environment into which an application is to be deployed. This can mean the effect of poor network performance on the application may never be observed within the environment in which it is developed and tested. This can, in turn, mean that the performance observed within a customer's environment might be very different to that observed in the environment from which it is tested.

This article focuses on the effect of dropped packets on a particular application's performance. Due to the fact that there can be very high numbers of packets transferred between a front-end and a back-end system and the patterns in which these application packets are transmitted are very specific to the nature of the front-end and back-end applications, the simplest approach to understand the impact on the application is to simulate the dropping of packets.

Packets can be dropped when transferring data between systems for two key reasons:

Heavy network utilization and resulting congestion
Faulty network hardware or connectors
TCP is designed to be able to react when packets are dropped on a network. When a packet is successfully delivered to its destination, the destination system sends an acknowledgement message back to the source system. If this acknowledgement is not received within a certain interval, that may be either because the destination system never received the packet or because the packet containing the acknowledgement was itself lost. In either case, if the acknowledgement is not received by the source system in the given time, the source system assumes that the destination system never received the message and retransmits it. It is easy to see that if the performance of the network is poor, packets are lost in the first place, and the increased load from these retransmit messages is only increasing the load on the network further, meaning that more packets will be lost. This behaviour can result in very quickly creating a critical situation on the network.

There are some freely available sophisticated software products that can help to simulate different characteristics of varying network performance. These include:
WANem (https://wanem.sourceforge.net/) : Runs from Knoppix Linux® based CD
ipfilter (https://coombs.anu.edu.au/~avalon/) : Public domain software but not fully ported to AIX
dummynet (https://www.freebsd.org/cgi/man.cgi?query=dummynet&sektion=4) (FreeBSD)
ALTQ (https://www.freebsd.org/cgi/man.cgi?query=altq) (FreeBSD)
WANem runs from a Knoppix-based CD and can simulate a large range of different network characteristics. It does offer the ability to drop a random number of packets with filtering options but would need to run on a separate system in between the source and target system.This may not be convenient, for example if the source and target systems are installed on dedicated high-speed networks.Building the kernel extension and utilities

Although ipfilter looked very promising, it had only been partially ported to AIX 5.3 and it became evident that it would be quicker to write a bespoke utility providing the minimal functionality required rather than porting the whole of ipfilter to both AIX 6.1 and 7.1.

dummynet is a component of the FreeBSD operating system and has also been ported to other platforms including Linux and Microsoft® Windows®. The disadvantage of using this though is that to simulate packet drops for packets originating from an AIX host, an intermediate FreeBSD/Linux host has to be configured and set up with dummynet.

ALTQ is an alternate queueing framework that helps to provide bandwidth control, mostly on BSD routers.

There are also other packages commercially available such as LANforge ICE but these were ruled out for cost reasons. LANforge also requires dedicated hardware.

How to build and use the kernel extension as supplied
Requirements
The packet drop simulator was built and tested in the following environments:
AIX V7.1.4.0 with gcc V4.7.2-1
AIX V6.1.2.0 with gcc V4.2.0
AIX V6.1.4.0 with gcc V4.2.0
The kernel extension and associated C programs were compiled using the gcc compiler. It should be straightforward to use an AIX C compiler instead if required, although some of the compilation flags will need to be changed.

Note that it will be necessary to install the AIX bos.adt.syscalls file set to build the kernel extension. This will be available on your AIX installation media. The file set will not be required on systems were the kernel extension is only to be deployed as long as the AIX level is identical to the build system. If there are any differences in AIX levels between the two systems, the kernel extension should be built on each.

The kernel extension, the kctrl utility to load and activate it and the C example control and monitor are all built with the AIX makefacility. A makefile to build all of these components is included in the downloadable zip file.
Precautions
Two important factors should be kept in mind before using this utility:

1) Care should be exercised when developing and testing any kernel extension. It is common for errors to result in system failure. A dedicated test system is ideal, but avoid using systems that are also used for other purposes or by other users. If the system is located in a remote data centre, you should also ensure you have the means for it to be rebooted when required if it does not reboot automatically.

2) Avoid the use of flood pings to test the utility on a shared network as this may severely impact other users.
Building the kernel extension and utilities
First make sure you have met the requirements on your development system as outlined above.

Next, extract the downloadable attachment into a working directory of your choice on the target AIX system.

The download does not include pre-built binaries so as to avoid the risk of running it on incompatible operating system levels. The software will therefore need to be built once it has been extracted. To this, change directory to the working directory you created above and then run the make commands as follows:
# make
        gcc -Wall -maix64 -ffreestanding -msoft-float   -o pdrop_kernex64.o -c
        pdrop_kernex.c
        ld -b64 -o pdrop_kernex64 pdrop_kernex64.o -e pdrop_init -bI:
        /home/jerry/kernext/kernex.exp -bI:/home
        /jerry/kernext/netinet.exp -bE:/home/jerry/kernext/pdrop_syscall.exp -lsys -lcsys
        rm -f pdrop_kernex
        ar -X64 -r -v pdrop_kernex pdrop_kernex64
        ar: Creating an archive file pdrop_kernex.
        a - pdrop_kernex64
        gcc -Wall -maix32 -o pdrop_ccm32  .c -Xlinker -bI:
        /home/jerry/kernext/pdrop_syscall.exp
        gcc -Wall -maix64 -o pdrop_ccm64 pdrop_ccm.c -Xlinker -bI:
        /home/jerry/kernext/pdrop_syscall.exp
        gcc -maix64 -o kctrl kctrl.c
        gcc -Wall -I/usr/java6/include -I. -shared -fPIC pdrop_jni.c -o libpdrop_jni.so 
        -Xlinker -bI:/home/jerry/kernext/pdrop_syscall.exp
Target "all" is up to date.
#
After the make command is run successfully, all C components of the packet drop utility required to use it will be ready for use.

Note that the Java control and monitor application need to be built separately as described in the Control and monitor applications (https://www.ibm.com/developerworks/aix/library/au-aix-packet-dropping/index.html#11.Controlandmonitorapplications|outline) section

Loading and activating the kernel extension
One of the binaries that will have been build in the proceeding step is the kctrl program. This permits the kernel extension to be loaded, activated, and unloaded. To load and activate the kernel extension, proceed as follows:
# ./kctrl /home/jerry/kernext/pdrop_kernex64

 Enter choice, (l)oad, (u)nload, (i)nit, (t)erm, (q)uery or (e)nd
l
Extension Successfully loaded, kmid is 1353523200

 Enter choice, (l)oad, (u)nload, (i)nit, (t)erm, (q)uery or (e)nd
i
 Extension Initialized

 Enter choice, (l)oad, (u)nload, (i)nit, (t)erm, (q)uery or (e)nd
e
#
At this point, the kernel extension will be loaded and active, but will not drop any packets to a target host until either the C or Java control and monitor utilities are used.
Initiating packet dropping and monitoring
Having loaded and initialized the kernel extension, you can now see how to use the supplied C utility, pdrop_ccm, to control and monitor the setting of packets to a target host.

pdrop_ccm is invoked with arguments that specify the location where the kernel extension was built, the target host name, and the drop rate.
# ./pdrop_ccm64 /home/jerry/kernext/pdrop_kernex64
Usage: ./pdrop_ccm64 <kernel_extension> <TargetIP> <drop_percentage>
#
You can use this, for example, with the host name fred and a drop rate of 0.5% as follows:
# ./pdrop_ccm64 /home/jerry/kernext/pdrop_kernex64 fred 0.5
Kernel extenstion is loaded.
Setting drop ip to: x.y.z.l
Drop rate:  0.50.

Total In In dropped  PC in dropped  Total Out  Out dropped  PC out dropped
 0         0           0.00             0          0           0.00
10120     57           0.56           10174       53           0.52
22224    134           0.60           22340      116           0.52
#
In this example, shortly after we started pdrop_ccm we started sending IP traffic to the target host. The pdrop_ccm utility will keep running until it is interrupted with a ctrl+c and will print an update line every 10 seconds.

Please note that the first command line parameter, the kernel extension name, must be specified exactly as it was when loaded with kctrl.

The drop percentage argument is optional. If it is not supplied, pdrop_ccm will display the current drop rate only and will not re-set it.

A Java-based control and monitor utility is also provided and this is described in the Control and monitor applications (https://www.ibm.com/developerworks/aix/library/au-aix-packet-dropping/index.html#11.Controlandmonitorapplications|outline) section.

That is all there is to get started with the kernel extension.

The rest of this article presents more details on how the kernel extension works and how it and the control and monitor applications can be developed and customized for individual use.
How the kernel extension works
The AIX kernel extension is written in the C programming language. The kernel function exposes access to it through a set of system calls. The C and Java control and monitor applications utilize these system calls to drive the kernel extension to drop packets and to and from a particular host at a given rate. For the Java environment, a JNI wrapper class provides access to the kernel extension's system calls from Java.
The kernel extension itself consists of:

A set of system calls which control the dropping of packets and the collection of packet statistics
Two functions which hook into the kernel's networking layers. One of these is for inbound traffic and the other for outbound. These functions are called whenever a packet is received or is to be dispatched to control the dropping of packets.
The system calls are accessed by the user-level b to set the remote system to which incoming and outgoing packets should be dropped and what percent of packets should be dropped. These system calls also contain functions to retrieve counters defining how many packets have been dropped in both inbound and outbound directions and also a function to reset the counters.

For the C environment, these system calls are used directly in the example control and monitor application pdrop_ccm.c, which we used in the Initiating packet dropping and monitoring (https://www.ibm.com/developerworks/aix/library/au-aix-packet-dropping/index.html#7.2.Initiatingpacketdroppingandmonitoring|outline) section above. For the Java environment, the system calls can be used using JNI. The JNI wrapper can then be used by a bespoke Java application to control and monitor the dropping of packets. Again, a sample Java application is provided as a downloaded resource with this article. This is called pdrop_jcm.java. Refer to the Java control and monitor (https://www.ibm.com/developerworks/aix/library/au-aix-packet-dropping/index.html#11.2.Javacontrolandmonitor|outline) section for further details on the example Java utility.

Figure 2 illustrates the different components to the kernel extension and the flow of data through it. The following two sections discusses the flow of packet flow through the extension, both outbound data to be sent to the target node and inbound data received from it.
Outbound traffic flow
First, consider the case of outbound traffic, where an application under test submits data to be transmitted across the network. Refer to point A in the Figure 2. The application submits a set of data to the kernel for sending to the remote node on the network. The TCP subsystem breaks this down into a number of packets which are normally then sent to the appropriate network device driver for dispatch across the network. When using the kernel extension, however, the hook outbound_fw is set in the IP layer which results in the kernel extension's outbound filter function pdrop_outbound_filter being called for every packet being dispatched. This retrieves the IP header from the packet and matches it against the target node for which packets are to be dropped. If the node does not match, the function, ip_output_post_fw is called which routes the packet to the appropriate interface on the host. If the node does match, then a random decision whether to pass the packet is made, which is weighted according to the number of packets to be dropped. If this decision is that the packet should be sent, the ip_output_post_fwfunction is called and the packet is passed. Otherwise, the mbuf holding the data is freed and the outbound filter returns and the packet is not sent.
Inbound traffic flow
For inbound traffic, a corresponding operation applies when data is received from the network by the device driver. Refer to point B in Figure 
2. The device driver forwards the packet of data to the TCP/IP subsystem. This now calls the inbound filter which again has been set by 
the kernel extension by assigning the inbound hook inbound_fw to the pdrop_inbound_filterfunction. This function makes the decision whether to pass the packet or not. 
If the packet is not from the target node for which packets are being dropped, it is automatically passed by calling the ipintr_noqueue_post_fw function. 
If it is from the target node, then again a random decision is made whether to pass the packet according to the required percentage of packets that are to be dropped. 
If the decision is to send the packet, the ipintr_noqueue_post_fw function is called and the packet is passed. Otherwise, 
the mbuf holding the data is freed and the inbound filter returns and the packet is not passed up to the higher layers.
The AIX IP filtering hook and kernel services (https://pic.dhe.ibm.com/infocenter/aix/v7r1/index.jsp?topic=/com.ibm.aix.kerneltechref/doc/ktechrf1/ip_fltr_in_hook.htm) described above are explained in the IBM AIX 7.1 information center.

Figure 2. The packet drop kernel extension
 
Inbound filter
This is the inbound filter function:
/*
** This function is the filter for incoming traffic
*/
void pdrop_inbound_filter(ifp, m, args)
struct ifnet *ifp;
struct mbuf *m;
inbound_fw_args_t *args;
{
  struct ip *ip_in;

  if (PDROP_TRUE == amDropping) 
  {
     ip_in = mtod(m, struct ip *);

     if ( (ip_in->ip_p == IPPROTO_TCP) &&
          (dropip.s_addr == ip_in->ip_src.s_addr))
     {
         fetch_and_addlp((atomic_l) &total_in, 1);
         if (dropMod != 0)
        {
         if ( (pdrop_random() % dropMod) == 1)
         {
             fetch_and_addlp((atomic_l) &nin_dropped, 1);
             if (m != NULL)
             {
                m_freem(m);
             }
             return;
         }
     }
  }
}
ipintr_noqueue_post_fw(ifp, m, args);
return;
}
The arguments to the filter function include an mbuf containing the received data. The mtod macro is used to convert the pointer to the mbuf into a pointer to the received data, which is addressed as an IP header. A counter of the total number of received packets from the target address is maintained.

The function then compares the IP address selected for dropping to the source address specified in the received packet. If these match, then the pdrop_random() function is called, which uses the modulus function to select the required percentage of packets for dropping. If the packet is to be dropped, then an internal counter of dropped packets is incremented. If it is not to be dropped, then the ipint_noqueue_post_fw function is called to pass the packet to TCP for processing.

The fetch_and_addlp system functions are called to increment the counts of the total number of received and dropped packets. These ensure that the counts are maintained atomically so as to be thread safe.

You can see from this example that it is possible to specify which protocol is to filtered. In this case, we are only dropping packets for the TCP protocol. For testing, it is a good idea to make it use another protocol, such as Internet Control Message Protocol (ICMP) so then the packet dropper can be used with commands, such as ping. To do that, the IPPROTO_TCP constant in the test above would be changed to IPPROTO_ICMP.

Note: amDropping, dropip, and dropMod in the above extract are defined as global variables.
Outbound filter
This is the outbound filter function:
/*
** This function is the filter for outbound network traffic
*/
int pdrop_outbound_filter(ifp, m, args)
struct ifnet *ifp;
struct mbuf *m;
outbound_fw_args_t *args;
{
  struct ip *ip_out;

  if (PDROP_TRUE==amDropping) 
  {
     ip_out = mtod(m, struct ip *);

     if  ( (ip_out->ip_p == IPPROTO_TCP) &&
           (dropip.s_addr == ip_out->ip_dst.s_addr))
     {
       fetch_and_addlp((atomic_l) &total_out, 1);
       if (dropMod != 0)
      {
       if ( (pdrop_random() % dropMod ) == 1)
       {
         fetch_and_addlp((atomic_l) &nout_dropped, 1);
         if (m != NULL)
         {
            m_freem(m);
         }
         return 0;
       }
    }
  }
}

ip_output_post_fw(ifp, m, args);
return 0;
}
This works very similar to the inbound filter. Counters are maintained for the total number of packets destined for the target IP address and for the total number of outbound packets dropped.

The pointer to the mbuf is freed if the packet is to be dropped.

Note: amDropping, dropip, and dropMod in the above extract are defined as global variables.
Randomizing the packets to be dropped
It is important for the kernel extension to select packets at random for dropping. If say, packets were dropped after a set number of packets had been sent, this would not necessarily be a true emulation of what happens on a heavily used network. Further, it is possible that the software under test may behave differently when it misses packets at regular and irregular intervals.

The standard C library rand() call to generate random numbers cannot be used in a kernel extension. This is because such functions are not safe to use in a the re-entrant kernel environment. If you attempt to use this function, the system might fail when it is called from the kernel extension.

A simple function to mimic a call to random was therefore used. This generates a long random number based on the following inputs:

The seconds field from the current time
The nano-seconds field from the current time
The number of calls to the random function
The number of processor ticks since system boot
This is the source of the random function that is used in the kernel extension.
long pdrop_random()
{
  static long calls = 0;
  struct timestruc_t ts;
  long x = 0;

  curtime(&ts);

  // lbolt is the number of clock ticks since boot, see HZ in /usr/include/sys
     /m_param.h for number of ticks/sec

  fetch_and_addlp((atomic_l) &x,
      (long) ts.tv_nsec + (long) ts.tv_sec +
      (long) lbolt +
      calls++);

  return x;
}
This is not of course a true random function but is a good enough mechanism for assuring that packets are dropped in a sufficiently irregular manner. As the calls variable is static, it is incremented atomically with the fetch_and_addlp kernel service.
System calls provided in the packet drop kernel extension

In this section, you are shown details of the various system calls provided in the kernel extension. These will be of interest if you need to write your own control and monitor applications or customize the kernel extension.
Setting the target address: int pdrop_set_drop_address(struct in_addr *block_addr)
This function takes a pointer to an in_addr struct as an argument. The method may be called from the application level from a string-based host name as follows:
int setDropAddress(char *hostname)
{
   int status = 0;
   struct in_addr block_addr;

   if (1 == inet_aton(hostname, &block_addr))
   {
      if (PDROP_TRUE == pdrop_set_drop_address(&block_addr))
         status = 1;
   }
   return status;
}
Retrieving the target address: int pdrop_get_drop_address()

This function returns the target address as a 32-bit unsigned integer.

Setting the rate at which packets are dropped: extern void pdrop_setDropMod(long m);

This function takes a long input value, which represents how often packets should be dropped. The way this is worked out is that the kernel extension generates a random number and then takes a modulus of that random number with the long value. If the result is one, then the packet is dropped, otherwise it is passed.

The call is designed in this way as it is not possible to perform floating point operations within the kernel extension.
Here is a simple way of callingpdop_setDropMod()from the application level based on a double percentage value:
void setDropPC(double d)
{
        long x = 0;
        x = 100.0 /d;
        pdrop_setDropMod(x);
}
So, for example, if it was required to drop 0.1% of packets, then d would be 0.1 and the long value passed topdrop_setDropModwould be 1000.

Retrieving the rate at which packets are dropped:extern long pdrop_getDropMod();

This function returns the long representation of how often packets should be dropped, which is expressed in the same way as a call topdrop_setDropMod();

Activate the dropping of packets: void pdrop_startDropping()

When the kernel extension is started, packets are not dropped until the pdrop_startDropping() function is called. You should call this function after setting the target address and the rate at which packets should be dropped.

Stop the dropping of packets: void pdrop_stopDropping()

This function stops the dropping of packets. The functionspdrop_startDropping()andpdrop_stopDropping()can be called as required to enable and disable packet loss.

Query whether packets are being dropped:int pdrop_amDropping()

This function returns a 1 if the kernel extension is currently dropping packets and a 0 it is not.

Retrieving kernel extension counters:void pdrop_getstats(struct pdrop_stats *p)

This function returns a structure which contains details of:

The total number of packets received from the target address
The total number of packets received from the target address which were dropped
The total number of packets sent to the target address
The total number of packets sent to the target address which were dropped.
The definition of the structure used is in the header file, kernext_pdrop.h.

Here is an example of how the counters might be received from the application level:
pdrop_stats_t j;
pdrop_getstats(&j);
printf("Total in: %d.\n",  j.total_in);
printf("In dropped: %d.\n", j.nin_dropped;);
printf("Total out: %d.\n",  j.total_out);
printf("Out dropped: %d.\n", j.nout_dropped);
Resetting the internal kernel extension counters:void pdrop_reset_counters()

This function is used to reset the counters returned bypdrop_getstatsto zero.
Configuring the kernel extension
TheHow to build and use the kernel extension as supplied section provided information about how to build the kernel extension and its utilities. This section provides:


More details on the build process
Information on AIX 6.1 and AIX 7.1 build issues
Details about exporting the system calls provided in the kernel extension to the application level
Details about loading and activating the kernel extension
Information about the use of system logging to record when the extension is loaded and unloaded
AIX 6.1 and AIX 7.1 build issues
Beginning with AIX 6.1, the AIX operating system simplified its kernel environment by providing only the 64-bit kernel. AIX 6.1 and AIX 7.1 maintain application binary compatibility with previous AIX versions as specified above, but device drivers and kernel extensions that are only 32-bit cannot be built on AIX 6.1 or AIX 7.1.

As this article presents the kernel extension as suitable for AIX 6.1 and AIX 7.1, it has been built in the 64-bit mode.

The build process

A Makefile is included with the compressed file provided with this article. This can be used to build the kernel extension and application layer programs associated with it. Note that this Makefile has been written for use with the AIX make utility and it will need to be modified if you wish to use gnu make.
The kernel extension itself is built with the following commands:
gcc -maix64 -ffreestanding -msoft-float -o pdrop_kernex64.o -c pdrop_kernex.c
ld -b64 -o pdrop_kernex64 pdrop_kernex64.o -e pdrop_init -bI:/usr/lib/kernex.exp -bI:
/usr/lib/netinet.exp -bE:/home/jerry/kernext/pdrop_syscall.exp -lsys -lcsys
As noted earlier, the kernel extension is built as a 64-bit binary. The -ffreestanding and -msoft-float options are used to prevent the use of floating point instructions to manipulate certain data structures. This was required on AIX 7.1, but was not necessary on AIX 6.1.

The ld command specifies the entry point into the kernel extension, which in this case is the pdrop_init() function. This function is called when the kernel extension is activated.

The ld command also refers to the files kernex.exp and netinet.exp. These files are provided with the bos.adt.syscalls file set. This file set may not be installed on your test system in which case you will need to ask the system administrator to install it.

Note that it is necessary to make one small modification to the /usr/include/sys/socketvar.h header file for gcc to compile the kernel extension satisfactorily. You should retain a safe copy of the file and locate the following line:
extern struct free_sock_hash_bucket free_sock_hash_table[];
This should be changed to:
extern struct free_sock_hash_bucket * free_sock_hash_table;
The kernel extension makes this #define in the source:
#define _MSGQSUPPORT 1
This is necessary to prevent the fd_select() system call being made which is not available to the kernel extension. Using#define changes the fd_select() call to the original select() call, which is available to the kernel extension.
Exporting the provided system calls
The pdrop_syscall.exp file defines the kernel extension system calls that are exported to the application level. The contents of this file are as follows:
#!/unix
pdrop_set_drop_address syscall3264
pdrop_get_drop_address syscall3264
pdrop_setDropMod syscall3264
pdrop_getDropMod syscall3264
pdrop_startDropping syscall3264
pdrop_stopDropping syscall3264
pdrop_amDropping syscall3264
pdrop_getstats syscall3264
pdrop_reset_counters syscall3264
If you need to customize the kernel extension to include further system calls, you will need to amend this file. The syscall3264identifier at the end of each line makes the system calls available to both 32-bit and 64-bit processes. The flag may also be set to syscall32 to support calls from 32-bit processes only or syscall64 for 64-bit processes only. If the flag is not set for the correct target process environment, the process will fail with a segmentation fault when the system call is made. For further details on how to set this identifier refer to the topic, Exporting Kernel Services and System Calls.
Use of kctrl to control loading of the kernel extension
The kernel extension is loaded and unloaded with the kctrl program provided as described earlier. The program should be invoked with the full path name of the kernel extension. It then interactively accepts the following commands:
q – checks whether the kernel extension has been loaded
l – loads the kernel extenstion
I – initializes the kernel extension
t – terminates the kernel extension
u – unloads the kernel exension
e – exits the utility
Here is an example where kctrl is used to query, load, initialize, terminate, unload, and quit the utility:
# ./kctrl /home/jerry/kernext/pdrop_kernex

 Enter choice, (l)oad, (u)nload, (i)nit, (t)erm, (q)uery or (e)nd
q
 Extension is not loaded

 Enter choice, (l)oad, (u)nload, (i)nit, (t)erm, (q)uery or (e)nd
l
Extension Successfully loaded, kmid is 1353052160

 Enter choice, (l)oad, (u)nload, (i)nit, (t)erm, (q)uery or (e)nd
i
 Extension Initialized

 Enter choice, (l)oad, (u)nload, (i)nit, (t)erm, (q)uery or (e)nd
q
 Extension is loaded, with kmid   1353052160

 Enter choice, (l)oad, (u)nload, (i)nit, (t)erm, (q)uery or (e)nd
e
#
You can also check whether the kernel extension has been loaded by using the AIX genkex command, for example:
# genkex  | grep -i kern
f1000000c02be000     2000 /home/jerry/kernext/kernext_hello
#
In this example, the kctrl executable works with interactive user input. It would be straightforward to modify kctrl to take the command as another argument on the command line and thereby make it easy to incorporate within system startup and shutdown scripts. However, this is not generally recommended given the nature of the utility.
Logging in the kernel extension
The kernel extension uses the syslogd daemon to record when the extension is loaded and unloaded. This can be useful for debugging or auditing purposes. To enable this logging:

Ensure that logging is enabled in /etc/syslog.conf. For example, the following line can be appended to this file:
*.debug /var/log/syslog.out rotate size 100k files 4
Ensure that the log file enabled in /etc/syslog.conf exists.
Refresh the syslogd subsystem (refresh -s syslogd)
Use with other IP protocols
Although the extension is primarily considered for TCP/IP, it would be simple to change it to work with other IP-based network protocols. This was discussed in the How the kernel extension works section.
Control and monitor applications
Two example applications that can use the system calls exposed by the kernel extension are provided. One is for the C environment and the other for the Java environment.
These applications show you how to write your own custom applications to control packet dropping. You can decide to do this if you need to write your own automated test framework to simulate different network conditions.
It should be noted that only the applications that collect statistics directly from the kernel extension can provide meaningful statistics on packets that have been dropped. Operating system provided utilities that report on dropped packets will not include details of packets that have been dropped through the kernel extension. This is because the packets are dropped by the extension before they are passed through the TCP/IP subsystem for dispatch or delivery.
C control and monitor
The test application, pdrop_ccm.c, is provided in the downloads section of this article. This is invoked with a target host name and drop percentage on the command line. The application passes details of the target host and the drop rate to the kernel extension and then monitors the inbound and outbound packets to the target system every 10 seconds.
The packet drop system calls can be invoked from both 32-bit and 64-bit applications. The makefile provided demonstrates this by building both 32-bit and 64-bit versions of the control and monitor application. These are called pdrop_ccm32 and pdrop_ccm64 respectively.
pdrop_ccm shows the total number of input and output packets, the number of input and output packets that were dropped, and the numbers of dropped packets as a percentage. It takes the name of the kernel extension, the name of the target host as arguments and an optional value specifying the target drop rate. If this third parameter is not specified on the command line, no change to the drop rate is made. Here is an example of the application in use:
# ./pdrop_ccm /home/jerry/kernext/pdrop_kernex64 fred 1.0
 Extension is loaded, with kmid   1353052160
Official name is: fred
    IP addresses: 9.20.XXX.YYY
Target IP address: 9.20.XXX.YYY.

Total In   In dropped       PC in dropped   Total Out    Out dropped     PC out dropped
0               0                0.00           0               0                0.00
0               0                0.00           0               0                0.00
13138           138              1.05           13283           144              1.08
29158           275              0.94           29460           302              1.03
43738           423              0.97           44206           467              1.06
58320           564              0.97           58952           632              1.07
72653           721              0.99           73437           784              1.07
87227           872              1.00           88153           926              1.05
#
Here, we can see that the host to which packets are to be dropped is fred and 1.0% of the packets are to be dropped. Status updates on total and dropped packets are then displayed at 10 second intervals.
The test application calls the pdrop_reset_counters() method to reset the kernel extension counters. After 10 seconds, you can see that network activity to the target system is started and the packet statistics are displayed.
Note that the example controls a single target system only. If you run the pdrop_ccm command again and specify a different target host name, packets to and from the original host will no longer be dropped.
Java control and monitor
A sample Java application, PDrop_jcm.java, is also provided, which demonstrates how to use the packet drop simulator from the Java environment.
PDrop_jcm.java uses JNI to access the C environment for controlling and monitoring the kernel extension. The shared librarylibpdrop_jni.so provides native methods which can be called from the Java environment. This shared library is built as part of the build process described earlier from the source, pdrop_jni.c.
The JNI wrapper provides the following native methods at the Java level which map to the functions in the shared library:
        public native boolean isExtensionLoaded(String extName);
        public native boolean setDropAddress(String hostname);
        private native String getDropAddress();
        public native boolean amDropping();
        public native int setDropping(boolean doDrop);
        public native void resetCounters();
        public native void setDropHostName();
        public native void setDropPC(float d);
        public native float getDropPC();
        public native long getTotalIn();
        public native long getTotalOut();
        public native long getInDropped();
        public native long getOutDropped();
When these native methods are invoked, the corresponding function in the shared library will be called and the result will be returned to the Java environment.
To build and use this test Java application, first, make sure that you have set the PATH to the Java SDK environment correctly, for example:
export PATH=/usr/java6/bin:${PATH}
Next, set the LIBPATH environment variable to reference the directory where the kernel extension is located, so the shared librarylibpdrop_jni.so can be resolved:
export LIBPATH=/home/jerry/kernext:/usr/lib
Now compile the PDrop_jcm.java application, for example:
 javac -d . PDrop_jcm.java
Optionally, if you need to regenerate the JNI header file, run the following command. It mightnot be necessary to run unless you have customized the kernel extension and changed or added to the native methods:
 javah -d . PDrop_jcm
If you have regenerated the header, you will need to rebuild the shared library using the process described earlier.
The Java application is then run with the path to the kernel extension, target host name, and optional new drop rate as arguments, as in the C example above:
# java PDrop_jcm /home/jerry/kernext/pdrop_kernex64 fred 1.0
Ext name: /home/jerry/kernext/pdrop_kernex64.
 Extension is loaded, with kmid   1353052160
Drop address is: 9.20.XXX.YYY
Drop PC: 1.0
Dropping enabled
Total In   In dropped      PC in dropped    Total Out       Out dropped     PC out dropped
0               0                0.0            0               0                0.0
0               0                0.0            0               0                0.0
13189           145              1.09           13307           118              0.88
28515           295              1.03           28782           267              0.92
44306           461              1.04           44701           395              0.88
59216           609              1.02           59753           537              0.89
72979           756              1.03           73688           709              0.96
88606           910              1.02           89455           849              0.94
102550          1054             1.02           103567          1017             0.98
104522          1071             1.02           105551          1029             0.97
104522          1071             1.02           105551          1029             0.97
In this example, you can see that when monitoring started there were zero packets sent or received to or from the target host, but there was then network activity that caused packets to be dropped in both directions. In this example, the drop rate had been configured at 1%.
Measuring non-simulated packet loss
It was mentioned earlier that operating system utilities should not be used to monitor packets dropped through the use of the kernel extension. However, these will be required when you need to access packets that are actually dropped across the network. This section gives some useful hints and tips for using these utilities.
The ping utility displays the packet loss on the ICMP packets being sent across the network. You can see the packet loss statistics in the above example, where it is zero. However, this measurement is only based on these packets being transferred from and to the ping utility and do not measure any other packets traversing the network.
On some systems, ping also supports an option to write ICMP packets as fast as possible onto the network and again gives you the loss statistics at the end. This is a so called flood ping. You should use this with caution as it is likely to impact general network performance while running. It should be run only for a few seconds and only under test conditions.
The netstat utility can also be used to see how many packets have been dropped on a network. Here is an example output from netstat -D on AIX.
Using netstat to report packet drops (AIX):
# netstat -D

Source                         Ipkts                Opkts     Idrops     Odrops
-------------------------------------------------------------------------------
ent_dev0                    26820670             16079610          0          0
                ---------------------------------------------------------------
Devices Total               26820670             16079610          0          0
-------------------------------------------------------------------------------
ent_dd0                     26820670             16079610          0          0
                ---------------------------------------------------------------
Drivers Total               26820670             16079610          0          0
-------------------------------------------------------------------------------
ent_dmx0                    26820664                  N/A          6        N/A
                ---------------------------------------------------------------
Demuxer Total               26820664                  N/A          6        N/A
-------------------------------------------------------------------------------
IP                          50335154             44013816    1110616     147099
IPv6                            1473                 1473          0          0
TCP                         43110957             40986657       6235          0
UDP                          6105902              2045877    5022268          0
                ---------------------------------------------------------------
Protocols Total             99552013             87046350    6139119     147099
-------------------------------------------------------------------------------
en_if0                      26820664             16079528          0          0
lo_if0                      27970975             27975366       4652          0
                ---------------------------------------------------------------
Net IF Total                54791639             44054894       4652          0
-------------------------------------------------------------------------------
NFS/RPC Client                    23                  N/A          0        N/A
NFS/RPC Server                     0                  N/A          0        N/A
NFS Client                     14949                  N/A          8        N/A
NFS Server                         0                  N/A          0        N/A
                ---------------------------------------------------------------
NFS/RPC Total                    N/A                14977          8          0
-------------------------------------------------------------------------------
(Note:  N/A -> Not Applicable)
#
On AIX, the netstat -Zs -p tcp command can be used to reset the protocol statistics before running the promotion activity.
If packet drops are consistently in excess of 0.1%, then you should raise this with your network administrator.
Retransmitted packets can be seen using the following command:
$ netstat -s -p tcp | grep retrans
Statistics of interest from the output of this command are:
Packets sent
Data packets
Data packets retransmitted
Packets received
Completely duplicate packets
Retransmit timeouts
Conclusion
This article provided reference material and instructions to build, use, and customize a simple utility to simulate dropped TCP packets on AIX. Such a utility is invaluable when writing cross network software to model how it will behave under non-ideal network conditions.
The tool may be adapted as required and can easily be enhanced to support simulation of other network issues that can give rise to performance problems, such as packet corruption, packets arriving out of order, and jitter.

Reff Original Link (https://www.ibm.com/developerworks/aix/library/au-aix-packet-dropping/index.html)


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

SMITTY / SMIT FASTPATH COMMANDS
You can access SMIT or Smitty  tasks and sub-menus directly by using a fast path.

Example: smit mkuser takes you directly to the menu Add a User

At any menu in SMIT, you can show the fast path to that menu by pressing the F8 key.

Application/Task	Fast Path
Software Installation and Maintenance	install
Install and Update Software	install_update
     Install Software	install_latest
     Update Installed Software to Latest Level (Update All)	update_all
     Install Software Bundle	install_bundle
     Update Software by Fix (APAR)	update_by_fix
     Install and Update from ALL Available Software	install_all
List Software and Related Information	list_software
     List Installed Software and Related Information	list_installed
           List Installed Software	list_installed_sw
           List Applied but Not Committed Software Updates	list_applied_sw
           Show Software Installation History	show_history
           Show Fix (APAR) Installation Status	show_apar_stat
           List Fileset Requisites	list_requisites
           List Fileset Dependents	list_dependents
           List Files Included in a Fileset	list_files
           List Fileset Containing File	what_fileset
           Show Installed License Agreements	installed_license
      List Software on Media and Related Information	list_media
           List Filesets in a Bundle	list_bundle
           List Software on Installation Media	list_media_sw
           List Software Fixes (APARs) on Installation Media	list_media_fixes
           List Supplemental Fileset Information on Installation Media	list_media_info
           Show License Agreements on Installation Media	license_on_media
Software Maintenance and Utilities	maintain_software
     Commit Applied Software Updates (Remove Saved Files)	commit
     Reject Applied Software Updates (Use Previous Version)	reject
     Remove Installed Software	remove
     Copy Software to Hard Disk for Future Installation	bffcreate
     Check Software File Sizes After Installation	check_files
     Verify Software Installation and Requisites	verify_install
Network Installation Management	nim_client
     Configure Network Installation Management Client Fileset	niminit
     Install and Update Software	nim_client_inst
     List Software on Media and Related Information	nim_client_list
           List Filesets in a Bundle	nim_c_list_bundle
           List Software on Installation Media	nim_c_list_sw
           List Software Fixes (APARs) on Installation Media	nim_c_list_fixes
     Manage Network Install Permissions	nim_perms
     Manage Network Install Resource Allocation	nim_c_mac_res
System Backup Manager	backsys
     Back Up the System	sysbackup
           Back Up This System to Tape/File	mksysb
           Create a Generic Backup CD	mkcdgeneric
     List Files in a System Image	lsmksysb
     Restore Files in a System Image	restmksysb
Software License Management	licenses
Manage Nodelocked Licenses	manage_nodelocked
     Add Nodelocked License from a File	add_nodelocked_from_file
     Add Nodelocked License from the Keyboard	add_nodelocked_from_keyboard
     Delete a Nodelocked License	delete_nodelocked
Manage License Servers and License Databases	manage_servers
     Show Server Characteristics	show_server_characteristics
     Manage Concurrent Use and Use Once Licenses	manage_prod_licenses
     Manage Vendor Information in License Databases	manage_vendors
Show License Usage on Servers	show_server_status
     Show License Usage Summary	show_total_license_usage
     Show Licenses Currently Being Used	show_current_license_usage
     Show License Information by Server	show_installed_licenses
     Show Licenses Held by a Specific User	show_user_license_held
Show License Agreements	show_license_agree
     Show Installed License Agreements	installed_license
     Show License Agreements on Installation Media	license_on_media
Devices	dev
Install/Configure Devices Added After IPL	cfgmgr
Printer/Plotter	printer
TTY	tty
PTY	pty
Console	console
Fixed Disk	disk
CD ROM Drive	cdrom
Read/Write Optical Drive	rwopt
Diskette Drive	diskette
Tape Drive	tape
Communication	commodev
Graphic Displays	g_display
Graphic Input Devices	input
Low Function Terminal (LFT)	lft
SCSI Initiator Device	scsiid
SCSI Adapter	scsia
Asynchronous I/O	aio
Multimedia	mm
List Devices	lsattr
Configure/Unconfigure Devices	devcfg
     Unconfigure a Device	devcfg_ucfg
     Configure a Defined Device	devcfg_cfg
Install Additional Device Software	devinst
PCI Hot Plug Manager	devdrpci
     Unconfigure a Device	rmdev
     Configure a Defined Device	mkdev
     Install/Configure Devices Added After IPL	cfgmgr
ISA Adapters	devisa
System Storage Management (Physical & Logical Storage)	storage
Logical Volume Manager	lvm
      Volume Groups	vg
           List All Volume Groups	lsvg2
           Add a Volume Groups	mkvg
           Set Characteristics of a Volume Group	vgsc
           List Contents of a Volume Group	lsvg1
           Remove a Volume Group	reducevg2
           Activate a Volume Group	varyonvg
           Deactivate a Volume Group	varyoffvg
           Import a Volume Group	importvg
           Export a Volume Group	exportvg
           Mirror a Volume Group	mirrorvg
           Unmirror a Volume Group	unmirrorvg
           Synchronize LVM Mirrors	syncvg
           Back Up a Volume Group	vgbackup
           Remake a Volume Group	restvg
           List Files in a Volume Group Backup	lsbackvg
           Restore Files in a Volume Group Backup	restsavevg
      Logical Volumes	lv
           List All Logical Volumes by Volume Group	lsvg
           Add a Logical Volume	mklv
           Set Characteristics of a Logical Volume	lvsc
           Show Characteristics of a Logical Volume	lslv
           Remove a Logical Volume	rmlv
           Copy a Logical Volume	cplv
      Physical Volumes	pv
           Add a Disk	makdsk
           Change Characteristics of a Physical Volume	chpv
           List Contents of a Physical Volume	lspv
           Move Contents of a Physical Volume	migratepv
      Paging Space	pgsp
           Add Another Paging Space	mkps
           Change/Show Characteristics of a Paging Space	chps
           Remove a Paging Space	rmps
           Activate a Paging Space	swapon
           Deactivate a Paging Space	swapoff
File Systems	fs
     List All File Systems	lsfs
     List All Mounted File Systems	mount
     Add/Change/Show/Delete File Systems	manfs
     Mount a File System	mountfs
     Mount a Group of File Systems	mountg
     Unmount a File System	umountfs
     Unmount a Group of File Systems	umountg
     Verify a File System	fsck
     Backup a File System	backfilesys
     Restore a File System	restfilesys
     List Contents of a Backup	listtoc
Files & Directories	filemgr
     Backup a File or Directory	backfile
     Restore a File or Directory	restfile
     List Contents of a Backup	listtoc
Removable Disk Management	rds
     List All Mounted File Systems on a Disk	lsmntdsk
     Unmount File Systems on a Disk	umntdsk
     Remove a Disk from the Operating System	removedsk
     Remove a Disk	rmvdsk1
     Open Door	open_door
System Backup Manager	backsys
     Back Up the System	sysbackup
     List Files in a System Image	lsmksysb
     Restore Files in a System Image	restmksysb
Security and Users	security
Users	users
     Add a User	mkuser
     Change a User's Password	passwd
     Change/Show Characteristics of a User	chuser
     Lock/Unlock a User's Account	lockuser
     Reset User's Failed Login Count	failed_logins
     Remove a User	rmuser
     List All Users	lsuser
Groups	groups
     List All Groups	lsgroup
     Add a Group	mkgroup
     Change/Show Characteristics of a Group	chgroup
     Remove a Group	rmgroup
Passwords	passwords
     Change a User's Password	passwd
     Change/Show Password Attributes for a User	passwdattrs
Login Controls	logins
     Change/Show Login Attributes for a User	login_user
     Change/Show Login Attributes for a Port	login_port
Roles	roles
     Add a Role	mkrole
     Change/Show Characteristics of a Role	chrole
     Remove a Role	rmrole
     List All Roles	lsrole
Communications Applications and Services	commo
TCP/IP	tcpip
      Minimum Configuration & Startup	mktcpip
      Further Configuration	configtcp
           Hostname	hostname
           Static Routes	route
           Network Interfaces	netinterface
           Name Resolution	namerslv
           Client Network Services	clientnet
           Server Network Services	ruser
           Manage Print Server	server
           Select BSD style rc Configuration	setbootup_option
           Authentication Configuration	auth_config
      Use DHCP for TCPIP Configuration & Startup	usedhcp
      IPV6 Configuration	configtcp6
           IPV6 Static Routes	route6
           IPV6 Network Interfaces	inet6
           IPV6 Daemon/Process Configuration	daemon6
      Quality of Service Configuration & Startup	configqos
           Start Using the QoS Subsystem	startqos
           Stop Using the QoS Subsystem	stopqos
NFS	nfs_menus
      Configure TCP/IP (If Not Already Configured)	tcpip
      Network File System (NFS)	nfs
           Configure NFS on This System	nfsconfigure
           Add a Directory to Exports List	mknfsexp
           Change/Show Attributes of an Exported Directory	chnfsexp
           Remove a Directory from Exports List	rmnfsexp
           Add a File System for Mounting	mknfsmnt
           Change/Show Attributes of an NFS File System	chnfsmnt
           Remove Remove an NFS File System	rmnfsmnt
Print Spooling	spooler
Start a Print Job	qprt
Manage Print Jobs	jobs
     Cancel a Print Job	qcan
     Show the Status of Print Jobs	qchk
     Prioritize a Print Job	qpri
     Hold/Release a Print Job	qhld
     Move a Job Between Print Queues	qmove
Manage Print Queues	pqmanage
     Show Status of Print Queues	qstatus
     Stop a Print Queue	qstop
     Start a Print Queue	qstart
     Set the System's Default Print Queue	qdefault
Add a Print Queue	mkpq
Add an Additional Printer to an Existing Print Queue	mkqprt
Change/Show Print Queue Characteristics	chpq
Remove a Print Queue	rmpq
Manage Print Server	server
Programming Tools	pqtools
Problem Determination	problem
Error Log	error
     Generate Error Report	errpt
     Change/Show Characteristics of the Error Log	errdemon
     Clean the Error Log	errclear
System Dump	dump
     Change the Primary Dump Device	dumpchgp
     Change the Secondary Dump Device	dumpchgs
     Change the Directory to which Dump is Copied on Boot	dumpchgd
     Copy a System Dump from a Dump Device to a File	dump_copy_file
     Copy a System Dump from a Dump Device to Diskette	dump_copy_dskt
     Always Allow System Dump	dump_allow
     System Dump Compression	dump_comprs
     Check Dump Resources Utility	dump_checkr
Alog	alog
     Show an Alog file	alog_show
     Change/Show Characteristics of an Alog File	alog_change
Hardware Diagnostics	diag
Verify Software Installation and Requisites	verify_install
Performance and Resource Scheduling	performance
Resource Status & Monitors	monitors
Analysis Tools	analysis
Resource Controls	controls
     Remove a Process	kill
     Set Initial Priority of a Process	nice
     Change Initial Priority of a Process	renice
     Set System Run Level	telinit
Schedule Jobs	at
Power Management	pm
     Configure/Unconfigure Power Management	pmConfig
     System State Transition from Enable State	pmState
     Display Power Management	pmDisplaySelect
     Battery	pmBattery
Workload Management	wlm
      Work on alternate configurations	wlmconfig
           Copy a configuration	wlmconfig_copy
           Create a configuration	wlmconfig_create
           Select a configuration	wlmconfig_select
           Enter configuration description	wlmconfig_enter
           Remove a configuration	wlmconfig_delete
      Work on a set of Subclasses	wlmsubclass
      Add a class	wlmaddclass
      Change/Show Characteristics of a class	wlmchclass
           General characteristics of a class	wlmclass_gal
           CPU resource management	wlmclass_cpu
           Memory resource management	wlmclass_mem
           diskIO resource management	wlmclass_bio
      Remove a class	wlmrmclass
      Class assignment rules	wlmrs
           Create a new Rule	crewlmrs
           Change/Show Characteristics of a Rule	chgwlmrs
      Start/Stop/Update WLM	wlmmanage
           Start Workload Management	wlmstart
           Update Workload Management	wlmupdate
           Stop Workload Management	wlmoff
      Assign/Unassign processes to a class/subclass	wlmassign
System Environments	system
Stop the System	shutdown
Assign the Console	chcons
Change/Show Date and Time	chtz_date
     Change/Show Date & Time	date
     Change Time Zone Using System Defined Values	chtz
     Change Time Zone Using User Inputted Values	chtz_user
Manage Language Environment	mlang
     Change/Show Primary Language Environment	chlang
     Add Additional Language Environments	mle_add_lang
     Remove Language Environments	mle_rm_lang_hdr
     Change/Show Language Hierarchy	mle_hier_cmd_hdr
     Set User Languages	chlang_user
     Change/Show Applications for a Language	mle_chapp_menu
     Convert System Messages and Flat Files	nu_iconv
Change/Show Characteristics of Operating System	chgsys
Change/Show Number of Licensed Users	chlicense
Manage AIX Floating User Licenses for this Server	netls_server
Broadcast Message to all Users	wall
Manage System Logs	logs
Change/Show Characteristics of System Dump	dump
Internet and Documentation Services	web_configure
     Change/Show Default Browser	change_default_browser
     Change Documentation and Search Server	change_doc_search_server
     Change/Show Default Documentation Language	chdoclang
     Web-based System Manager	web_based_system_manager
Change System User Interface	dt_config
Change/Show Default Documentation Language	chdoclang
Manage Remote Reboot Facility	rrbtty
Manage System Hang Detection	shd
Processes and Subsystems	src
Processes	process
     Remove a Process	kill
     Bind a Process to a Processor	bindproc
     Unbind a Process	unbindproc
Subsystems	subsys
     Query a Subsystem	qssys
     Start a Subsystem	startssys
     Stop a Subsystem	stopssys
           Stop a Single Subsystem	stopassys
           Stop All Subsystems	stopallssys
     Refresh a Subsystem	refresh
     Trace Subsystem	tracessys
           Start Trace	tracessyson
           Stop Trace	tracessysoff
Subservers	subserver
     Query a Subserver	qserver
     Start a Subserver	startserver
     Stop a Subserver	stopserver
     Trace Subserver	traceserver
           Start Trace	startserver.trace
           Stop Trace	stopserver.trace


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Software Installation & Maintenance- AIX
By Surya13:191 comment
Software States:
When a software or an update is first installed, it is in the APPLIED state. It can be later commited or rejectd.
APPLIED state
Provide opportunity to test the software
Enable to go back to the previous version in case of any problem
Enable to commit software at a later stage
Requires more disk
Prevents future re-installation of product
COMMITED state
Requires less disk space
Permits future upgrade
Prevents from easily going back to previous version
Reject action removes the APPLIED software and go back to the previous commited version
List the installed filesets/fileset updates
To list all the installed software
 # lslpp -l
To display the maintenance level and state of a fileset
 # lslpp -l bos.net.nfs.client
Lists installed software using ':' as the delimeter
 # lslpp -Lc 
To display the names of all the files of fileset bos.perf
 # lslpp -f  bos.perf
To find out which fileset a file belongs to
 # lslpp -w /usr/sbin/nfsd 
To list installation history of filesets
 # lslpp -ha
To the filesets that do not have the required prerequisites or are not completely installed
 # lslpp -v 

Install filesets / software
installp command is used to install the software. The options are
        -a  Install filesets in APPLIIED state
        -c  Commit filesets  
        -r  Reject filesets which are in APPLIED state
        -u  Uninstall filesets
        -C  Cleanup failed installtion
        -g  To Install or Uninstall dependencies
        -x  To expand file systems if there is not enough space
        -d <device>    Device or directory which contains  
                       the software
        -f <filename>  User created file which has a list of 
                       software to be installed or deleted
Emaples:
To list all installable software in media /dev/cd0
 installp [-L|-l] -d /dev/cd0    
To cleanup all failed installtion
 installp -C                     
To install bos.net software (apply and commit) package with all pre-requisites from directory /tmp/net
 installp -acgx -d /tmp/net bos.net 
To commit teh applied updates
 installp -cgx all
To remove bos.net package
 installp -ug bos.net
instfix coomand is used to install a fix or set of fixes. It is also used to find out if a fix is installed on a system.
To find out whether a Fix is installed or not
 # instfix -i -k <APAR Number>
To list all the fixes that are installed on your system
 # instfix -i -v 
To list filesets which are lesser than the specified maintenance level
 # instfix -ciqk 5100-04_AIX_ML | grep ":-:"
To install all filesets associated with fix Ix38794 from the tape
 # instfix  -k Ix38794  -d /dev/rmt0
To Display the entire list of fixes present on the media
 # instfix -T -d /dev/cd0
To confirm the AIX preventive maintenance level on your system
 # instfix -i | grep ML
 All filesets for 5.0.0.0_AIX_ML were found.
 All filesets for 5.1.0.0_AIX_ML were found.
 All filesets for 5.1.0.0_AIX_ML were found.
 All filesets for 5100-01_AIX_ML were found.
 All filesets for 5100-02_AIX_ML were found.
To verify that all filesets have all required requisites and are completely installed
 #lppchk -v
oslevel command is used to find out the version and maintenance level of AIX
To see the current OS and Maintenance level
# oslevel
 # oslevel -r     - To see the current maintenance level
 # oslevel -s     - To see the current service pack level
 # oslevel -l 4.1.2.0  -  To determine the file sets that are below level 4.1.2.
 # oslevel -g     - To determine the file sets that are later than the current maintenance level
 # oslevel -rq    - To list all known recommended maintenance levels on the system 
Updating the software to the latest level
01. Using smit
    # smit update_all
02. To update all filesets in a system using command line
    
a. Create the list of filesets installed
       # lslpp -Lc | awk -F: '{print $2}'| tail -n +2 > /tmp/lslpp    
b. Update the softwares using installp command
       # installp -agxYd /dev/cd0 -e /tmp/<exclude_list> -f /tmp/lslpp
Another way of updating all the filesets
 # /usr/lib/instl/sm_inst installp_cmd  -acgNXY -d <localtion_of_updates> -f '_update_all'
For not committing and saving all replaced files
 # /usr/lib/instl/sm_inst installp_cmd  -agX -d <localtion_of_updates> -f '_update_all'
To list all the installed efixes on a system
 # emgr -l
To install a efix IY93496.070302.epkg.Z in /mnt directory
 # emgr -e /mnt/IY93496.070302.epkg.Z
inutoc
The inutoc command creates the .toc file in Directory. If a .toc file already exists, it is recreated with new information. The inutoc command adds table of contents entries in the .toc file for every installation image in Directory.

The installp command and the bffcreate command call this command automatically upon the creation or use of an installation image in a directory without a .toc file

To create a .tocfile for the /tmp/images directory, enter:
 # inutoc /tmp/images
bffcreate
The bffcreate command creates an installation image file in backup file format (bff) to support software installation operations. It creates an installation image file from an installation image file on the specified installation media

To create an installation image file from the bos.net software package on the tape in the /dev/rmt0 tape drive and use /var/tmp as the working directory, type:
 # bffcreate  -d /dev/rmt0.1 -w /var/tmp bos.net


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Software management in AIX
By Surya12:091 comment

Fileset in AIX is named for softwares or dependencies.
Group of filesets is called a package.
For eg: bos.net is a package and bos.net.nfs.client is a fileset.
BOS stands for Base Operating System.
BOS is a licensed programming product (LPP).
Bundle : A bundle is a collection of a fileset, package or LPP.
Bundle is of 3 types:
Server bundle
Graphics bundle
Migration bundle
Command used to install softwares is installp
Various commands to install software:
# installp –aVx –d <directory or device name> <application name>
For eg:
# installp – aVx –d /dev/rmt0 bos.net.nfs.client
Flags:
a stands for APPLIED mode. Software installed in applied mode means, admin can rollback the software if the wrong version gets installed or software is not suited as per end user requirements. Because the software is not committed to the OS, so rollback is possible.
To commit the software/application permanently in the OS, command used:
# installp –aCx –d <directory or device name> <application file>
For eg:
# installp –aCx –d /dev/rmt0 bos.net.nfs.client
Flags:
c stands for COMMITTED mode. Once the application is installed using c flag, it cannot be removed later from the OS. Admin must be very careful in running this command.
To remove an application which is installed in applied mode, command used is:
# installp –r <application name>
To uninstall the fileset, command used:
# installp –u <application name>
To clean broken software parts, command used:
# installp –C
To check all softwares installed in APPLIED mode, command used:
# installp –S
To list all the softwares installed in AIX or LINUX OS, command used are:
# lslpp –l (works only in AIX)
# lslpp –L (works in both AIX as well as Linux)
# lslpp –h <application name>
This command will give complete history about the application including the versions installed.
For eg:
# lslpp –h bos.obj
# lslpp –L | grep APPLIED
Will list all the applications installed in APPLIED mode in the OS.
Command used to find the filesets installed for a particular application is:
# lslpp –f <application name>
Command used to find the filesets installed for running any command is:
# lslpp –w /usr/bin/<command>
For eg:
# lslpp –w /usr/bin/path
This command will give the list of filesets needed to run the PATH command.
# lslpp –c command is used to verify the checksum
# lslpp –v command is used to verify the software parts.
To install softwares in Linux commands used are:
# rpm –ivh <application name>
POINTS TO REMEMBER:
Install command’s output is always stored in user’s smit.log directory i.e. /home/smit.log
Software components are basically broken down into 3 types:
Root
Usr
Share
Fileset + package together is called a Bundle.
To check using SMIT whether software is installed properly or not, command used is:
# smit list_installed
To report comparison for softwares, command used:
# smit compare_report
To check software management and utilities, command used:
# smit maintain_software
To install fix from a cd, command used:
# instfix –ik <fix number> -d /dev/cd0
To search for a fix by keyword:
# instfix –s <keyword> -d /dev/cd0
To display all fixes available on cd:
# instfix –T –d /dev/cd0
# instfix –I | grep ML command will list all the fixes for ML (maintenance Level)
# instfix –I | grep TL command will list all the fixes for TL (Technology Level)
Formula for RISC (Reduced Instructions Set Computer):
Time to execute a program = number of instructions X number of clock cycles per instruction X time taken for a clock cycle
mkinstallp command creates software package in install format.
To install updates available on a cd and verify the current maintenance level, command used is:
# install_all_updates –d /dev/cd0


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Some Interesting Facts About mksysb
By Surya14:14No comments
1.     mksysb does not include data on raw devices in its backup image.

2.     mksysb does not include user-defined paging space in backup image.

3.     In case we use remote-mounted /usr files system, the system cannot be re-installed from a backup image.

4.     While doing mksysb restore, all device configurations for special features may not be restored. e.g /dev/netbios and the device drivers not shipped with the product.

5.     The mksysb command uses “backup” command at the backend to create the backup archive image.

6.     The command saves Extended Attributes format for any JFS2 file systems being backed up. The information is stored by using /usr/bin/mkvgdata shell script.

7.     What to do if mksysb is prepared on rspc servers which don’t support booting from tape:

a.     Boot from CDROM.

b.     Enter maintenance mode.

c.     Install the system backup from tape.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Some tips and techniques for managing GPFS file systems
By Surya21:01No comments

Mount a file system on some nodes
Set special mount options for a specific node
Specify mount order (GPFS Version 3.4 or later only)
MOUNT A FILE SYSTEM ON SOME NODES
If you do not want any file systems that are configured for automount to be mounted on a specific node. On that node create the file  /var/mmfs/etc/ignoreStartupMount
#echo "some text" > /var/mmfs/etc/ignoreStartupMount
If you want to mount some of the file system that are configured for automount create a /var/mmfs/etc/ignoreStartupMount file for each file system by adding a “.devicename” to the end of the file.
#echo "some text" > /var/mmfs/etc/ignoreStartupMount.<devicename>
For example if you have file systems fs1 and fs1 configured for automount and you do not want to mount fs2 on this node you would create a file called “/var/mmfs/etc/ignoreStartupMount.fs2″
#echo "some text" /var/mmfs/etc/ignoreStartupMount.fs2
(With a period between the keyword and the device name)

If you do not want the file system to mount at all instead of using ignoreStartupMount you can create an ignoreAnyMount file using the same syntax. This keeps the file system from being mounted on this node when mmmount is used in addition to not mounting on startup.
SET SPECIAL MOUNT OPTIONS FOR A SPECIFIC NODE
You may want to set special file system mount options for a specific node. To set special mount options create a file called /var/mmfs/etc/localMountOptions.$fsname where $fsname is the name of the file system. You can create a file for each file system that requires special mount options.

The file /var/mmfs/etc/localMountOptions.$fsname contains a single line with the mount options you wish to use. The mount options available are the same as your operating system mount options for the mount commands -o flag.

For example, to mount the file system fs1 as read only, start by creating a file.

/var/mmfs/etc/localMountOptions.fs1 ,That contains the value ro in the first line of the file.If you want all the file system on a particular node to mount with the same options create a file without the file system name at the end that contains a single line of text with the desired mount options.
/var/mmfs/etc/localMountOptions
SPECIFY MOUNT ORDER
You may want to set the order of file system mounts when the daemon starts and successfully joins the cluster (if mmlsconfig autoload shows yes) or when a mmount all command is executed. This is especially useful when you have nested GPFS file systems.

To do so, use the –mount-priority NumericPriority option on the mmcrfs, mmchfs or mmremotefscommands.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

SRC (System Resource Controller) commands in AIX


Command 	Description
lssrc -a  	To list the status of all subsystems
lssrc -h node1-a 	To list the status of all subsystems  on foreign host node1
lssrc -s inetd   	To list the status of the subsystem inetd
lssrc -g tcpip   	To get the status of the subsystem group tcpip 
startsrc -s inetd  	To start the subsystem inetd
startsrc -g tcpip  	To start the subsystem group tcpip
stopsrc -s inetd  	To stop the subsystem inetd (If process is under srcmstr. ie PPID of process=PID of srcmstr)
stopsrc -g tcpip   	To stop the subsystem group tcpip
refresh -s nfsd    	To refresh nfsd subsystem
refresh -g tcpip   	To refresh tcpip subsystem group
lssrc -p [PID of process]	To get  status of the subsystem by process ID 
kill  [PID of process] 	To kill a process that not started by srcmstr 
mkssys     	To add a subsystem
rmssys -s kerberos   	To remove the subsystem kerberos
chssys -s kerb -s kad 	To rename the subsystem kerb to kad

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Start up - Shutdown AIX
By Surya11:50No comments
mkitab                     adds record to the /etc/inittab file (-i: insert the newline anywher in the inittab file)
                           (without the -i parameter, the line wil be appended to the end of the file)
lsitab                     lists record to the /etc/inittab file (lsitab -a -->lists all records of the inittab)
chitab                     adds record to the /etc/inittab file

uptime                     shows the time the server is up
last reboot                shows the history when the server has been rebooted

who -b                     info about the last boot

/dev/ipldevice             it is a hardlink to the device which holds hd5 (check major minor numbers)
ipl_varyon -i              shows the state of the bootrecord

------------------------------
Telinit:

The telinit command sets the system at a specific run level. A run level is a software configuration that allows only a selected group of processes to exist.

who -r                     shows what is the runlevel of the system
cat /etc/.init.state       displays the current runlevel

telinit M or shutdown -m   enter to maintenance mode (single user mode)
telinit 2                  return to normal mode
telinit q                  force the system to reread the etc/inittab file


------------------------------

System Management Services
Another boot option is to boot machine specific code called the System Management Services (SMS) programs. These programs are not part of AIX. This code is shipped with the hardware and is built-in to the firmware. This can be used to examine the system configuration and set boot lists without dependency on an operating system. It is invoked using the F1 function key or the numeric 1 key.

Maintenance Mode
If your system will not boot or you have lost the root password, you will need to boot your machine using bootable media other than the hard drive (like an installation CD or NIM server). This will boot you into “maintenance” mode, which will give you “backdoor” access to your system.

------------------------------


BOOTING TERMINOLOGY

0. firmware bootlist:
    in SMS set boot devices:disk, cd-rom, network

1. AIX bootlist: 
    At startup, the system searches for an AIX boot image in the boot list, a list of hdisks stored in the hardware's NVRAM.
    If the system fails to boot, you can change the boot list

    bootlist -m normal -o               <--shows bootlist
    bootlist -m normal hdisk0 hdisk1    <--sets bootlist
    bootlist -m normal en0 bserver=10.20.10.10 gateway=10.20.50.1 client=10.20.50.6    <--force the system for network boot
                                        (bs:boot server, client:the machine what we reboot)
    bootlist -m normal -ov              <--it will show boot disks location codes (can be compared what sms shows during boot)

    root@aix31: / # bootlist -m normal -ov
    'ibm,max-boot-devices' = 0x5
    NVRAM variable: (boot-device=/pci@80000002000000c/pci@2/pci1069,b166@1/scsi@0/sd@4:2)
    Path name: (/pci@80000002000000c/pci@2/pci1069,b166@1/scsi@0/sd@4:4)               <--this pathname shows which blv is used
    match_specific_info: ut=disk/scsi/scsd
    hdisk0 blv=bos_hd5

2. boot record: (bootrec, bootstrap code)
    locates the boot logical volume from the harddisk, it is the first 512 byte on the disk.

    ipl_varyon -i                       <--shows the state of the bootrecord
    bosboot -ad /dev/hdisk1             <--creates the boot record and the boot logical volume as well!!!
    chpv -c hdiskX                      <--clears the boot record

3. boot logical volume (blv) (hd5):
    Contents of the boot logical volume: 
        -AIX kernel (kernel is always loaded from the blv) (a copy of the kernel is under /unix)
        -boot commands (cfgmgr, bootinfo)
        -reduced copy of the ODM (mini-ODM)
        -rc.boot: after starting the kernel it gets over the control

    if blv (hd5) has to be created again: one physical partition in size, must be in rootvg and outer edge as intrapolicy. 
    Specify boot as logical volume type. (mklv -y hd5 -t boot -a e rootvg 1)

    bosboot -ad /dev/hdisk1            <--creates the boot logical volume
    savebase -v                        <--updates the mini-ODM (in the boot lv) that resides on the same disk as /dev/ipldevice (-v verbose)

    It may happen that 1 partition is not enough for hd5. If you add a new partition make sure the 2nd partition is next to the 1st one.
    (IPL code won't be able to jump from partition 1 to 10, for example (lslv -m hd5))

----------------------------------------



The bootrec (also known as bootstrap) is read by a special part of the firmware called System ROS (- the Read Only Storage is responsibe for the initial preparation of the machine -), and it (bootrec)  tells the ROS that it needs to jump X bytes into the disk platter, to read the boot logical volume, hd5. During reading the blv, there is a mini-ODM read into the RAM. (Later, when the real rootvg fs comes online, AIX merges the data in mini-ODM with the real ODM held in /etc/objrepos.) When an LVM commands changes the mini-ODM, the command 'savebase' needed to run as well. Savebase takes a snapshot of the ODM and compresses it

-----------------------------------------
-----------------------------------------

THE AIX BOOT SEQUENCE:

1.POST
After you've turned on the power and the server is starting, the server's hardware is verified and checked for possible issues. This step is called power-on self-test (POST), it is checking the memory, keyboard, sound card, and network devices.

2. Bootstrap
After the POST process has finished, the bootstrap -or a smaller program used to load a larger program-is loaded into memory. The bootstrap then loads the Boot Logical Volume (BLV) into memory. 

3. BLV
The BLV is the location that contains AIX's bootable images. Typically, the BLV can be found on the local disk of the server. The BLV contains the AIX kernel, the rc.boot file, commands required during the boot process, and a trimmed-down version of the Object Data Manager (ODM).
After the BLV is loaded, the kernel takes over the boot process. 

4. The AIX kernel
The AIX kernel stored in the BLV creates the / (root), /usr, and /var file systems in RAM. These file systems as well as the kernel are stored in RAM initially during the boot process. After the file systems have been loaded into RAM, the kernel executes the init process, which was loaded out of the blv (not from the root filesystem). This init process executes rc.boot.
            
5. The rc.boot file
The rc.boot file has three important cases of execution during the AIX boot-up process:
    -The first section of rc.boot initializes the system's hardware to prepare it for the operating system to boot. 
    A limited amount of devices needed to start the system are configured at this time with the Configuration Manager command cfgmgr.

    -During the second phase of rc.boot, rootvg is activated and the file systems /, /usr, and /var as well as the paging space are mounted. 
    After these file systems have been mounted, init is replaced with init on the disk as PID 1.
    All /dev files and the customized ODM files from the RAM file system are merged to disk and the RAM is cleared.

    -In the third and final section of rc.boot, the actual init process is executed from disk. 
    When init is executed, the /etc/inittab file is read, and each item is executed and /tmp file system is now being mounted to disk. 
    The cfgmgr command is run again on the remaining devices that were not configured in the first section of rc.boot. 

After booting, during start-up first initialisation is runnning (/etc/inittab) and after that the actual run level scripts (/etc/rc.d/rc2).
('rc' name is used in places, it is an abbreviation of 'run command')
-----------------------------------------
-----------------------------------------

1.SYSTEM INITIALISATION: INIT

The init process runs first. Its primary role is to start other processes listed in the /etc/inittab file. The init process rereads the /etc/inittab file every 60 seconds.

Order of the /etc/inittab entries:
    1.initdefault--> init:2:initdefault (init reads the runlevel from this line, in this case 2)
    2.sysinit --> brc::sysinit:/sbin/rc.boot 3 (itt calls rc.boot file with argument 3)
    3.powerfailure detection (powerfail)
    ...
    6.system resource controller (srcmstr)
    7.start TCP/IP daemons (rctcpip)
    8.start NFS daemons (rcnfs)
    9.cron
    ...

format of the entries: Identifier:RunLevel:Action:Command

Identifier: uniquely identifies an object
RunLevel: the runlevel at which the enrty can be processed. (0-9)
Action: how to treat the process: respwawn, wait (wait for its termination), once, boot...
Command: A shell command to execute

The colon character ( : ) is used as a delimiter as well as a comment character. To comment out an inittab entry, add : at the beginning of the entry (:Identifier:RunLevel:Action:Command)

e.g..:
srcmstr:23456789:respawn:/usr/sbin/srcmstr # System Resource Controller
harc:2:wait:/usr/es/sbin/cluster/etc/harc.net # HACMP for AIX network startup
rctcpip:a:wait:/etc/rc.tcpip > /dev/console 2>&1 # Start TCP/IP daemons

--------------------------------------------
many daemons are started from /etc/inittab:for example src, cron..and the rc.tcpip as well
rc.tcpip contains even more daemons to start: dhcpd, lpd, syslogd...             <--these can be controlled usually by src
and rc.tcpip starts inetd as well which contains other daemons: ftp, telnet..    <--these should be controlled by src
--------------------------------------------


2. Startup and Shutdown scripts:

There are more places to put these scripts:

/etc/rc.d:
-init.d: here you can put your own scripts for start/stop

-rcX.d (e.g. rc2.d): you can simply add your script to the different levels (rcX.d). 
 The start script must start with a capitol S and the stop scripts must start with a capitol K.
 Usually the scripts in rcX.d are symbolic relative links to the actual scripts in init.d. 
 The scripts know whether to (S)tart or (K)ill the service by checking to see if it is running, I think.
 (K and S scripts are identical (??), check Ksshd/Ssshd)

AIX does not follow the System V R4 (SVR4) run level specification. It defines run levels from 0 to 9, 0 and 1 are reserved, 2 is the default normal multiuser mode and run levels from 3 to 9 are defined by administrator.

-----------------------------------------
-----------------------------------------

SHUTDOWN:

You can shut down the system using the shutdown command, which sends all terminals the following warning message: 
shutdown: PLEASE LOG OFF. System maintenance is in progress. All the processes will be killed in one minute. 

One minute after the message is displayed, the terminals are disabled, and then the system gracefully shuts down

shutdown [ -options] [ +time message]
    -F performs a fast shutdown, sends no warning message, does not wait for applications to finish 
    -r reboots after shutdown, sends a warning message, and shuts down gracefully
    -m shuts down into Maintenance mode, sends a warning message, and shuts down gracefully
    -k sends a warning message but does not shut down the system. 
       (It is used to quickly determine whether it is okay to shut down the system)
    -l  logs the output to the file /etc/shutdown.log
    -h halts the operating system completely; same as the -v flag.

The halt command shuts down the system, but it does not send a warning message. It does not wait for applications to finish processing. It is generally not used when users are logged in to the system since it does not restart the computer

The reboot command shuts down processes only. It leaves services and communications running. It does not send a warning message, and after shutdown, it checks the file systems and then restarts the system. 

The fastboot command performs the same function, but it does not check the file systems when the system reboots

/etc/rc.shutdown        customize shutdown sequence, it is called by the shutdown command and executed first
                        (for example it is useful if you need to close a databse prior to a shutdown) 
                        If rc.shutdown fails (non-zero return code value) the shutdown sequence is terminated.
-------------------------------------------------------------

Modifying the /etc/inittab file:
(we want to add the find command to it, on run level 2, and start it again once it has finished)

1.ps -ef| grep find                                          <--checking that no find processes are running
2.mkitab "xcmd:2:respawn:find / -type f > /dev/null 2>&1"    <--adds a record named xcmd to /etc/inittab
3.lsitab xcmd                                                <--shows the new record
4.ps -ef| grep find                                          <--checking the new process
5.kill <pid>                                                 <--cancel the find process
6.ps -ef| grep find                                          <--as it is configured as respawn it will respawn
7.chitab "xcmd:2:once:find / -type f > /dev/null 2>&1"       <--changes it from respawn to once (after kill <pid> it won't respawn)
                                                             (if you can change it to "off", then the line will be ignored)
8.rmitab xcmd                                                <--deletes this record from /etc/inittab

After editing the /etc/inittab file, force the system to reread the file by using telinit q command.
-------------------------------------------------------------

Modifying the bootlist:
1. bootlist -m normal -o                                     <--checking the devices in the bootlist)
2. bosboot -ad hdisk1                                        <--creates a new BLV (boot logical volume) on the disk)
3. bootlist -m normal hdisk1 hdisk0                          <--change the order of the devices: (first hdisk1 and after hdisk0))

bootlist -m normal hdisk0 blv=hd5 hdisk0 blv=bos_hd5
-------------------------------------------------------------

Correct a damaged boot image:

1.lslv -m hd5                                                 <--obtain the boot disk
2.bosboot -a -d /dev/hdiskn                                   <--recreate the bootimage, n is the disk number of the boot logical volume)
3.shutdown -Fr                                                <--restart the system
-------------------------------------------------------------

Changing the ipldevice:
It is Initial Program Load device. It should be a link to the device which is holding hd5 (the disk which was used for boot)

bootinfo -s                                                   <--checking disk used for boot (getconf -a | grep BOOT)
ls -l /dev/ipldevice                                          <--check ipldevice file (find corresponding disk major, minor number)

If there is a difference between bootinfo -s and ipldevice, /dev/ipldevice should be changed:
1. rm /dev/ipldevice                                          <--remove wrong ipldevice file
2. ln /dev/r<bootdisk> /dev/ipldevice                         <--create hard link for coorect rdisk (!!note the r prefix)
3. ls -i /dev/r<bootdisk> /dev/ipldevice                      <--check if ipldevice is correct (same inode number should be seen)

-------------------------------------------------------------

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Step-by-step guide to IBM Power Systems firmware update
By Surya13:291 comment
Background
Overview of IBM Power Systems servers
Hardware Management Console can be a desktop or a rack-mounted appliance that manages the servers, and is used for partitioning and as a service tool.
A managed system is a single physical server. It can have I/O expansion units, towers, drawers, and storage area network (SAN) resources.
HMC communicates to the managed system through the service processor.
The service processor is an embedded controller that monitors and controls the entire system and is running the bare metal Linux.
The IBM POWER Hypervisor™ is a layer of system firmware that supports virtualization technologies, logical partitioning (LPAR), and dynamic resource movement across multiple operating system environments.
Figure 1.


Introduction
The flexible service processor (FSP) firmware provides diagnostics, initialization, configuration, run-time error detection, and correction. It is required to periodically update the firmware on the Power Systems server. Keeping the firmware up-to-date can help in attaining the maximum reliability and functionality from your systems.
Firmware releases enable new function and might also contain fixes or enhancements.
Firmware service packs provide fixes and enhancements within a specific release.
This tutorial provides the following information:
Current firmware details
Different kinds of code download and update methods
Steps to obtain the relevant firmware code updates or releases from the IBM FixCentral website
Steps to update the firmware concurrently using DVD media, that is, the fixes that can be deployed on a running system without rebooting partitions or performing an initial program load (IPL) within a specific release
Steps to update the firmware disruptively, that is, update requiring the system IPL within a specific release
Advanced code update options from the Change Licensed Internal Code wizard
Steps to upgrade to recent firmware releases disruptively using the File Transfer Protocol (FTP) method
Steps to upgrade the firmware disruptively through the IBM Service website to a required level
In the following sections, let's go through in detail covering all the topics highlighted above.
Section 1. View system information
We will use the View system information option to get the current system firmware information.
We will be using this information in IBM Fix Central to obtain information on the latest firmware updates or upgrades available for the system and proceed with the firmware update or upgrade to newer release using the instructions described in the following sections.
Select the system under test, click Updates, and then click View system information to check the currently installed, activated, and accepted levels.
Figure 1.1

The following figure shows the currently installed firmware levels on the system.
Figure 1.2

Fields in figure 1.2 are described below:
EC Number
This displays the numerical identifier of the engineering change (EC) that shows the system and GA level. It has the format ofPPNNSSS, where:
PP is the two-character package identifier.
NN is the two-character name that identifies a set of platforms. This is the model-unique code for the type of system.
SSS is the three-character service pack code stream identifier.
LIC Type
This displays the LIC types associated with the selected target.
Machine Type/Model/Serial Number
This displays the corresponding machine type, model number, and serial number.
Installed Level
This displays the LIC level that will be activated and loaded into memory at the next system restart.
Activated Level
This displays the LIC level that is activated and loaded into memory (for example, from a level 5 to level 7).
Accepted Level
This displays the LIC level that was committed. This refers to the updates selected on the system.
This is the backup level of code that you can return to, if necessary. Generally, this is the level of code on the permanent side (p-side).
Unactivated Deferred Level
This displays the latest or highest LIC level that contains unactivated deferred updates. This refers to the updates selected on the system.
A deferred update requires a system restart to activate.
Platform IPL Level
This displays the LIC level on which the hypervisor and partition firmware were last restarted. When concurrent LIC updates are performed, the activated level will change, but the platform IPL level will remain unchanged.
Update Control
This displays the current owner of LIC update control. It can be either HMC or operating system.
Section 2. Different kinds of “Code download and update” methods
Having known the current firmware levels on the system as described in Section 1 and in order to move up to the necessary latest update that is available, we have various firmware update and upgrade methods as mentioned below. Select the one that is appropriate to your requirement.
DVD method
We can get the latest firmware code information from Fix Central. You need to download the code (as described inSection 3). You will be able to download the file in the ISO format. Then, you need to burn it to a DVD media to perform the update/upgrade using the obtained DVD (and this is described in Section 4).

Section 4 describes the concurrent firmware update procedure. We can also use the DVD method to perform code upgrades (to a new release). This can be used when the HMC cannot access Internet due to firewall.
FTP method
Download the required code levels using bulk FTP from Fix Central to a remote FTP-enabled system (also described inSection 3) Then, perform the code update/upgrade procedures using the FTP method, providing the login credentials and location of the update/upgrade code on your remote FTP-enabled repository system ( as described for firmware upgrade in Section 7.

Section 7 describes the disruptive upgrade procedure using the FTP method. Similarly, the FTP procedure can also be used for concurrent code updates (within the same release).
IBM service website method We can perform the Power Systems firmware update/upgrade through the IBM service website to a required level (as described in Section 8).

Section 8 describes the code upgrade procedure disruptively using the IBM website. A similar procedure can be used for performing concurrent code updates as well.

After selecting the required system from the HMC, ensure to select Change Licensed Internal Code in order to perform code updates (any updates within the same release) and select Upgrade Licensed Internal Code in order to perform code upgrades (by installing the different release).

Section 3. Power Systems firmware code location and download from Fix Central
Power Systems firmware fix packs or firmware releases can be obtained from the IBM Fix Central website.
Select the following categories for Power Systems firmware update and choose the appropriate machine type and model of your system to be updated.
As per the example shown in Figure 3.0, the machine type and model used is: 8203-E4A. Select the appropriate machine type of your choice and continue.
Figure 3.0

Example in Figure 3.1 shown below is for the system firmware only. Similarly, you can explore other options too.
Figure 3.1

If users are aware of the specific firmware level, then users can select the necessary option directly. If not, users can also take help from the recommendations that the website can provide about the latest and the best-suited firmware levels. If you need help, select the I need guidance. I am not sure what level of firmware is recommended option as shown in Figure 3.2.
Choose the specific level or get the recommended level as shown below:
Figure 3.2

Figure 3.3

Decide whether your system needs firmware update to the latest fix pack or upgrade to a new release based on the current levels installed on the system as obtained from View system information in the above section.
Figure 3.4

Figure 3.5

As an example, let us continue to get the firmware service pack within the current release, as shown in Figure 3.6.
Figure 3.6

Figure 3.7

Similarly, users can get the upgrade code, that is, newer release using the second option. Note that this will be a disruptive code install, that is, system power recycles.
Note:
Download the update code, if you are planning an update within the current release.
Download the upgrade code if you are planning for an upgrade to a newer release itself.
Figure 3.7 lists the latest, recommended, and available updates to your current release. Select the appropriate option and proceed further.
Continue with downloading the ISO file if you want burn it to a DVD to proceed with the firmware update using the DVD media, orget the code to a remote FTP-enabled system to perform update using the FTP method. The firmware update procedure is explained in detail in the following sections.
Figure 3.8

Figure 3.9

Figure 3.10

Section 4. Power Systems firmware concurrent update procedure using the DVD method
You can update the firmware concurrently (that is, the fixes that can be deployed on a running system without rebooting partitions or performing an IPL) within a specific release. Select the Change Licensed Internal Code option for the current release.
Figure 4.0

Figure 4.1

In the Specify LIC Repository section (as shown in Figure 4.2), select the location of the LIC update repository.
Figure 4.2

Figure 4.3

elect the DVD-RAM drive option,where you have the DVD placed and proceed with code update concurrently, as shown in Figure 4.3.
Note: Place the DVD in the HMC's DVD drive (and not in the system's DVD drive).
Figure 4.4

Click OK to proceed further to the subsequent steps to perform code update. It verifies whether the system is ready for code update by performing the health check and if everything fine, we can proceed further.
The following screen captures show the step-by-step procedure to perform concurrent code update.
Figure 4.5

Figure 4.6

Figure 4.7


Figure 4.8

Figure 4.9

Figure 4.10

Section 5. Steps to update the firmware disruptively (that is, update requiring the system IPL within a specific release)
Firmware updates are usually concurrent. Disruptive update service packs are very rare. The procedure to perform disruptive update is quite similar to concurrent update (explained in Section 4) but this process will prompt for system power cycle during the operation.
Section 6. Advanced code update options from Change Licensed Internal Code wizard
We use the Select advanced features option to perform advanced operations, such as Remove and activate and Reject fix.
Remove and activate option
The Remove and activate option brings the system back to the update level that is on the permanent side. You can use this option to back off an update level.
Figure 6.0

Figure 6.1

Figure 6.2

Figure 6.3

Click OK and then Close to remove and activate the permanent side update level.
Figure 6.4

Reject Fix operation:
Boot the system in the Permanent Side mode (from ASMI -> Power/Restart Control -> Power On/Off System, and make sure that the Current firmware boot side option is displayed as Permanent) and only then the Reject Fix option gets enabled and the operation can be performed. This operation copies the currently running level (permanent side) to the temporary side. This can be used to reject a fix that has been applied.
Figure 6.5

Figure 6.6

Figure 6.7

Click OK to start this operation.
Section 7. Upgrade to newer firmware releases disruptively using the FTP method
Installing a release or a disruptive fix pack causes system IPL. All release upgrades are disruptive.
We can obtain the upgrade code, that is, the disruptive fix pack from Fix Central and burn it to a media drive and proceed with the upgrade process, which is quite similar to the concurrent update process explained in the earlier sections (except that this operation is disruptive).
In this section, let us learn how to use the FTP method to upgrade the system using the firmware code stored in a remote repository.
The following screen captures shows the steps to upgrade to newer firmware releases disruptively using the FTP method.
Figure 7.0

Figure 7.1

Figure 7.2

Figure 7.3

Figure 7.4

Figure 7.5

Figure 7.6

Figure 7.7

Figure 7.8

Clicking OK starts the disruptive upgrade. System will be on the applied release level after the upgrade operation completes.
Section 8. Steps to upgrade the firmware disruptively using the IBM service website to the required level
After logging in to the HMC, click System Management > Servers > Target Server on the left pane. Instead, you can also click the Updates icon on the same pane. All the available servers will be displayed in the right pane. In the following figure, the red highlight in the right pane shows the current level installed.
Figure 8.0

Make sure that your target server is in the shutdown mode, and if not, switch off the server.
Now, click the Upgrade Licensed Internal Code to a new release link at the bottom of the page as shown in the following figure.
Figure 8.1

After clicking the link, you will be directed to the web page which will show information about the readiness check. If there is no errors found, you can click OK and proceed further, as shown in the following figure.
Figure 8.2

After clicking OK, you will be directed to the Specify LIC Repository page. Here, you need to select the location of the code. The options shown in the following figure are available.
Figure 8.3

If you are setting a new server configuration, the best practice at this prompt is always to select the IBM service web site option and you need not worry about the need to power off and power on the managed systems in this method.
After selecting the IBM Service web site option, you will have a new web page opened, which will show you the available LIC level details. Here, the best practice is to select the latest available code (that is, the latest available version). Most of the fixes are added by IBM and your Power Systems server will be upgraded to the latest level. Then, select the best as per your requirement, or the latest supported.
Be patient here and follow the prompts to complete the upgrade. The firmware upgrade activity will need time depending on your Internet bandwidth speed. Do not forget to switch on the server, so that the latest firmware gets activated and reflected in the navigation pane, as shown in the following figure.
Figure 8.4

Now you are done with the upgrade. Remember if you select multiple systems, you can upgrade them as well.

Resources
Microcode and firmware update presentation		(https://www.ibm.com/developerworks/wikis/download/attachments/53871900/2007-4-26-presentation.pdf?version=1)
Updating POWER5 system firmware			(https://www.ibm.com/developerworks/mydeveloperworks/wikis/home/wiki/Power%20Systems/page/Updating%20POWER5%20system%20firmware?lang=en)
HMC and firmware management for POWER5/POWER6/POWER7 		(https://www.ibm.com/developerworks/wikis/download/attachments/53871900/HMC+and+Firmware+AIX+VUG_Feb+2011.pdf)
Virtualization best practice		(https://www.ibm.com/developerworks/mydeveloperworks/wikis/home/wiki/Not%20AIX/page/Virtualization%20Best%20Practice?lang=en)
Power Systems - firmware			(https://www.ibm.com/developerworks/mydeveloperworks/wikis/home/wiki/Power%20Systems/page/Firmware?lang=en)
Virtual I/O and virtualization		(https://www.ibm.com/developerworks/mydeveloperworks/wikis/home/wiki/Power%20Systems/page/Virtual%20IO%20and%20virtualization?lang=en)


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Steps To Increase/Decrease A FS Size-AIX
By Surya12:041 comment
A FS once created, can be increased (for jfs/jfs2) or decreased (for jfs2) as per the end user requirements by the administrator.

Increasing the FS will automatically increase the size of LV. Increase the size of LV will not increase the size of FS but will make provision for increasing the size of FS later when required.

Making size of the filesystem to exact size:
# chfs –a size =1G /ora
This command will  make the size of /ora FS  equal to 1 GB.

To raise the size by 1 GB will alter the above command as follows:
# chfs –a size =+1G  /ora
To verify the above command is executed properly or not:
# lsfs
# df –g
Steps involved to reduce/decrease the size of FS
Reduction of size is only possible for jfs2 types of FS. Reduction is not possible in jfs type of FS. Also, one of the limitations of a LVM is that reduction of size of LV is not possible. Refer:
Run the following command to reduce the size of FS:
# chfs –a size =512M /ora
OR
# chfs –a size =-512M /ora
Verify the same by:
# lsfs
OR
# df –m
chfs command is basically used when needs to increase the size of FS for end user as per the requirement.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Steps to Virtualize a VIO CD-ROM
1. Start on the profile for the VIO server that has the CD/DVD ROM on its bus.
2. Create a new SCSI virtual adapter.
3. On the "Add" screen, make it required for partition activation, make sure it's set for Any Partition, Note the virtual SCSI adapter ID, and hit OK
4. Deactivate and Reactivate the VIO server so that it reads the new profile.
5. Log into the VIO server as padmin
6. Issue the command "lsdev -type optical" to verify that the VIO server has an available CD rom
7. Issue the command "lsdev -type adapter" to identify the vhost number of the newly added vscsi adapter.
8. Issue the command "mkvdev -vdev cd0 -vadapter vhost#" where vhost# is the newly added vscsi adapter.
9. The command "lsmap -vadapter vhost#" should display the vhost and backing device information.
10. At this point, we're done on the VIO server.  Log out.
11. Open up a profile for one of the LPARs, go to Virtual Adapters, and Create a new SCSI adapter.
12. Make sure the Server partition is the VIO server and make sure the Server adapter ID matches what you've noted from step 3 (when you added the CD to the VIO server).
13. Perform steps 11 & 12 on any LPAR that you want to see the CD.
14. Deactivate and Reactivate the LPAR and it should see the CD.
To remove the CD from an LPAR to discover on another, perform these steps:
1. Log into the LPAR
2. Issue the command "lsdev -l cd0 -F parent".  This should identity the virtual scsi bus.
3. Issue the command "rmdev -dl vscsi# -R" to remove the bus and the CD.
4. Run "cfgmgr" on another LPAR to discover it (Assuming the virtual SCSI adapter for the CD has already been added and the LPAR reactivated)


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Syntax for /etc/inittab
By Surya11:59No comments
This post will discuss about the syntax used in /etc/inittab.

Remember, run level for the system is always read from /etc/inittab
Syntax:
<ID>:<Run Level>:<Action>:<Command>
Run level is used for maintenance purpose.
In AIX, there are 10 run levels from 0 to 9.
0 and 1 is reserved run levels.
2 is default run level.
3 to 9 is user defined run level.

Eg:
Oracle:2/3/6/8:<once>/<wait>/<respawn>:startsrc –s oracle

Explanation:
Oracle is the ID,
2/3/6/8 is the run level for this particular process,
Once, wait, respawn is the action taken on this particular process
where
          once means the process will run and stop,
          wait means will wait for the process to complete (if error occurs will stop, system            needs to be rebooted then
          respawn means if the process does not exists, it will start it.
startsrc –s oracled is the command given to start the subsystem oracle daemon.
1. To modify records of the /etc/inittab file, commands used are:
mkitab : will add new record (entry) in /etc/inittab
2. To add an entry in /etc/inittab file,
# mkitab <rule>
For eg:
# mkitab “cdrom : 2 : respawn : startsrc –d cdromd”
3. To change an entry in /etc/inittab file,
chitab : will change the existing records in /etc/inittab
# chitab <rule>
For eg:
# chitab “cdrom : 3 : respawn : startsrc –s cdromd”
rmitab : will remove the records from /etc/inittab
4. To Remove an entry in /etc/inittab file,
# rmitab <rule>
For eg:
# rmitab “cdrom : 3 : respawn : startsrc –s cdromd”
lsitab : will list the records available in /etc/inittab
5. To list entries in /etc/inittab file,
# lsitab <rule>
For eg:
# lsitab “cdrom : 3 : respawn : startsrc –s cdromd”
6.Here’s a question, check whether the records listed by lsitab command is same as 
# cat /etc/inittab?
A:Yes
7. To identify current run level, command used is:
# cat /etc/init.state
OR
# who –r


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

System Dump [AIX]
By Surya13:06No comments
What is dump?
Configuring dump devices in AIX
How to start the system dump manually?
Copying system dump to other directory or media
Examining system dump using kdb
Important LED codes related to dump

If a kernel panic occurs, a dump will be invoked automatically. The followings are dumped during the dump process.
List of currently running processes and related information about the process
Currently mounted filesystems, inode table and open file table
currently configured ttys and their status
Memory buffers for data
system buffers
system variables and statistics
Kernel's own record of process it is currently running.
Configuring dump devices
sysdumpdev command is used to change the primary or secondary dump device designation in a running system.
 sysdumpdev 
           -l list the current dump destination
           -L view statistical information about previous dump
           -e estimate the dump size
           -d <directory> directory to copy the dump during boot time
           -p <device name>  to set the device as primary dump device
           -s <device name> to set the device as secondary dump device
           -P to make the changes permanent even after reboot
Examples:
To permanently make /dev/hd7 as the primary dump device
 # sysdumpdev -Pp /dev/hd7
To make /dev/sysdumpnull as the secondary dump device
 # sysdumpdev -s /dev/sysdumpnull
To estimate the dump size
 #susdumpdev -e
To start the dump manually
sysdumpstart command is used to start a kernel dump to the primary or secondary dump device. When the dump completes, the system halts. Use the kdb command to examine the dump.
 # sysdumpstart {-p | -s}
Copying system dump
If there is enough space to copy the dump to /var/adm/ras directory, then it will be copied directly during reboot. Dump is copied as /var/adm/ras/vmcore.x file. If there is not enough space, then "copydumpmenu" is run by /sbin/rc.boot to display the copy dump menu. Using this copydumpmenu utility, a dump can be copied to removable such as tape.
snap
 utility can be used to gather system information along with dump and compress the information in a tar file.
snap
    -a  gathers all system configuration information
    -c  creates compressed pax image (snap.pax.Z)
    -e  HACMP specific information
    -g  gathers general info
    -f  gathers filesystem info
    -k  gathers kernel info
    -d <directory> optional snap command output directory
       default directory is /tmp/ibmsupt
    -D  gathers dump and /unix
    -o <output_device>  copies the compressed image to tape or diskette
Example:
To send dump with other gathered information in to tape drive
 # snap -gfkD -o /dev/rmt0
  Examining system dump
kdb command is an interactive utility for examining an OS image or the running kernel.
 kdb <systemImageFile [Kernel File]]
LED Codes Related to dump
 0c0 - Dump completed successfully
 0c2 - Dump started
 0c4 - Dump unsuccessful. Not enough space on dump device
 0c5 - Dump failed to start
 0c9 - System initiated dump started

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

System Hangs at c33 with an LFT - AIX

Question

System hangs at c33 with an LFT.

Answer

System Hangs at c33 with an LFT

c33 is configuring the console as a tty. Typically this occurs because the console is configured as a tty but has no tty. In this situation, when booting into service mode and executing an lscons, the console will show up as anlft. To verify that this is the case, enter smitty chcons. PATHNAME of console will be set to /dev/tty0. Change the pathname to /dev/lft0 and reboot your system.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

System Resource Control (SRC)


SRC is basically used to control the entire subsystem.
It allows you to start, stop and check status information about various subsystem processes.
SRC lists all the services present in /etc/inittab.
Once the kernel starts all the background services, SRC is activated.
SRC:
-          Subsystem group
Subsystem
Subsystem server (subserver)
SRC is basically designed to minimize human intervention.
For a subsystem group:
To list:
# lssrc –g <subsystem group>
To start:
# startsrc –g <subsystem group>
To stop:
# stopsrc –g <subsystem group>
For a subsystem:
To list:
# lssrc –s <subsystem>
To start:
# startsrc –s <subsystem>
To stop:
# stopsrc –s <subsystem>
For a subserver:
To list:
# lssrc –t <subserver>
To start:
# startsrc –t <subserver>
To stop:
# stopsrc –s <subserver>
To refresh:
# refresh will refresh/restart the services. Application need not be restarted for end user.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

TCP/IP commands
By Surya13:53No comments

TCP/IP is part of the underlying structure of your system. It allows you to communicate with another terminal or system merely by executing a command or program.
TCP/IP is part of the underlying structure of your system. It allows you to communicate with another terminal or system merely by executing a command or program. Your system takes care of the rest.
Item	Description
chnamsv	Changes Transmission Control Protocol/Internet Protocol (TCP/IP) based name service configuration on a host.
chprtsv	Changes a print service configuration on a client or server machine.
hostent	Directly manipulates address-mapping entries in the system configuration database.
ifconfig	Configures or displays network interface parameters for a network, using TCP/IP.
mknamsv	Configures TCP/IP-based name service on a host for a client.
mkprtsv	Configures TCP/IP-based print service on a host.
mktcpip	Sets the required values for starting TCP/IP on a host.
no	Configures network options.
rmnamsv	Unconfigures TCP/IP-based name service on a host.
rmprtsv	Unconfigures a print service on a client or server machine.
slattach	Attaches serial lines as network interfaces.
arp	Displays or changes the Internet address to hardware address translation tables used by the Address Resolution Protocol (ARP).
gettable	Gets Network Information Center (NIC) format host tables from a host.
hostid	Sets or displays the identifier of the current local host.
hostname	Sets or displays the name of the current host system.
htable	Converts host files to the format used by network library routines.
ipreport	Generates a packet trace report from the specified packet trace file.
iptrace	Provides interface-level packet tracing for Internet protocols.
lsnamsv	Shows name service information stored in the database.
lsprtsv	Shows print service information stored in the database.
mkhosts	Generates the host table file.
namerslv	Directly manipulates domain name server entries for local resolver routines in the system configuration database.
netstat	Shows network status.
route	Manually manipulates the routing tables.
ruser	Directly manipulates entries in three separate system databases that control foreign host access to programs.
ruptime	Displays the status of each host on a network.
securetcpip	Enables the network security feature.
setclock	Sets the time and date for a host on a network.
timedc	Returns information about the timed daemon.
trpt	Performs protocol tracing on Transmission Control Protocol (TCP) sockets.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Too many open files

To determine if the number of open files is growing over a period of time, issue lsof to report the open files against a PID on a periodic basis.  For example:
# lsof -p (PID of process) -r (interval) > lsof.out
Note: The interval is in seconds, 1800 for 30 minutes.

This output does not give the actual file names to which the handles are open. It provides only the name of the file system (directory) in which they are contained. The lsof command indicates if the open file is associated with an open socket or a file. When it references a file, it identifies the file system and the inode, not the file name.

Run the following command to determine the file name:
# df -kP filesystem_from_lsof | awk '{print $6}' | tail -1
Now note the filesystem name. And then run:
# find filesystem_name -inum inode_from_lsof -print
This will show the actual file name.

To increase the number, change or add the nofiles=XXXXX parameter in the /etc/security/limitsfile, run:
# chuser nofiles=XXXXX user_id
You can also use svmon:
# svmon -P java_pid -m | grep pers
This lists opens files in the format: filesystem_device:inode. Use the same procedure as above for finding the actual file name.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Understanding AIX Volume Group limitations and types
By Surya01:01No comments

Modern versions of AIX have three types of Volume Groups:  Original, Big, and Scalable.    

In my opinion, for any new volume groups you are creating you should always use scalable unless you will have the need to export the volume group and import it on very old versions of AIX.  Scalable volume groups have very few limitations when compared to big and original volume groups.  

Unfortunately there are a ton of original and big volume groups out there in the world, and it can be very tricky to understand their limitations.  The main barriers people hit with original and big volume groups is the limit on the maximum number of disks in the volume group ("MAX PVs") and the limit on how many PP's can be on the disk which directly impacts how large a disk in the volume group can be ("MAX PPs per PV").

To further complicate this, these 2 limitations are variable based on the volume group "Factor".   The factor is a number between 1-16 for original volume groups, and between 1-64 for big volume groups.   As you increase the factor, the "MAX PVs" does down and the "MAX PPs per PV" goes up.   It is essentially a trade off:  if you would like larger disks, you can't have as many.  If you want more disks, they can't have as many PP's on them.  

The factor of a volume group can be changed with the "chvg -t" command.   

Below is how the factor affects original VG's and Big VG's  ( Scalable VG's don't have a factor settings ) :

Original(Normal) VG											Big VG		
Factor	Max PV's 	Max PP's per PV							Factor	Max PV's	Max PP's per PV
2		16			2032									1		128			1016
1		32			1016									2		64			2032
3		10			3048									3		42			3048
4		8			4064									4		32			4064
5		6			5080									5		25			5080
6		5			6096									6		21			6096
8		4			8128									8		16			8128
9		3			9144									9		14			9144
7		4			7112									7		18			7112
10		3       	10160									10		12			10160
11		2			11176									11		11			11176
12		2			12192									12		10			12192
13		2			13208									13		9			13208
14		2			14224									14		9			14224
15		2			15240									15		8			15240
16		2			16256									16		8			16256
															17		7			17272
															18		7			18288
															20		6			20320
															19		6			19304
															21		6			21336
															22		5			22352
															23		5			23368
															24		5			24384
															25		5			25400
															26		4			26416
															27		4			27432
															28		4			28448
															29		4			29464
															30		4			30480
															31		4			31496
															32		4			32512
															33		3			33528
															34		3			34544
															35		3			35560
															36		3			36576
															37		3			37592
															38		3			38608
															39		3			39624
															40		3			40640
															41		3			41656
															42		3			42672
															43		2			43688
															44		2			44704
															45		2			45720
															46		2			46736
															47		2			47752
															48		2			48768
															49		2			49784
															50		2			50800
															51		2			51816
															52		2			52832
															53		2			53848
															54		2			54864
															55		2			55880
															56		2			56896
															57		2			57912
															58		2			58928
															59		2			59944
															60		2			60960
															61		2			61976
															62		2			62992
															63		2			64008
															64		2			65024

The standard AIX utilities such as "lsvg" don't directly show you the volume group type or the volume group factor.   There is a "readvgda" command that you can run on a hdisk (i.e. "readvgda hdisk0") that will show the volume group type and the factor, but it also shows a bunch of other info so its difficult to quickly and efficiently get information from. 

Here is a script that produces a quick report showing several things such as the volume group type, factor size, max PV's, used PV's, Max PP's per PV, PP Size, and max disk size.

Here is a screenshot of the report produced:
 
Here is the script:
#!/usr/bin/perl
use strict;
my (@vgs,$vg,@output,$line,$type,$maxpvs,$maxppsperpv);
my ($activepvs,$ppsize,$total,$factor,$maxdisk);
@vgs = `lsvg -o | sort`;

print "                                        Max           Max  \n";
print "                                        PP's    PP    disk \n";
print "                    Max   Used  VG      per     Size  size \n";
print "VG Name      Type   PV's  PV's  Factor  PV      (MB)  (MB) \n";
print "-----------------------------------------------------------\n";
foreach $vg (@vgs){
        chomp($vg);
        @output = `lsvg $vg`;
        $ppsize = $maxpvs = $activepvs = $type = $maxppsperpv = "";
        foreach $line (@output){
                if ($line =~ /PP SIZE:\s+(\d+)\s+mega.*/) {$ppsize = $1;}
                if ($line =~ /MAX PVs:\s+(\d+).*/) {$maxpvs = $1;}
                if ($line =~ /ACTIVE PVs:\s+(\d+).*/) {$activepvs = $1;}
                if ($line =~ /MAX PPs per PV:\s+(\d+).*/) {$maxppsperpv = $1;}
        }
        $total=$maxpvs*$maxppsperpv;
        $maxdisk=$ppsize*$maxppsperpv;
        if ($maxpvs == 1024) {
                $type = "scale";
        }elsif (($total >= 22352) && ($total <= 32512)){
                $type = "orig";
        }elsif (($total >= 87376) && ($total <= 130048)){
                $type = "big";
        }else{
                print "error determining VG type\n";
                next;
        }

        if ($type eq "orig" || $type eq "big"){
                $factor = $maxppsperpv/1016   
        }else{
                $factor = "N/A";
                $maxppsperpv = "N/A";
                $maxdisk = $ppsize*2097152;
        }

        printf "%-12s %-6s %-5s %-5s ",$vg,$type,$maxpvs,$activepvs;
        printf "%-7s %-7s %-5s %-7s \n",$factor,$maxppsperpv,$ppsize,$maxdisk;
}


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Understanding viostat -adapter vfchost output
By Surya12:08No comments
 Understanding viostat -adapter vfchost output
The ’viostat  –adapter’ command  expected to find non-zero values for kbps, tps, etc, for each vfchost adapter. However, the values were always zero, no matter how much traffic traversed the adapters.                            
$ viostat -adapter 1 10                                                 
...                                                                     
vadapter:                  Kbps      tps     bkread    bkwrtn          
vfchost0                    0.0      0.0        0.0       0.0          
...                                                                    
vadapter:                  Kbps      tps     bkread    bkwrtn          
vfchost1                    0.0      0.0        0.0       0.0          
                                                                       
I wondered if this was expected behaviour. Was the output supposed to report the amount of pass-thru traffic per vfchost? In 2011, I posed this question on the IBM developerWorks PowerVM forum regarding this observation. One of the replies stated:

"viostat does not give statistics for NPIV devices. The vfchost adapter is just a passthru, it doesn't know what the commands it gets are."    
                                                                        
https://www.ibm.com/developerworks/forums/thread.jspa?messageID=14697753&#14697753

I appreciated someone taking the time to answer my question but I was still curious. I tested the same command again (in 2013) on a recent VIOS level (2.2.2.1), but I received the same result. It was time to source an official answer on this behavior.

Here is the official response I received from IBM:

1.  FC adapter stats in viostat/iostat do not include NPIV.           
                                                                   
2.  viostat & iostat are an aggregate of all the stats from the underlying disks, which of course NPIV doesn't have.There's really no way for the vfchost adapter to monitor I/O, since it doesn't know what the commands it gets are. He's just a passthru, passing the commands he gets from the client directly to the physical FC adapter.                         

3.  You can run fcstat on the VIOS but that has the same issues/limitations mentioned above.
Intent here was that customers would use tools on the client to monitor this sort of thing.
To summarize the comments from Development:                            
                                                                       
viostat does NOT give statistics for NPIV devices.”

This made sense but I wondered why the tool hadn’t been changed to exclude vfchost adapters from the output (to avoid customer confusion). There's obviously no valid reason to ever display any information for this type of adapter. I also understood that it was expected that I/O would be monitored at the client LPAR level. But I must say that an option for monitoring VFC I/O from a VIO server would be advantageous i.e. a single source view of all I/O activity for all VFC clients; particularly when there are several hundred partitions on a frame.  The response was:

“…the way the vfchost driver currently works is that it calls iostadd to register a dkstat structure, resulting in the adapter being listed when viostat is called.  This is misleading, however, since the vfchost driver does not actually track I/O.  The commands coming from the client partition are simply passed as-is to the physical FC adapter, and we don't know if a particular command is an I/O command or not.  The iostadd call is left over from porting the code from the vscsi driver, and Development agrees it should probably have been removed before shipping the code.                            
                                                                       
There has also been mention of a DCR #MR0413117456 (Title: FC adapter stats in viostat/iostat does not include NPIV) which you can follow-up with Marketing to register your interest/track progress if that is something you're interested in pursuing.”


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Uninstalling on AIX using SMIT
By Surya10:48No comments

Uninstalling on AIX using SMIT

Follow this procedure to uninstall Tivoli Access Manager for Operating Systems on AIX using SMIT:
Log on as root.
Enter the following command:
smit
The System Management Interface Tool panel is displayed.
From the System Management window, click Software Installation and Maintenance.
From the Software Installation and Maintenance menu, click Software Maintenance and Utilities.
From the Software Maintenance and Utilities menu, click Remove Installed Software. The Remove Installed Software pop-up panel is displayed.
Click the entry field for Software Name "PDOS.rte". and enter 
Before uninstalling the selected software, SMIT determines if it is possible to uninstall. PREVIEW only should be set to yes. Click OK, and then click OK on the confirmation window.During the Preview, a split screen shows the uninstall command and the output log for the preview of the uninstallation.
When the preview is complete, click Done.
The Remove Installed Software window is displayed. Specify No in PREVIEW only. Click OK.
Click OK on the confirmation window.
During the uninstallation, a split screen shows the uninstall command and the output log for the uninstallation.
When the uninstallation is complete, the Remove Installed Software panel is displayed. Click Done.
Close the Remove Installed Software panel.
Close the Software Maintenance Interface Tool panel.
Reboot when uninstallation is complete if required.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Uninstalling on AIX using the command line
By Surya10:50No comments

Uninstalling on AIX using the command line
To uninstall Tivoli Access Manager for Operating Systems on AIX from the command line, follow this procedure:
Log on as root.
On the command line, enter:
 installp -u -g PDOS.rte 
Reboot when the uninstall process is complete.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Unix Create a Symbolic Link
By Surya10:332 comments
Q. How do I create links under UNIX / Linux operating systems?
A. You need to use ln command, which is a standard Unix / Linux / BSD command, used to create links to files. There are two types of links under UNIX, hard and soft link:
Hardlink vs. Softlink in Linux or UNIX
[a] Hard links cannot links directories ( cannot link /tmp with /home/you/tmp)
[b] Hard links cannot cross file system boundaries ( cannot link /tmp mounted on /tmp to 2nd hard disk mounted on /harddisk2)
[c] Symbolic links refer to a symbolic path indicating the abstract location of another file
[d] Hard links, refer to the specific location of physical data.
UNIX Create Symbolic link Command
To create a symbolic link, enter
$ ln -s {/path/to/file-name} {link-name}
$ ln -s /shared/sales/data/file.txt sales.data.txt
$ vi sales.data.txt
$ ls -l sales.data.txt
To delete a link, enter
$ rm {link-name}
$ rm sales.data.txt
$ ls -l
$ ls -l /shared/sales/data/file.txt
If you delete the soft link itself (sales.data.txt) , the data file would still be there ( /shared/sales/data/file.txt ). However, if you delete /shared/sales/data/file.txt, sales.data.txt becomes a broken link and data is lost.
UNIX Create Hardlink Command
To create hard link, enter (without the -s option):
$ ln {file.txt} {hard-link}
$ ln /tmp/file link-here
You can delete hard link with rm command itself:
$ rm {hard-link}
$ rm link-here
If you delete a hard link, your data would be there. If you delete /tmp/file your data still be accessible via link-here hard link file.
UNIX Create Soft-link between Directories
$ ln -s {path to actual directory} {Link-Name}
$ ls -ld {link-Name} <== To verify the link



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Unix/Linux find command examples
By Surya15:27No comments
Real world FIND usage

find / -type f -name *.jpg  -exec cp {} . \;
find /dir -type f -size 0 -print
find . -type f -size +10000 -exec ls -al {} \;
find /var/nmon -mtime +30 | xargs -i rm {}
find /var/nmon -mtime +1 -exec gzip -9 {} \;
find . -atime +1 -type f -exec mv {} TMP \; # mv files older then 1 day to dir TMP
find . -name "-F" -exec rm {} \;   # a script error created a file called -F
find . -exec grep -i "vds admin" {} \;
find . \! -name "*.Z" -exec compress -f {} \;
find . -type f \! -name "*.Z" \! -name ".comment" -print | tee -a /tmp/list
find . -name *.ini
find . -exec chmod 775 {} \;
find . -user xuser1 -exec chown -R user2 {} \;
find . -user psoft  -exec rm -rf  {} \;
find . -name ebtcom*
find . -name mkbook
find . -exec grep PW0 {} \;
find . -exec grep -i "pw0" {} \;
find . -atime +6
find . -atime +6 -exec ll | more
find . -atime +6 -exec ll | more \;
find . -atime +6 -exec ll \;
find . -atime +6 -exec ls \;
find . -atime +30 -exec ls \;
find . -atime +30 -exec ls \; | wc -l
find . -name auth*
find . -exec grep -i plotme10 {};
find . -exec grep -i plotme10 {} \;
find . -ls -exec grep 'PLOT_FORMAT 22' {} \;
find . -print -exec grep 'PLOT_FORMAT 22' {} \;
find . -print -exec grep 'PLOT_FORMAT' {} \;
find . -print -exec grep 'PLOT_FORMAT' {} \;
find ./machbook -exec chown 184 {} \;
find . \! -name '*.Z' -exec compress {} \;
find . \! -name "*.Z" -exec compress -f {} \;
find /raid/03c/ecn -xdev -type f -print
find /raid/03c/ecn -xdev -path -type f -print
find / -name .ssh* -print | tee -a ssh-stuff
find . -name "*font*"
find . -name hpmcad*
find . -name *fnt*
find . -name hp_mcad* -print
find . -grep Pld {} \;
find . -exec grep Pld {} \;
find . -exec grep Pld {} \;
find . -exec grep PENWIDTH {} \; | more
find . -name config.pro
find . -name config.pro
find /raid -type d ".local_sd_customize" -print
find /raid -type d -name ".local_sd_customize" -print
find /raid -type d -name ".local_sd_customize" -ok cp /raid/04d/MCAD-apps/I_Custom/SD_custom/site_sd_customize/user_filer_project_dirs {} \;
find /raid -type d -name ".local_sd_customize" -exec cp /raid/04d/MCAD-apps/I_Custom/SD_custom/site_sd_customize/user_filer_project_dirs {} \;
find . -name xeroxrelease
find . -exec grep xeroxrelease {} \;
find . -name xeroxrelease
find . -name xeroxrelease* -print 2>/dev/null
find . -name "*release*" 2>/dev/null
find / -name "*xerox*" 2>/dev/null
find . -exec grep -i xeroxrelease {} \;
find . -print -exec grep -i xeroxrelease {} \;
find . -print -exec grep -i xeroxrelease {} \; > xeroxrel.lis
find . -exec grep -i xeroxrel {} \;
find . -print -exec grep -i xeroxrel {} \;
find . -print -exec grep -i xeroxrel {} \; | more
find /raid/03c/inwork -xdev -type f -print >> /raid/04d/user_scripts/prt_list.tmp
find . -exec grep '31.53' {} \;
find . -ls -exec grep "31/.53" {} \; > this.lis
find . -print -exec grep "31/.53" {} \; > this.lis
find . -print -exec grep 31.53 {} \; > this.lis
find . -exec grep -i pen {} /;
find . -exec grep -i pen {} \;
find . -print -exec grep -i pen {} \; | more
find . -exec grep -i pen {} \;
find . -atime +6 -exec ll | more \;
find . -atime +6 -exec ll \;
find . -atime +6 -exec ls \;
find . -atime +30 -exec ls \;
find . -atime +30 -exec ls \; | wc -l
find . \! -name '*.Z' -exec compress -f {} \;
find . -name 'cache*' -depth -exec rm {} \;
find . -name 'cache*' -depth -print | tee -a /tmp/cachefiles
find . -name 'cache[0-9][0-9]*' -depth -print | tee -a /tmp/cachefiles
find . -name 'hp_catfile' 'hp_catlock' -depth -print | tee -a /tmp/hp.cats
find . -name 'hp_catfile' -name 'hp_catlock' -depth -print | tee -a /tmp/hp.cats
find . -name 'hp_cat*' -depth -print | tee -a /tmp/hp.cats
find . -name 'hp_cat[fl]*' -depth -print | tee -a /tmp/hp.cats
find /raid -name 'hp_cat[fl]*' -depth -print
find . \! -name '*.Z' -exec compress -f {} \;
find . -name '*' -exec compress -f {} \;
find . -xdev -name "wshp1*" -print
find . -xdev -name "wagoneer*" -print
find . -name "xcmd" -depth -print
find /usr/contrib/src -name "xcmd" -depth -print
find /raid -type d -name ".local_sd_customize" -exec ls {} \;
find /raid -type d -name ".local_sd_customize" \
   -exec cp /raid/04d/MCAD-apps/I_Custom/SD_custom/site_sd_customize/user_filer_project_dirs {} \;
find . -name "rc.conf" -print
find . -name "rc.conf " -exec chmod o+r '{}' \; -print
find . -not (\ -name "*.v" -o -name "*,v" \) '{}' \; -print
=================================================================
Basic find command examples
This first Linux find example searches through the root filesystem ("/") for the file named "Chapter1". If it finds the file, it prints the location to the screen.
find / -name Chapter1 -type f -print

On Linux systems and modern Unix system you no longer need the -print option at the end of the find command, so you can issue it like this:
find / -name Chapter1 -type f

The "-f" option here tells the find command to return only files. If you don't use it, the find command will returns files, directories, and other things like named pipes and device files that match the name pattern you specify. If you don't care about that, just leave the "-type f" option off your command.

This next find command searches through only the /usr and /home directories for any file named "Chapter1.txt":
find /usr /home -name Chapter1.txt -type f

To search in the current directory -- and all subdirectories -- just use the . character to reference the current directory in your find commands, like this:
find . -name Chapter1 -type f

This next example searches through the /usr directory for all files that begin with the letters Chapter, followed by anything else. The filename can end with any other combination of characters. It will match filenames such as Chapter, Chapter1,Chapter1.bad, Chapter-in-life, etc.:
find /usr -name "Chapter*" -type f

This next command searches through the /usr/local directory for files that end with the extension .html. These file locations are then printed to the screen.
find /usr/local -name "*.html" -type f
Find directories with the Unix find command
Every option you just saw for finding files can also be used on directories. Just replace the -f option with a -d option. For instance, to find all directories named build under the current directory, use this command:
find . -type d -name build
Find files that don't match a pattern
To find all files that don't match a filename pattern, use the "-not" argument of the find command, like this:
find . -type f -not -name "*.html"

That generates a list of all files beneath the current directory whose filename DOES NOT end in ".html", so it matches files like *.txt, *.jpg, and so on.
Finding files that contain text (find + grep)
You can combine the Linux find and grep commands to powerfully search for text strings in many files.

This next command shows how to find all files beneath the current directory that end with the extension .java, and contain the characters StringBuffer. The -l argument to the grep command tells it to just print the name of the file where a match is found, instead of printing all the matches themselves:
find . -type f -name "*.java" -exec grep -l StringBuffer {} \;

(Those last few characters are required any time you want to exec a command on the files that are found. I find it helpful to think of them as a placeholder for each file that is found.)

This next example is similar, but here I use the -i argument to the grep command, telling it to ignore the case of the characters string, so it will find files that contain string, String, STRING, etc.:
find . -type f -name "*.java" -exec grep -il string {} \;
Acting on files you find (find + exec)
This command searches through the /usr/local directory for files that end with the extension .html. When these files are found, their permission is changed to mode 644 (rw-r--r--).
find /usr/local -name "*.html" -type f -exec chmod 644 {} \;

This find command searches through the htdocs and cgi-bin directories for files that end with the extension .cgi. When these files are found, their permission is changed to mode 755 (rwxr-xr-x). This example shows that the find command can easily search through multiple sub-directories (htdocs, cgi-bin) at one time.
find htdocs cgi-bin -name "*.cgi" -type f -exec chmod 755 {} \;
Running the ls command on files you find
From time to time I run the find command with the ls command so I can get detailed information about files the find command locates. To get started, this find command will find all the "*.pl" files (Perl files) beneath the current directory:
find . -name "*.pl"

In my current directory, the output of this command looks like this:
./news/newsbot/old/3filter.pl
./news/newsbot/tokenParser.pl
./news/robonews/makeListOfNewsURLs.pl

That's nice, but what if I want to see the last modification time of these files, or their filesize? No problem, I just add the "ls -ld" command to my find command, like this:
find . -name "*.pl" -exec ls -ld {} \;

This results in this very different output:
-rwxrwxr-x 1 root root 2907 Jun 15  2002 ./news/newsbot/old/3filter.pl
-rwxrwxr-x 1 root root 336 Jun 17  2002 ./news/newsbot/tokenParser.pl
-rwxr-xr-x 1 root root 2371 Jun 17  2002 ./news/robonews/makeListOfNewsURLs.pl

The "-l" flag of the ls command tells ls to give me a "long listing" of each file, while the -d flag is extremely useful in this case; it tells ls to give me the same output for a directory. Normally if you use the ls command on a directory, ls will list the contents of the directory, but if you use the -d option, you'll get one line of information, as shown above.
Find and delete
Be very careful with these next two commands. If you type them in wrong, or make the wrong assumptions about what you're searching for, you can delete a lot of files very fast. Make sure you have backups and all that, you have been warned.

Here's how to find all files beneath the current directory that begin with the letters 'Foo' and delete them.
find . -type f -name "Foo*" -exec rm {} \;

This one is even more dangerous. It finds all directories named CVS, and deletes them and their contents. Just like the previous command, be very careful with this command, it is dangerous(!), and not recommended for newbies, or if you don't have a backup.
find . -type d -name CVS -exec rm -r {} \;
Find files with different file extensions
The syntax to find multiple filename extensions with one command looks like this:
find . -type f \( -name "*.c" -o -name "*.sh" \)

Just keep adding more "-o" (or) options for each filename extension. Here's a link to
Case-insensitive file searching
To perform a case-insensitive search with the Unix/Linux find command, use the -iname option instead of -name. So, to search for all files and directories named foo, FOO, or any other combination of uppercase and lowercase characters beneath the current directory, use this command:
find . -iname foo

If you're just interested in directories, search like this:
find . -iname foo -type d

And if you're just looking for files, search like this:
find . -iname foo -type f
Find files by modification time
To find all files and directories that have been modified in the last seven days, use this find command:
find . -mtime -7

To limit the output to just files, add the "-type f" option as shown earlier:
find . -mtime -7 -type f

and to show just directories:
find . -mtime -7 -type d



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

UNIX-FILE SYSTEMS BASICS
12:38  AIX, Linux  No comments
A file system is a logical collection of files on a partition or disk. A partition is a container for information and can span an entire hard drive if desired.
Your hard drive can have various partitions which usually contains only one file system, such as one file system housing the / file system or another containing the /home file system.
One file system per partition allows for the logical maintenance and management of differing file systems.
Everything in Unix is considered to be a file, including physical devices such as DVD-ROMs, USB devices, floppy drives, and so forth.
Directory Structure:
Unix uses a hierarchical file system structure, much like an upside-down tree, with root (/) at the base of the file system and all other directories spreading from there.
A UNIX filesystem is a collection of files and directories that has the following properties:
It has a root directory (/) that contains other files and directories.
Each file or directory is uniquely identified by its name, the directory in which it resides, and a unique identifier, typically called an inode.
By convention, the root directory has an inode number of 2 and the lost+found directory has an inode number of 3. Inode numbers 0 and 1 are not used. File inode numbers can be seen by specifying the -i option to ls command.
It is self contained. There are no dependencies between one filesystem and any other.
The directories have specific purposes and generally hold the same types of information for easily locating files. Following are the directories that exist on the major versions of Unix:
Directory	Description
/	This is the root directory which should contain only the directories needed at the top level of the file structure.
/bin	This is where the executable files are located. They are available to all user.
/dev	These are device drivers.
/etc	Supervisor directory commands, configuration files, disk configuration files, valid user lists, groups, ethernet, hosts, where to send critical messages.
/lib	Contains shared library files and sometimes other kernel-related files.
/boot	Contains files for booting the system.
/home	Contains the home directory for users and other accounts.
/mnt	Used to mount other temporary file systems, such as cdrom and floppy for the CD-ROM drive and floppy diskette drive, respectively
/proc	Contains all processes marked as a file by process number or other information that is dynamic to the system.
/tmp	Holds temporary files used between system boots
/usr	Used for miscellaneous purposes, or can be used by many users. Includes administrative commands, shared files, library files, and others
/var	Typically contains variable-length files such as log and print files and any other type of file that may contain a variable amount of data
/sbin	Contains binary (executable) files, usually for system administration. For examplefdisk and ifconfig utlities.
/kernel	Contains kernel files
Navigating the File System:
Now that you understand the basics of the file system, you can begin navigating to the files you need. The following are commands you'll use to navigate the system:
Command	Description
cat filename	Displays a filename.
cd dirname	Moves you to the directory identified.
cp file1 file2	Copies one file/directory to specified location.
file filename	Identifies the file type (binary, text, etc).
find filename dir	Finds a file/directory.
head filename	Shows the beginning of a file.
less filename	Browses through a file from end or beginning.
ls dirname	Shows the contents of the directory specified.
mkdir dirname	Creates the specified directory.
more filename	Browses through a file from beginning to end.
mv file1 file2	Moves the location of or renames a file/directory.
pwd	Shows the current directory the user is in.
rm filename	Removes a file.
rmdir dirname	Removes a directory.
tail filename	Shows the end of a file.
touch filename	Creates a blank file or modifies an existing file.s attributes.
whereis filename	Shows the location of a file.
which filename	Shows the location of a file if it is in your PATH.
You can use Manage Help to check complete syntax for each command mentioned here.
The df Command:
The first way to manage your partition space is with the df (disk free) command. The command df -k (disk free) displays the disk space usage in kilobytes, as shown below:
$df -k
Filesystem      1K-blocks      Used   Available Use% Mounted on
/dev/vzfs        10485760   7836644     2649116  75% /
/devices                0         0           0   0% /devices
$
Some of the directories, such as /devices, shows 0 in the kbytes, used, and avail columns as well as 0% for capacity. These are special (or virtual) file systems, and although they reside on the disk under /, by themselves they do not take up disk space.
The df -k output is generally the same on all Unix systems. Here's what it usually includes:
Column	Description
Filesystem	The physical file system name.
kbytes	Total kilobytes of space available on the storage medium.
used	Total kilobytes of space used (by files).
avail	Total kilobytes available for use.
capacity	Percentage of total space used by files.
Mounted on	What the file system is mounted on.
You can use the -h (human readable) option to display the output in a format that shows the size in easier-to-understand notation.
The du Command:
The du (disk usage) command enables you to specify directories to show disk space usage on a particular directory.
This command is helpful if you want to determine how much space a particular directory is taking. Following command would display number of blocks consumed by each directory. A single block may take either 512 Bytes or 1 Kilo Byte depending on your system.
$du /etc
10     /etc/cron.d
126    /etc/default6      /etc/dfs
...
$
The -h option makes the output easier to comprehend:
$du -h /etc
5k    /etc/cron.d
63k   /etc/default3k    /etc/dfs
...
$
Mounting the File System:
A file system must be mounted in order to be usable by the system. To see what is currently mounted (available for use) on your system, use this command:
$ mount
/dev/vzfs on / type reiserfs (rw,usrquota,grpquota)
proc on /proc type proc (rw,nodiratime)
devpts on /dev/pts type devpts (rw)
$
The /mnt directory, by Unix convention, is where temporary mounts (such as CD-ROM drives, remote network drives, and floppy drives) are located. If you need to mount a file system, you can use the mount command with the following syntax:
mount -t file_system_type device_to_mount directory_to_mount_to
For example, if you want to mount a CD-ROM to the directory /mnt/cdrom, for example, you can type:
$ mount -t iso9660 /dev/cdrom /mnt/cdrom
This assumes that your CD-ROM device is called /dev/cdrom and that you want to mount it to /mnt/cdrom. Refer to the mount man page for more specific information or type mount -h at the command line for help information.
After mounting, you can use the cd command to navigate the newly available file system through the mountpoint you just made.
Unmounting the File System:
To unmount (remove) the file system from your system, use the umount command by identifying the mountpoint or device
For example, to unmount cdrom, use the following command:
$ umount /dev/cdrom
The mount command enables you to access your file systems, but on most modern Unix systems, the automount function makes this process invisible to the user and requires no intervention.
User and Group Quotas:
User and group quotas provide the mechanisms by which the amount of space used by a single user or all users within a specific group can be limited to a value defined by the administrator.
Quotas operate around two limits that allow the user to take some action if the amount of space or number of disk blocks start to exceed the administrator defined limits:
Soft Limit: If the user exceeds the limit defined, there is a grace period that allows the user to free up some space.
Hard Limit: When the hard limit is reached, regardless of the grace period, no further files or blocks can be allocated.
There are a number of commands to administer quotas:
Command	Description
quota	Displays disk usage and limits for a user of group.
edquota	This is a quota editor. Users or Groups quota can be edited using this command.
quotacheck	Scan a filesystem for disk usage, create, check and repair quota files
setquota	This is also a command line quota editor.
quotaon	This announces to the system that disk quotas should be enabled on one or more filesystems.
quotaoff	This announces to the system that disk quotas should be disabled off one or more filesystems.
repquota	This prints a summary of the disc usage and quotas for the specified file systems
You can use Manage Help to check complete syntax for each command mentioned here.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Up and down the directory tree
By Surya20:20No comments
Even if you've been using the cd command for years, you might be surprised at some of its features. After all, when did you last run man cd? (For a link to the documentation for the cd command, see Resources.) The cd command has a few little tricks that can save you lots of unnecessary typing. Considering how often you have to change directories, that's good news for you.

This article looks at the UNIX® directory structure and shows how you can see your current directory path and add your directory to your shell prompt. After looking at some simple cd examples, the article explains what is meant by the absolute path and the relative path and when to use each one. Then, I share some of my favourite time-saving cd shortcuts, such as how to get to your home directory and how to identify the home directory of any user. I show how to toggle back and forth between two directories and provide a little-known gem about cd that I like to call the cd shuffle. It's a simple way of moving between two similar directory paths.

Before looking at changing directories, however, it's important to understand a bit about the UNIX directory structure.
Uprooting the directory tree
What you may know as folders in Windows® operating systems are called directories in UNIX. A directory is a container that holds groups of files and other directories.

All directories in UNIX branch downward from the root directory, denoted by the forward slash (/). For example:

The directory /usr is a subdirectory of the root directory (/).
The /usr/spool directory is a subdirectory of /usr.
The /usr/spool/mail directory is a subdirectory of /usr/spool.
. . . and so on.
What directory am I in?
From a shell prompt, you can display the path name of the directory you're in by running the command pwd, shown in Listing 1. Remember this command as the present working directory.

Listing 1. Display the present working directory (pwd)
# pwd
# /home/surya
The abc of cd
To change to another directory, use cd followed by a space, and then the directory you want to go to. Remember that UNIX commands are case-sensitive, so make it all lowercase unless the directory name actually has uppercase letters in it. In the examples in Listing 2, each directory I'm changing to starts with a slash (/), because I'm using the absolute path, tracing the trail of directories all the way from the root directory.

Listing 2. The cd command using an absolute path
# cd /var
# cd /usr/spool/mail
# cd /home/surya
You can get to any directory at all—if you have permission (you need execute permission)—using its absolute path name. The commands in Listing 2 are provided as examples. You wouldn't ordinarily run two cd commands in a row, because the point of changing your working directory is to do some work in it, not to move on to somewhere else straight away.

If the directory you entered isn't a valid directory or you don't have permission to go there, the cd command reports an error. If your cd command fails, then you stay in the directory you started from.
Where am I?
Okay. Your cd command didn't report any failures, so you assume that it worked. But it would be nice to know for sure which directory you're now in.

Of course, you could run the pwd command every time you need to check the current working directory, but there's a better way. Whenever you run the cd command successfully, the new working directory is stored in the environmental variable $PWD (Present Working Directory). Note that this variable is in uppercase letters, unlike the pwd command. So, you could display the value of $PWD using echo, as you can see in Listing 3.
Listing 3. Display $PWD
# echo $PWD
# /home/surya
Doesn't seem much easier than running that pwd command you saw earlier, does it? Still, it's helpful to know that your directory is stored in a variable. Here's why: You can display the value of $PWD as part of the shell prompt.
Prompt my working directory
In the examples used so far, the shell prompt is set to the hash, or pound, symbol (#). But if you include $PWD in your shell prompt, you always know what directory you're in. Then, when you run cd, the variable PWD will be updated and displayed as part of the shell prompt.

You can set the shell prompt variable PS1 in your .profile in your home directory by adding the lines shown in Listing 4.

Listing 4. Include $PWD in the shell prompt
PS1='${PWD} > '
export PS1
When you next log in, your .profile should execute as part of the login process, and this should display the working directory as part of the shell prompt. If you know how to get to your home directory, you could execute the .profile right now (see Listing 5).

Listing 5. Execute your new .profile with the new shell prompt
# . ./.profile
/home/surya >
You can tailor the prompt to include the host name, your login name, or some other display characters. For details about enhancing the shell prompt, see the link to the article "Tip: Prompt magic" in Resources.
Relatively better
It's a bit cumbersome using absolute paths when you only want to jump from one branch of the tree to another nearby. That's why cd allows you to use relative paths. By default, the relative path refers to the directory relative to the current directory you are in. Using the relative path often means fewer keystrokes, although that depends on the directory you are going from and the one you're headed to.

To get from /home/surya to /home/surya/bin, for example, you don't have to enter the absolute path of the target directory (/home/surya/bin); it's enough to enter the new path relative to the one you're already in, as you can see in Listing 6.

Listing 6. The cd command using a relative path
/home/surya > cd bin
/home/surya/bin >
Notice how the shell prompt shows the new value for $PWD.
Visit your parents
If you run the ls command using the -a flag, you can see an entry for . (dot) and another for .. (dot-dot). The single dot represents the current directory. The two dots are for the parent directory—the one immediately above the directory you're in.

Using the parent directory is handy when you want to go up a level via cd. Listing 7 shows how.

Listing 7. Using the cd command to go to the parent directory (dot-dot) 
/var/spool/mqueue > cd ..
/var/spool > 
You can then head down to a new sub-directory (see Listing 8 ).

Listing 8. Using cd to go to a sub-directory
/var/spool > cd mail
/var/spool/mail >
Or, you could do all of that in a single command, as you see in Listing 9.

Listing 9. Branch to branch in one command
/var/spool/mqueue > cd ../mail
/var/spool/mail >
You can even jump up a couple of levels, and then down a couple, as shown in Listing 10.

Listing 10. Jump through branches
/usr/IBM/WebSphere/AppServer/profiles > cd ../../PortalServer/log
/usr/IBM/WebSphere/PortalServer/log > 
Once you get used to using the relative path, it becomes second nature.
The shortcut home
Every UNIX user has a home directory that is defined when the user is created. You could look up your home directory in /etc/passwd or use smit, but there's a better way of getting home.

Using cd straight to home
If you want to get to your own home directory, use the cd command without any parameters, as shown in Listing 11.

Listing 11. Fast-track home with cd
/usr/IBM/WebSphere/PortalServer/log > cd
/home/surya >
Your home directory is stored in the variable $HOME. That means that the cd command without parameters is equivalent to typing cd $HOME (see Listing 12).

Listing 12. cd $HOME
/var/spool/mail > cd $HOME
/home/surya >
That $HOME variable is useful for knowing your home directory even if you're not headed there just yet. In fact, the $HOME variable can be so helpful that it's got an alias: the tilde (~).

Call home, tilde

You may want to view or work on files in your home directory. If you're in some other directory, there's no need to go home first or to type the full directory path. Just use the tilde character. In Listing 13, I make a copy of my .profile in my home directory, all from the comfort of somewhere else.

Listing 13. Tilde shortcut for $HOME
/usr/IBM/WebSphere > cp ~/.profile ~/.profile.save
Remote access to your neighbour's home
You can also use tilde to list or work with files in another user's home directory (if your permissions allow it). To do this, just use tilde followed by the user's login name, as Listing 14 shows.

Listing 14. Tilde is everyone's HOME
/home/surya > cp ~john/.profile ~john/.profile.save
This is safer than guessing the user's home directory and easier than looking it up in /etc/passwd.
Dashing back
Quite often, you need to change directory only to run a command or two, and then return to the directory you were in previously ($OLDPWD). To do that, use the cd dashback. That's cd followed by a dash (cd -). In Listing 15, notice how the $PS1 shell prompt displays the new directory each time I run cd.

Listing 15. Return to previous directory
/home/surya > cd /usr/sys/inst.images
/usr/sys/inst.images > cd -
/home/surya >
The toggle switch
A consequence of this cd dashback is that if you enter it twice, you can toggle back and forth between two directories. This functionality could be useful if you wanted to change a program or configuration file in one directory and see the results in a log file in a different directory. Listing 16 shows the toggle between two directories. As with the other examples, I'm skipping the commands you might run right after you've actually changed directory.

Listing 16. Toggle between $PWD and $OLDPWD
/data/log > cd /apps/config
/apps/config > cd -
ps/config >
/data/log > cd -
/a
p
The cd shuffle
The feature that I find especially helpful is the cd shuffle. It's a simple way of switching from an old directory to a new one when the two directory paths have only one difference, such as a single word.

The syntax may look odd to UNIX old hands if they have never used it, but it works. See Listing 17.

Listing 17. cd shuffle syntax
cd directorya directoryb
The first parameter is the string you want to replace in the current directory path. The second parameter is the replacement string. For example, to move from v7 to v8, you just type cd v7 v8, as you can see in Listing 18.

Listing 18. Using cd shuffle
/programs/v7/reports/monthly > cd v7 v8
/programs/v8/reports/monthly >
That single command has saved 19 keystrokes! That's much simpler than going up three parent directories, and then heading back down the directory tree or using the absolute path.

This two-parameter cd command has lots of uses: swapping between similar directory paths where the only difference is a database instance name, a branch name, or maybe a date. The cd shuffle can save you thousands of keystrokes in a very short time.
Jump through history
If you have a directory for each year and each month of history, cd shuffle allows you to jump around from one year to another. See how it works in Listing 19.

Listing 19. New year
/hist/2010/april/reports > cd 2010 2011
/hist/2011/april/reports >
If you want to change to a different month within the same year, use cd shuffle with the from month and the to month as its parameters, as shown in Listing 20.

Listing 20. Swap month directory
/hist/2011/april/reports > cd april may
/hist/2011/may/reports > 
If two directory paths have only one string different, cd shuffle is ideal.
Is cd okay?
When I use cd in scripts, I always verify that the change directory has worked before continuing with the next command. I once saw an operating system wiped out by a two-line cleanup script that had been working every day for two years. An NFS-mounted directory became unavailable when a remote host was turned off. The cd command failed, and the cleanup script continued anyway until there was nothing left on the system to clean up.

A simple way of verifying that cd worked before proceeding with something else is to use the shell short-circuit && straight after a cd command. If the cd command fails, the next command won't continue. See Listing 21.

Listing 21. cd and short-circuit
cd /some/dir && rm *.log
Conclusion
In this article, you learned about the cd command. You saw how to change directories using the absolute path and the relative path, and you learned how to display the working directory you are in and toggle back and forth between two directories. You saw different ways of referring to home directories, and you learned about the little-known cd shuffle, which allows you to substitute a string in your current path and switch to a new path.

The cd command is so important on the command line, and it's used so often, that it's worth knowing some of its many shortcuts.

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Using AIX Tools to Debug Network Problems
By Surya01:461 comment
Question
Using AIX Tools to Debug Network Problems
Answer
This document discusses some standard AIX commands that can check for network connectivity or performance problems.

From time to time users may be unable to access servers via their client applications or they may experience performance problems. When application and system checks do not indicate the problem, the system administrator may need to check the network or the system's network settings to find the problem. Using standard AIX tools, you can quickly determine if a server is experiencing a network problem due to configuration or network issues. These tools include thenetstat and tcpdump commands, which can help you isolate problems, from loss of connectivity to more complex network performance problems.

Basic tools and the OSI-RM
Using the netstat command
Using the tcpdump command
Basic tools and the OSI-RM
The AIX commands you can use for a quick checkup include the lsdev, errpt, netstat and tcpdump commands. With these tools, you can assess the lower layers of your system's network configuration within the model known as the Open Systems Interconnection (OSI) Reference Model (RM) (see Table 1). Using the OSI-RM allows you to check common points of failure, without spending too much time looking at elusive errors that might be caused by loss of network access within an application.
Open Systems Interconnection Reference Model
 Model Layer           Function                         Assessment Tools
             
7. Application Layer  Consists of application          . 
                      programs that use the network.
6. Presentation Layer Standardizes data presentation 
                      to the applications.
5. Session Layer      Manages sessions between 
                      applications.
4. Transport Layer    Organizes data grams into        netstat -s 
                      segments and reliably delivers   iptrace 
                      them to upper layers.            tcpdump
3. Network Layer      Manages connections across the   netstat -in, -rn, -s, -D
                      network for the upper layers.    topas
                                                       iptrace
                                                       tcpdump
2. Data Link Layer    Provides reliable data delivery  netstat -v, -D
                      across the physical link.        iptrace
                                                       tcpdump
1.  Physical Layer    Defines the physical             netstat -v, -D 
                      characteristics of the           lsdev -C
                      network media.                   errpt
                                                       iptrace
                                                       tcpdump
Using the netstat command
One of the netstat tools, the netstat -v command, can help you decide if corrective action needs to be taken on the server or elsewhere in the network. Output from this command is the same as the entstat, tokstat, fddistat, and atmstat commands combined. The netstat -v command assesses the physical and data link layers of the OSI-RM. Thus, it is one of the first commands you should use, after determining that there is no hardware availability problem. (The errpt andlsdev -C commands can help determine availability.) The netstat -v output can indicate whether you need to adjust configuration of a network adapter (to reestablish or improve communications) or tune an adapter for better data throughput.
Sample scenario
A simple scenario illustrates how the netstat -v command helps determine why a system is not communicating on its network.

The scenario assumes a system with the following characteristics:
An IBM 4-Port 10/100 Mbps Ethernet PCI Adapter (ent0 - ent3)
An onboard IBM 10/100 Mbps Ethernet PCI Adapter (ent4)
A single cable connected to one of the ports on the four-port adapters
A single IP address configured, on en0, which also maps to one of the logical devices (ent0) on the 4-Port card
The problem: Since TCP/IP was configured on en0, the system has been unable to ping any system on the network.
Example 1
The lsdev -C and errpt commands were used to verify the availability of the adapter and interface.'

The netstat -in command (interface configuration) and the netstat -rn (route configuration) command were used to check the IP configuration.

After the first two preliminary steps, the next step is to use the netstat -v command to review specific statistics for adapter operations. Without a filter, thenetstat -v command produces at least 10 screens of data, so this examples uses the netstat -v ent0 command to limit the output as follows:

netstat -v ent0 | grep -p "Specific Statistics"

The RJ45 Port Link Status line in the sample output indicates whether or not the adapter has a link to the network. In this example, the RJ45 Port Link Status is down. 
IBM 4-Port 10/100 Base-TX Ethernet PCI Adapter Specific Statistics:
------------------------------------------------
Chip Version: 26
RJ45 Port Link Status : down
Media Speed Selected: Auto negotiation
Media Speed Running: 100 Mbps Full Duplex
Receive Pool Buffer Size: 384
Free Receive Pool Buffers: 128
No Receive Pool Buffer Errors: 0
Inter Packet Gap: 96
Adapter Restarts due to IOCTL commands: 1
Running netstat -v a second time without a filter allows you to check the port link status for every adapter. For example, enter:

netstat -v | more

and then use /Specific as the search string for the more command. In this example, such a search shows that ent3, not ent0, shows a port link status ofup. This information indicates that the cable is in the wrong port on the 4-Port Adapter, and that moving the cable to the correct (that is, configured) port fixes the problem.
Example 2
Interpreting the portion of the netstat -v output that indicates adapter resource configuration can help isolate a system configuration problem. When setting up servers that provide for network backup (such as, TSM or SysBack), administrators commonly do some preliminary testing and achieve good results. Then, as more remote servers are added to the backup schedule, performance can decrease. Where network throughput was once good, but then has decreased, netstat -v can uncover potential problems with adapter resources.

Many modern adapters have tunable buffers that allow you to adjust the resources a device can obtain. When a backup server requires extensive resources to handle data reception, looking at the output of netstat -v for Receive Statistics and for Adapter Specific Statistics can help isolate potential network performance bottlenecks. It is not uncommon to see errors in the Adapter Specific section of the 10/100 Mbps adapter that indicate "No Receive Pool Buffer Errors". In Example 2 the netstat -v command is run twice, 30 seconds apart, while the server is handling several backup jobs. The output shows the default setting of 384 on the receive pool buffer needs to be adjusted higher. As long as no other errors suggesting additional problems show up in the output, you can safely assume that performance will improve when the receive pool buffer on ent4 is adjusted.
Run the following command to see specific statistics for en4:

netstat -v ent4 | grep -p "Specific Statistics"

Command output is similar to the following:
IBM 4-Port 10/100 Base-TX Ethernet PCI Adapter Specific Statistics:
------------------------------------------------
Chip Version: 26
RJ45 Port Link Status : up
Media Speed Selected: Auto negotiation
Media Speed Running: 100 Mbps Full Duplex
Receive Pool Buffer Size: 384
Free Receive Pool Buffers: 128
No Receive Pool Buffer Errors: 999875
Inter Packet Gap: 96
Adapter Restarts due to IOCTL commands: 1
Run the following commands to check the No Receive Pool Buffer Errors after 30 seconds:

sleep 30 ; netstat -v ent4 | grep "Receive Pool Buffer Errors"

Output is similar to the following:
No Receive Pool Buffer Errors: 1005761
Using the tcpdump command
The netstat tools (netstat -in, netstat -rn and netstat -v) cannot always determine the nature of a connection problem.
Example 3
Suppose your server has four separate network adapters configured and attached to separate network segments. Two are working fine (VLAN A and B) while no connections can be established to your server on the other two segments (VLAN C and D). The output of netstat -v shows that data is coming in on all four adapters and no errors are being logged, indicating that the configuration at the physical and data link layers is working. In such a case, you need to examine the inbound data itself. You can use the tcpdump tool to examine the data online to help you determine the connection problem.

The tcpdump command provides much data, but for quick analysis only some basics pieces of its output (IP addresses) are needed:
You also want to consider the logical configuration you have set up for your interfaces (netstat -in). In this example, en2 was configured with address 9.3.6.225 and is in VLAN C (IP network 9.3.6.224, netmask 255.255.255.240); en3 was configured with address 9.3.6.243 and is in VLAN D (IP network 9.3.6.240, netmask 255.255.255.240).

Run the following command to check traffic on en2:

tcpdump -i en2 -I -n

Output similar to the following is displayed:
-TIME STAMP-    -SOURCE IP-    -DESTINATION IP-   -FLAG   -ADDITION INFO- 
09:04:27.313527323 9.3.6.244.23 > 9.3.6.241.38160: P 7:9(2) ack 8 win 
65535
09:04:27.402377282 9.3.6.245.45017 > 9.53.168.52.23: . ack 24 win 
17520 (DF) [tos 0x10]
09:04:27.418818536 9.3.6.241.38160 > 9.3.6.244.23: . ack 9 win 65535 
[tos 0x10
09:04:27.419054751 9.3.6.244.23 > 9.3.6.241.38160: P 9:49(40) ack 8 
win 65535
09:04:27.524512144 9.3.6.245.45017 > 9.53.168.52.23: P 4:5(1) ack 24 
win 17520 (DF) [tos 0x10]
09:04:27.526159054 9.53.168.52.23 > 9.3.6.245.45017: P 24:25(1) ack 5 
win 2482 (DF)
09:04:27.602600775 9.3.6.245.45017 > 9.53.168.52.23: . ack 25 win 
17520 (DF) [tos 0x10]
09:04:27.628488745 9.3.6.241.38160 > 9.3.6.244.23: . ack 49 win 65535 
[tos 0x1
Press Ctrl-C to stop the output display:

^C
38 packets received by filter
0 packets dropped by kernel
Useful data can be gained from the tcpdump output simply by recognizing the source IP addresses in the traffice (shown in bold type in the sample output). Thus, the sample output shows that ent2 is physically attached to the wrong network segment. The source IP addressses should be in the 9.2.6.22x range, not the 9.3.6.24x range. It is possible that swapping the cables for ent2 and ent3 may solve the problem. If not, you may need to ask your network administrator to reconfigure switch ports to pass the correct traffic. With the information you gain from using the netstat -v and tcpdump tools, you can better decide which action is most appropriate.

AIX provides many tools for querying TCP/IP status on AIX servers. However, the netstat and tcpdump commands do provide some methods for quick problem determination. For example, these tools can help determine if you own the problem or if it needs to be addressed by a network administrator.

For additional information, please refer to AIX Online Documents at the following URL: Link


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Using uuencode to embed binaries in scripts and copy/paste transfer files between servers
By Surya01:04No comments
The uuendiv utility converts binary to text, and uudediv converts the text back to binary.   Wikipedia has a great article on the details of how this proces works (http://en.wikipedia.org/wiki/Uuencoding) 

These utilities create some interesting possibilities.    In this posting I'll cover embeding binary files in scripts and cover how to copy/paste transfer files between servers.
Embeding binary files in a script
If you have a script that also needs to include a binary file, you can uuendiv it and include it within the script itself.  So if you are writing a script to install/setup a binary you could actually also embed the binary within the script itself.   

Here is an example of what this would look like:
#!/usr/bin/ksh
echo this script will extract a binary file
echo the script could also do any other normal scripting stuff here

uudediv -o /tmp/testbinaryfile << 'ENDOFFILE'
<insert uuendiv output of the binary here>
ENDOFFILE

echo the /tmp/testbinaryfile has been extracted
To get the uuendiv output of the binary run a command like this:   uuendiv /usr/bin/ls /dev/stdout .  Take the output and replace the "<insert uuendiv output of the binary here>" text in the example with the uuendiv output.  
When the script runs, the file will be extracted.
Copy/Paste transfer files across servers
If you have a relatively small binary file that you need to transfer between servers, you can easily transfer it by copying and pasting it using uuendiv/uudediv.  This can be a time saver in some circumstances.   It also might be helpful if you have a server that isn't connected to the network but for which you can get a console on through something like the HMC. 

In this example, we will copy and paste the /usr/bin/ls binary between servers. 

On the source server, type:
uuendiv /usr/bin/ls /dev/stdout
Then copy all of the output in to the clipboard.

On the destination server, type:
uudediv -o /tmp/ls
Then press enter, and then paste in the uuendiv output from the source server.   The copy/pasted "ls" binary will be saved to /tmp/ls.   You can verify the source and destination "ls" files are identical by comparing the checksum of the files with the "csum" command.  


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Versions POWER/PowerPC releases
By Surya09:02No comments


AIX 7.1, September 10, 2010[3] 
AIX 6.1, November 9, 2007[2] 
AIX 5L 5.3, August 13, 2004[3] 
AIX 5L 5.2, October 18, 2002[4], end of support April 30, 2009[5] 
AIX 5L 5.1, May 4, 2001 (Support discontinued April 1, 2006)[7] 
AIX 4.3.3, September 17,1999 
AIX 4.3.2, October 23,1998 
AIX 4.3.1, April 24,1998 
AIX 4.3, October 31,1997 
AIX 4.2.1, April 25,1997 
AIX 4.2, May 17,1996 
AIX 4.1.5, November 8,1996 
AIX 4.1.4, October 20,1995 
AIX 4.1.3, July 7,1995 
AIX 4.1.1, October 28,1994 
AIX 4.1, August 12,1994 
AIX 4.0, 1994 
AIX 3.2 1992 
AIX 3.1, February 1990 
IBM PS/2 releases 
IBM 6150 RT releases


AIX V7 7.1, Sept 10, 2010[3] 

AIX 5.2 Workload Partitions for AIX 7
Support for export of fibre channel adapters to WPARs
VIOS disk support in a WPAR
Cluster Aware AIX

AIX 6.1, November 9, 2007[2] 

Workload Partitions (WPARs) operating system-level virtualization
Live Application Mobility
Live Partition Mobility
Security

Role Based Access Control RBAC
AIX Security Expert - A system and network security hardening tool
Encrypting JFS2 filesystem
Trusted AIX
Trusted Execution


Integrated Electronic Service Agent(tm) for auto error reporting
Concurrent Kernel Maintenance
Kernel exploitation of POWER6 storage keys
ProbeVue dynamic tracing
Systems Director Console for AIX
Integrated filesystem snapshot


AIX 5L 5.3, August 13, 2004[3] 

NFS Version 4
Advanced Accounting
Virtual SCSI
Virtual Ethernet
Exploitation of Simultaneous multithreading (SMT)
Micro-Partitioning enablement
POWER5 exploitation
JFS2 quotas
Ability to shrink a JFS2 filesystem
kernel scheduler has been enhanced to dynamically increase and decrease the use of virtual processors.

AIX 5L 5.2, October 18, 2002[4], end of support April 30, 2009[5] 

Ability to run on the IBM BladeCenter JS20 with the PowerPC 970.
Minimum level required for POWER5 hardware
MPIO for Fibre Channel disks
iSCSI Initiator software
Participation in Dynamic LPAR
Concurrrent I/O (CIO) feature introduced for JFS2 released in Maintenance Level 01 in May 2003[6]

AIX 5L 5.1, May 4, 2001 (Support discontinued April 1, 2006)[7] 

Ability to run on an IA-64 architecture processor, although this never went beyond beta[8]
Minimum level required for POWER4 hardware and the last release that worked on the Micro Channel architecture
64-bit kernel, installed but not activated by default
JFS2
Ability to run in a Logical Partition on POWER4
The L stands for Linux affinity
Trusted Computing Base (TCB)
Support for mirroring with striping


AIX 4.3.3, September 17,1999 

Online backup function
Workload Manager (WLM)
Introduction of topas utility

AIX 4.3.2, October 23,1998 AIX 4.3.1, April 24,1998 AIX 4.3, October 31,1997 

Ability to run on 64-bit architecture CPUs
IPv6
Web-based System Manager

AIX 4.2.1, April 25,1997 

NFS Version 3

AIX 4.2, May 17,1996 AIX 4.1.5, November 8,1996 AIX 4.1.4, October 20,1995 AIX 4.1.3, July 7,1995 

CDE 1.0 became the default GUI environment, replacing Motif X Window Manager.

AIX 4.1.1, October 28,1994 AIX 4.1, August 12,1994 AIX 4.0, 1994 

Run on RS/6000 systems with PowerPC processors and PCI busses.

AIX 3.2 1992 AIX 3.1, February 1990 

Journaled File System (JFS) filesystem type

AIX 3.0 1989 

LVM (Logical Volume Manager) was incorporated into OSF/1, and in 1995 for HP-UX[9], and the Linux LVM implementation is similar to the HP-UX LVM implementation.[10]
SMIT was introduced.
IBM PS/2 releases 

AIX PS/2 v1.1, 1989 

last version was 1.3, 1992.
IBM 6150 RT releases 

AIX v1.0, 1986 AIX v2.0 

last version was 2.2.1.


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

VMM concepts
By Surya20:43No comments

Virtual-memory segments are partitioned in units called pages; each page is either located in real physical memory (RAM) or stored on disk until it is needed. AIX uses virtual memory to address more memory than is physically available in the system. The management of memory pages in RAM or on disk is handled by the VMM.

A page is a fixed-size block of data (usually 4096 byte). A page might be resident in memory (that is, mapped into a location in physical memory), or a page might be resident on a disk (that is, paged out of physical memory into paging space or a file system).

The VMM maintains a free list of available page frames. The VMM also uses a page-replacement algorithm to determine which virtual-memory pages currently in RAM will have their page frames reassigned to the free list.

AIX tries to use all of RAM all of the time, except for a small amount which it maintains on the free list. To maintain this small amount of unallocated pages the VMM uses page outs and page steals to free up space and reassign those page frames to the free list.

overhead             -- The load that AIX incurs while sharing resources between user processes and performing its internal accounting.
page                 -- A fixed-size (4KB) block of memory.
page fault           -- It occurs when a process tries to access an address in virt mem. that does not have a location in physical memory.
                        In response, the system tries to load the appropriate data from the hard disk
page stealing daemon -- The daemon responsible for releasing pages of memory for use by other processes
                        (It makes room for incoming pages, by swapping out mem. pages that are not the part of the working set of a process.)
paging in            -- Reading pages from swap.
paging out           -- Releasing pages of physical memory for use.

Kernel continuously checks to see if the number of pages on the free list is below a threshold. If so the page stealing daemon, becomes active and begins copying pages to the swap area, starting with least recently used pages. Each page placed on the free list then becomes available for use by other processes. Pages written out to swap must be read back into physical memory when the process needs them again.

The AIX VMM integrates cached file data with the management of other types of virtual memory (for example, process data, process stack, and so forth). It caches the file data as pages, just like virtual memory for processes.

(In most modern computer systems, each thread has a reserved region of memory referred to as its stack.)
------------------
Working Storage
Working storage pages are pages that contain volatile data (in other words, data that is not preserved across a reboot).

Examples of virtual memory regions that consist of working storage pages are:

    - Process data
    - Stack
    - Shared memory
    - Kernel data

When modified working storage pages need to be paged out (moved from memory to the disk), they are written to paging space. Working storage pages are never written to a file system.

When a process exits, the system releases all of its private working storage pages. Thus, the system releases the working storage pages for the data of a process and stack when the process exits.
Permanent Storage
Permanent storage pages are pages that contain permanent data (that is, data that is preserved across a reboot). This permanent data is just file data. So, permanent storage pages are basically just pieces of files cached in memory.

When a modified permanent storage page needs to be paged out (moved from memory to disk), it is written to a file system.

You can divide permanent storage pages into two sub-types:

    - Non-client pages (aka persistent pages): these are pages containing cached Journaled File System (JFS) file data
    - Client pages: These are pages containing cached data for all other file systems (for example, JFS2 and Network File System (NFS)

------------------

In order to help optimize which pages are selected for replacement by the page replacement daemons, AIX classifies pages into one of two types:

    - Computational pages: pages used for the text, data, stack, and shared memory of a process
    - Non-computational pages: pages containing file data for files that are being read and written.

All working storage pages are computational. A working storage page is never marked as non-computational.

Depending on how you use the permanent storage pages, the pages can be computational or non-computational. If a file contains executable text for a process, the system treats the file as computational and marks all of the permanent storage pages in the file as computational. If the file does not contain executable text, the system treats the file as non-computational file and marks all of the pages in the file as non-computational.

Once a file has been marked as computational, it remains marked as a computational file until the file is deleted (or the system is rebooted). Thus, a file remains marked as computational even after it is moved or renamed.
------------------
Page replacement
The AIX page replacement daemons scan memory a page at a time to find pages to evict in order to free up memory. The page replacement daemons must choose pages carefully to minimize the performance impact of paging on the system, and the page replacement daemons target pages of different classes based on tunable parameter settings and system conditions.

There are a number of tunable parameters that you can use to control how AIX selects pages to replace.

------------------
minperm and maxperm
The two most basic page replacement tunable parameters are minperm and maxperm. These tunable parameters are used to indicate how much memory the AIX kernel should use to cache non-computational pages. The maxperm tunable parameter indicates the maximum amount of memory that should be used to cache non-computational pages. The minperm limit indicates the target minimum amount of memory that should be used for non-computational pages.

By default, maxperm is an "un-strict" limit, so it allows more non-computational files to be cached in memory when there is available free memory. The maxperm limit can be made a "strict" limit by setting the strict_maxperm tunable parameter to 1.
(The disadvantage of this is, that the number of non-computational pages cannot grow beyond maxperm and consume more memory when there is free memory on the system.)
numperm (lru_file_repage)
The number of non-computational pages is referred to as numperm: The vmstat -v command displays the numperm value for a system as a percentage of a system’s real memory.

When the number of non-computational pages (numperm) is greater than or equal to maxperm, the AIX page replacement daemons strictly target non-computational pages (for example, cached files that are not executables).

When the number of non-computational pages (numperm) is less than or equal to minperm, the AIX page replacement daemons target both computational and non-computational pages. In this case, AIX scans both classes of pages and evicts the least recently used pages.

When the number of non-computational pages (numperm) is between minperm and maxperm, the lru_file_repage (least recently used) tunable parameter controls what kind of pages the AIX page replacement daemons should steal.

Thus, the lru_file_repage tunable parameter can be set to 0. In this case, the AIX kernel always targets non-computational pages when numperm is between minperm and maxperm.

In most customer environments, it is most optimal to just have the kernel always target non-computational pages, because paging computational pages (for example, a process’s stack, data, and so forth) usually has a much higher performance cost on a process than paging non-computational pages (that is, data file cache). Thus, the lru_file_repage tunable parameter can be set to 0. In this case, the AIX kernel always targets non-computational pages when numperm is between minperm and maxperm

------
maxclient
The maxclient tunable parameter specifies a limit on the maximum amount of memory that should be used to cache non-computational client pages. Because all non-computational client pages are a subset of the total number of non-computational permanent storage pages, the maxclient limit must always be less than or equal to the maxperm limit.
numclient
The number of non-computational client pages is referred to as numclient. The vmstat -v command displays the numclient value for a system as a percentage of a system’s real memory.
By default, the maxclient limit is a strict limit. This means that the AIX kernel does not allow the non-computational client file cache to exceed the maxclient limit (that is, the AIX kernel does not allow numclient to exceed maxclient). When numclient reaches the maxclient limit, the AIX page replacement daemons strictly target client pages.

------
minfree, maxfree
Two other important parameters are minfree and maxfree. If the number of pages on your free list (vmstat -v: free pages) falls below the minfree parameter, VMM starts to steal pages (just to add to the free list), which is not good. It continues to do this until the free list has at least the number of pages in the maxfree parameter.

# vmstat -v                <-- for non-computational file-cache
       4980736 memory pages
        739175 lruable pages
        432957 free pages
             1 memory pools
         84650 pinned pages
          80.0 maxpin percentage
          20.0 minperm percentage      <<- system’s minperm% setting
          80.0 maxperm percentage      <<- system’s maxperm% setting
           2.2 numperm percentage      <<- % of memory containing non-comp. pages
         16529 file pages              <<- # of non-comp. pages
           0.0 compressed percentage
             0 compressed pages
           2.2 numclient percentage    <<- % of memory containing non-comp. client pages
          80.0 maxclient percentage    <<- system’s maxclient% setting
         16503 client pages            <<- # of client pages

So, in the above example, there are 16529 non-computational file pages mapped into memory. These non-computational pages consume 2.2 percent of memory. Of these 16529 non-computational file pages, 16503 of them are client pages.

The vmstat output does not provide information about computational file pages. Information about computational file pages can be gathered from the svmon command
# svmon -G                <--in memory pages of each type (work, pers., client)
               size      inuse       free        pin    virtual
memory       786432     209710     576722     133537     188426
pg space     131072       1121

               work       pers       clnt
pin          133537          0          0
in use       188426          0      21284

    - work: working storage
    - pers: persistent storage (persistent storage pages are non-client pages - that is, JFS pages.)
    - clnt: client storage

For each page type, svmon displays two rows:

    - in use: number of 4K pages mapped into memory
    - pin: number of 4K pages mapped into memory and pinned (pin is a subset of inuse)

So, in the above example, there are 188426 working storage pages mapped into memory. Of those 188426 working storage pages, 133537 of them are pinned (that is, can’t be paged out).

There are no persistent storage pages (because there are no JFS filesystems in use on the system). There are 21284 client storage pages, and none of them are pinned.

The svmon command does not display the number of permanent storage pages, but it can be calculated from the svmon output. As mentioned earlier, the number of permanent storage pages is the sum of the number of persistent storage pages and the number of client storage pages. So, in the above example, there are a total of 21284 permanent storage pages on the system:

0 persistent storage pages + 21284 client storage pages = 21284 permanent storage pages

The type of information reported by svmon is slightly different than vmstat. svmon  reports information about the number of in-memory pages of different types: working, persistent (that is, non-client), and client. svmon does not report information about computational versus non-computational. svmon just reports the total number of in-memory pages of each page type.

In contrast, vmstat reports information about non-computational versus computational pages.

To illustrate this difference, consider the above example of svmon output. Some of the 21284 client pages will be computational, and the rest of the 21284 client pages will be non-computational. To determine the breakdown of these client pages between computational and non-computational, use the vmstat command to determine how many of the 21284 client pages are non-computational.
-----------
suggested:
lru_file_repage = 0
maxperm = 90%
maxclient = 90%
minperm = 3%
strict_maxclient = 1 (default)
strict_maxperm = 0 (default)

# vmo -p -o lru_file_repage=0 -o maxclient%=90 -o maxperm%=90 -o minperm%=3
# vmo -p -o strict_maxclient=1 -o strict_maxperm=0

The above tunable parameters settings are the default settings for AIX Version 6.1.
-----------------------------
minfree: Minimum acceptable number of real-memory page frames in the free list. When the size of the free list falls below this number, the VMM begins stealing pages. It continues stealing pages until the size of the free list reaches maxfree.

-----------------------------
An example:
topas:
 MEMORY
 Real,MB   26623
 % Comp     57          <--this is used for processes (OS+appl.), if you add nmon Process+System, for me it was the same (46+11)
 % Noncomp  22          <--fs cache
 % Client   22          <--fs cache (for jfs2)

nmon:
 FileSystemCache
 (numperm) 22.5%        <--this is for fs cache
 Process   46.0%        <--this is for appl. processes
 System    11.3%        <--this is for the OS
 Free      20.2%        <--free
           -----
 Total    100.0%

-----------------------------
Excerpts from a tuning docs:

Set vmo:lru_file_repage=0; default=1  # Mandatory critical change

This change directs lrud to steal only JFS/JFS2 file-buffer pages unless/until numperm/numclient is less-than/equal-to vmo:minperm%, at which point lrud begins stealing both JFS/JFS2 file-buffer pages and computational memory pages.

Essentially stealing computational memory invokes pagingspace-pageouts.

I have found this change already made by most AIX 5.3 customers.

Set vmo:page_steal_method=1; default=0  # helpful, not critical

This change switches the lrud page-stealing algorithm from a physical memory address page-scanning method (=0) to a List-based page-scanning method (=1).

Set ioo:sync_release_ilock=1; default=0  # helpful, not critical

Default value =0 means that the i-node lock is held while all dirty pages of a file are flushed; thus, I/O to a file is blocked when the syncd daemon is running. Setting =1 will cause a sync() to flush all I/O to a file without holding the i-node lock, and then use the  i-node lock to do the commit.

Execute vmstat -v and compare the following values/settings:

minperm    should be 10, 5 or 3; default=20  
maxperm    should be 80 or higher; default=80 or 90
maxclient    should be 80 or higher; default=80 or 90
numperm    real-time percent of non-computational memory (includes client below)
numclient    real-time percent of JFS2/NFS/vxfs filesystem buffer-cache

paging space page outs are triggered when numperm or numclient is less-than-or-equal-to minperm.  

Typically numperm and numclient is greater than minperm, and as such, no paging space page outs can be triggered.

paging space page outs are triggered when numperm or numclient is less-than-or-equal-to minperm.  Typically numperm and numclient is greater than minperm, and as such, no paging space page outs can be triggered.



------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

UNIX: Set Environment Variable
By Surya00:371 comment
How do I set environment variables on UNIX systems?

UNIX and all UNIX-like operating systems such as OpenBSD, Linux, Redhat, CentOS, Debian allows you to set environment variables. When you log in on UNIX, your current shell (login shell) sets a unique working environment for you which is maintained until you log out. Following are most command examples of environment variables used under UNIX operating systems:

PATH - Display lists directories the shell searches, for the commands.
HOME - User's home directory to store files.
TERM - Set terminal emulator being used by UNIX.
PS1 - Display shell prompt in the Bourne shell and variants.
MAIL - Path to user's mailbox.
TEMP - Path to where processes can store temporary files.
JAVA_HOME - Sun (now Oracle) JDK path.
ORACLE_HOME - Oracle database installation path.
TZ - Timezone settings
PWD - Path to the current directory.
HISTFILE - The name of the file in which command history is saved
HISTFILESIZE -The maximum number of lines contained in the history file
HOSTNAME -The system's host name
LD_LIBRARY_PATH -It is a colon-separated set of directories where libraries should be searched for.
USER -Current logged in user's name.
DISPLAY -Network name of the X11 display to connect to, if available.
SHELL -The current shell.
TERMCAP - Database entry of the terminal escape divs to perform various terminal functions.
OSTYPE - Type of operating system.
MACHTYPE - The CPU architecture that the system is running on.
EDITOR - The user's preferred text editor.
PAGER - The user's preferred text pager.
MANPATH - Colon separated list of directories to search for manual pages.
Display Environment Variable
Open the terminal and type the following commands to display all environment variables and their values under UNIX-like operating systems:
$ set
OR
$ printenv
OR
$ env

Sample outputs:


Fig.01: Displaying all environment variables and their values command

To display search path, enter:
echo $PATH
To display prompt settings, enter:
echo $PS1
A few more examples:
echo $USER
echo $PWD
echo $MAIL
echo $JAVA_PATH
echo $DB2INSTANCE
Change or Set Environment Variable
You can use the following command to change the environment variable for the current session as per your shell.
For Korn shell (KSH)
The syntax is as follows:
var=value
export var
To set JAVA_PATH, enter:
JAVA_PATH=/opt/jdk/bin
export JAVA_PATH
For Bourne shell (sh and bash)
The syntax is as follows:
export var=value
To set PATH, enter:
export PATH=$PATH:/opt/bin:/usr/local/bin:$HOME/bin
For C shell (csh or tcsh)
The syntax is as follows:
setenv var value
Set EDITOR to vim, enter:
setenv EDITOR vim
Example: UNIX C Shell Startup Configuration Files For Environment Variable
C shell use the following files:
/etc/csh.login - It is executed if C shell is your login shell.
$HOME/.cshrc and $HOME/.login - These files are executed every time C Shell starts. The ~/.login is csh login script, read by login shell, after ~/.cshrc at login.
The above set or setenv commands can be placed in the ~/.cshrc or ~/.login files. A sample $HOME/.cshrc file is as follows:
alias h  history 25alias j  jobs -l
alias la ls -a
alias lf ls -FA
alias ll ls -lA

umask 22
set path = (/sbin /bin /usr/sbin /usr/bin /usr/games /usr/local/sbin /usr/local/bin $HOME/bin)
setenv EDITOR vi
setenv PAGER more
setenv BLOCKSIZE K

if ($?prompt) then
 # An interactive shell -- set some stuff up
 set filec
 set history = 100
 set savehist = 100
 set mail = (/var/mail/$USER)
 if ( $?tcsh ) then
  bindkey "^W" backward-delete-word
  bindkey -k up history-search-backward
  bindkey -k down history-search-forward
 endif
endif
# Traps CTRL-D
's to avoid accidental system log off
set ignoreeof

# Set prompt
set prompt = "[\!] %"

# Sequentially keeps a buffer of your last events.
set history=100
set savehist=100

# Stops C Shell from overwriting and destroying the information in an existing file.
set noclobber
A sample ~/.login file is as follows:
# Show fortune :)if ( -x /usr/games/fortune ) /usr/games/fortune

# Sets the system variable TERM to recognize the xterm
setenv TERM xterm

# This command sets the time zone variable
setenv TZ IST

# set PATH 
setenv PATH /opt/gnu/bin:/bin/posix:/bin:/usr/bin:/usr/local/bin:/etc:/users/vivek:.

# set mail boxset mail=/usr/mail/vivek

# alias bye is easier to remember alias bye logoutalias c clear
# read mail as soon as I get into the systems
mutt
Example: UNIX KSH Shell Startup Configuration Files For Environment Variable
KSH shell use the following files:
/etc/profile - This default system file is executed by the KSH and sets up default environment variables.
$HOME/.profile - Put your customization in this file.
A sample $HOME/.profile for the ksh shell:
PATH=/opt/gnu/bin:/bin/posix:/usr/bin:/usr/lib:/bin:/users/v/vivek/bin
MAIL=/usr/mail/vivek
HOME=/users/vivek
EDITOR=/opt/gnu/bin/vim
START=~/.kshrc
TERM=xterm

# export itexport ENV START EDITOR TERM PATH MAIL HOME
stty sane susp ^Z

# email notification if mail -e
then
   echo "You have mail."fi
# promptPS1="$ "
# Check system messages
msgs -q
# Allow terminal messagesmesg y
WHO=$(whoami)
WHERE=$(hostname -s)
PS1='$WHO@$WHERE:$PWD #'
export PS1
set -o vi
stty erase ^?

------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------

Difference between major and minor number
By Surya12:00No comments
Major number:
A major number refers to a type of device, and a minor number specifies a particular device of that type or sometimes the operation mode of that device type.

Example:
    # lsdev -Cc tape
    rmt0 Available 3F-08-02 IBM 3580 Ultrium Tape Drive (FCP)
    rmt1 Available 3F-08-02 IBM 3592 Tape Drive (FCP)
    smc0 Available 3F-08-02 IBM 3576 Library Medium Changer (FCP)

In the list above:

rmt1 is a standalone IBM 3592 tape drive;

rmt0 is an LTO4 drive of a library;

smc0 is the medium changer (or robotic part) of above tape library.

Now look at their major and minor numbers:
    # ls -l /dev/rmt* /dev/smc*
    crw-rw-rwT 1 root system 38, 0 Nov 13 17:40 /dev/rmt0
    crw-rw-rwT 1 root system 38,128 Nov 13 17:40 /dev/rmt1
    crw-rw-rwT 1 root system 38, 1 Nov 13 17:40 /dev/rmt0.1
    crw-rw-rwT 1 root system 38, 66 Nov 13 17:40 /dev/smc0

All use IBM tape device driver (and so have the same major number of 38), but actually they are different entities (with minor number of 0, 128 and 66 respectively). Also, compare rmt0 and rmt0.1. It's the same device, but with different mode of operation.

------------------------------------------------------------------------------------------------

AIX 6/7 Script to create a file with commands to remove missing and failed paths

To create a file with commands to remove the missing paths

#!/bin/sh
# rmpaths
>xrmpaths
echo "#!/bin/sh" >>xrmpaths
disks=$(lspv | awk '{print $1}')
for loop in $disks
do
lspath -l $loop -H -F "name:parent:connection:status" |grep Missing| awk -F: '{print "rmpath -dl",$1,"-p", $2, "-w", $3}'>>xrmpaths
done
 

To create a file with commands to remove the failed paths

#!/bin/sh
# rmpaths
>xrmpaths
echo "#!/bin/sh" >>xrmpaths
disks=$(lspv | awk '{print $1}')
for loop in $disks
do
lspath -l $loop -H -F "name:parent:connection:status" |grep Failed| awk -F: '{print "rmpath -dl",$1,"-p", $2, "-w", $3}'>>xrmpaths
done
  


------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------






	
	
















































































































































